<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>Softmax - 标签 - 剑胆琴心</title>
    <link>https://shuai06.github.io/tags/softmax/</link>
    <description>Softmax - 标签 - 剑胆琴心</description>
    <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>xuepengshuai@gmail.com (剑胆琴心)</managingEditor>
      <webMaster>xuepengshuai@gmail.com (剑胆琴心)</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Tue, 06 Sep 2022 23:04:57 &#43;0800</lastBuildDate><atom:link href="https://shuai06.github.io/tags/softmax/" rel="self" type="application/rss+xml" /><item>
  <title>实现Softmax回归</title>
  <link>https://shuai06.github.io/%E5%AE%9E%E7%8E%B0softmax%E5%9B%9E%E5%BD%92/</link>
  <pubDate>Tue, 06 Sep 2022 23:04:57 &#43;0800</pubDate>
  <author>剑胆琴心</author>
  <guid>https://shuai06.github.io/%E5%AE%9E%E7%8E%B0softmax%E5%9B%9E%E5%BD%92/</guid>
  <description><![CDATA[从零实现softmax回归 softmax的公式: $$ softmax(X){ij} = \frac{e^{X{ij}}}{\sum_k{e^{X_{ij}}}} $$ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41]]></description>
</item>
<item>
  <title>常用激活函数</title>
  <link>https://shuai06.github.io/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/</link>
  <pubDate>Fri, 01 Jul 2022 22:38:23 &#43;0800</pubDate>
  <author>剑胆琴心</author>
  <guid>https://shuai06.github.io/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/</guid>
  <description><![CDATA[什么是激活函数(what) Nerual Network中的每个神经元节点接受上一层神经元的输出值作为本神经元的输入值，并将输入值传递给下一层，输入层神经]]></description>
</item>
</channel>
</rss>
