<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>注意力机制 - 标签 - 剑胆琴心</title>
    <link>https://geoer.cn/tags/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/</link>
    <description>注意力机制 - 标签 - 剑胆琴心</description>
    <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>xuepengshuai@gmail.com (剑胆琴心)</managingEditor>
      <webMaster>xuepengshuai@gmail.com (剑胆琴心)</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Mon, 10 Oct 2022 10:33:04 &#43;0800</lastBuildDate><atom:link href="https://geoer.cn/tags/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/" rel="self" type="application/rss+xml" /><item>
  <title>Attention UNet</title>
  <link>https://geoer.cn/attention-unet/</link>
  <pubDate>Mon, 10 Oct 2022 10:33:04 &#43;0800</pubDate>
  <author>剑胆琴心</author>
  <guid>https://geoer.cn/attention-unet/</guid>
  <description><![CDATA[论文简介 论文地址：https://arxiv.org/abs/1804.03999 出自于MIDL2018(深度学习医学影像会议), 论文中提出]]></description>
</item>
<item>
  <title>Attention Is All You Need论文及代码</title>
  <link>https://geoer.cn/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/</link>
  <pubDate>Sun, 09 Oct 2022 13:35:15 &#43;0800</pubDate>
  <author>剑胆琴心</author>
  <guid>https://geoer.cn/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/</guid>
  <description><![CDATA[简介 论文地址：https://arxiv.org/abs/1706.03762 该论文提出了Transformer模型，完全基于Attenti]]></description>
</item>
</channel>
</rss>
