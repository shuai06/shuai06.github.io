# k折交叉验证(k-fold Cross-validation)是什么

<script type="text/javascript" src="/js/src/bai.js"></script>


**交叉验证：**就是重复的使用数据，把得到的样本数据进行切分，组合为不同的训练集和测试集，用训练集来训练模型，用测试集来评估模型预测的好坏（一般在数据不是很充足的时候使用）
如果数据样本量小于一万条，我们就会采用交叉验证来训练优化选择模型。如果样本大于一万条的话，我们一般随机的把数据分成三份，一份为训练集（Training Set），一份为验证集（Validation Set），最后一份为测试集（Test Set）。用训练集来训练模型，用验证集来评估模型预测的好坏和选择模型及其对应的参数。把最终得到的模型再用于测试集，最终决定使用哪个模型以及对应参数。



**k折交叉验证(k-fold Cross-validation)：**
k折交叉验证先将数据集随机划分为 k个大小相同的互斥子集，即 ，每次随机的选择 k-1份作为训练集，剩下的1份做测试集。
当这一轮完成后，重新随机选择 k份来训练数据。若干轮（小于 k ）之后，选择损失函数评估最优的模型和参数。

步骤：
```bash
将数据集分为训练集和测试集，将测试集放在一边
将训练集分为 k 份
每次使用 k 份中的 1 份作为验证集，其他全部作为训练集。
通过 k 次训练后，我们得到了 k 个不同的模型。
评估 k 个模型的效果，从中挑选效果最好的超参数
使用最优的超参数，然后将 k 份数据全部作为训练集重新训练模型，得到最终模型。
```

**最大优点：**所有数据都会参与到训练和预测中，有效避免过拟合，充分体现了交叉的思想。








---

> 作者: [剑胆琴心](http://shuai06.github.io)  
> URL: https://shuai06.github.io/k%E6%8A%98%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81-k-fold-cross-validation/  

